{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BelfastHowe/phase/blob/main/%E2%80%9Cpix2pix%E2%80%9D%E7%9A%84%E5%89%AF%E6%9C%AC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7wNjDKdQy35h"
      },
      "source": [
        "# Install"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "23TOba33L4qf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eccd21fc-fe1a-47e5-c4ac-74431789bf7f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wed May 11 07:04:53 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   37C    P0    26W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PP6TXjer6XaL",
        "outputId": "e9ea985b-035d-4733-d42c-8eb265b6e1da"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! unzip phase4.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V29_tWjz63cC",
        "outputId": "29dce7f2-f6c2-4979-f2c7-67ec475390dd"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  phase4.zip\n",
            "   creating: phase4/\n",
            "   creating: phase4/train/\n",
            "  inflating: phase4/train/0000.png   \n",
            "  inflating: phase4/train/0001.png   \n",
            "  inflating: phase4/train/0002.png   \n",
            "  inflating: phase4/train/0003.png   \n",
            "  inflating: phase4/train/0004.png   \n",
            "  inflating: phase4/train/0005.png   \n",
            "  inflating: phase4/train/0006.png   \n",
            "  inflating: phase4/train/0007.png   \n",
            "  inflating: phase4/train/0008.png   \n",
            "  inflating: phase4/train/0009.png   \n",
            "  inflating: phase4/train/0010.png   \n",
            "  inflating: phase4/train/0011.png   \n",
            "  inflating: phase4/train/0012.png   \n",
            "  inflating: phase4/train/0013.png   \n",
            "  inflating: phase4/train/0014.png   \n",
            "  inflating: phase4/train/0015.png   \n",
            "  inflating: phase4/train/0016.png   \n",
            "  inflating: phase4/train/0017.png   \n",
            "  inflating: phase4/train/0018.png   \n",
            "  inflating: phase4/train/0019.png   \n",
            "  inflating: phase4/train/0020.png   \n",
            "  inflating: phase4/train/0021.png   \n",
            "  inflating: phase4/train/0022.png   \n",
            "  inflating: phase4/train/0023.png   \n",
            "  inflating: phase4/train/0024.png   \n",
            "  inflating: phase4/train/0025.png   \n",
            "  inflating: phase4/train/0026.png   \n",
            "  inflating: phase4/train/0027.png   \n",
            "  inflating: phase4/train/0028.png   \n",
            "  inflating: phase4/train/0029.png   \n",
            "  inflating: phase4/train/0030.png   \n",
            "  inflating: phase4/train/0031.png   \n",
            "  inflating: phase4/train/0032.png   \n",
            "  inflating: phase4/train/0033.png   \n",
            "  inflating: phase4/train/0034.png   \n",
            "  inflating: phase4/train/0035.png   \n",
            "  inflating: phase4/train/0036.png   \n",
            "  inflating: phase4/train/0037.png   \n",
            "  inflating: phase4/train/0038.png   \n",
            "  inflating: phase4/train/0039.png   \n",
            "  inflating: phase4/train/0040.png   \n",
            "  inflating: phase4/train/0041.png   \n",
            "  inflating: phase4/train/0042.png   \n",
            "  inflating: phase4/train/0043.png   \n",
            "  inflating: phase4/train/0044.png   \n",
            "  inflating: phase4/train/0045.png   \n",
            "  inflating: phase4/train/0046.png   \n",
            "  inflating: phase4/train/0047.png   \n",
            "  inflating: phase4/train/0048.png   \n",
            "  inflating: phase4/train/0049.png   \n",
            "  inflating: phase4/train/0050.png   \n",
            "  inflating: phase4/train/0051.png   \n",
            "  inflating: phase4/train/0052.png   \n",
            "  inflating: phase4/train/0053.png   \n",
            "  inflating: phase4/train/0054.png   \n",
            "  inflating: phase4/train/0055.png   \n",
            "  inflating: phase4/train/0056.png   \n",
            "  inflating: phase4/train/0057.png   \n",
            "  inflating: phase4/train/0058.png   \n",
            "  inflating: phase4/train/0059.png   \n",
            "  inflating: phase4/train/0060.png   \n",
            "  inflating: phase4/train/0061.png   \n",
            "  inflating: phase4/train/0062.png   \n",
            "  inflating: phase4/train/0063.png   \n",
            "  inflating: phase4/train/0064.png   \n",
            "  inflating: phase4/train/0065.png   \n",
            "  inflating: phase4/train/0066.png   \n",
            "  inflating: phase4/train/0067.png   \n",
            "  inflating: phase4/train/0068.png   \n",
            "  inflating: phase4/train/0069.png   \n",
            "  inflating: phase4/train/0070.png   \n",
            "  inflating: phase4/train/0071.png   \n",
            "  inflating: phase4/train/0072.png   \n",
            "  inflating: phase4/train/0073.png   \n",
            "  inflating: phase4/train/0074.png   \n",
            "  inflating: phase4/train/0075.png   \n",
            "  inflating: phase4/train/0076.png   \n",
            "  inflating: phase4/train/0077.png   \n",
            "  inflating: phase4/train/0078.png   \n",
            "  inflating: phase4/train/0079.png   \n",
            "  inflating: phase4/train/0080.png   \n",
            "  inflating: phase4/train/0081.png   \n",
            "  inflating: phase4/train/0082.png   \n",
            "  inflating: phase4/train/0083.png   \n",
            "  inflating: phase4/train/0084.png   \n",
            "  inflating: phase4/train/0085.png   \n",
            "  inflating: phase4/train/0086.png   \n",
            "  inflating: phase4/train/0087.png   \n",
            "  inflating: phase4/train/0088.png   \n",
            "  inflating: phase4/train/0089.png   \n",
            "  inflating: phase4/train/0090.png   \n",
            "  inflating: phase4/train/0091.png   \n",
            "  inflating: phase4/train/0092.png   \n",
            "  inflating: phase4/train/0093.png   \n",
            "  inflating: phase4/train/0094.png   \n",
            "  inflating: phase4/train/0095.png   \n",
            "  inflating: phase4/train/0096.png   \n",
            "  inflating: phase4/train/0097.png   \n",
            "  inflating: phase4/train/0098.png   \n",
            "  inflating: phase4/train/0099.png   \n",
            "  inflating: phase4/train/0100.png   \n",
            "  inflating: phase4/train/0101.png   \n",
            "  inflating: phase4/train/0102.png   \n",
            "  inflating: phase4/train/0103.png   \n",
            "  inflating: phase4/train/0104.png   \n",
            "  inflating: phase4/train/0105.png   \n",
            "  inflating: phase4/train/0106.png   \n",
            "  inflating: phase4/train/0107.png   \n",
            "  inflating: phase4/train/0108.png   \n",
            "  inflating: phase4/train/0109.png   \n",
            "  inflating: phase4/train/0110.png   \n",
            "  inflating: phase4/train/0111.png   \n",
            "  inflating: phase4/train/0112.png   \n",
            "  inflating: phase4/train/0113.png   \n",
            "  inflating: phase4/train/0114.png   \n",
            "  inflating: phase4/train/0115.png   \n",
            "  inflating: phase4/train/0116.png   \n",
            "  inflating: phase4/train/0117.png   \n",
            "  inflating: phase4/train/0118.png   \n",
            "  inflating: phase4/train/0119.png   \n",
            "  inflating: phase4/train/0120.png   \n",
            "  inflating: phase4/train/0121.png   \n",
            "  inflating: phase4/train/0122.png   \n",
            "  inflating: phase4/train/0123.png   \n",
            "  inflating: phase4/train/0124.png   \n",
            "  inflating: phase4/train/0125.png   \n",
            "  inflating: phase4/train/0126.png   \n",
            "  inflating: phase4/train/0127.png   \n",
            "  inflating: phase4/train/0128.png   \n",
            "  inflating: phase4/train/0129.png   \n",
            "  inflating: phase4/train/0130.png   \n",
            "  inflating: phase4/train/0131.png   \n",
            "  inflating: phase4/train/0132.png   \n",
            "  inflating: phase4/train/0133.png   \n",
            "  inflating: phase4/train/0134.png   \n",
            "  inflating: phase4/train/0135.png   \n",
            "  inflating: phase4/train/0136.png   \n",
            "  inflating: phase4/train/0137.png   \n",
            "  inflating: phase4/train/0138.png   \n",
            "  inflating: phase4/train/0139.png   \n",
            "  inflating: phase4/train/0140.png   \n",
            "  inflating: phase4/train/0141.png   \n",
            "  inflating: phase4/train/0142.png   \n",
            "  inflating: phase4/train/0143.png   \n",
            "  inflating: phase4/train/0144.png   \n",
            "  inflating: phase4/train/0145.png   \n",
            "  inflating: phase4/train/0146.png   \n",
            "  inflating: phase4/train/0147.png   \n",
            "  inflating: phase4/train/0148.png   \n",
            "  inflating: phase4/train/0149.png   \n",
            "  inflating: phase4/train/0150.png   \n",
            "  inflating: phase4/train/0151.png   \n",
            "  inflating: phase4/train/0152.png   \n",
            "  inflating: phase4/train/0153.png   \n",
            "  inflating: phase4/train/0154.png   \n",
            "  inflating: phase4/train/0155.png   \n",
            "  inflating: phase4/train/0156.png   \n",
            "  inflating: phase4/train/0157.png   \n",
            "  inflating: phase4/train/0158.png   \n",
            "  inflating: phase4/train/0159.png   \n",
            "  inflating: phase4/train/0160.png   \n",
            "  inflating: phase4/train/0161.png   \n",
            "  inflating: phase4/train/0162.png   \n",
            "  inflating: phase4/train/0163.png   \n",
            "  inflating: phase4/train/0164.png   \n",
            "  inflating: phase4/train/0165.png   \n",
            "  inflating: phase4/train/0166.png   \n",
            "  inflating: phase4/train/0167.png   \n",
            "  inflating: phase4/train/0168.png   \n",
            "  inflating: phase4/train/0169.png   \n",
            "  inflating: phase4/train/0170.png   \n",
            "  inflating: phase4/train/0171.png   \n",
            "  inflating: phase4/train/0172.png   \n",
            "  inflating: phase4/train/0173.png   \n",
            "  inflating: phase4/train/0174.png   \n",
            "  inflating: phase4/train/0175.png   \n",
            "  inflating: phase4/train/0176.png   \n",
            "  inflating: phase4/train/0177.png   \n",
            "  inflating: phase4/train/0178.png   \n",
            "  inflating: phase4/train/0179.png   \n",
            "  inflating: phase4/train/0180.png   \n",
            "  inflating: phase4/train/0181.png   \n",
            "  inflating: phase4/train/0182.png   \n",
            "  inflating: phase4/train/0183.png   \n",
            "  inflating: phase4/train/0184.png   \n",
            "  inflating: phase4/train/0185.png   \n",
            "  inflating: phase4/train/0186.png   \n",
            "  inflating: phase4/train/0187.png   \n",
            "  inflating: phase4/train/0188.png   \n",
            "  inflating: phase4/train/0189.png   \n",
            "  inflating: phase4/train/0190.png   \n",
            "  inflating: phase4/train/0191.png   \n",
            "  inflating: phase4/train/0192.png   \n",
            "  inflating: phase4/train/0193.png   \n",
            "  inflating: phase4/train/0194.png   \n",
            "  inflating: phase4/train/0195.png   \n",
            "  inflating: phase4/train/0196.png   \n",
            "  inflating: phase4/train/0197.png   \n",
            "  inflating: phase4/train/0198.png   \n",
            "  inflating: phase4/train/0199.png   \n",
            "  inflating: phase4/train/0200.png   \n",
            "  inflating: phase4/train/0201.png   \n",
            "  inflating: phase4/train/0202.png   \n",
            "  inflating: phase4/train/0203.png   \n",
            "  inflating: phase4/train/0204.png   \n",
            "  inflating: phase4/train/0205.png   \n",
            "  inflating: phase4/train/0206.png   \n",
            "  inflating: phase4/train/0207.png   \n",
            "  inflating: phase4/train/0208.png   \n",
            "  inflating: phase4/train/0209.png   \n",
            "  inflating: phase4/train/0210.png   \n",
            "  inflating: phase4/train/0211.png   \n",
            "  inflating: phase4/train/0212.png   \n",
            "  inflating: phase4/train/0213.png   \n",
            "  inflating: phase4/train/0214.png   \n",
            "  inflating: phase4/train/0215.png   \n",
            "  inflating: phase4/train/0216.png   \n",
            "  inflating: phase4/train/0217.png   \n",
            "  inflating: phase4/train/0218.png   \n",
            "  inflating: phase4/train/0219.png   \n",
            "  inflating: phase4/train/0220.png   \n",
            "  inflating: phase4/train/0221.png   \n",
            "  inflating: phase4/train/0222.png   \n",
            "  inflating: phase4/train/0223.png   \n",
            "  inflating: phase4/train/0224.png   \n",
            "  inflating: phase4/train/0225.png   \n",
            "  inflating: phase4/train/0226.png   \n",
            "  inflating: phase4/train/0227.png   \n",
            "  inflating: phase4/train/0228.png   \n",
            "  inflating: phase4/train/0229.png   \n",
            "  inflating: phase4/train/0230.png   \n",
            "  inflating: phase4/train/0231.png   \n",
            "  inflating: phase4/train/0232.png   \n",
            "  inflating: phase4/train/0233.png   \n",
            "  inflating: phase4/train/0234.png   \n",
            "  inflating: phase4/train/0235.png   \n",
            "  inflating: phase4/train/0236.png   \n",
            "  inflating: phase4/train/0237.png   \n",
            "  inflating: phase4/train/0238.png   \n",
            "  inflating: phase4/train/0239.png   \n",
            "  inflating: phase4/train/0240.png   \n",
            "  inflating: phase4/train/0241.png   \n",
            "  inflating: phase4/train/0242.png   \n",
            "  inflating: phase4/train/0243.png   \n",
            "  inflating: phase4/train/0244.png   \n",
            "  inflating: phase4/train/0245.png   \n",
            "  inflating: phase4/train/0246.png   \n",
            "  inflating: phase4/train/0247.png   \n",
            "  inflating: phase4/train/0248.png   \n",
            "  inflating: phase4/train/0249.png   \n",
            "  inflating: phase4/train/0250.png   \n",
            "  inflating: phase4/train/0251.png   \n",
            "  inflating: phase4/train/0252.png   \n",
            "  inflating: phase4/train/0253.png   \n",
            "  inflating: phase4/train/0254.png   \n",
            "  inflating: phase4/train/0255.png   \n",
            "  inflating: phase4/train/0256.png   \n",
            "  inflating: phase4/train/0257.png   \n",
            "  inflating: phase4/train/0258.png   \n",
            "  inflating: phase4/train/0259.png   \n",
            "  inflating: phase4/train/0260.png   \n",
            "  inflating: phase4/train/0261.png   \n",
            "  inflating: phase4/train/0262.png   \n",
            "  inflating: phase4/train/0263.png   \n",
            "  inflating: phase4/train/0264.png   \n",
            "  inflating: phase4/train/0265.png   \n",
            "  inflating: phase4/train/0266.png   \n",
            "  inflating: phase4/train/0267.png   \n",
            "  inflating: phase4/train/0268.png   \n",
            "  inflating: phase4/train/0269.png   \n",
            "  inflating: phase4/train/0270.png   \n",
            "  inflating: phase4/train/0271.png   \n",
            "  inflating: phase4/train/0272.png   \n",
            "  inflating: phase4/train/0273.png   \n",
            "  inflating: phase4/train/0274.png   \n",
            "  inflating: phase4/train/0275.png   \n",
            "  inflating: phase4/train/0276.png   \n",
            "  inflating: phase4/train/0277.png   \n",
            "  inflating: phase4/train/0278.png   \n",
            "  inflating: phase4/train/0279.png   \n",
            "  inflating: phase4/train/0280.png   \n",
            "  inflating: phase4/train/0281.png   \n",
            "  inflating: phase4/train/0282.png   \n",
            "  inflating: phase4/train/0283.png   \n",
            "  inflating: phase4/train/0284.png   \n",
            "  inflating: phase4/train/0285.png   \n",
            "  inflating: phase4/train/0286.png   \n",
            "  inflating: phase4/train/0287.png   \n",
            "  inflating: phase4/train/0288.png   \n",
            "  inflating: phase4/train/0289.png   \n",
            "  inflating: phase4/train/0290.png   \n",
            "  inflating: phase4/train/0291.png   \n",
            "  inflating: phase4/train/0292.png   \n",
            "  inflating: phase4/train/0293.png   \n",
            "  inflating: phase4/train/0294.png   \n",
            "  inflating: phase4/train/0295.png   \n",
            "  inflating: phase4/train/0296.png   \n",
            "  inflating: phase4/train/0297.png   \n",
            "  inflating: phase4/train/0298.png   \n",
            "  inflating: phase4/train/0299.png   \n",
            "  inflating: phase4/train/0300.png   \n",
            "  inflating: phase4/train/0301.png   \n",
            "  inflating: phase4/train/0302.png   \n",
            "  inflating: phase4/train/0303.png   \n",
            "  inflating: phase4/train/0304.png   \n",
            "  inflating: phase4/train/0305.png   \n",
            "  inflating: phase4/train/0306.png   \n",
            "  inflating: phase4/train/0307.png   \n",
            "  inflating: phase4/train/0308.png   \n",
            "  inflating: phase4/train/0309.png   \n",
            "  inflating: phase4/train/0310.png   \n",
            "  inflating: phase4/train/0311.png   \n",
            "  inflating: phase4/train/0312.png   \n",
            "  inflating: phase4/train/0313.png   \n",
            "  inflating: phase4/train/0314.png   \n",
            "  inflating: phase4/train/0315.png   \n",
            "  inflating: phase4/train/0316.png   \n",
            "  inflating: phase4/train/0317.png   \n",
            "  inflating: phase4/train/0318.png   \n",
            "  inflating: phase4/train/0319.png   \n",
            "  inflating: phase4/train/0320.png   \n",
            "  inflating: phase4/train/0321.png   \n",
            "  inflating: phase4/train/0322.png   \n",
            "  inflating: phase4/train/0323.png   \n",
            "  inflating: phase4/train/0324.png   \n",
            "  inflating: phase4/train/0325.png   \n",
            "  inflating: phase4/train/0326.png   \n",
            "  inflating: phase4/train/0327.png   \n",
            "  inflating: phase4/train/0328.png   \n",
            "  inflating: phase4/train/0329.png   \n",
            "  inflating: phase4/train/0330.png   \n",
            "  inflating: phase4/train/0331.png   \n",
            "  inflating: phase4/train/0332.png   \n",
            "  inflating: phase4/train/0333.png   \n",
            "  inflating: phase4/train/0334.png   \n",
            "  inflating: phase4/train/0335.png   \n",
            "  inflating: phase4/train/0336.png   \n",
            "  inflating: phase4/train/0337.png   \n",
            "  inflating: phase4/train/0338.png   \n",
            "  inflating: phase4/train/0339.png   \n",
            "  inflating: phase4/train/0340.png   \n",
            "  inflating: phase4/train/0341.png   \n",
            "  inflating: phase4/train/0342.png   \n",
            "  inflating: phase4/train/0343.png   \n",
            "  inflating: phase4/train/0344.png   \n",
            "  inflating: phase4/train/0345.png   \n",
            "  inflating: phase4/train/0346.png   \n",
            "  inflating: phase4/train/0347.png   \n",
            "  inflating: phase4/train/0348.png   \n",
            "  inflating: phase4/train/0349.png   \n",
            "  inflating: phase4/train/0350.png   \n",
            "  inflating: phase4/train/0351.png   \n",
            "  inflating: phase4/train/0352.png   \n",
            "  inflating: phase4/train/0353.png   \n",
            "  inflating: phase4/train/0354.png   \n",
            "  inflating: phase4/train/0355.png   \n",
            "  inflating: phase4/train/0356.png   \n",
            "  inflating: phase4/train/0357.png   \n",
            "  inflating: phase4/train/0358.png   \n",
            "  inflating: phase4/train/0359.png   \n",
            "  inflating: phase4/train/0360.png   \n",
            "  inflating: phase4/train/0361.png   \n",
            "  inflating: phase4/train/0362.png   \n",
            "  inflating: phase4/train/0363.png   \n",
            "  inflating: phase4/train/0364.png   \n",
            "  inflating: phase4/train/0365.png   \n",
            "  inflating: phase4/train/0366.png   \n",
            "  inflating: phase4/train/0367.png   \n",
            "  inflating: phase4/train/0368.png   \n",
            "  inflating: phase4/train/0369.png   \n",
            "  inflating: phase4/train/0370.png   \n",
            "  inflating: phase4/train/0371.png   \n",
            "  inflating: phase4/train/0372.png   \n",
            "  inflating: phase4/train/0373.png   \n",
            "  inflating: phase4/train/0374.png   \n",
            "  inflating: phase4/train/0375.png   \n",
            "  inflating: phase4/train/0376.png   \n",
            "  inflating: phase4/train/0377.png   \n",
            "  inflating: phase4/train/0378.png   \n",
            "  inflating: phase4/train/0379.png   \n",
            "  inflating: phase4/train/0380.png   \n",
            "  inflating: phase4/train/0381.png   \n",
            "  inflating: phase4/train/0382.png   \n",
            "  inflating: phase4/train/0383.png   \n",
            "  inflating: phase4/train/0384.png   \n",
            "  inflating: phase4/train/0385.png   \n",
            "  inflating: phase4/train/0386.png   \n",
            "  inflating: phase4/train/0387.png   \n",
            "  inflating: phase4/train/0388.png   \n",
            "  inflating: phase4/train/0389.png   \n",
            "  inflating: phase4/train/0390.png   \n",
            "  inflating: phase4/train/0391.png   \n",
            "  inflating: phase4/train/0392.png   \n",
            "  inflating: phase4/train/0393.png   \n",
            "  inflating: phase4/train/0394.png   \n",
            "  inflating: phase4/train/0395.png   \n",
            "  inflating: phase4/train/0396.png   \n",
            "  inflating: phase4/train/0397.png   \n",
            "  inflating: phase4/train/0398.png   \n",
            "  inflating: phase4/train/0399.png   \n",
            "  inflating: phase4/train/0400.png   \n",
            "  inflating: phase4/train/0401.png   \n",
            "  inflating: phase4/train/0402.png   \n",
            "  inflating: phase4/train/0403.png   \n",
            "  inflating: phase4/train/0404.png   \n",
            "  inflating: phase4/train/0405.png   \n",
            "  inflating: phase4/train/0406.png   \n",
            "  inflating: phase4/train/0407.png   \n",
            "  inflating: phase4/train/0408.png   \n",
            "  inflating: phase4/train/0409.png   \n",
            "  inflating: phase4/train/0410.png   \n",
            "  inflating: phase4/train/0411.png   \n",
            "  inflating: phase4/train/0412.png   \n",
            "  inflating: phase4/train/0413.png   \n",
            "  inflating: phase4/train/0414.png   \n",
            "  inflating: phase4/train/0415.png   \n",
            "  inflating: phase4/train/0416.png   \n",
            "  inflating: phase4/train/0417.png   \n",
            "  inflating: phase4/train/0418.png   \n",
            "  inflating: phase4/train/0419.png   \n",
            "  inflating: phase4/train/0420.png   \n",
            "  inflating: phase4/train/0421.png   \n",
            "  inflating: phase4/train/0422.png   \n",
            "  inflating: phase4/train/0423.png   \n",
            "  inflating: phase4/train/0424.png   \n",
            "  inflating: phase4/train/0425.png   \n",
            "  inflating: phase4/train/0426.png   \n",
            "  inflating: phase4/train/0427.png   \n",
            "  inflating: phase4/train/0428.png   \n",
            "  inflating: phase4/train/0429.png   \n",
            "  inflating: phase4/train/0430.png   \n",
            "  inflating: phase4/train/0431.png   \n",
            "  inflating: phase4/train/0432.png   \n",
            "  inflating: phase4/train/0433.png   \n",
            "  inflating: phase4/train/0434.png   \n",
            "  inflating: phase4/train/0435.png   \n",
            "  inflating: phase4/train/0436.png   \n",
            "  inflating: phase4/train/0437.png   \n",
            "  inflating: phase4/train/0438.png   \n",
            "  inflating: phase4/train/0439.png   \n",
            "  inflating: phase4/train/0440.png   \n",
            "  inflating: phase4/train/0441.png   \n",
            "  inflating: phase4/train/0442.png   \n",
            "  inflating: phase4/train/0443.png   \n",
            "  inflating: phase4/train/0444.png   \n",
            "  inflating: phase4/train/0445.png   \n",
            "  inflating: phase4/train/0446.png   \n",
            "  inflating: phase4/train/0447.png   \n",
            "  inflating: phase4/train/0448.png   \n",
            "  inflating: phase4/train/0449.png   \n",
            "  inflating: phase4/train/0450.png   \n",
            "  inflating: phase4/train/0451.png   \n",
            "  inflating: phase4/train/0452.png   \n",
            "  inflating: phase4/train/0453.png   \n",
            "  inflating: phase4/train/0454.png   \n",
            "  inflating: phase4/train/0455.png   \n",
            "  inflating: phase4/train/0456.png   \n",
            "  inflating: phase4/train/0457.png   \n",
            "  inflating: phase4/train/0458.png   \n",
            "  inflating: phase4/train/0459.png   \n",
            "  inflating: phase4/train/0460.png   \n",
            "  inflating: phase4/train/0461.png   \n",
            "  inflating: phase4/train/0462.png   \n",
            "  inflating: phase4/train/0463.png   \n",
            "  inflating: phase4/train/0464.png   \n",
            "  inflating: phase4/train/0465.png   \n",
            "  inflating: phase4/train/0466.png   \n",
            "  inflating: phase4/train/0467.png   \n",
            "  inflating: phase4/train/0468.png   \n",
            "  inflating: phase4/train/0469.png   \n",
            "  inflating: phase4/train/0470.png   \n",
            "  inflating: phase4/train/0471.png   \n",
            "  inflating: phase4/train/0472.png   \n",
            "  inflating: phase4/train/0473.png   \n",
            "  inflating: phase4/train/0474.png   \n",
            "  inflating: phase4/train/0475.png   \n",
            "  inflating: phase4/train/0476.png   \n",
            "  inflating: phase4/train/0477.png   \n",
            "  inflating: phase4/train/0478.png   \n",
            "  inflating: phase4/train/0479.png   \n",
            "  inflating: phase4/train/0480.png   \n",
            "  inflating: phase4/train/0481.png   \n",
            "  inflating: phase4/train/0482.png   \n",
            "  inflating: phase4/train/0483.png   \n",
            "  inflating: phase4/train/0484.png   \n",
            "  inflating: phase4/train/0485.png   \n",
            "  inflating: phase4/train/0486.png   \n",
            "  inflating: phase4/train/0487.png   \n",
            "  inflating: phase4/train/0488.png   \n",
            "  inflating: phase4/train/0489.png   \n",
            "  inflating: phase4/train/0490.png   \n",
            "  inflating: phase4/train/0491.png   \n",
            "  inflating: phase4/train/0492.png   \n",
            "  inflating: phase4/train/0493.png   \n",
            "  inflating: phase4/train/0494.png   \n",
            "  inflating: phase4/train/0495.png   \n",
            "  inflating: phase4/train/0496.png   \n",
            "  inflating: phase4/train/0497.png   \n",
            "  inflating: phase4/train/0498.png   \n",
            "  inflating: phase4/train/0499.png   \n",
            "  inflating: phase4/train/0500.png   \n",
            "  inflating: phase4/train/0501.png   \n",
            "  inflating: phase4/train/0502.png   \n",
            "  inflating: phase4/train/0503.png   \n",
            "  inflating: phase4/train/0504.png   \n",
            "  inflating: phase4/train/0505.png   \n",
            "  inflating: phase4/train/0506.png   \n",
            "  inflating: phase4/train/0507.png   \n",
            "  inflating: phase4/train/0508.png   \n",
            "  inflating: phase4/train/0509.png   \n",
            "  inflating: phase4/train/0510.png   \n",
            "  inflating: phase4/train/0511.png   \n",
            "  inflating: phase4/train/0512.png   \n",
            "  inflating: phase4/train/0513.png   \n",
            "  inflating: phase4/train/0514.png   \n",
            "  inflating: phase4/train/0515.png   \n",
            "  inflating: phase4/train/0516.png   \n",
            "  inflating: phase4/train/0517.png   \n",
            "  inflating: phase4/train/0518.png   \n",
            "  inflating: phase4/train/0519.png   \n",
            "  inflating: phase4/train/0520.png   \n",
            "  inflating: phase4/train/0521.png   \n",
            "  inflating: phase4/train/0522.png   \n",
            "  inflating: phase4/train/0523.png   \n",
            "  inflating: phase4/train/0524.png   \n",
            "  inflating: phase4/train/0525.png   \n",
            "  inflating: phase4/train/0526.png   \n",
            "  inflating: phase4/train/0527.png   \n",
            "  inflating: phase4/train/0528.png   \n",
            "  inflating: phase4/train/0529.png   \n",
            "  inflating: phase4/train/0530.png   \n",
            "  inflating: phase4/train/0531.png   \n",
            "  inflating: phase4/train/0532.png   \n",
            "  inflating: phase4/train/0533.png   \n",
            "  inflating: phase4/train/0534.png   \n",
            "  inflating: phase4/train/0535.png   \n",
            "  inflating: phase4/train/0536.png   \n",
            "  inflating: phase4/train/0537.png   \n",
            "  inflating: phase4/train/0538.png   \n",
            "  inflating: phase4/train/0539.png   \n",
            "  inflating: phase4/train/0540.png   \n",
            "  inflating: phase4/train/0541.png   \n",
            "  inflating: phase4/train/0542.png   \n",
            "  inflating: phase4/train/0543.png   \n",
            "  inflating: phase4/train/0544.png   \n",
            "  inflating: phase4/train/0545.png   \n",
            "  inflating: phase4/train/0546.png   \n",
            "  inflating: phase4/train/0547.png   \n",
            "  inflating: phase4/train/0548.png   \n",
            "  inflating: phase4/train/0549.png   \n",
            "  inflating: phase4/train/0550.png   \n",
            "  inflating: phase4/train/0551.png   \n",
            "  inflating: phase4/train/0552.png   \n",
            "  inflating: phase4/train/0553.png   \n",
            "  inflating: phase4/train/0554.png   \n",
            "  inflating: phase4/train/0555.png   \n",
            "  inflating: phase4/train/0556.png   \n",
            "  inflating: phase4/train/0557.png   \n",
            "  inflating: phase4/train/0558.png   \n",
            "  inflating: phase4/train/0559.png   \n",
            "  inflating: phase4/train/0560.png   \n",
            "  inflating: phase4/train/0561.png   \n",
            "  inflating: phase4/train/0562.png   \n",
            "  inflating: phase4/train/0563.png   \n",
            "  inflating: phase4/train/0564.png   \n",
            "  inflating: phase4/train/0565.png   \n",
            "  inflating: phase4/train/0566.png   \n",
            "  inflating: phase4/train/0567.png   \n",
            "  inflating: phase4/train/0568.png   \n",
            "  inflating: phase4/train/0569.png   \n",
            "  inflating: phase4/train/0570.png   \n",
            "  inflating: phase4/train/0571.png   \n",
            "  inflating: phase4/train/0572.png   \n",
            "  inflating: phase4/train/0573.png   \n",
            "  inflating: phase4/train/0574.png   \n",
            "  inflating: phase4/train/0575.png   \n",
            "  inflating: phase4/train/0576.png   \n",
            "  inflating: phase4/train/0577.png   \n",
            "  inflating: phase4/train/0578.png   \n",
            "  inflating: phase4/train/0579.png   \n",
            "  inflating: phase4/train/0580.png   \n",
            "  inflating: phase4/train/0581.png   \n",
            "  inflating: phase4/train/0582.png   \n",
            "  inflating: phase4/train/0583.png   \n",
            "  inflating: phase4/train/0584.png   \n",
            "  inflating: phase4/train/0585.png   \n",
            "  inflating: phase4/train/0586.png   \n",
            "  inflating: phase4/train/0587.png   \n",
            "  inflating: phase4/train/0588.png   \n",
            "  inflating: phase4/train/0589.png   \n",
            "  inflating: phase4/train/0590.png   \n",
            "  inflating: phase4/train/0591.png   \n",
            "  inflating: phase4/train/0592.png   \n",
            "  inflating: phase4/train/0593.png   \n",
            "  inflating: phase4/train/0594.png   \n",
            "  inflating: phase4/train/0595.png   \n",
            "  inflating: phase4/train/0596.png   \n",
            "  inflating: phase4/train/0597.png   \n",
            "  inflating: phase4/train/0598.png   \n",
            "  inflating: phase4/train/0599.png   \n",
            "  inflating: phase4/train/0600.png   \n",
            "  inflating: phase4/train/0601.png   \n",
            "  inflating: phase4/train/0602.png   \n",
            "  inflating: phase4/train/0603.png   \n",
            "  inflating: phase4/train/0604.png   \n",
            "  inflating: phase4/train/0605.png   \n",
            "  inflating: phase4/train/0606.png   \n",
            "  inflating: phase4/train/0607.png   \n",
            "  inflating: phase4/train/0608.png   \n",
            "  inflating: phase4/train/0609.png   \n",
            "  inflating: phase4/train/0610.png   \n",
            "  inflating: phase4/train/0611.png   \n",
            "  inflating: phase4/train/0612.png   \n",
            "  inflating: phase4/train/0613.png   \n",
            "  inflating: phase4/train/0614.png   \n",
            "  inflating: phase4/train/0615.png   \n",
            "  inflating: phase4/train/0616.png   \n",
            "  inflating: phase4/train/0617.png   \n",
            "  inflating: phase4/train/0618.png   \n",
            "  inflating: phase4/train/0619.png   \n",
            "  inflating: phase4/train/0620.png   \n",
            "  inflating: phase4/train/0621.png   \n",
            "  inflating: phase4/train/0622.png   \n",
            "  inflating: phase4/train/0623.png   \n",
            "  inflating: phase4/train/0624.png   \n",
            "  inflating: phase4/train/0625.png   \n",
            "  inflating: phase4/train/0626.png   \n",
            "  inflating: phase4/train/0627.png   \n",
            "  inflating: phase4/train/0628.png   \n",
            "  inflating: phase4/train/0629.png   \n",
            "  inflating: phase4/train/0630.png   \n",
            "  inflating: phase4/train/0631.png   \n",
            "  inflating: phase4/train/0632.png   \n",
            "  inflating: phase4/train/0633.png   \n",
            "  inflating: phase4/train/0634.png   \n",
            "  inflating: phase4/train/0635.png   \n",
            "  inflating: phase4/train/0636.png   \n",
            "  inflating: phase4/train/0637.png   \n",
            "  inflating: phase4/train/0638.png   \n",
            "  inflating: phase4/train/0639.png   \n",
            "  inflating: phase4/train/0640.png   \n",
            "  inflating: phase4/train/0641.png   \n",
            "  inflating: phase4/train/0642.png   \n",
            "  inflating: phase4/train/0643.png   \n",
            "  inflating: phase4/train/0644.png   \n",
            "  inflating: phase4/train/0645.png   \n",
            "  inflating: phase4/train/0646.png   \n",
            "  inflating: phase4/train/0647.png   \n",
            "  inflating: phase4/train/0648.png   \n",
            "  inflating: phase4/train/0649.png   \n",
            "  inflating: phase4/train/0650.png   \n",
            "  inflating: phase4/train/0651.png   \n",
            "  inflating: phase4/train/0652.png   \n",
            "  inflating: phase4/train/0653.png   \n",
            "  inflating: phase4/train/0654.png   \n",
            "  inflating: phase4/train/0655.png   \n",
            "  inflating: phase4/train/0656.png   \n",
            "  inflating: phase4/train/0657.png   \n",
            "  inflating: phase4/train/0658.png   \n",
            "  inflating: phase4/train/0659.png   \n",
            "  inflating: phase4/train/0660.png   \n",
            "  inflating: phase4/train/0661.png   \n",
            "  inflating: phase4/train/0662.png   \n",
            "  inflating: phase4/train/0663.png   \n",
            "  inflating: phase4/train/0664.png   \n",
            "  inflating: phase4/train/0665.png   \n",
            "  inflating: phase4/train/0666.png   \n",
            "  inflating: phase4/train/0667.png   \n",
            "  inflating: phase4/train/0668.png   \n",
            "  inflating: phase4/train/0669.png   \n",
            "  inflating: phase4/train/0670.png   \n",
            "  inflating: phase4/train/0671.png   \n",
            "  inflating: phase4/train/0672.png   \n",
            "  inflating: phase4/train/0673.png   \n",
            "  inflating: phase4/train/0674.png   \n",
            "  inflating: phase4/train/0675.png   \n",
            "  inflating: phase4/train/0676.png   \n",
            "  inflating: phase4/train/0677.png   \n",
            "  inflating: phase4/train/0678.png   \n",
            "  inflating: phase4/train/0679.png   \n",
            "  inflating: phase4/train/0680.png   \n",
            "  inflating: phase4/train/0681.png   \n",
            "  inflating: phase4/train/0682.png   \n",
            "  inflating: phase4/train/0683.png   \n",
            "  inflating: phase4/train/0684.png   \n",
            "  inflating: phase4/train/0685.png   \n",
            "  inflating: phase4/train/0686.png   \n",
            "  inflating: phase4/train/0687.png   \n",
            "  inflating: phase4/train/0688.png   \n",
            "  inflating: phase4/train/0689.png   \n",
            "  inflating: phase4/train/0690.png   \n",
            "  inflating: phase4/train/0691.png   \n",
            "  inflating: phase4/train/0692.png   \n",
            "  inflating: phase4/train/0693.png   \n",
            "  inflating: phase4/train/0694.png   \n",
            "  inflating: phase4/train/0695.png   \n",
            "  inflating: phase4/train/0696.png   \n",
            "  inflating: phase4/train/0697.png   \n",
            "  inflating: phase4/train/0698.png   \n",
            "  inflating: phase4/train/0699.png   \n",
            "  inflating: phase4/train/0700.png   \n",
            "  inflating: phase4/train/0701.png   \n",
            "  inflating: phase4/train/0702.png   \n",
            "  inflating: phase4/train/0703.png   \n",
            "  inflating: phase4/train/0704.png   \n",
            "  inflating: phase4/train/0705.png   \n",
            "  inflating: phase4/train/0706.png   \n",
            "  inflating: phase4/train/0707.png   \n",
            "  inflating: phase4/train/0708.png   \n",
            "  inflating: phase4/train/0709.png   \n",
            "  inflating: phase4/train/0710.png   \n",
            "  inflating: phase4/train/0711.png   \n",
            "  inflating: phase4/train/0712.png   \n",
            "  inflating: phase4/train/0713.png   \n",
            "  inflating: phase4/train/0714.png   \n",
            "  inflating: phase4/train/0715.png   \n",
            "  inflating: phase4/train/0716.png   \n",
            "  inflating: phase4/train/0717.png   \n",
            "  inflating: phase4/train/0718.png   \n",
            "  inflating: phase4/train/0719.png   \n",
            "  inflating: phase4/train/0720.png   \n",
            "  inflating: phase4/train/0721.png   \n",
            "  inflating: phase4/train/0722.png   \n",
            "  inflating: phase4/train/0723.png   \n",
            "  inflating: phase4/train/0724.png   \n",
            "  inflating: phase4/train/0725.png   \n",
            "  inflating: phase4/train/0726.png   \n",
            "  inflating: phase4/train/0727.png   \n",
            "  inflating: phase4/train/0728.png   \n",
            "  inflating: phase4/train/0729.png   \n",
            "  inflating: phase4/train/0730.png   \n",
            "  inflating: phase4/train/0731.png   \n",
            "  inflating: phase4/train/0732.png   \n",
            "  inflating: phase4/train/0733.png   \n",
            "  inflating: phase4/train/0734.png   \n",
            "  inflating: phase4/train/0735.png   \n",
            "  inflating: phase4/train/0736.png   \n",
            "  inflating: phase4/train/0737.png   \n",
            "  inflating: phase4/train/0738.png   \n",
            "  inflating: phase4/train/0739.png   \n",
            "  inflating: phase4/train/0740.png   \n",
            "  inflating: phase4/train/0741.png   \n",
            "  inflating: phase4/train/0742.png   \n",
            "  inflating: phase4/train/0743.png   \n",
            "  inflating: phase4/train/0744.png   \n",
            "  inflating: phase4/train/0745.png   \n",
            "  inflating: phase4/train/0746.png   \n",
            "  inflating: phase4/train/0747.png   \n",
            "  inflating: phase4/train/0748.png   \n",
            "  inflating: phase4/train/0749.png   \n",
            "  inflating: phase4/train/0750.png   \n",
            "  inflating: phase4/train/0751.png   \n",
            "  inflating: phase4/train/0752.png   \n",
            "  inflating: phase4/train/0753.png   \n",
            "  inflating: phase4/train/0754.png   \n",
            "  inflating: phase4/train/0755.png   \n",
            "  inflating: phase4/train/0756.png   \n",
            "  inflating: phase4/train/0757.png   \n",
            "  inflating: phase4/train/0758.png   \n",
            "  inflating: phase4/train/0759.png   \n",
            "  inflating: phase4/train/0760.png   \n",
            "  inflating: phase4/train/0761.png   \n",
            "  inflating: phase4/train/0762.png   \n",
            "  inflating: phase4/train/0763.png   \n",
            "  inflating: phase4/train/0764.png   \n",
            "  inflating: phase4/train/0765.png   \n",
            "  inflating: phase4/train/0766.png   \n",
            "  inflating: phase4/train/0767.png   \n",
            "  inflating: phase4/train/0768.png   \n",
            "  inflating: phase4/train/0769.png   \n",
            "  inflating: phase4/train/0770.png   \n",
            "  inflating: phase4/train/0771.png   \n",
            "  inflating: phase4/train/0772.png   \n",
            "  inflating: phase4/train/0773.png   \n",
            "  inflating: phase4/train/0774.png   \n",
            "  inflating: phase4/train/0775.png   \n",
            "  inflating: phase4/train/0776.png   \n",
            "  inflating: phase4/train/0777.png   \n",
            "  inflating: phase4/train/0778.png   \n",
            "  inflating: phase4/train/0779.png   \n",
            "  inflating: phase4/train/0780.png   \n",
            "  inflating: phase4/train/0781.png   \n",
            "  inflating: phase4/train/0782.png   \n",
            "  inflating: phase4/train/0783.png   \n",
            "  inflating: phase4/train/0784.png   \n",
            "  inflating: phase4/train/0785.png   \n",
            "  inflating: phase4/train/0786.png   \n",
            "  inflating: phase4/train/0787.png   \n",
            "  inflating: phase4/train/0788.png   \n",
            "  inflating: phase4/train/0789.png   \n",
            "  inflating: phase4/train/0790.png   \n",
            "  inflating: phase4/train/0791.png   \n",
            "  inflating: phase4/train/0792.png   \n",
            "  inflating: phase4/train/0793.png   \n",
            "  inflating: phase4/train/0794.png   \n",
            "  inflating: phase4/train/0795.png   \n",
            "  inflating: phase4/train/0796.png   \n",
            "  inflating: phase4/train/0797.png   \n",
            "  inflating: phase4/train/0798.png   \n",
            "  inflating: phase4/train/0799.png   \n",
            "  inflating: phase4/train/0800.png   \n",
            "  inflating: phase4/train/0801.png   \n",
            "  inflating: phase4/train/0802.png   \n",
            "  inflating: phase4/train/0803.png   \n",
            "  inflating: phase4/train/0804.png   \n",
            "  inflating: phase4/train/0805.png   \n",
            "  inflating: phase4/train/0806.png   \n",
            "  inflating: phase4/train/0807.png   \n",
            "  inflating: phase4/train/0808.png   \n",
            "  inflating: phase4/train/0809.png   \n",
            "  inflating: phase4/train/0810.png   \n",
            "  inflating: phase4/train/0811.png   \n",
            "  inflating: phase4/train/0812.png   \n",
            "  inflating: phase4/train/0813.png   \n",
            "  inflating: phase4/train/0814.png   \n",
            "  inflating: phase4/train/0815.png   \n",
            "  inflating: phase4/train/0816.png   \n",
            "  inflating: phase4/train/0817.png   \n",
            "  inflating: phase4/train/0818.png   \n",
            "  inflating: phase4/train/0819.png   \n",
            "  inflating: phase4/train/0820.png   \n",
            "  inflating: phase4/train/0821.png   \n",
            "  inflating: phase4/train/0822.png   \n",
            "  inflating: phase4/train/0823.png   \n",
            "  inflating: phase4/train/0824.png   \n",
            "  inflating: phase4/train/0825.png   \n",
            "  inflating: phase4/train/0826.png   \n",
            "  inflating: phase4/train/0827.png   \n",
            "  inflating: phase4/train/0828.png   \n",
            "  inflating: phase4/train/0829.png   \n",
            "  inflating: phase4/train/0830.png   \n",
            "  inflating: phase4/train/0831.png   \n",
            "  inflating: phase4/train/0832.png   \n",
            "  inflating: phase4/train/0833.png   \n",
            "  inflating: phase4/train/0834.png   \n",
            "  inflating: phase4/train/0835.png   \n",
            "  inflating: phase4/train/0836.png   \n",
            "  inflating: phase4/train/0837.png   \n",
            "  inflating: phase4/train/0838.png   \n",
            "  inflating: phase4/train/0839.png   \n",
            "  inflating: phase4/train/0840.png   \n",
            "  inflating: phase4/train/0841.png   \n",
            "  inflating: phase4/train/0842.png   \n",
            "  inflating: phase4/train/0843.png   \n",
            "  inflating: phase4/train/0844.png   \n",
            "  inflating: phase4/train/0845.png   \n",
            "  inflating: phase4/train/0846.png   \n",
            "  inflating: phase4/train/0847.png   \n",
            "  inflating: phase4/train/0848.png   \n",
            "  inflating: phase4/train/0849.png   \n",
            "  inflating: phase4/train/0850.png   \n",
            "  inflating: phase4/train/0851.png   \n",
            "  inflating: phase4/train/0852.png   \n",
            "  inflating: phase4/train/0853.png   \n",
            "  inflating: phase4/train/0854.png   \n",
            "  inflating: phase4/train/0855.png   \n",
            "  inflating: phase4/train/0856.png   \n",
            "  inflating: phase4/train/0857.png   \n",
            "  inflating: phase4/train/0858.png   \n",
            "  inflating: phase4/train/0859.png   \n",
            "  inflating: phase4/train/0860.png   \n",
            "  inflating: phase4/train/0861.png   \n",
            "  inflating: phase4/train/0862.png   \n",
            "  inflating: phase4/train/0863.png   \n",
            "  inflating: phase4/train/0864.png   \n",
            "  inflating: phase4/train/0865.png   \n",
            "  inflating: phase4/train/0866.png   \n",
            "  inflating: phase4/train/0867.png   \n",
            "  inflating: phase4/train/0868.png   \n",
            "  inflating: phase4/train/0869.png   \n",
            "  inflating: phase4/train/0870.png   \n",
            "  inflating: phase4/train/0871.png   \n",
            "  inflating: phase4/train/0872.png   \n",
            "  inflating: phase4/train/0873.png   \n",
            "  inflating: phase4/train/0874.png   \n",
            "  inflating: phase4/train/0875.png   \n",
            "  inflating: phase4/train/0876.png   \n",
            "  inflating: phase4/train/0877.png   \n",
            "  inflating: phase4/train/0878.png   \n",
            "  inflating: phase4/train/0879.png   \n",
            "  inflating: phase4/train/0880.png   \n",
            "  inflating: phase4/train/0881.png   \n",
            "  inflating: phase4/train/0882.png   \n",
            "  inflating: phase4/train/0883.png   \n",
            "  inflating: phase4/train/0884.png   \n",
            "  inflating: phase4/train/0885.png   \n",
            "  inflating: phase4/train/0886.png   \n",
            "  inflating: phase4/train/0887.png   \n",
            "  inflating: phase4/train/0888.png   \n",
            "  inflating: phase4/train/0889.png   \n",
            "  inflating: phase4/train/0890.png   \n",
            "  inflating: phase4/train/0891.png   \n",
            "  inflating: phase4/train/0892.png   \n",
            "  inflating: phase4/train/0893.png   \n",
            "  inflating: phase4/train/0894.png   \n",
            "  inflating: phase4/train/0895.png   \n",
            "  inflating: phase4/train/0896.png   \n",
            "  inflating: phase4/train/0897.png   \n",
            "  inflating: phase4/train/0898.png   \n",
            "  inflating: phase4/train/0899.png   \n",
            "  inflating: phase4/train/0900.png   \n",
            "  inflating: phase4/train/0901.png   \n",
            "  inflating: phase4/train/0902.png   \n",
            "  inflating: phase4/train/0903.png   \n",
            "  inflating: phase4/train/0904.png   \n",
            "  inflating: phase4/train/0905.png   \n",
            "  inflating: phase4/train/0906.png   \n",
            "  inflating: phase4/train/0907.png   \n",
            "  inflating: phase4/train/0908.png   \n",
            "  inflating: phase4/train/0909.png   \n",
            "  inflating: phase4/train/0910.png   \n",
            "  inflating: phase4/train/0911.png   \n",
            "  inflating: phase4/train/0912.png   \n",
            "  inflating: phase4/train/0913.png   \n",
            "  inflating: phase4/train/0914.png   \n",
            "  inflating: phase4/train/0915.png   \n",
            "  inflating: phase4/train/0916.png   \n",
            "  inflating: phase4/train/0917.png   \n",
            "  inflating: phase4/train/0918.png   \n",
            "  inflating: phase4/train/0919.png   \n",
            "  inflating: phase4/train/0920.png   \n",
            "  inflating: phase4/train/0921.png   \n",
            "  inflating: phase4/train/0922.png   \n",
            "  inflating: phase4/train/0923.png   \n",
            "  inflating: phase4/train/0924.png   \n",
            "  inflating: phase4/train/0925.png   \n",
            "  inflating: phase4/train/0926.png   \n",
            "  inflating: phase4/train/0927.png   \n",
            "  inflating: phase4/train/0928.png   \n",
            "  inflating: phase4/train/0929.png   \n",
            "  inflating: phase4/train/0930.png   \n",
            "  inflating: phase4/train/0931.png   \n",
            "  inflating: phase4/train/0932.png   \n",
            "  inflating: phase4/train/0933.png   \n",
            "  inflating: phase4/train/0934.png   \n",
            "  inflating: phase4/train/0935.png   \n",
            "  inflating: phase4/train/0936.png   \n",
            "  inflating: phase4/train/0937.png   \n",
            "  inflating: phase4/train/0938.png   \n",
            "  inflating: phase4/train/0939.png   \n",
            "  inflating: phase4/train/0940.png   \n",
            "  inflating: phase4/train/0941.png   \n",
            "  inflating: phase4/train/0942.png   \n",
            "  inflating: phase4/train/0943.png   \n",
            "  inflating: phase4/train/0944.png   \n",
            "  inflating: phase4/train/0945.png   \n",
            "  inflating: phase4/train/0946.png   \n",
            "  inflating: phase4/train/0947.png   \n",
            "  inflating: phase4/train/0948.png   \n",
            "  inflating: phase4/train/0949.png   \n",
            "  inflating: phase4/train/0950.png   \n",
            "  inflating: phase4/train/0951.png   \n",
            "  inflating: phase4/train/0952.png   \n",
            "  inflating: phase4/train/0953.png   \n",
            "  inflating: phase4/train/0954.png   \n",
            "  inflating: phase4/train/0955.png   \n",
            "  inflating: phase4/train/0956.png   \n",
            "  inflating: phase4/train/0957.png   \n",
            "  inflating: phase4/train/0958.png   \n",
            "  inflating: phase4/train/0959.png   \n",
            "  inflating: phase4/train/0960.png   \n",
            "  inflating: phase4/train/0961.png   \n",
            "  inflating: phase4/train/0962.png   \n",
            "  inflating: phase4/train/0963.png   \n",
            "  inflating: phase4/train/0964.png   \n",
            "  inflating: phase4/train/0965.png   \n",
            "  inflating: phase4/train/0966.png   \n",
            "  inflating: phase4/train/0967.png   \n",
            "  inflating: phase4/train/0968.png   \n",
            "  inflating: phase4/train/0969.png   \n",
            "  inflating: phase4/train/0970.png   \n",
            "  inflating: phase4/train/0971.png   \n",
            "  inflating: phase4/train/0972.png   \n",
            "  inflating: phase4/train/0973.png   \n",
            "  inflating: phase4/train/0974.png   \n",
            "  inflating: phase4/train/0975.png   \n",
            "  inflating: phase4/train/0976.png   \n",
            "  inflating: phase4/train/0977.png   \n",
            "  inflating: phase4/train/0978.png   \n",
            "  inflating: phase4/train/0979.png   \n",
            "  inflating: phase4/train/0980.png   \n",
            "  inflating: phase4/train/0981.png   \n",
            "  inflating: phase4/train/0982.png   \n",
            "  inflating: phase4/train/0983.png   \n",
            "  inflating: phase4/train/0984.png   \n",
            "  inflating: phase4/train/0985.png   \n",
            "  inflating: phase4/train/0986.png   \n",
            "  inflating: phase4/train/0987.png   \n",
            "  inflating: phase4/train/0988.png   \n",
            "  inflating: phase4/train/0989.png   \n",
            "  inflating: phase4/train/0990.png   \n",
            "  inflating: phase4/train/0991.png   \n",
            "  inflating: phase4/train/0992.png   \n",
            "  inflating: phase4/train/0993.png   \n",
            "  inflating: phase4/train/0994.png   \n",
            "  inflating: phase4/train/0995.png   \n",
            "  inflating: phase4/train/0996.png   \n",
            "  inflating: phase4/train/0997.png   \n",
            "  inflating: phase4/train/0998.png   \n",
            "  inflating: phase4/train/0999.png   \n",
            "  inflating: phase4/train/1000.png   \n",
            "  inflating: phase4/train/1001.png   \n",
            "  inflating: phase4/train/1002.png   \n",
            "  inflating: phase4/train/1003.png   \n",
            "  inflating: phase4/train/1004.png   \n",
            "  inflating: phase4/train/1005.png   \n",
            "  inflating: phase4/train/1006.png   \n",
            "  inflating: phase4/train/1007.png   \n",
            "  inflating: phase4/train/1008.png   \n",
            "  inflating: phase4/train/1009.png   \n",
            "  inflating: phase4/train/1010.png   \n",
            "  inflating: phase4/train/1011.png   \n",
            "  inflating: phase4/train/1012.png   \n",
            "  inflating: phase4/train/1013.png   \n",
            "  inflating: phase4/train/1014.png   \n",
            "  inflating: phase4/train/1015.png   \n",
            "  inflating: phase4/train/1016.png   \n",
            "  inflating: phase4/train/1017.png   \n",
            "  inflating: phase4/train/1018.png   \n",
            "  inflating: phase4/train/1019.png   \n",
            "  inflating: phase4/train/1020.png   \n",
            "  inflating: phase4/train/1021.png   \n",
            "  inflating: phase4/train/1022.png   \n",
            "  inflating: phase4/train/1023.png   \n",
            "  inflating: phase4/train/1024.png   \n",
            "  inflating: phase4/train/1025.png   \n",
            "  inflating: phase4/train/1026.png   \n",
            "  inflating: phase4/train/1027.png   \n",
            "  inflating: phase4/train/1028.png   \n",
            "  inflating: phase4/train/1029.png   \n",
            "  inflating: phase4/train/1030.png   \n",
            "  inflating: phase4/train/1031.png   \n",
            "  inflating: phase4/train/1032.png   \n",
            "  inflating: phase4/train/1033.png   \n",
            "  inflating: phase4/train/1034.png   \n",
            "  inflating: phase4/train/1035.png   \n",
            "  inflating: phase4/train/1036.png   \n",
            "  inflating: phase4/train/1037.png   \n",
            "  inflating: phase4/train/1038.png   \n",
            "  inflating: phase4/train/1039.png   \n",
            "  inflating: phase4/train/1040.png   \n",
            "  inflating: phase4/train/1041.png   \n",
            "  inflating: phase4/train/1042.png   \n",
            "  inflating: phase4/train/1043.png   \n",
            "  inflating: phase4/train/1044.png   \n",
            "  inflating: phase4/train/1045.png   \n",
            "  inflating: phase4/train/1046.png   \n",
            "  inflating: phase4/train/1047.png   \n",
            "  inflating: phase4/train/1048.png   \n",
            "  inflating: phase4/train/1049.png   \n",
            "  inflating: phase4/train/1050.png   \n",
            "  inflating: phase4/train/1051.png   \n",
            "  inflating: phase4/train/1052.png   \n",
            "  inflating: phase4/train/1053.png   \n",
            "  inflating: phase4/train/1054.png   \n",
            "  inflating: phase4/train/1055.png   \n",
            "  inflating: phase4/train/1056.png   \n",
            "  inflating: phase4/train/1057.png   \n",
            "  inflating: phase4/train/1058.png   \n",
            "  inflating: phase4/train/1059.png   \n",
            "  inflating: phase4/train/1060.png   \n",
            "  inflating: phase4/train/1061.png   \n",
            "  inflating: phase4/train/1062.png   \n",
            "  inflating: phase4/train/1063.png   \n",
            "  inflating: phase4/train/1064.png   \n",
            "  inflating: phase4/train/1065.png   \n",
            "  inflating: phase4/train/1066.png   \n",
            "  inflating: phase4/train/1067.png   \n",
            "  inflating: phase4/train/1068.png   \n",
            "  inflating: phase4/train/1069.png   \n",
            "  inflating: phase4/train/1070.png   \n",
            "  inflating: phase4/train/1071.png   \n",
            "  inflating: phase4/train/1072.png   \n",
            "  inflating: phase4/train/1073.png   \n",
            "  inflating: phase4/train/1074.png   \n",
            "  inflating: phase4/train/1075.png   \n",
            "  inflating: phase4/train/1076.png   \n",
            "  inflating: phase4/train/1077.png   \n",
            "  inflating: phase4/train/1078.png   \n",
            "  inflating: phase4/train/1079.png   \n",
            "  inflating: phase4/train/1080.png   \n",
            "  inflating: phase4/train/1081.png   \n",
            "  inflating: phase4/train/1082.png   \n",
            "  inflating: phase4/train/1083.png   \n",
            "  inflating: phase4/train/1084.png   \n",
            "  inflating: phase4/train/1085.png   \n",
            "  inflating: phase4/train/1086.png   \n",
            "  inflating: phase4/train/1087.png   \n",
            "  inflating: phase4/train/1088.png   \n",
            "  inflating: phase4/train/1089.png   \n",
            "  inflating: phase4/train/1090.png   \n",
            "  inflating: phase4/train/1091.png   \n",
            "  inflating: phase4/train/1092.png   \n",
            "  inflating: phase4/train/1093.png   \n",
            "  inflating: phase4/train/1094.png   \n",
            "  inflating: phase4/train/1095.png   \n",
            "  inflating: phase4/train/1096.png   \n",
            "  inflating: phase4/train/1097.png   \n",
            "  inflating: phase4/train/1098.png   \n",
            "  inflating: phase4/train/1099.png   \n",
            "  inflating: phase4/train/1100.png   \n",
            "  inflating: phase4/train/1101.png   \n",
            "  inflating: phase4/train/1102.png   \n",
            "  inflating: phase4/train/1103.png   \n",
            "  inflating: phase4/train/1104.png   \n",
            "  inflating: phase4/train/1105.png   \n",
            "  inflating: phase4/train/1106.png   \n",
            "  inflating: phase4/train/1107.png   \n",
            "  inflating: phase4/train/1108.png   \n",
            "  inflating: phase4/train/1109.png   \n",
            "  inflating: phase4/train/1110.png   \n",
            "  inflating: phase4/train/1111.png   \n",
            "  inflating: phase4/train/1112.png   \n",
            "  inflating: phase4/train/1113.png   \n",
            "  inflating: phase4/train/1114.png   \n",
            "  inflating: phase4/train/1115.png   \n",
            "  inflating: phase4/train/1116.png   \n",
            "  inflating: phase4/train/1117.png   \n",
            "  inflating: phase4/train/1118.png   \n",
            "  inflating: phase4/train/1119.png   \n",
            "  inflating: phase4/train/1120.png   \n",
            "  inflating: phase4/train/1121.png   \n",
            "  inflating: phase4/train/1122.png   \n",
            "  inflating: phase4/train/1123.png   \n",
            "  inflating: phase4/train/1124.png   \n",
            "  inflating: phase4/train/1125.png   \n",
            "  inflating: phase4/train/1126.png   \n",
            "  inflating: phase4/train/1127.png   \n",
            "  inflating: phase4/train/1128.png   \n",
            "  inflating: phase4/train/1129.png   \n",
            "  inflating: phase4/train/1130.png   \n",
            "  inflating: phase4/train/1131.png   \n",
            "  inflating: phase4/train/1132.png   \n",
            "  inflating: phase4/train/1133.png   \n",
            "  inflating: phase4/train/1134.png   \n",
            "  inflating: phase4/train/1135.png   \n",
            "  inflating: phase4/train/1136.png   \n",
            "  inflating: phase4/train/1137.png   \n",
            "  inflating: phase4/train/1138.png   \n",
            "  inflating: phase4/train/1139.png   \n",
            "  inflating: phase4/train/1140.png   \n",
            "  inflating: phase4/train/1141.png   \n",
            "  inflating: phase4/train/1142.png   \n",
            "  inflating: phase4/train/1143.png   \n",
            "  inflating: phase4/train/1144.png   \n",
            "  inflating: phase4/train/1145.png   \n",
            "  inflating: phase4/train/1146.png   \n",
            "  inflating: phase4/train/1147.png   \n",
            "  inflating: phase4/train/1148.png   \n",
            "  inflating: phase4/train/1149.png   \n",
            "  inflating: phase4/train/1150.png   \n",
            "  inflating: phase4/train/1151.png   \n",
            "  inflating: phase4/train/1152.png   \n",
            "  inflating: phase4/train/1153.png   \n",
            "  inflating: phase4/train/1154.png   \n",
            "  inflating: phase4/train/1155.png   \n",
            "  inflating: phase4/train/1156.png   \n",
            "  inflating: phase4/train/1157.png   \n",
            "  inflating: phase4/train/1158.png   \n",
            "  inflating: phase4/train/1159.png   \n",
            "  inflating: phase4/train/1160.png   \n",
            "  inflating: phase4/train/1161.png   \n",
            "  inflating: phase4/train/1162.png   \n",
            "  inflating: phase4/train/1163.png   \n",
            "  inflating: phase4/train/1164.png   \n",
            "  inflating: phase4/train/1165.png   \n",
            "  inflating: phase4/train/1166.png   \n",
            "  inflating: phase4/train/1167.png   \n",
            "  inflating: phase4/train/1168.png   \n",
            "  inflating: phase4/train/1169.png   \n",
            "  inflating: phase4/train/1170.png   \n",
            "  inflating: phase4/train/1171.png   \n",
            "  inflating: phase4/train/1172.png   \n",
            "  inflating: phase4/train/1173.png   \n",
            "  inflating: phase4/train/1174.png   \n",
            "  inflating: phase4/train/1175.png   \n",
            "  inflating: phase4/train/1176.png   \n",
            "  inflating: phase4/train/1177.png   \n",
            "  inflating: phase4/train/1178.png   \n",
            "  inflating: phase4/train/1179.png   \n",
            "  inflating: phase4/train/1180.png   \n",
            "  inflating: phase4/train/1181.png   \n",
            "  inflating: phase4/train/1182.png   \n",
            "  inflating: phase4/train/1183.png   \n",
            "  inflating: phase4/train/1184.png   \n",
            "  inflating: phase4/train/1185.png   \n",
            "  inflating: phase4/train/1186.png   \n",
            "  inflating: phase4/train/1187.png   \n",
            "  inflating: phase4/train/1188.png   \n",
            "  inflating: phase4/train/1189.png   \n",
            "  inflating: phase4/train/1190.png   \n",
            "  inflating: phase4/train/1191.png   \n",
            "  inflating: phase4/train/1192.png   \n",
            "  inflating: phase4/train/1193.png   \n",
            "  inflating: phase4/train/1194.png   \n",
            "  inflating: phase4/train/1195.png   \n",
            "  inflating: phase4/train/1196.png   \n",
            "  inflating: phase4/train/1197.png   \n",
            "  inflating: phase4/train/1198.png   \n",
            "  inflating: phase4/train/1199.png   \n",
            "  inflating: phase4/train/1200.png   \n",
            "  inflating: phase4/train/1201.png   \n",
            "  inflating: phase4/train/1202.png   \n",
            "  inflating: phase4/train/1203.png   \n",
            "  inflating: phase4/train/1204.png   \n",
            "  inflating: phase4/train/1205.png   \n",
            "  inflating: phase4/train/1206.png   \n",
            "  inflating: phase4/train/1207.png   \n",
            "  inflating: phase4/train/1208.png   \n",
            "  inflating: phase4/train/1209.png   \n",
            "  inflating: phase4/train/1210.png   \n",
            "  inflating: phase4/train/1211.png   \n",
            "  inflating: phase4/train/1212.png   \n",
            "  inflating: phase4/train/1213.png   \n",
            "  inflating: phase4/train/1214.png   \n",
            "  inflating: phase4/train/1215.png   \n",
            "  inflating: phase4/train/1216.png   \n",
            "  inflating: phase4/train/1217.png   \n",
            "  inflating: phase4/train/1218.png   \n",
            "  inflating: phase4/train/1219.png   \n",
            "  inflating: phase4/train/1220.png   \n",
            "  inflating: phase4/train/1221.png   \n",
            "  inflating: phase4/train/1222.png   \n",
            "  inflating: phase4/train/1223.png   \n",
            "  inflating: phase4/train/1224.png   \n",
            "  inflating: phase4/train/1225.png   \n",
            "  inflating: phase4/train/1226.png   \n",
            "  inflating: phase4/train/1227.png   \n",
            "  inflating: phase4/train/1228.png   \n",
            "  inflating: phase4/train/1229.png   \n",
            "  inflating: phase4/train/1230.png   \n",
            "  inflating: phase4/train/1231.png   \n",
            "  inflating: phase4/train/1232.png   \n",
            "  inflating: phase4/train/1233.png   \n",
            "  inflating: phase4/train/1234.png   \n",
            "  inflating: phase4/train/1235.png   \n",
            "  inflating: phase4/train/1236.png   \n",
            "  inflating: phase4/train/1237.png   \n",
            "  inflating: phase4/train/1238.png   \n",
            "  inflating: phase4/train/1239.png   \n",
            "  inflating: phase4/train/1240.png   \n",
            "  inflating: phase4/train/1241.png   \n",
            "  inflating: phase4/train/1242.png   \n",
            "  inflating: phase4/train/1243.png   \n",
            "  inflating: phase4/train/1244.png   \n",
            "  inflating: phase4/train/1245.png   \n",
            "  inflating: phase4/train/1246.png   \n",
            "  inflating: phase4/train/1247.png   \n",
            "  inflating: phase4/train/1248.png   \n",
            "  inflating: phase4/train/1249.png   \n",
            "  inflating: phase4/train/1250.png   \n",
            "  inflating: phase4/train/1251.png   \n",
            "  inflating: phase4/train/1252.png   \n",
            "  inflating: phase4/train/1253.png   \n",
            "  inflating: phase4/train/1254.png   \n",
            "  inflating: phase4/train/1255.png   \n",
            "  inflating: phase4/train/1256.png   \n",
            "  inflating: phase4/train/1257.png   \n",
            "  inflating: phase4/train/1258.png   \n",
            "  inflating: phase4/train/1259.png   \n",
            "  inflating: phase4/train/1260.png   \n",
            "  inflating: phase4/train/1261.png   \n",
            "  inflating: phase4/train/1262.png   \n",
            "  inflating: phase4/train/1263.png   \n",
            "  inflating: phase4/train/1264.png   \n",
            "  inflating: phase4/train/1265.png   \n",
            "  inflating: phase4/train/1266.png   \n",
            "  inflating: phase4/train/1267.png   \n",
            "  inflating: phase4/train/1268.png   \n",
            "  inflating: phase4/train/1269.png   \n",
            "  inflating: phase4/train/1270.png   \n",
            "  inflating: phase4/train/1271.png   \n",
            "  inflating: phase4/train/1272.png   \n",
            "  inflating: phase4/train/1273.png   \n",
            "  inflating: phase4/train/1274.png   \n",
            "  inflating: phase4/train/1275.png   \n",
            "  inflating: phase4/train/1276.png   \n",
            "  inflating: phase4/train/1277.png   \n",
            "  inflating: phase4/train/1278.png   \n",
            "  inflating: phase4/train/1279.png   \n",
            "  inflating: phase4/train/1280.png   \n",
            "  inflating: phase4/train/1281.png   \n",
            "  inflating: phase4/train/1282.png   \n",
            "  inflating: phase4/train/1283.png   \n",
            "  inflating: phase4/train/1284.png   \n",
            "  inflating: phase4/train/1285.png   \n",
            "  inflating: phase4/train/1286.png   \n",
            "  inflating: phase4/train/1287.png   \n",
            "  inflating: phase4/train/1288.png   \n",
            "  inflating: phase4/train/1289.png   \n",
            "  inflating: phase4/train/1290.png   \n",
            "  inflating: phase4/train/1291.png   \n",
            "  inflating: phase4/train/1292.png   \n",
            "  inflating: phase4/train/1293.png   \n",
            "  inflating: phase4/train/1294.png   \n",
            "  inflating: phase4/train/1295.png   \n",
            "  inflating: phase4/train/1296.png   \n",
            "  inflating: phase4/train/1297.png   \n",
            "  inflating: phase4/train/1298.png   \n",
            "  inflating: phase4/train/1299.png   \n",
            "  inflating: phase4/train/1300.png   \n",
            "  inflating: phase4/train/1301.png   \n",
            "  inflating: phase4/train/1302.png   \n",
            "  inflating: phase4/train/1303.png   \n",
            "  inflating: phase4/train/1304.png   \n",
            "  inflating: phase4/train/1305.png   \n",
            "  inflating: phase4/train/1306.png   \n",
            "  inflating: phase4/train/1307.png   \n",
            "  inflating: phase4/train/1308.png   \n",
            "  inflating: phase4/train/1309.png   \n",
            "  inflating: phase4/train/1310.png   \n",
            "  inflating: phase4/train/1311.png   \n",
            "  inflating: phase4/train/1312.png   \n",
            "  inflating: phase4/train/1313.png   \n",
            "  inflating: phase4/train/1314.png   \n",
            "  inflating: phase4/train/1315.png   \n",
            "  inflating: phase4/train/1316.png   \n",
            "  inflating: phase4/train/1317.png   \n",
            "  inflating: phase4/train/1318.png   \n",
            "  inflating: phase4/train/1319.png   \n",
            "  inflating: phase4/train/1320.png   \n",
            "  inflating: phase4/train/1321.png   \n",
            "  inflating: phase4/train/1322.png   \n",
            "  inflating: phase4/train/1323.png   \n",
            "  inflating: phase4/train/1324.png   \n",
            "  inflating: phase4/train/1325.png   \n",
            "  inflating: phase4/train/1326.png   \n",
            "  inflating: phase4/train/1327.png   \n",
            "  inflating: phase4/train/1328.png   \n",
            "  inflating: phase4/train/1329.png   \n",
            "  inflating: phase4/train/1330.png   \n",
            "  inflating: phase4/train/1331.png   \n",
            "  inflating: phase4/train/1332.png   \n",
            "  inflating: phase4/train/1333.png   \n",
            "  inflating: phase4/train/1334.png   \n",
            "  inflating: phase4/train/1335.png   \n",
            "  inflating: phase4/train/1336.png   \n",
            "  inflating: phase4/train/1337.png   \n",
            "  inflating: phase4/train/1338.png   \n",
            "  inflating: phase4/train/1339.png   \n",
            "  inflating: phase4/train/1340.png   \n",
            "  inflating: phase4/train/1341.png   \n",
            "  inflating: phase4/train/1342.png   \n",
            "  inflating: phase4/train/1343.png   \n",
            "  inflating: phase4/train/1344.png   \n",
            "  inflating: phase4/train/1345.png   \n",
            "  inflating: phase4/train/1346.png   \n",
            "  inflating: phase4/train/1347.png   \n",
            "  inflating: phase4/train/1348.png   \n",
            "  inflating: phase4/train/1349.png   \n",
            "  inflating: phase4/train/1350.png   \n",
            "  inflating: phase4/train/1351.png   \n",
            "  inflating: phase4/train/1352.png   \n",
            "  inflating: phase4/train/1353.png   \n",
            "  inflating: phase4/train/1354.png   \n",
            "  inflating: phase4/train/1355.png   \n",
            "  inflating: phase4/train/1356.png   \n",
            "  inflating: phase4/train/1357.png   \n",
            "  inflating: phase4/train/1358.png   \n",
            "  inflating: phase4/train/1359.png   \n",
            "  inflating: phase4/train/1360.png   \n",
            "  inflating: phase4/train/1361.png   \n",
            "  inflating: phase4/train/1362.png   \n",
            "  inflating: phase4/train/1363.png   \n",
            "  inflating: phase4/train/1364.png   \n",
            "  inflating: phase4/train/1365.png   \n",
            "  inflating: phase4/train/1366.png   \n",
            "  inflating: phase4/train/1367.png   \n",
            "  inflating: phase4/train/1368.png   \n",
            "  inflating: phase4/train/1369.png   \n",
            "  inflating: phase4/train/1370.png   \n",
            "  inflating: phase4/train/1371.png   \n",
            "  inflating: phase4/train/1372.png   \n",
            "  inflating: phase4/train/1373.png   \n",
            "  inflating: phase4/train/1374.png   \n",
            "  inflating: phase4/train/1375.png   \n",
            "  inflating: phase4/train/1376.png   \n",
            "  inflating: phase4/train/1377.png   \n",
            "  inflating: phase4/train/1378.png   \n",
            "  inflating: phase4/train/1379.png   \n",
            "  inflating: phase4/train/1380.png   \n",
            "  inflating: phase4/train/1381.png   \n",
            "  inflating: phase4/train/1382.png   \n",
            "  inflating: phase4/train/1383.png   \n",
            "  inflating: phase4/train/1384.png   \n",
            "  inflating: phase4/train/1385.png   \n",
            "  inflating: phase4/train/1386.png   \n",
            "  inflating: phase4/train/1387.png   \n",
            "  inflating: phase4/train/1388.png   \n",
            "  inflating: phase4/train/1389.png   \n",
            "  inflating: phase4/train/1390.png   \n",
            "  inflating: phase4/train/1391.png   \n",
            "  inflating: phase4/train/1392.png   \n",
            "  inflating: phase4/train/1393.png   \n",
            "  inflating: phase4/train/1394.png   \n",
            "  inflating: phase4/train/1395.png   \n",
            "  inflating: phase4/train/1396.png   \n",
            "  inflating: phase4/train/1397.png   \n",
            "  inflating: phase4/train/1398.png   \n",
            "  inflating: phase4/train/1399.png   \n",
            "  inflating: phase4/train/1400.png   \n",
            "  inflating: phase4/train/1401.png   \n",
            "  inflating: phase4/train/1402.png   \n",
            "  inflating: phase4/train/1403.png   \n",
            "  inflating: phase4/train/1404.png   \n",
            "  inflating: phase4/train/1405.png   \n",
            "  inflating: phase4/train/1406.png   \n",
            "  inflating: phase4/train/1407.png   \n",
            "  inflating: phase4/train/1408.png   \n",
            "  inflating: phase4/train/1409.png   \n",
            "  inflating: phase4/train/1410.png   \n",
            "  inflating: phase4/train/1411.png   \n",
            "  inflating: phase4/train/1412.png   \n",
            "  inflating: phase4/train/1413.png   \n",
            "  inflating: phase4/train/1414.png   \n",
            "  inflating: phase4/train/1415.png   \n",
            "  inflating: phase4/train/1416.png   \n",
            "  inflating: phase4/train/1417.png   \n",
            "  inflating: phase4/train/1418.png   \n",
            "  inflating: phase4/train/1419.png   \n",
            "  inflating: phase4/train/1420.png   \n",
            "  inflating: phase4/train/1421.png   \n",
            "  inflating: phase4/train/1422.png   \n",
            "  inflating: phase4/train/1423.png   \n",
            "  inflating: phase4/train/1424.png   \n",
            "  inflating: phase4/train/1425.png   \n",
            "  inflating: phase4/train/1426.png   \n",
            "  inflating: phase4/train/1427.png   \n",
            "  inflating: phase4/train/1428.png   \n",
            "  inflating: phase4/train/1429.png   \n",
            "  inflating: phase4/train/1430.png   \n",
            "  inflating: phase4/train/1431.png   \n",
            "  inflating: phase4/train/1432.png   \n",
            "  inflating: phase4/train/1433.png   \n",
            "  inflating: phase4/train/1434.png   \n",
            "  inflating: phase4/train/1435.png   \n",
            "  inflating: phase4/train/1436.png   \n",
            "  inflating: phase4/train/1437.png   \n",
            "  inflating: phase4/train/1438.png   \n",
            "  inflating: phase4/train/1439.png   \n",
            "  inflating: phase4/train/1440.png   \n",
            "  inflating: phase4/train/1441.png   \n",
            "  inflating: phase4/train/1442.png   \n",
            "  inflating: phase4/train/1443.png   \n",
            "  inflating: phase4/train/1444.png   \n",
            "  inflating: phase4/train/1445.png   \n",
            "  inflating: phase4/train/1446.png   \n",
            "  inflating: phase4/train/1447.png   \n",
            "  inflating: phase4/train/1448.png   \n",
            "  inflating: phase4/train/1449.png   \n",
            "  inflating: phase4/train/1450.png   \n",
            "  inflating: phase4/train/1451.png   \n",
            "  inflating: phase4/train/1452.png   \n",
            "  inflating: phase4/train/1453.png   \n",
            "  inflating: phase4/train/1454.png   \n",
            "  inflating: phase4/train/1455.png   \n",
            "  inflating: phase4/train/1456.png   \n",
            "  inflating: phase4/train/1457.png   \n",
            "  inflating: phase4/train/1458.png   \n",
            "  inflating: phase4/train/1459.png   \n",
            "  inflating: phase4/train/1460.png   \n",
            "  inflating: phase4/train/1461.png   \n",
            "  inflating: phase4/train/1462.png   \n",
            "  inflating: phase4/train/1463.png   \n",
            "  inflating: phase4/train/1464.png   \n",
            "  inflating: phase4/train/1465.png   \n",
            "  inflating: phase4/train/1466.png   \n",
            "  inflating: phase4/train/1467.png   \n",
            "  inflating: phase4/train/1468.png   \n",
            "  inflating: phase4/train/1469.png   \n",
            "  inflating: phase4/train/1470.png   \n",
            "  inflating: phase4/train/1471.png   \n",
            "  inflating: phase4/train/1472.png   \n",
            "  inflating: phase4/train/1473.png   \n",
            "  inflating: phase4/train/1474.png   \n",
            "  inflating: phase4/train/1475.png   \n",
            "  inflating: phase4/train/1476.png   \n",
            "  inflating: phase4/train/1477.png   \n",
            "  inflating: phase4/train/1478.png   \n",
            "  inflating: phase4/train/1479.png   \n",
            "  inflating: phase4/train/1480.png   \n",
            "  inflating: phase4/train/1481.png   \n",
            "  inflating: phase4/train/1482.png   \n",
            "  inflating: phase4/train/1483.png   \n",
            "  inflating: phase4/train/1484.png   \n",
            "  inflating: phase4/train/1485.png   \n",
            "  inflating: phase4/train/1486.png   \n",
            "  inflating: phase4/train/1487.png   \n",
            "  inflating: phase4/train/1488.png   \n",
            "  inflating: phase4/train/1489.png   \n",
            "  inflating: phase4/train/1490.png   \n",
            "  inflating: phase4/train/1491.png   \n",
            "  inflating: phase4/train/1492.png   \n",
            "  inflating: phase4/train/1493.png   \n",
            "  inflating: phase4/train/1494.png   \n",
            "  inflating: phase4/train/1495.png   \n",
            "  inflating: phase4/train/1496.png   \n",
            "  inflating: phase4/train/1497.png   \n",
            "  inflating: phase4/train/1498.png   \n",
            "  inflating: phase4/train/1499.png   \n",
            "  inflating: phase4/train/1500.png   \n",
            "  inflating: phase4/train/1501.png   \n",
            "  inflating: phase4/train/1502.png   \n",
            "  inflating: phase4/train/1503.png   \n",
            "  inflating: phase4/train/1504.png   \n",
            "  inflating: phase4/train/1505.png   \n",
            "  inflating: phase4/train/1506.png   \n",
            "  inflating: phase4/train/1507.png   \n",
            "  inflating: phase4/train/1508.png   \n",
            "  inflating: phase4/train/1509.png   \n",
            "  inflating: phase4/train/1510.png   \n",
            "  inflating: phase4/train/1511.png   \n",
            "  inflating: phase4/train/1512.png   \n",
            "  inflating: phase4/train/1513.png   \n",
            "  inflating: phase4/train/1514.png   \n",
            "  inflating: phase4/train/1515.png   \n",
            "  inflating: phase4/train/1516.png   \n",
            "  inflating: phase4/train/1517.png   \n",
            "  inflating: phase4/train/1518.png   \n",
            "  inflating: phase4/train/1519.png   \n",
            "  inflating: phase4/train/1520.png   \n",
            "  inflating: phase4/train/1521.png   \n",
            "  inflating: phase4/train/1522.png   \n",
            "  inflating: phase4/train/1523.png   \n",
            "  inflating: phase4/train/1524.png   \n",
            "  inflating: phase4/train/1525.png   \n",
            "  inflating: phase4/train/1526.png   \n",
            "  inflating: phase4/train/1527.png   \n",
            "  inflating: phase4/train/1528.png   \n",
            "  inflating: phase4/train/1529.png   \n",
            "  inflating: phase4/train/1530.png   \n",
            "  inflating: phase4/train/1531.png   \n",
            "  inflating: phase4/train/1532.png   \n",
            "  inflating: phase4/train/1533.png   \n",
            "  inflating: phase4/train/1534.png   \n",
            "  inflating: phase4/train/1535.png   \n",
            "  inflating: phase4/train/1536.png   \n",
            "  inflating: phase4/train/1537.png   \n",
            "  inflating: phase4/train/1538.png   \n",
            "  inflating: phase4/train/1539.png   \n",
            "  inflating: phase4/train/1540.png   \n",
            "  inflating: phase4/train/1541.png   \n",
            "  inflating: phase4/train/1542.png   \n",
            "  inflating: phase4/train/1543.png   \n",
            "  inflating: phase4/train/1544.png   \n",
            "  inflating: phase4/train/1545.png   \n",
            "  inflating: phase4/train/1546.png   \n",
            "  inflating: phase4/train/1547.png   \n",
            "  inflating: phase4/train/1548.png   \n",
            "  inflating: phase4/train/1549.png   \n",
            "  inflating: phase4/train/1550.png   \n",
            "  inflating: phase4/train/1551.png   \n",
            "  inflating: phase4/train/1552.png   \n",
            "  inflating: phase4/train/1553.png   \n",
            "  inflating: phase4/train/1554.png   \n",
            "  inflating: phase4/train/1555.png   \n",
            "  inflating: phase4/train/1556.png   \n",
            "  inflating: phase4/train/1557.png   \n",
            "  inflating: phase4/train/1558.png   \n",
            "  inflating: phase4/train/1559.png   \n",
            "  inflating: phase4/train/1560.png   \n",
            "  inflating: phase4/train/1561.png   \n",
            "  inflating: phase4/train/1562.png   \n",
            "  inflating: phase4/train/1563.png   \n",
            "  inflating: phase4/train/1564.png   \n",
            "  inflating: phase4/train/1565.png   \n",
            "  inflating: phase4/train/1566.png   \n",
            "  inflating: phase4/train/1567.png   \n",
            "  inflating: phase4/train/1568.png   \n",
            "  inflating: phase4/train/1569.png   \n",
            "  inflating: phase4/train/1570.png   \n",
            "  inflating: phase4/train/1571.png   \n",
            "  inflating: phase4/train/1572.png   \n",
            "  inflating: phase4/train/1573.png   \n",
            "  inflating: phase4/train/1574.png   \n",
            "  inflating: phase4/train/1575.png   \n",
            "  inflating: phase4/train/1576.png   \n",
            "  inflating: phase4/train/1577.png   \n",
            "  inflating: phase4/train/1578.png   \n",
            "  inflating: phase4/train/1579.png   \n",
            "  inflating: phase4/train/1580.png   \n",
            "  inflating: phase4/train/1581.png   \n",
            "  inflating: phase4/train/1582.png   \n",
            "  inflating: phase4/train/1583.png   \n",
            "  inflating: phase4/train/1584.png   \n",
            "  inflating: phase4/train/1585.png   \n",
            "  inflating: phase4/train/1586.png   \n",
            "  inflating: phase4/train/1587.png   \n",
            "  inflating: phase4/train/1588.png   \n",
            "  inflating: phase4/train/1589.png   \n",
            "  inflating: phase4/train/1590.png   \n",
            "  inflating: phase4/train/1591.png   \n",
            "  inflating: phase4/train/1592.png   \n",
            "  inflating: phase4/train/1593.png   \n",
            "  inflating: phase4/train/1594.png   \n",
            "  inflating: phase4/train/1595.png   \n",
            "  inflating: phase4/train/1596.png   \n",
            "  inflating: phase4/train/1597.png   \n",
            "  inflating: phase4/train/1598.png   \n",
            "  inflating: phase4/train/1599.png   \n",
            "  inflating: phase4/train/1600.png   \n",
            "  inflating: phase4/train/1601.png   \n",
            "  inflating: phase4/train/1602.png   \n",
            "  inflating: phase4/train/1603.png   \n",
            "  inflating: phase4/train/1604.png   \n",
            "  inflating: phase4/train/1605.png   \n",
            "  inflating: phase4/train/1606.png   \n",
            "  inflating: phase4/train/1607.png   \n",
            "  inflating: phase4/train/1608.png   \n",
            "  inflating: phase4/train/1609.png   \n",
            "  inflating: phase4/train/1610.png   \n",
            "  inflating: phase4/train/1611.png   \n",
            "  inflating: phase4/train/1612.png   \n",
            "  inflating: phase4/train/1613.png   \n",
            "  inflating: phase4/train/1614.png   \n",
            "  inflating: phase4/train/1615.png   \n",
            "  inflating: phase4/train/1616.png   \n",
            "  inflating: phase4/train/1617.png   \n",
            "  inflating: phase4/train/1618.png   \n",
            "  inflating: phase4/train/1619.png   \n",
            "  inflating: phase4/train/1620.png   \n",
            "  inflating: phase4/train/1621.png   \n",
            "  inflating: phase4/train/1622.png   \n",
            "  inflating: phase4/train/1623.png   \n",
            "  inflating: phase4/train/1624.png   \n",
            "  inflating: phase4/train/1625.png   \n",
            "  inflating: phase4/train/1626.png   \n",
            "  inflating: phase4/train/1627.png   \n",
            "  inflating: phase4/train/1628.png   \n",
            "  inflating: phase4/train/1629.png   \n",
            "  inflating: phase4/train/1630.png   \n",
            "  inflating: phase4/train/1631.png   \n",
            "  inflating: phase4/train/1632.png   \n",
            "  inflating: phase4/train/1633.png   \n",
            "  inflating: phase4/train/1634.png   \n",
            "  inflating: phase4/train/1635.png   \n",
            "  inflating: phase4/train/1636.png   \n",
            "  inflating: phase4/train/1637.png   \n",
            "  inflating: phase4/train/1638.png   \n",
            "  inflating: phase4/train/1639.png   \n",
            "  inflating: phase4/train/1640.png   \n",
            "  inflating: phase4/train/1641.png   \n",
            "  inflating: phase4/train/1642.png   \n",
            "  inflating: phase4/train/1643.png   \n",
            "  inflating: phase4/train/1644.png   \n",
            "  inflating: phase4/train/1645.png   \n",
            "  inflating: phase4/train/1646.png   \n",
            "  inflating: phase4/train/1647.png   \n",
            "  inflating: phase4/train/1648.png   \n",
            "  inflating: phase4/train/1649.png   \n",
            "  inflating: phase4/train/1650.png   \n",
            "  inflating: phase4/train/1651.png   \n",
            "  inflating: phase4/train/1652.png   \n",
            "  inflating: phase4/train/1653.png   \n",
            "  inflating: phase4/train/1654.png   \n",
            "  inflating: phase4/train/1655.png   \n",
            "  inflating: phase4/train/1656.png   \n",
            "  inflating: phase4/train/1657.png   \n",
            "  inflating: phase4/train/1658.png   \n",
            "  inflating: phase4/train/1659.png   \n",
            "  inflating: phase4/train/1660.png   \n",
            "  inflating: phase4/train/1661.png   \n",
            "  inflating: phase4/train/1662.png   \n",
            "  inflating: phase4/train/1663.png   \n",
            "  inflating: phase4/train/1664.png   \n",
            "  inflating: phase4/train/1665.png   \n",
            "  inflating: phase4/train/1666.png   \n",
            "  inflating: phase4/train/1667.png   \n",
            "  inflating: phase4/train/1668.png   \n",
            "  inflating: phase4/train/1669.png   \n",
            "  inflating: phase4/train/1670.png   \n",
            "  inflating: phase4/train/1671.png   \n",
            "  inflating: phase4/train/1672.png   \n",
            "  inflating: phase4/train/1673.png   \n",
            "  inflating: phase4/train/1674.png   \n",
            "  inflating: phase4/train/1675.png   \n",
            "  inflating: phase4/train/1676.png   \n",
            "  inflating: phase4/train/1677.png   \n",
            "  inflating: phase4/train/1678.png   \n",
            "  inflating: phase4/train/1679.png   \n",
            "  inflating: phase4/train/1680.png   \n",
            "  inflating: phase4/train/1681.png   \n",
            "  inflating: phase4/train/1682.png   \n",
            "  inflating: phase4/train/1683.png   \n",
            "  inflating: phase4/train/1684.png   \n",
            "  inflating: phase4/train/1685.png   \n",
            "  inflating: phase4/train/1686.png   \n",
            "  inflating: phase4/train/1687.png   \n",
            "  inflating: phase4/train/1688.png   \n",
            "  inflating: phase4/train/1689.png   \n",
            "  inflating: phase4/train/1690.png   \n",
            "  inflating: phase4/train/1691.png   \n",
            "  inflating: phase4/train/1692.png   \n",
            "  inflating: phase4/train/1693.png   \n",
            "  inflating: phase4/train/1694.png   \n",
            "  inflating: phase4/train/1695.png   \n",
            "  inflating: phase4/train/1696.png   \n",
            "  inflating: phase4/train/1697.png   \n",
            "  inflating: phase4/train/1698.png   \n",
            "  inflating: phase4/train/1699.png   \n",
            "  inflating: phase4/train/1700.png   \n",
            "  inflating: phase4/train/1701.png   \n",
            "  inflating: phase4/train/1702.png   \n",
            "  inflating: phase4/train/1703.png   \n",
            "  inflating: phase4/train/1704.png   \n",
            "  inflating: phase4/train/1705.png   \n",
            "  inflating: phase4/train/1706.png   \n",
            "  inflating: phase4/train/1707.png   \n",
            "  inflating: phase4/train/1708.png   \n",
            "  inflating: phase4/train/1709.png   \n",
            "  inflating: phase4/train/1710.png   \n",
            "  inflating: phase4/train/1711.png   \n",
            "  inflating: phase4/train/1712.png   \n",
            "  inflating: phase4/train/1713.png   \n",
            "  inflating: phase4/train/1714.png   \n",
            "  inflating: phase4/train/1715.png   \n",
            "  inflating: phase4/train/1716.png   \n",
            "  inflating: phase4/train/1717.png   \n",
            "  inflating: phase4/train/1718.png   \n",
            "  inflating: phase4/train/1719.png   \n",
            "  inflating: phase4/train/1720.png   \n",
            "  inflating: phase4/train/1721.png   \n",
            "  inflating: phase4/train/1722.png   \n",
            "  inflating: phase4/train/1723.png   \n",
            "  inflating: phase4/train/1724.png   \n",
            "  inflating: phase4/train/1725.png   \n",
            "  inflating: phase4/train/1726.png   \n",
            "  inflating: phase4/train/1727.png   \n",
            "  inflating: phase4/train/1728.png   \n",
            "  inflating: phase4/train/1729.png   \n",
            "  inflating: phase4/train/1730.png   \n",
            "  inflating: phase4/train/1731.png   \n",
            "  inflating: phase4/train/1732.png   \n",
            "  inflating: phase4/train/1733.png   \n",
            "  inflating: phase4/train/1734.png   \n",
            "  inflating: phase4/train/1735.png   \n",
            "  inflating: phase4/train/1736.png   \n",
            "  inflating: phase4/train/1737.png   \n",
            "  inflating: phase4/train/1738.png   \n",
            "  inflating: phase4/train/1739.png   \n",
            "  inflating: phase4/train/1740.png   \n",
            "  inflating: phase4/train/1741.png   \n",
            "  inflating: phase4/train/1742.png   \n",
            "  inflating: phase4/train/1743.png   \n",
            "  inflating: phase4/train/1744.png   \n",
            "  inflating: phase4/train/1745.png   \n",
            "  inflating: phase4/train/1746.png   \n",
            "  inflating: phase4/train/1747.png   \n",
            "  inflating: phase4/train/1748.png   \n",
            "  inflating: phase4/train/1749.png   \n",
            "  inflating: phase4/train/1750.png   \n",
            "  inflating: phase4/train/1751.png   \n",
            "  inflating: phase4/train/1752.png   \n",
            "  inflating: phase4/train/1753.png   \n",
            "  inflating: phase4/train/1754.png   \n",
            "  inflating: phase4/train/1755.png   \n",
            "  inflating: phase4/train/1756.png   \n",
            "  inflating: phase4/train/1757.png   \n",
            "  inflating: phase4/train/1758.png   \n",
            "  inflating: phase4/train/1759.png   \n",
            "  inflating: phase4/train/1760.png   \n",
            "  inflating: phase4/train/1761.png   \n",
            "  inflating: phase4/train/1762.png   \n",
            "  inflating: phase4/train/1763.png   \n",
            "  inflating: phase4/train/1764.png   \n",
            "  inflating: phase4/train/1765.png   \n",
            "  inflating: phase4/train/1766.png   \n",
            "  inflating: phase4/train/1767.png   \n",
            "  inflating: phase4/train/1768.png   \n",
            "  inflating: phase4/train/1769.png   \n",
            "  inflating: phase4/train/1770.png   \n",
            "  inflating: phase4/train/1771.png   \n",
            "  inflating: phase4/train/1772.png   \n",
            "  inflating: phase4/train/1773.png   \n",
            "  inflating: phase4/train/1774.png   \n",
            "  inflating: phase4/train/1775.png   \n",
            "  inflating: phase4/train/1776.png   \n",
            "  inflating: phase4/train/1777.png   \n",
            "  inflating: phase4/train/1778.png   \n",
            "  inflating: phase4/train/1779.png   \n",
            "  inflating: phase4/train/1780.png   \n",
            "  inflating: phase4/train/1781.png   \n",
            "  inflating: phase4/train/1782.png   \n",
            "  inflating: phase4/train/1783.png   \n",
            "  inflating: phase4/train/1784.png   \n",
            "  inflating: phase4/train/1785.png   \n",
            "  inflating: phase4/train/1786.png   \n",
            "  inflating: phase4/train/1787.png   \n",
            "  inflating: phase4/train/1788.png   \n",
            "  inflating: phase4/train/1789.png   \n",
            "  inflating: phase4/train/1790.png   \n",
            "  inflating: phase4/train/1791.png   \n",
            "  inflating: phase4/train/1792.png   \n",
            "  inflating: phase4/train/1793.png   \n",
            "  inflating: phase4/train/1794.png   \n",
            "  inflating: phase4/train/1795.png   \n",
            "  inflating: phase4/train/1796.png   \n",
            "  inflating: phase4/train/1797.png   \n",
            "  inflating: phase4/train/1798.png   \n",
            "  inflating: phase4/train/1799.png   \n",
            "  inflating: phase4/train/1800.png   \n",
            "  inflating: phase4/train/1801.png   \n",
            "  inflating: phase4/train/1802.png   \n",
            "  inflating: phase4/train/1803.png   \n",
            "  inflating: phase4/train/1804.png   \n",
            "  inflating: phase4/train/1805.png   \n",
            "  inflating: phase4/train/1806.png   \n",
            "  inflating: phase4/train/1807.png   \n",
            "  inflating: phase4/train/1808.png   \n",
            "  inflating: phase4/train/1809.png   \n",
            "  inflating: phase4/train/1810.png   \n",
            "  inflating: phase4/train/1811.png   \n",
            "  inflating: phase4/train/1812.png   \n",
            "  inflating: phase4/train/1813.png   \n",
            "  inflating: phase4/train/1814.png   \n",
            "  inflating: phase4/train/1815.png   \n",
            "  inflating: phase4/train/1816.png   \n",
            "  inflating: phase4/train/1817.png   \n",
            "  inflating: phase4/train/1818.png   \n",
            "  inflating: phase4/train/1819.png   \n",
            "  inflating: phase4/train/1820.png   \n",
            "  inflating: phase4/train/1821.png   \n",
            "  inflating: phase4/train/1822.png   \n",
            "  inflating: phase4/train/1823.png   \n",
            "  inflating: phase4/train/1824.png   \n",
            "  inflating: phase4/train/1825.png   \n",
            "  inflating: phase4/train/1826.png   \n",
            "  inflating: phase4/train/1827.png   \n",
            "  inflating: phase4/train/1828.png   \n",
            "  inflating: phase4/train/1829.png   \n",
            "  inflating: phase4/train/1830.png   \n",
            "  inflating: phase4/train/1831.png   \n",
            "  inflating: phase4/train/1832.png   \n",
            "  inflating: phase4/train/1833.png   \n",
            "  inflating: phase4/train/1834.png   \n",
            "  inflating: phase4/train/1835.png   \n",
            "  inflating: phase4/train/1836.png   \n",
            "  inflating: phase4/train/1837.png   \n",
            "  inflating: phase4/train/1838.png   \n",
            "  inflating: phase4/train/1839.png   \n",
            "  inflating: phase4/train/1840.png   \n",
            "  inflating: phase4/train/1841.png   \n",
            "  inflating: phase4/train/1842.png   \n",
            "  inflating: phase4/train/1843.png   \n",
            "  inflating: phase4/train/1844.png   \n",
            "  inflating: phase4/train/1845.png   \n",
            "  inflating: phase4/train/1846.png   \n",
            "  inflating: phase4/train/1847.png   \n",
            "  inflating: phase4/train/1848.png   \n",
            "  inflating: phase4/train/1849.png   \n",
            "  inflating: phase4/train/1850.png   \n",
            "  inflating: phase4/train/1851.png   \n",
            "  inflating: phase4/train/1852.png   \n",
            "  inflating: phase4/train/1853.png   \n",
            "  inflating: phase4/train/1854.png   \n",
            "  inflating: phase4/train/1855.png   \n",
            "  inflating: phase4/train/1856.png   \n",
            "  inflating: phase4/train/1857.png   \n",
            "  inflating: phase4/train/1858.png   \n",
            "  inflating: phase4/train/1859.png   \n",
            "  inflating: phase4/train/1860.png   \n",
            "  inflating: phase4/train/1861.png   \n",
            "  inflating: phase4/train/1862.png   \n",
            "  inflating: phase4/train/1863.png   \n",
            "  inflating: phase4/train/1864.png   \n",
            "  inflating: phase4/train/1865.png   \n",
            "  inflating: phase4/train/1866.png   \n",
            "  inflating: phase4/train/1867.png   \n",
            "  inflating: phase4/train/1868.png   \n",
            "  inflating: phase4/train/1869.png   \n",
            "  inflating: phase4/train/1870.png   \n",
            "  inflating: phase4/train/1871.png   \n",
            "  inflating: phase4/train/1872.png   \n",
            "  inflating: phase4/train/1873.png   \n",
            "  inflating: phase4/train/1874.png   \n",
            "  inflating: phase4/train/1875.png   \n",
            "  inflating: phase4/train/1876.png   \n",
            "  inflating: phase4/train/1877.png   \n",
            "  inflating: phase4/train/1878.png   \n",
            "  inflating: phase4/train/1879.png   \n",
            "  inflating: phase4/train/1880.png   \n",
            "  inflating: phase4/train/1881.png   \n",
            "  inflating: phase4/train/1882.png   \n",
            "  inflating: phase4/train/1883.png   \n",
            "  inflating: phase4/train/1884.png   \n",
            "  inflating: phase4/train/1885.png   \n",
            "  inflating: phase4/train/1886.png   \n",
            "  inflating: phase4/train/1887.png   \n",
            "  inflating: phase4/train/1888.png   \n",
            "  inflating: phase4/train/1889.png   \n",
            "  inflating: phase4/train/1890.png   \n",
            "  inflating: phase4/train/1891.png   \n",
            "  inflating: phase4/train/1892.png   \n",
            "  inflating: phase4/train/1893.png   \n",
            "  inflating: phase4/train/1894.png   \n",
            "  inflating: phase4/train/1895.png   \n",
            "  inflating: phase4/train/1896.png   \n",
            "  inflating: phase4/train/1897.png   \n",
            "  inflating: phase4/train/1898.png   \n",
            "  inflating: phase4/train/1899.png   \n",
            "  inflating: phase4/train/1900.png   \n",
            "  inflating: phase4/train/1901.png   \n",
            "  inflating: phase4/train/1902.png   \n",
            "  inflating: phase4/train/1903.png   \n",
            "  inflating: phase4/train/1904.png   \n",
            "  inflating: phase4/train/1905.png   \n",
            "  inflating: phase4/train/1906.png   \n",
            "  inflating: phase4/train/1907.png   \n",
            "  inflating: phase4/train/1908.png   \n",
            "  inflating: phase4/train/1909.png   \n",
            "  inflating: phase4/train/1910.png   \n",
            "  inflating: phase4/train/1911.png   \n",
            "  inflating: phase4/train/1912.png   \n",
            "  inflating: phase4/train/1913.png   \n",
            "  inflating: phase4/train/1914.png   \n",
            "  inflating: phase4/train/1915.png   \n",
            "  inflating: phase4/train/1916.png   \n",
            "  inflating: phase4/train/1917.png   \n",
            "  inflating: phase4/train/1918.png   \n",
            "  inflating: phase4/train/1919.png   \n",
            "  inflating: phase4/train/1920.png   \n",
            "  inflating: phase4/train/1921.png   \n",
            "  inflating: phase4/train/1922.png   \n",
            "  inflating: phase4/train/1923.png   \n",
            "  inflating: phase4/train/1924.png   \n",
            "  inflating: phase4/train/1925.png   \n",
            "  inflating: phase4/train/1926.png   \n",
            "  inflating: phase4/train/1927.png   \n",
            "  inflating: phase4/train/1928.png   \n",
            "  inflating: phase4/train/1929.png   \n",
            "  inflating: phase4/train/1930.png   \n",
            "  inflating: phase4/train/1931.png   \n",
            "  inflating: phase4/train/1932.png   \n",
            "  inflating: phase4/train/1933.png   \n",
            "  inflating: phase4/train/1934.png   \n",
            "  inflating: phase4/train/1935.png   \n",
            "  inflating: phase4/train/1936.png   \n",
            "  inflating: phase4/train/1937.png   \n",
            "  inflating: phase4/train/1938.png   \n",
            "  inflating: phase4/train/1939.png   \n",
            "  inflating: phase4/train/1940.png   \n",
            "  inflating: phase4/train/1941.png   \n",
            "  inflating: phase4/train/1942.png   \n",
            "  inflating: phase4/train/1943.png   \n",
            "  inflating: phase4/train/1944.png   \n",
            "  inflating: phase4/train/1945.png   \n",
            "  inflating: phase4/train/1946.png   \n",
            "  inflating: phase4/train/1947.png   \n",
            "  inflating: phase4/train/1948.png   \n",
            "  inflating: phase4/train/1949.png   \n",
            "  inflating: phase4/train/1950.png   \n",
            "  inflating: phase4/train/1951.png   \n",
            "  inflating: phase4/train/1952.png   \n",
            "  inflating: phase4/train/1953.png   \n",
            "  inflating: phase4/train/1954.png   \n",
            "  inflating: phase4/train/1955.png   \n",
            "  inflating: phase4/train/1956.png   \n",
            "  inflating: phase4/train/1957.png   \n",
            "  inflating: phase4/train/1958.png   \n",
            "  inflating: phase4/train/1959.png   \n",
            "  inflating: phase4/train/1960.png   \n",
            "  inflating: phase4/train/1961.png   \n",
            "  inflating: phase4/train/1962.png   \n",
            "  inflating: phase4/train/1963.png   \n",
            "  inflating: phase4/train/1964.png   \n",
            "  inflating: phase4/train/1965.png   \n",
            "  inflating: phase4/train/1966.png   \n",
            "  inflating: phase4/train/1967.png   \n",
            "  inflating: phase4/train/1968.png   \n",
            "  inflating: phase4/train/1969.png   \n",
            "  inflating: phase4/train/1970.png   \n",
            "  inflating: phase4/train/1971.png   \n",
            "  inflating: phase4/train/1972.png   \n",
            "  inflating: phase4/train/1973.png   \n",
            "  inflating: phase4/train/1974.png   \n",
            "  inflating: phase4/train/1975.png   \n",
            "  inflating: phase4/train/1976.png   \n",
            "  inflating: phase4/train/1977.png   \n",
            "  inflating: phase4/train/1978.png   \n",
            "  inflating: phase4/train/1979.png   \n",
            "  inflating: phase4/train/1980.png   \n",
            "  inflating: phase4/train/1981.png   \n",
            "  inflating: phase4/train/1982.png   \n",
            "  inflating: phase4/train/1983.png   \n",
            "  inflating: phase4/train/1984.png   \n",
            "  inflating: phase4/train/1985.png   \n",
            "  inflating: phase4/train/1986.png   \n",
            "  inflating: phase4/train/1987.png   \n",
            "  inflating: phase4/train/1988.png   \n",
            "  inflating: phase4/train/1989.png   \n",
            "  inflating: phase4/train/1990.png   \n",
            "  inflating: phase4/train/1991.png   \n",
            "  inflating: phase4/train/1992.png   \n",
            "  inflating: phase4/train/1993.png   \n",
            "  inflating: phase4/train/1994.png   \n",
            "  inflating: phase4/train/1995.png   \n",
            "  inflating: phase4/train/1996.png   \n",
            "  inflating: phase4/train/1997.png   \n",
            "  inflating: phase4/train/1998.png   \n",
            "  inflating: phase4/train/1999.png   \n",
            "  inflating: phase4/train/2000.png   \n",
            "  inflating: phase4/train/2001.png   \n",
            "  inflating: phase4/train/2002.png   \n",
            "  inflating: phase4/train/2003.png   \n",
            "  inflating: phase4/train/2004.png   \n",
            "  inflating: phase4/train/2005.png   \n",
            "  inflating: phase4/train/2006.png   \n",
            "  inflating: phase4/train/2007.png   \n",
            "  inflating: phase4/train/2008.png   \n",
            "  inflating: phase4/train/2009.png   \n",
            "  inflating: phase4/train/2010.png   \n",
            "  inflating: phase4/train/2011.png   \n",
            "  inflating: phase4/train/2012.png   \n",
            "  inflating: phase4/train/2013.png   \n",
            "  inflating: phase4/train/2014.png   \n",
            "  inflating: phase4/train/2015.png   \n",
            "  inflating: phase4/train/2016.png   \n",
            "  inflating: phase4/train/2017.png   \n",
            "  inflating: phase4/train/2018.png   \n",
            "  inflating: phase4/train/2019.png   \n",
            "  inflating: phase4/train/2020.png   \n",
            "  inflating: phase4/train/2021.png   \n",
            "  inflating: phase4/train/2022.png   \n",
            "  inflating: phase4/train/2023.png   \n",
            "  inflating: phase4/train/2024.png   \n",
            "  inflating: phase4/train/2025.png   \n",
            "  inflating: phase4/train/2026.png   \n",
            "  inflating: phase4/train/2027.png   \n",
            "  inflating: phase4/train/2028.png   \n",
            "  inflating: phase4/train/2029.png   \n",
            "  inflating: phase4/train/2030.png   \n",
            "  inflating: phase4/train/2031.png   \n",
            "  inflating: phase4/train/2032.png   \n",
            "  inflating: phase4/train/2033.png   \n",
            "  inflating: phase4/train/2034.png   \n",
            "  inflating: phase4/train/2035.png   \n",
            "  inflating: phase4/train/2036.png   \n",
            "  inflating: phase4/train/2037.png   \n",
            "  inflating: phase4/train/2038.png   \n",
            "  inflating: phase4/train/2039.png   \n",
            "  inflating: phase4/train/2040.png   \n",
            "  inflating: phase4/train/2041.png   \n",
            "  inflating: phase4/train/2042.png   \n",
            "  inflating: phase4/train/2043.png   \n",
            "  inflating: phase4/train/2044.png   \n",
            "  inflating: phase4/train/2045.png   \n",
            "  inflating: phase4/train/2046.png   \n",
            "  inflating: phase4/train/2047.png   \n",
            "  inflating: phase4/train/2048.png   \n",
            "  inflating: phase4/train/2049.png   \n",
            "  inflating: phase4/train/2050.png   \n",
            "  inflating: phase4/train/2051.png   \n",
            "  inflating: phase4/train/2052.png   \n",
            "  inflating: phase4/train/2053.png   \n",
            "  inflating: phase4/train/2054.png   \n",
            "  inflating: phase4/train/2055.png   \n",
            "  inflating: phase4/train/2056.png   \n",
            "  inflating: phase4/train/2057.png   \n",
            "  inflating: phase4/train/2058.png   \n",
            "  inflating: phase4/train/2059.png   \n",
            "  inflating: phase4/train/2060.png   \n",
            "  inflating: phase4/train/2061.png   \n",
            "  inflating: phase4/train/2062.png   \n",
            "  inflating: phase4/train/2063.png   \n",
            "  inflating: phase4/train/2064.png   \n",
            "  inflating: phase4/train/2065.png   \n",
            "  inflating: phase4/train/2066.png   \n",
            "  inflating: phase4/train/2067.png   \n",
            "  inflating: phase4/train/2068.png   \n",
            "  inflating: phase4/train/2069.png   \n",
            "  inflating: phase4/train/2070.png   \n",
            "  inflating: phase4/train/2071.png   \n",
            "  inflating: phase4/train/2072.png   \n",
            "  inflating: phase4/train/2073.png   \n",
            "  inflating: phase4/train/2074.png   \n",
            "  inflating: phase4/train/2075.png   \n",
            "  inflating: phase4/train/2076.png   \n",
            "  inflating: phase4/train/2077.png   \n",
            "  inflating: phase4/train/2078.png   \n",
            "  inflating: phase4/train/2079.png   \n",
            "  inflating: phase4/train/2080.png   \n",
            "  inflating: phase4/train/2081.png   \n",
            "  inflating: phase4/train/2082.png   \n",
            "  inflating: phase4/train/2083.png   \n",
            "  inflating: phase4/train/2084.png   \n",
            "  inflating: phase4/train/2085.png   \n",
            "  inflating: phase4/train/2086.png   \n",
            "  inflating: phase4/train/2087.png   \n",
            "  inflating: phase4/train/2088.png   \n",
            "  inflating: phase4/train/2089.png   \n",
            "  inflating: phase4/train/2090.png   \n",
            "  inflating: phase4/train/2091.png   \n",
            "  inflating: phase4/train/2092.png   \n",
            "  inflating: phase4/train/2093.png   \n",
            "  inflating: phase4/train/2094.png   \n",
            "  inflating: phase4/train/2095.png   \n",
            "  inflating: phase4/train/2096.png   \n",
            "  inflating: phase4/train/2097.png   \n",
            "  inflating: phase4/train/2098.png   \n",
            "  inflating: phase4/train/2099.png   \n",
            "  inflating: phase4/train/2100.png   \n",
            "  inflating: phase4/train/2101.png   \n",
            "  inflating: phase4/train/2102.png   \n",
            "  inflating: phase4/train/2103.png   \n",
            "  inflating: phase4/train/2104.png   \n",
            "  inflating: phase4/train/2105.png   \n",
            "  inflating: phase4/train/2106.png   \n",
            "  inflating: phase4/train/2107.png   \n",
            "  inflating: phase4/train/2108.png   \n",
            "  inflating: phase4/train/2109.png   \n",
            "  inflating: phase4/train/2110.png   \n",
            "  inflating: phase4/train/2111.png   \n",
            "  inflating: phase4/train/2112.png   \n",
            "  inflating: phase4/train/2113.png   \n",
            "  inflating: phase4/train/2114.png   \n",
            "  inflating: phase4/train/2115.png   \n",
            "  inflating: phase4/train/2116.png   \n",
            "  inflating: phase4/train/2117.png   \n",
            "  inflating: phase4/train/2118.png   \n",
            "  inflating: phase4/train/2119.png   \n",
            "  inflating: phase4/train/2120.png   \n",
            "  inflating: phase4/train/2121.png   \n",
            "  inflating: phase4/train/2122.png   \n",
            "  inflating: phase4/train/2123.png   \n",
            "  inflating: phase4/train/2124.png   \n",
            "  inflating: phase4/train/2125.png   \n",
            "  inflating: phase4/train/2126.png   \n",
            "  inflating: phase4/train/2127.png   \n",
            "  inflating: phase4/train/2128.png   \n",
            "  inflating: phase4/train/2129.png   \n",
            "  inflating: phase4/train/2130.png   \n",
            "  inflating: phase4/train/2131.png   \n",
            "  inflating: phase4/train/2132.png   \n",
            "  inflating: phase4/train/2133.png   \n",
            "  inflating: phase4/train/2134.png   \n",
            "  inflating: phase4/train/2135.png   \n",
            "  inflating: phase4/train/2136.png   \n",
            "  inflating: phase4/train/2137.png   \n",
            "  inflating: phase4/train/2138.png   \n",
            "  inflating: phase4/train/2139.png   \n",
            "  inflating: phase4/train/2140.png   \n",
            "  inflating: phase4/train/2141.png   \n",
            "  inflating: phase4/train/2142.png   \n",
            "  inflating: phase4/train/2143.png   \n",
            "  inflating: phase4/train/2144.png   \n",
            "  inflating: phase4/train/2145.png   \n",
            "  inflating: phase4/train/2146.png   \n",
            "  inflating: phase4/train/2147.png   \n",
            "  inflating: phase4/train/2148.png   \n",
            "  inflating: phase4/train/2149.png   \n",
            "  inflating: phase4/train/2150.png   \n",
            "  inflating: phase4/train/2151.png   \n",
            "  inflating: phase4/train/2152.png   \n",
            "  inflating: phase4/train/2153.png   \n",
            "  inflating: phase4/train/2154.png   \n",
            "  inflating: phase4/train/2155.png   \n",
            "  inflating: phase4/train/2156.png   \n",
            "  inflating: phase4/train/2157.png   \n",
            "  inflating: phase4/train/2158.png   \n",
            "  inflating: phase4/train/2159.png   \n",
            "  inflating: phase4/train/2160.png   \n",
            "  inflating: phase4/train/2161.png   \n",
            "  inflating: phase4/train/2162.png   \n",
            "  inflating: phase4/train/2163.png   \n",
            "  inflating: phase4/train/2164.png   \n",
            "  inflating: phase4/train/2165.png   \n",
            "  inflating: phase4/train/2166.png   \n",
            "  inflating: phase4/train/2167.png   \n",
            "  inflating: phase4/train/2168.png   \n",
            "  inflating: phase4/train/2169.png   \n",
            "  inflating: phase4/train/2170.png   \n",
            "  inflating: phase4/train/2171.png   \n",
            "  inflating: phase4/train/2172.png   \n",
            "  inflating: phase4/train/2173.png   \n",
            "  inflating: phase4/train/2174.png   \n",
            "  inflating: phase4/train/2175.png   \n",
            "  inflating: phase4/train/2176.png   \n",
            "  inflating: phase4/train/2177.png   \n",
            "  inflating: phase4/train/2178.png   \n",
            "  inflating: phase4/train/2179.png   \n",
            "  inflating: phase4/train/2180.png   \n",
            "  inflating: phase4/train/2181.png   \n",
            "  inflating: phase4/train/2182.png   \n",
            "  inflating: phase4/train/2183.png   \n",
            "  inflating: phase4/train/2184.png   \n",
            "  inflating: phase4/train/2185.png   \n",
            "  inflating: phase4/train/2186.png   \n",
            "  inflating: phase4/train/2187.png   \n",
            "  inflating: phase4/train/2188.png   \n",
            "  inflating: phase4/train/2189.png   \n",
            "  inflating: phase4/train/2190.png   \n",
            "  inflating: phase4/train/2191.png   \n",
            "  inflating: phase4/train/2192.png   \n",
            "  inflating: phase4/train/2193.png   \n",
            "  inflating: phase4/train/2194.png   \n",
            "  inflating: phase4/train/2195.png   \n",
            "  inflating: phase4/train/2196.png   \n",
            "  inflating: phase4/train/2197.png   \n",
            "  inflating: phase4/train/2198.png   \n",
            "  inflating: phase4/train/2199.png   \n",
            "  inflating: phase4/train/2200.png   \n",
            "  inflating: phase4/train/2201.png   \n",
            "  inflating: phase4/train/2202.png   \n",
            "  inflating: phase4/train/2203.png   \n",
            "  inflating: phase4/train/2204.png   \n",
            "  inflating: phase4/train/2205.png   \n",
            "  inflating: phase4/train/2206.png   \n",
            "  inflating: phase4/train/2207.png   \n",
            "  inflating: phase4/train/2208.png   \n",
            "  inflating: phase4/train/2209.png   \n",
            "  inflating: phase4/train/2210.png   \n",
            "  inflating: phase4/train/2211.png   \n",
            "  inflating: phase4/train/2212.png   \n",
            "  inflating: phase4/train/2213.png   \n",
            "  inflating: phase4/train/2214.png   \n",
            "  inflating: phase4/train/2215.png   \n",
            "  inflating: phase4/train/2216.png   \n",
            "  inflating: phase4/train/2217.png   \n",
            "  inflating: phase4/train/2218.png   \n",
            "  inflating: phase4/train/2219.png   \n",
            "  inflating: phase4/train/2220.png   \n",
            "  inflating: phase4/train/2221.png   \n",
            "  inflating: phase4/train/2222.png   \n",
            "  inflating: phase4/train/2223.png   \n",
            "  inflating: phase4/train/2224.png   \n",
            "  inflating: phase4/train/2225.png   \n",
            "  inflating: phase4/train/2226.png   \n",
            "  inflating: phase4/train/2227.png   \n",
            "  inflating: phase4/train/2228.png   \n",
            "  inflating: phase4/train/2229.png   \n",
            "  inflating: phase4/train/2230.png   \n",
            "  inflating: phase4/train/2231.png   \n",
            "  inflating: phase4/train/2232.png   \n",
            "  inflating: phase4/train/2233.png   \n",
            "  inflating: phase4/train/2234.png   \n",
            "  inflating: phase4/train/2235.png   \n",
            "  inflating: phase4/train/2236.png   \n",
            "  inflating: phase4/train/2237.png   \n",
            "  inflating: phase4/train/2238.png   \n",
            "  inflating: phase4/train/2239.png   \n",
            "  inflating: phase4/train/2240.png   \n",
            "  inflating: phase4/train/2241.png   \n",
            "  inflating: phase4/train/2242.png   \n",
            "  inflating: phase4/train/2243.png   \n",
            "  inflating: phase4/train/2244.png   \n",
            "  inflating: phase4/train/2245.png   \n",
            "  inflating: phase4/train/2246.png   \n",
            "  inflating: phase4/train/2247.png   \n",
            "  inflating: phase4/train/2248.png   \n",
            "  inflating: phase4/train/2249.png   \n",
            "  inflating: phase4/train/2250.png   \n",
            "  inflating: phase4/train/2251.png   \n",
            "  inflating: phase4/train/2252.png   \n",
            "  inflating: phase4/train/2253.png   \n",
            "  inflating: phase4/train/2254.png   \n",
            "  inflating: phase4/train/2255.png   \n",
            "  inflating: phase4/train/2256.png   \n",
            "  inflating: phase4/train/2257.png   \n",
            "  inflating: phase4/train/2258.png   \n",
            "  inflating: phase4/train/2259.png   \n",
            "  inflating: phase4/train/2260.png   \n",
            "  inflating: phase4/train/2261.png   \n",
            "  inflating: phase4/train/2262.png   \n",
            "  inflating: phase4/train/2263.png   \n",
            "  inflating: phase4/train/2264.png   \n",
            "  inflating: phase4/train/2265.png   \n",
            "  inflating: phase4/train/2266.png   \n",
            "  inflating: phase4/train/2267.png   \n",
            "  inflating: phase4/train/2268.png   \n",
            "  inflating: phase4/train/2269.png   \n",
            "  inflating: phase4/train/2270.png   \n",
            "  inflating: phase4/train/2271.png   \n",
            "  inflating: phase4/train/2272.png   \n",
            "  inflating: phase4/train/2273.png   \n",
            "  inflating: phase4/train/2274.png   \n",
            "  inflating: phase4/train/2275.png   \n",
            "  inflating: phase4/train/2276.png   \n",
            "  inflating: phase4/train/2277.png   \n",
            "  inflating: phase4/train/2278.png   \n",
            "  inflating: phase4/train/2279.png   \n",
            "  inflating: phase4/train/2280.png   \n",
            "  inflating: phase4/train/2281.png   \n",
            "  inflating: phase4/train/2282.png   \n",
            "  inflating: phase4/train/2283.png   \n",
            "  inflating: phase4/train/2284.png   \n",
            "  inflating: phase4/train/2285.png   \n",
            "  inflating: phase4/train/2286.png   \n",
            "  inflating: phase4/train/2287.png   \n",
            "  inflating: phase4/train/2288.png   \n",
            "  inflating: phase4/train/2289.png   \n",
            "  inflating: phase4/train/2290.png   \n",
            "  inflating: phase4/train/2291.png   \n",
            "  inflating: phase4/train/2292.png   \n",
            "  inflating: phase4/train/2293.png   \n",
            "  inflating: phase4/train/2294.png   \n",
            "  inflating: phase4/train/2295.png   \n",
            "  inflating: phase4/train/2296.png   \n",
            "  inflating: phase4/train/2297.png   \n",
            "  inflating: phase4/train/2298.png   \n",
            "  inflating: phase4/train/2299.png   \n",
            "  inflating: phase4/train/2300.png   \n",
            "  inflating: phase4/train/2301.png   \n",
            "  inflating: phase4/train/2302.png   \n",
            "  inflating: phase4/train/2303.png   \n",
            "  inflating: phase4/train/2304.png   \n",
            "  inflating: phase4/train/2305.png   \n",
            "  inflating: phase4/train/2306.png   \n",
            "  inflating: phase4/train/2307.png   \n",
            "  inflating: phase4/train/2308.png   \n",
            "  inflating: phase4/train/2309.png   \n",
            "  inflating: phase4/train/2310.png   \n",
            "  inflating: phase4/train/2311.png   \n",
            "  inflating: phase4/train/2312.png   \n",
            "  inflating: phase4/train/2313.png   \n",
            "  inflating: phase4/train/2314.png   \n",
            "  inflating: phase4/train/2315.png   \n",
            "  inflating: phase4/train/2316.png   \n",
            "  inflating: phase4/train/2317.png   \n",
            "  inflating: phase4/train/2318.png   \n",
            "  inflating: phase4/train/2319.png   \n",
            "  inflating: phase4/train/2320.png   \n",
            "  inflating: phase4/train/2321.png   \n",
            "  inflating: phase4/train/2322.png   \n",
            "  inflating: phase4/train/2323.png   \n",
            "  inflating: phase4/train/2324.png   \n",
            "  inflating: phase4/train/2325.png   \n",
            "  inflating: phase4/train/2326.png   \n",
            "  inflating: phase4/train/2327.png   \n",
            "  inflating: phase4/train/2328.png   \n",
            "  inflating: phase4/train/2329.png   \n",
            "  inflating: phase4/train/2330.png   \n",
            "  inflating: phase4/train/2331.png   \n",
            "  inflating: phase4/train/2332.png   \n",
            "  inflating: phase4/train/2333.png   \n",
            "  inflating: phase4/train/2334.png   \n",
            "  inflating: phase4/train/2335.png   \n",
            "  inflating: phase4/train/2336.png   \n",
            "  inflating: phase4/train/2337.png   \n",
            "  inflating: phase4/train/2338.png   \n",
            "  inflating: phase4/train/2339.png   \n",
            "  inflating: phase4/train/2340.png   \n",
            "  inflating: phase4/train/2341.png   \n",
            "  inflating: phase4/train/2342.png   \n",
            "  inflating: phase4/train/2343.png   \n",
            "  inflating: phase4/train/2344.png   \n",
            "  inflating: phase4/train/2345.png   \n",
            "  inflating: phase4/train/2346.png   \n",
            "  inflating: phase4/train/2347.png   \n",
            "  inflating: phase4/train/2348.png   \n",
            "  inflating: phase4/train/2349.png   \n",
            "  inflating: phase4/train/2350.png   \n",
            "  inflating: phase4/train/2351.png   \n",
            "  inflating: phase4/train/2352.png   \n",
            "  inflating: phase4/train/2353.png   \n",
            "  inflating: phase4/train/2354.png   \n",
            "  inflating: phase4/train/2355.png   \n",
            "  inflating: phase4/train/2356.png   \n",
            "  inflating: phase4/train/2357.png   \n",
            "  inflating: phase4/train/2358.png   \n",
            "  inflating: phase4/train/2359.png   \n",
            "  inflating: phase4/train/2360.png   \n",
            "  inflating: phase4/train/2361.png   \n",
            "  inflating: phase4/train/2362.png   \n",
            "  inflating: phase4/train/2363.png   \n",
            "  inflating: phase4/train/2364.png   \n",
            "  inflating: phase4/train/2365.png   \n",
            "  inflating: phase4/train/2366.png   \n",
            "  inflating: phase4/train/2367.png   \n",
            "  inflating: phase4/train/2368.png   \n",
            "  inflating: phase4/train/2369.png   \n",
            "  inflating: phase4/train/2370.png   \n",
            "  inflating: phase4/train/2371.png   \n",
            "  inflating: phase4/train/2372.png   \n",
            "  inflating: phase4/train/2373.png   \n",
            "  inflating: phase4/train/2374.png   \n",
            "  inflating: phase4/train/2375.png   \n",
            "  inflating: phase4/train/2376.png   \n",
            "  inflating: phase4/train/2377.png   \n",
            "  inflating: phase4/train/2378.png   \n",
            "  inflating: phase4/train/2379.png   \n",
            "  inflating: phase4/train/2380.png   \n",
            "  inflating: phase4/train/2381.png   \n",
            "  inflating: phase4/train/2382.png   \n",
            "  inflating: phase4/train/2383.png   \n",
            "  inflating: phase4/train/2384.png   \n",
            "  inflating: phase4/train/2385.png   \n",
            "  inflating: phase4/train/2386.png   \n",
            "  inflating: phase4/train/2387.png   \n",
            "  inflating: phase4/train/2388.png   \n",
            "  inflating: phase4/train/2389.png   \n",
            "  inflating: phase4/train/2390.png   \n",
            "  inflating: phase4/train/2391.png   \n",
            "  inflating: phase4/train/2392.png   \n",
            "  inflating: phase4/train/2393.png   \n",
            "  inflating: phase4/train/2394.png   \n",
            "  inflating: phase4/train/2395.png   \n",
            "  inflating: phase4/train/2396.png   \n",
            "  inflating: phase4/train/2397.png   \n",
            "  inflating: phase4/train/2398.png   \n",
            "  inflating: phase4/train/2399.png   \n",
            "  inflating: phase4/train/2400.png   \n",
            "  inflating: phase4/train/2401.png   \n",
            "  inflating: phase4/train/2402.png   \n",
            "  inflating: phase4/train/2403.png   \n",
            "  inflating: phase4/train/2404.png   \n",
            "  inflating: phase4/train/2405.png   \n",
            "  inflating: phase4/train/2406.png   \n",
            "  inflating: phase4/train/2407.png   \n",
            "  inflating: phase4/train/2408.png   \n",
            "  inflating: phase4/train/2409.png   \n",
            "  inflating: phase4/train/2410.png   \n",
            "  inflating: phase4/train/2411.png   \n",
            "  inflating: phase4/train/2412.png   \n",
            "  inflating: phase4/train/2413.png   \n",
            "  inflating: phase4/train/2414.png   \n",
            "  inflating: phase4/train/2415.png   \n",
            "  inflating: phase4/train/2416.png   \n",
            "  inflating: phase4/train/2417.png   \n",
            "  inflating: phase4/train/2418.png   \n",
            "  inflating: phase4/train/2419.png   \n",
            "  inflating: phase4/train/2420.png   \n",
            "  inflating: phase4/train/2421.png   \n",
            "  inflating: phase4/train/2422.png   \n",
            "  inflating: phase4/train/2423.png   \n",
            "  inflating: phase4/train/2424.png   \n",
            "  inflating: phase4/train/2425.png   \n",
            "  inflating: phase4/train/2426.png   \n",
            "  inflating: phase4/train/2427.png   \n",
            "  inflating: phase4/train/2428.png   \n",
            "  inflating: phase4/train/2429.png   \n",
            "  inflating: phase4/train/2430.png   \n",
            "  inflating: phase4/train/2431.png   \n",
            "  inflating: phase4/train/2432.png   \n",
            "  inflating: phase4/train/2433.png   \n",
            "  inflating: phase4/train/2434.png   \n",
            "  inflating: phase4/train/2435.png   \n",
            "  inflating: phase4/train/2436.png   \n",
            "  inflating: phase4/train/2437.png   \n",
            "  inflating: phase4/train/2438.png   \n",
            "  inflating: phase4/train/2439.png   \n",
            "  inflating: phase4/train/2440.png   \n",
            "  inflating: phase4/train/2441.png   \n",
            "  inflating: phase4/train/2442.png   \n",
            "  inflating: phase4/train/2443.png   \n",
            "  inflating: phase4/train/2444.png   \n",
            "  inflating: phase4/train/2445.png   \n",
            "  inflating: phase4/train/2446.png   \n",
            "  inflating: phase4/train/2447.png   \n",
            "  inflating: phase4/train/2448.png   \n",
            "  inflating: phase4/train/2449.png   \n",
            "  inflating: phase4/train/2450.png   \n",
            "  inflating: phase4/train/2451.png   \n",
            "  inflating: phase4/train/2452.png   \n",
            "  inflating: phase4/train/2453.png   \n",
            "  inflating: phase4/train/2454.png   \n",
            "  inflating: phase4/train/2455.png   \n",
            "  inflating: phase4/train/2456.png   \n",
            "  inflating: phase4/train/2457.png   \n",
            "  inflating: phase4/train/2458.png   \n",
            "  inflating: phase4/train/2459.png   \n",
            "  inflating: phase4/train/2460.png   \n",
            "  inflating: phase4/train/2461.png   \n",
            "  inflating: phase4/train/2462.png   \n",
            "  inflating: phase4/train/2463.png   \n",
            "  inflating: phase4/train/2464.png   \n",
            "  inflating: phase4/train/2465.png   \n",
            "  inflating: phase4/train/2466.png   \n",
            "  inflating: phase4/train/2467.png   \n",
            "  inflating: phase4/train/2468.png   \n",
            "  inflating: phase4/train/2469.png   \n",
            "  inflating: phase4/train/2470.png   \n",
            "  inflating: phase4/train/2471.png   \n",
            "  inflating: phase4/train/2472.png   \n",
            "  inflating: phase4/train/2473.png   \n",
            "  inflating: phase4/train/2474.png   \n",
            "  inflating: phase4/train/2475.png   \n",
            "  inflating: phase4/train/2476.png   \n",
            "  inflating: phase4/train/2477.png   \n",
            "  inflating: phase4/train/2478.png   \n",
            "  inflating: phase4/train/2479.png   \n",
            "  inflating: phase4/train/2480.png   \n",
            "  inflating: phase4/train/2481.png   \n",
            "  inflating: phase4/train/2482.png   \n",
            "  inflating: phase4/train/2483.png   \n",
            "  inflating: phase4/train/2484.png   \n",
            "  inflating: phase4/train/2485.png   \n",
            "  inflating: phase4/train/2486.png   \n",
            "  inflating: phase4/train/2487.png   \n",
            "  inflating: phase4/train/2488.png   \n",
            "  inflating: phase4/train/2489.png   \n",
            "  inflating: phase4/train/2490.png   \n",
            "  inflating: phase4/train/2491.png   \n",
            "  inflating: phase4/train/2492.png   \n",
            "  inflating: phase4/train/2493.png   \n",
            "  inflating: phase4/train/2494.png   \n",
            "  inflating: phase4/train/2495.png   \n",
            "  inflating: phase4/train/2496.png   \n",
            "  inflating: phase4/train/2497.png   \n",
            "  inflating: phase4/train/2498.png   \n",
            "  inflating: phase4/train/2499.png   \n",
            "  inflating: phase4/train/2500.png   \n",
            "  inflating: phase4/train/2501.png   \n",
            "  inflating: phase4/train/2502.png   \n",
            "  inflating: phase4/train/2503.png   \n",
            "  inflating: phase4/train/2504.png   \n",
            "  inflating: phase4/train/2505.png   \n",
            "  inflating: phase4/train/2506.png   \n",
            "  inflating: phase4/train/2507.png   \n",
            "  inflating: phase4/train/2508.png   \n",
            "  inflating: phase4/train/2509.png   \n",
            "  inflating: phase4/train/2510.png   \n",
            "  inflating: phase4/train/2511.png   \n",
            "  inflating: phase4/train/2512.png   \n",
            "  inflating: phase4/train/2513.png   \n",
            "  inflating: phase4/train/2514.png   \n",
            "  inflating: phase4/train/2515.png   \n",
            "  inflating: phase4/train/2516.png   \n",
            "  inflating: phase4/train/2517.png   \n",
            "  inflating: phase4/train/2518.png   \n",
            "  inflating: phase4/train/2519.png   \n",
            "  inflating: phase4/train/2520.png   \n",
            "  inflating: phase4/train/2521.png   \n",
            "  inflating: phase4/train/2522.png   \n",
            "  inflating: phase4/train/2523.png   \n",
            "  inflating: phase4/train/2524.png   \n",
            "  inflating: phase4/train/2525.png   \n",
            "  inflating: phase4/train/2526.png   \n",
            "  inflating: phase4/train/2527.png   \n",
            "  inflating: phase4/train/2528.png   \n",
            "  inflating: phase4/train/2529.png   \n",
            "  inflating: phase4/train/2530.png   \n",
            "  inflating: phase4/train/2531.png   \n",
            "  inflating: phase4/train/2532.png   \n",
            "  inflating: phase4/train/2533.png   \n",
            "  inflating: phase4/train/2534.png   \n",
            "  inflating: phase4/train/2535.png   \n",
            "  inflating: phase4/train/2536.png   \n",
            "  inflating: phase4/train/2537.png   \n",
            "  inflating: phase4/train/2538.png   \n",
            "  inflating: phase4/train/2539.png   \n",
            "  inflating: phase4/train/2540.png   \n",
            "  inflating: phase4/train/2541.png   \n",
            "  inflating: phase4/train/2542.png   \n",
            "  inflating: phase4/train/2543.png   \n",
            "  inflating: phase4/train/2544.png   \n",
            "  inflating: phase4/train/2545.png   \n",
            "  inflating: phase4/train/2546.png   \n",
            "  inflating: phase4/train/2547.png   \n",
            "  inflating: phase4/train/2548.png   \n",
            "  inflating: phase4/train/2549.png   \n",
            "  inflating: phase4/train/2550.png   \n",
            "  inflating: phase4/train/2551.png   \n",
            "  inflating: phase4/train/2552.png   \n",
            "  inflating: phase4/train/2553.png   \n",
            "  inflating: phase4/train/2554.png   \n",
            "  inflating: phase4/train/2555.png   \n",
            "  inflating: phase4/train/2556.png   \n",
            "  inflating: phase4/train/2557.png   \n",
            "  inflating: phase4/train/2558.png   \n",
            "  inflating: phase4/train/2559.png   \n",
            "  inflating: phase4/train/2560.png   \n",
            "  inflating: phase4/train/2561.png   \n",
            "  inflating: phase4/train/2562.png   \n",
            "  inflating: phase4/train/2563.png   \n",
            "  inflating: phase4/train/2564.png   \n",
            "  inflating: phase4/train/2565.png   \n",
            "  inflating: phase4/train/2566.png   \n",
            "  inflating: phase4/train/2567.png   \n",
            "  inflating: phase4/train/2568.png   \n",
            "  inflating: phase4/train/2569.png   \n",
            "  inflating: phase4/train/2570.png   \n",
            "  inflating: phase4/train/2571.png   \n",
            "  inflating: phase4/train/2572.png   \n",
            "  inflating: phase4/train/2573.png   \n",
            "  inflating: phase4/train/2574.png   \n",
            "  inflating: phase4/train/2575.png   \n",
            "  inflating: phase4/train/2576.png   \n",
            "  inflating: phase4/train/2577.png   \n",
            "  inflating: phase4/train/2578.png   \n",
            "  inflating: phase4/train/2579.png   \n",
            "  inflating: phase4/train/2580.png   \n",
            "  inflating: phase4/train/2581.png   \n",
            "  inflating: phase4/train/2582.png   \n",
            "  inflating: phase4/train/2583.png   \n",
            "  inflating: phase4/train/2584.png   \n",
            "  inflating: phase4/train/2585.png   \n",
            "  inflating: phase4/train/2586.png   \n",
            "  inflating: phase4/train/2587.png   \n",
            "  inflating: phase4/train/2588.png   \n",
            "  inflating: phase4/train/2589.png   \n",
            "  inflating: phase4/train/2590.png   \n",
            "  inflating: phase4/train/2591.png   \n",
            "  inflating: phase4/train/2592.png   \n",
            "  inflating: phase4/train/2593.png   \n",
            "  inflating: phase4/train/2594.png   \n",
            "  inflating: phase4/train/2595.png   \n",
            "  inflating: phase4/train/2596.png   \n",
            "  inflating: phase4/train/2597.png   \n",
            "  inflating: phase4/train/2598.png   \n",
            "  inflating: phase4/train/2599.png   \n",
            "  inflating: phase4/train/2600.png   \n",
            "  inflating: phase4/train/2601.png   \n",
            "  inflating: phase4/train/2602.png   \n",
            "  inflating: phase4/train/2603.png   \n",
            "  inflating: phase4/train/2604.png   \n",
            "  inflating: phase4/train/2605.png   \n",
            "  inflating: phase4/train/2606.png   \n",
            "  inflating: phase4/train/2607.png   \n",
            "  inflating: phase4/train/2608.png   \n",
            "  inflating: phase4/train/2609.png   \n",
            "  inflating: phase4/train/2610.png   \n",
            "  inflating: phase4/train/2611.png   \n",
            "  inflating: phase4/train/2612.png   \n",
            "  inflating: phase4/train/2613.png   \n",
            "  inflating: phase4/train/2614.png   \n",
            "  inflating: phase4/train/2615.png   \n",
            "  inflating: phase4/train/2616.png   \n",
            "  inflating: phase4/train/2617.png   \n",
            "  inflating: phase4/train/2618.png   \n",
            "  inflating: phase4/train/2619.png   \n",
            "  inflating: phase4/train/2620.png   \n",
            "  inflating: phase4/train/2621.png   \n",
            "  inflating: phase4/train/2622.png   \n",
            "  inflating: phase4/train/2623.png   \n",
            "  inflating: phase4/train/2624.png   \n",
            "  inflating: phase4/train/2625.png   \n",
            "  inflating: phase4/train/2626.png   \n",
            "  inflating: phase4/train/2627.png   \n",
            "  inflating: phase4/train/2628.png   \n",
            "  inflating: phase4/train/2629.png   \n",
            "  inflating: phase4/train/2630.png   \n",
            "  inflating: phase4/train/2631.png   \n",
            "  inflating: phase4/train/2632.png   \n",
            "  inflating: phase4/train/2633.png   \n",
            "  inflating: phase4/train/2634.png   \n",
            "  inflating: phase4/train/2635.png   \n",
            "  inflating: phase4/train/2636.png   \n",
            "  inflating: phase4/train/2637.png   \n",
            "  inflating: phase4/train/2638.png   \n",
            "  inflating: phase4/train/2639.png   \n",
            "  inflating: phase4/train/2640.png   \n",
            "  inflating: phase4/train/2641.png   \n",
            "  inflating: phase4/train/2642.png   \n",
            "  inflating: phase4/train/2643.png   \n",
            "  inflating: phase4/train/2644.png   \n",
            "  inflating: phase4/train/2645.png   \n",
            "  inflating: phase4/train/2646.png   \n",
            "  inflating: phase4/train/2647.png   \n",
            "  inflating: phase4/train/2648.png   \n",
            "  inflating: phase4/train/2649.png   \n",
            "  inflating: phase4/train/2650.png   \n",
            "  inflating: phase4/train/2651.png   \n",
            "  inflating: phase4/train/2652.png   \n",
            "  inflating: phase4/train/2653.png   \n",
            "  inflating: phase4/train/2654.png   \n",
            "  inflating: phase4/train/2655.png   \n",
            "  inflating: phase4/train/2656.png   \n",
            "  inflating: phase4/train/2657.png   \n",
            "  inflating: phase4/train/2658.png   \n",
            "  inflating: phase4/train/2659.png   \n",
            "  inflating: phase4/train/2660.png   \n",
            "  inflating: phase4/train/2661.png   \n",
            "  inflating: phase4/train/2662.png   \n",
            "  inflating: phase4/train/2663.png   \n",
            "  inflating: phase4/train/2664.png   \n",
            "  inflating: phase4/train/2665.png   \n",
            "  inflating: phase4/train/2666.png   \n",
            "  inflating: phase4/train/2667.png   \n",
            "  inflating: phase4/train/2668.png   \n",
            "  inflating: phase4/train/2669.png   \n",
            "  inflating: phase4/train/2670.png   \n",
            "  inflating: phase4/train/2671.png   \n",
            "  inflating: phase4/train/2672.png   \n",
            "  inflating: phase4/train/2673.png   \n",
            "  inflating: phase4/train/2674.png   \n",
            "  inflating: phase4/train/2675.png   \n",
            "  inflating: phase4/train/2676.png   \n",
            "  inflating: phase4/train/2677.png   \n",
            "  inflating: phase4/train/2678.png   \n",
            "  inflating: phase4/train/2679.png   \n",
            "  inflating: phase4/train/2680.png   \n",
            "  inflating: phase4/train/2681.png   \n",
            "  inflating: phase4/train/2682.png   \n",
            "  inflating: phase4/train/2683.png   \n",
            "  inflating: phase4/train/2684.png   \n",
            "  inflating: phase4/train/2685.png   \n",
            "  inflating: phase4/train/2686.png   \n",
            "  inflating: phase4/train/2687.png   \n",
            "  inflating: phase4/train/2688.png   \n",
            "  inflating: phase4/train/2689.png   \n",
            "  inflating: phase4/train/2690.png   \n",
            "  inflating: phase4/train/2691.png   \n",
            "  inflating: phase4/train/2692.png   \n",
            "  inflating: phase4/train/2693.png   \n",
            "  inflating: phase4/train/2694.png   \n",
            "  inflating: phase4/train/2695.png   \n",
            "  inflating: phase4/train/2696.png   \n",
            "  inflating: phase4/train/2697.png   \n",
            "  inflating: phase4/train/2698.png   \n",
            "  inflating: phase4/train/2699.png   \n",
            "  inflating: phase4/train/2700.png   \n",
            "  inflating: phase4/train/2701.png   \n",
            "  inflating: phase4/train/2702.png   \n",
            "  inflating: phase4/train/2703.png   \n",
            "  inflating: phase4/train/2704.png   \n",
            "  inflating: phase4/train/2705.png   \n",
            "  inflating: phase4/train/2706.png   \n",
            "  inflating: phase4/train/2707.png   \n",
            "  inflating: phase4/train/2708.png   \n",
            "  inflating: phase4/train/2709.png   \n",
            "  inflating: phase4/train/2710.png   \n",
            "  inflating: phase4/train/2711.png   \n",
            "  inflating: phase4/train/2712.png   \n",
            "  inflating: phase4/train/2713.png   \n",
            "  inflating: phase4/train/2714.png   \n",
            "  inflating: phase4/train/2715.png   \n",
            "  inflating: phase4/train/2716.png   \n",
            "  inflating: phase4/train/2717.png   \n",
            "  inflating: phase4/train/2718.png   \n",
            "  inflating: phase4/train/2719.png   \n",
            "  inflating: phase4/train/2720.png   \n",
            "  inflating: phase4/train/2721.png   \n",
            "  inflating: phase4/train/2722.png   \n",
            "  inflating: phase4/train/2723.png   \n",
            "  inflating: phase4/train/2724.png   \n",
            "  inflating: phase4/train/2725.png   \n",
            "  inflating: phase4/train/2726.png   \n",
            "  inflating: phase4/train/2727.png   \n",
            "  inflating: phase4/train/2728.png   \n",
            "  inflating: phase4/train/2729.png   \n",
            "  inflating: phase4/train/2730.png   \n",
            "  inflating: phase4/train/2731.png   \n",
            "  inflating: phase4/train/2732.png   \n",
            "  inflating: phase4/train/2733.png   \n",
            "  inflating: phase4/train/2734.png   \n",
            "  inflating: phase4/train/2735.png   \n",
            "  inflating: phase4/train/2736.png   \n",
            "  inflating: phase4/train/2737.png   \n",
            "  inflating: phase4/train/2738.png   \n",
            "  inflating: phase4/train/2739.png   \n",
            "  inflating: phase4/train/2740.png   \n",
            "  inflating: phase4/train/2741.png   \n",
            "  inflating: phase4/train/2742.png   \n",
            "  inflating: phase4/train/2743.png   \n",
            "  inflating: phase4/train/2744.png   \n",
            "  inflating: phase4/train/2745.png   \n",
            "  inflating: phase4/train/2746.png   \n",
            "  inflating: phase4/train/2747.png   \n",
            "  inflating: phase4/train/2748.png   \n",
            "  inflating: phase4/train/2749.png   \n",
            "  inflating: phase4/train/2750.png   \n",
            "  inflating: phase4/train/2751.png   \n",
            "  inflating: phase4/train/2752.png   \n",
            "  inflating: phase4/train/2753.png   \n",
            "  inflating: phase4/train/2754.png   \n",
            "  inflating: phase4/train/2755.png   \n",
            "  inflating: phase4/train/2756.png   \n",
            "  inflating: phase4/train/2757.png   \n",
            "  inflating: phase4/train/2758.png   \n",
            "  inflating: phase4/train/2759.png   \n",
            "  inflating: phase4/train/2760.png   \n",
            "  inflating: phase4/train/2761.png   \n",
            "  inflating: phase4/train/2762.png   \n",
            "  inflating: phase4/train/2763.png   \n",
            "  inflating: phase4/train/2764.png   \n",
            "  inflating: phase4/train/2765.png   \n",
            "  inflating: phase4/train/2766.png   \n",
            "  inflating: phase4/train/2767.png   \n",
            "  inflating: phase4/train/2768.png   \n",
            "  inflating: phase4/train/2769.png   \n",
            "  inflating: phase4/train/2770.png   \n",
            "  inflating: phase4/train/2771.png   \n",
            "  inflating: phase4/train/2772.png   \n",
            "  inflating: phase4/train/2773.png   \n",
            "  inflating: phase4/train/2774.png   \n",
            "  inflating: phase4/train/2775.png   \n",
            "  inflating: phase4/train/2776.png   \n",
            "  inflating: phase4/train/2777.png   \n",
            "  inflating: phase4/train/2778.png   \n",
            "  inflating: phase4/train/2779.png   \n",
            "  inflating: phase4/train/2780.png   \n",
            "  inflating: phase4/train/2781.png   \n",
            "  inflating: phase4/train/2782.png   \n",
            "  inflating: phase4/train/2783.png   \n",
            "  inflating: phase4/train/2784.png   \n",
            "  inflating: phase4/train/2785.png   \n",
            "  inflating: phase4/train/2786.png   \n",
            "  inflating: phase4/train/2787.png   \n",
            "  inflating: phase4/train/2788.png   \n",
            "  inflating: phase4/train/2789.png   \n",
            "  inflating: phase4/train/2790.png   \n",
            "  inflating: phase4/train/2791.png   \n",
            "  inflating: phase4/train/2792.png   \n",
            "  inflating: phase4/train/2793.png   \n",
            "  inflating: phase4/train/2794.png   \n",
            "  inflating: phase4/train/2795.png   \n",
            "  inflating: phase4/train/2796.png   \n",
            "  inflating: phase4/train/2797.png   \n",
            "  inflating: phase4/train/2798.png   \n",
            "  inflating: phase4/train/2799.png   \n",
            "  inflating: phase4/train/2800.png   \n",
            "  inflating: phase4/train/2801.png   \n",
            "  inflating: phase4/train/2802.png   \n",
            "  inflating: phase4/train/2803.png   \n",
            "  inflating: phase4/train/2804.png   \n",
            "  inflating: phase4/train/2805.png   \n",
            "  inflating: phase4/train/2806.png   \n",
            "  inflating: phase4/train/2807.png   \n",
            "  inflating: phase4/train/2808.png   \n",
            "  inflating: phase4/train/2809.png   \n",
            "  inflating: phase4/train/2810.png   \n",
            "  inflating: phase4/train/2811.png   \n",
            "  inflating: phase4/train/2812.png   \n",
            "  inflating: phase4/train/2813.png   \n",
            "  inflating: phase4/train/2814.png   \n",
            "  inflating: phase4/train/2815.png   \n",
            "  inflating: phase4/train/2816.png   \n",
            "  inflating: phase4/train/2817.png   \n",
            "  inflating: phase4/train/2818.png   \n",
            "  inflating: phase4/train/2819.png   \n",
            "  inflating: phase4/train/2820.png   \n",
            "  inflating: phase4/train/2821.png   \n",
            "  inflating: phase4/train/2822.png   \n",
            "  inflating: phase4/train/2823.png   \n",
            "  inflating: phase4/train/2824.png   \n",
            "  inflating: phase4/train/2825.png   \n",
            "  inflating: phase4/train/2826.png   \n",
            "  inflating: phase4/train/2827.png   \n",
            "  inflating: phase4/train/2828.png   \n",
            "  inflating: phase4/train/2829.png   \n",
            "  inflating: phase4/train/2830.png   \n",
            "  inflating: phase4/train/2831.png   \n",
            "  inflating: phase4/train/2832.png   \n",
            "  inflating: phase4/train/2833.png   \n",
            "  inflating: phase4/train/2834.png   \n",
            "  inflating: phase4/train/2835.png   \n",
            "  inflating: phase4/train/2836.png   \n",
            "  inflating: phase4/train/2837.png   \n",
            "  inflating: phase4/train/2838.png   \n",
            "  inflating: phase4/train/2839.png   \n",
            "  inflating: phase4/train/2840.png   \n",
            "  inflating: phase4/train/2841.png   \n",
            "  inflating: phase4/train/2842.png   \n",
            "  inflating: phase4/train/2843.png   \n",
            "  inflating: phase4/train/2844.png   \n",
            "  inflating: phase4/train/2845.png   \n",
            "  inflating: phase4/train/2846.png   \n",
            "  inflating: phase4/train/2847.png   \n",
            "  inflating: phase4/train/2848.png   \n",
            "  inflating: phase4/train/2849.png   \n",
            "  inflating: phase4/train/2850.png   \n",
            "  inflating: phase4/train/2851.png   \n",
            "  inflating: phase4/train/2852.png   \n",
            "  inflating: phase4/train/2853.png   \n",
            "  inflating: phase4/train/2854.png   \n",
            "  inflating: phase4/train/2855.png   \n",
            "  inflating: phase4/train/2856.png   \n",
            "  inflating: phase4/train/2857.png   \n",
            "  inflating: phase4/train/2858.png   \n",
            "  inflating: phase4/train/2859.png   \n",
            "  inflating: phase4/train/2860.png   \n",
            "  inflating: phase4/train/2861.png   \n",
            "  inflating: phase4/train/2862.png   \n",
            "  inflating: phase4/train/2863.png   \n",
            "  inflating: phase4/train/2864.png   \n",
            "  inflating: phase4/train/2865.png   \n",
            "  inflating: phase4/train/2866.png   \n",
            "  inflating: phase4/train/2867.png   \n",
            "  inflating: phase4/train/2868.png   \n",
            "  inflating: phase4/train/2869.png   \n",
            "  inflating: phase4/train/2870.png   \n",
            "  inflating: phase4/train/2871.png   \n",
            "  inflating: phase4/train/2872.png   \n",
            "  inflating: phase4/train/2873.png   \n",
            "  inflating: phase4/train/2874.png   \n",
            "  inflating: phase4/train/2875.png   \n",
            "  inflating: phase4/train/2876.png   \n",
            "  inflating: phase4/train/2877.png   \n",
            "  inflating: phase4/train/2878.png   \n",
            "  inflating: phase4/train/2879.png   \n",
            "  inflating: phase4/train/2880.png   \n",
            "  inflating: phase4/train/2881.png   \n",
            "  inflating: phase4/train/2882.png   \n",
            "  inflating: phase4/train/2883.png   \n",
            "  inflating: phase4/train/2884.png   \n",
            "  inflating: phase4/train/2885.png   \n",
            "  inflating: phase4/train/2886.png   \n",
            "  inflating: phase4/train/2887.png   \n",
            "  inflating: phase4/train/2888.png   \n",
            "  inflating: phase4/train/2889.png   \n",
            "  inflating: phase4/train/2890.png   \n",
            "  inflating: phase4/train/2891.png   \n",
            "  inflating: phase4/train/2892.png   \n",
            "  inflating: phase4/train/2893.png   \n",
            "  inflating: phase4/train/2894.png   \n",
            "  inflating: phase4/train/2895.png   \n",
            "  inflating: phase4/train/2896.png   \n",
            "  inflating: phase4/train/2897.png   \n",
            "  inflating: phase4/train/2898.png   \n",
            "  inflating: phase4/train/2899.png   \n",
            "  inflating: phase4/train/2900.png   \n",
            "  inflating: phase4/train/2901.png   \n",
            "  inflating: phase4/train/2902.png   \n",
            "  inflating: phase4/train/2903.png   \n",
            "  inflating: phase4/train/2904.png   \n",
            "  inflating: phase4/train/2905.png   \n",
            "  inflating: phase4/train/2906.png   \n",
            "  inflating: phase4/train/2907.png   \n",
            "  inflating: phase4/train/2908.png   \n",
            "  inflating: phase4/train/2909.png   \n",
            "  inflating: phase4/train/2910.png   \n",
            "  inflating: phase4/train/2911.png   \n",
            "  inflating: phase4/train/2912.png   \n",
            "  inflating: phase4/train/2913.png   \n",
            "  inflating: phase4/train/2914.png   \n",
            "  inflating: phase4/train/2915.png   \n",
            "  inflating: phase4/train/2916.png   \n",
            "  inflating: phase4/train/2917.png   \n",
            "  inflating: phase4/train/2918.png   \n",
            "  inflating: phase4/train/2919.png   \n",
            "  inflating: phase4/train/2920.png   \n",
            "  inflating: phase4/train/2921.png   \n",
            "  inflating: phase4/train/2922.png   \n",
            "  inflating: phase4/train/2923.png   \n",
            "  inflating: phase4/train/2924.png   \n",
            "  inflating: phase4/train/2925.png   \n",
            "  inflating: phase4/train/2926.png   \n",
            "  inflating: phase4/train/2927.png   \n",
            "  inflating: phase4/train/2928.png   \n",
            "  inflating: phase4/train/2929.png   \n",
            "  inflating: phase4/train/2930.png   \n",
            "  inflating: phase4/train/2931.png   \n",
            "  inflating: phase4/train/2932.png   \n",
            "  inflating: phase4/train/2933.png   \n",
            "  inflating: phase4/train/2934.png   \n",
            "  inflating: phase4/train/2935.png   \n",
            "  inflating: phase4/train/2936.png   \n",
            "  inflating: phase4/train/2937.png   \n",
            "  inflating: phase4/train/2938.png   \n",
            "  inflating: phase4/train/2939.png   \n",
            "  inflating: phase4/train/2940.png   \n",
            "  inflating: phase4/train/2941.png   \n",
            "  inflating: phase4/train/2942.png   \n",
            "  inflating: phase4/train/2943.png   \n",
            "  inflating: phase4/train/2944.png   \n",
            "  inflating: phase4/train/2945.png   \n",
            "  inflating: phase4/train/2946.png   \n",
            "  inflating: phase4/train/2947.png   \n",
            "  inflating: phase4/train/2948.png   \n",
            "  inflating: phase4/train/2949.png   \n",
            "  inflating: phase4/train/2950.png   \n",
            "  inflating: phase4/train/2951.png   \n",
            "  inflating: phase4/train/2952.png   \n",
            "  inflating: phase4/train/2953.png   \n",
            "  inflating: phase4/train/2954.png   \n",
            "  inflating: phase4/train/2955.png   \n",
            "  inflating: phase4/train/2956.png   \n",
            "  inflating: phase4/train/2957.png   \n",
            "  inflating: phase4/train/2958.png   \n",
            "  inflating: phase4/train/2959.png   \n",
            "  inflating: phase4/train/2960.png   \n",
            "  inflating: phase4/train/2961.png   \n",
            "  inflating: phase4/train/2962.png   \n",
            "  inflating: phase4/train/2963.png   \n",
            "  inflating: phase4/train/2964.png   \n",
            "  inflating: phase4/train/2965.png   \n",
            "  inflating: phase4/train/2966.png   \n",
            "  inflating: phase4/train/2967.png   \n",
            "  inflating: phase4/train/2968.png   \n",
            "  inflating: phase4/train/2969.png   \n",
            "  inflating: phase4/train/2970.png   \n",
            "  inflating: phase4/train/2971.png   \n",
            "  inflating: phase4/train/2972.png   \n",
            "  inflating: phase4/train/2973.png   \n",
            "  inflating: phase4/train/2974.png   \n",
            "  inflating: phase4/train/2975.png   \n",
            "  inflating: phase4/train/2976.png   \n",
            "  inflating: phase4/train/2977.png   \n",
            "  inflating: phase4/train/2978.png   \n",
            "  inflating: phase4/train/2979.png   \n",
            "  inflating: phase4/train/2980.png   \n",
            "  inflating: phase4/train/2981.png   \n",
            "  inflating: phase4/train/2982.png   \n",
            "  inflating: phase4/train/2983.png   \n",
            "  inflating: phase4/train/2984.png   \n",
            "  inflating: phase4/train/2985.png   \n",
            "  inflating: phase4/train/2986.png   \n",
            "  inflating: phase4/train/2987.png   \n",
            "  inflating: phase4/train/2988.png   \n",
            "  inflating: phase4/train/2989.png   \n",
            "  inflating: phase4/train/2990.png   \n",
            "  inflating: phase4/train/2991.png   \n",
            "  inflating: phase4/train/2992.png   \n",
            "  inflating: phase4/train/2993.png   \n",
            "  inflating: phase4/train/2994.png   \n",
            "  inflating: phase4/train/2995.png   \n",
            "  inflating: phase4/train/2996.png   \n",
            "  inflating: phase4/train/2997.png   \n",
            "  inflating: phase4/train/2998.png   \n",
            "  inflating: phase4/train/2999.png   \n",
            "  inflating: phase4/train/3000.png   \n",
            "  inflating: phase4/train/3001.png   \n",
            "  inflating: phase4/train/3002.png   \n",
            "  inflating: phase4/train/3003.png   \n",
            "  inflating: phase4/train/3004.png   \n",
            "  inflating: phase4/train/3005.png   \n",
            "  inflating: phase4/train/3006.png   \n",
            "  inflating: phase4/train/3007.png   \n",
            "  inflating: phase4/train/3008.png   \n",
            "  inflating: phase4/train/3009.png   \n",
            "  inflating: phase4/train/3010.png   \n",
            "  inflating: phase4/train/3011.png   \n",
            "  inflating: phase4/train/3012.png   \n",
            "  inflating: phase4/train/3013.png   \n",
            "  inflating: phase4/train/3014.png   \n",
            "  inflating: phase4/train/3015.png   \n",
            "  inflating: phase4/train/3016.png   \n",
            "  inflating: phase4/train/3017.png   \n",
            "  inflating: phase4/train/3018.png   \n",
            "  inflating: phase4/train/3019.png   \n",
            "  inflating: phase4/train/3020.png   \n",
            "  inflating: phase4/train/3021.png   \n",
            "  inflating: phase4/train/3022.png   \n",
            "  inflating: phase4/train/3023.png   \n",
            "  inflating: phase4/train/3024.png   \n",
            "  inflating: phase4/train/3025.png   \n",
            "  inflating: phase4/train/3026.png   \n",
            "  inflating: phase4/train/3027.png   \n",
            "  inflating: phase4/train/3028.png   \n",
            "  inflating: phase4/train/3029.png   \n",
            "  inflating: phase4/train/3030.png   \n",
            "  inflating: phase4/train/3031.png   \n",
            "  inflating: phase4/train/3032.png   \n",
            "  inflating: phase4/train/3033.png   \n",
            "  inflating: phase4/train/3034.png   \n",
            "  inflating: phase4/train/3035.png   \n",
            "  inflating: phase4/train/3036.png   \n",
            "  inflating: phase4/train/3037.png   \n",
            "  inflating: phase4/train/3038.png   \n",
            "  inflating: phase4/train/3039.png   \n",
            "  inflating: phase4/train/3040.png   \n",
            "  inflating: phase4/train/3041.png   \n",
            "  inflating: phase4/train/3042.png   \n",
            "  inflating: phase4/train/3043.png   \n",
            "  inflating: phase4/train/3044.png   \n",
            "  inflating: phase4/train/3045.png   \n",
            "  inflating: phase4/train/3046.png   \n",
            "  inflating: phase4/train/3047.png   \n",
            "  inflating: phase4/train/3048.png   \n",
            "  inflating: phase4/train/3049.png   \n",
            "  inflating: phase4/train/3050.png   \n",
            "  inflating: phase4/train/3051.png   \n",
            "  inflating: phase4/train/3052.png   \n",
            "  inflating: phase4/train/3053.png   \n",
            "  inflating: phase4/train/3054.png   \n",
            "  inflating: phase4/train/3055.png   \n",
            "  inflating: phase4/train/3056.png   \n",
            "  inflating: phase4/train/3057.png   \n",
            "  inflating: phase4/train/3058.png   \n",
            "  inflating: phase4/train/3059.png   \n",
            "  inflating: phase4/train/3060.png   \n",
            "  inflating: phase4/train/3061.png   \n",
            "  inflating: phase4/train/3062.png   \n",
            "  inflating: phase4/train/3063.png   \n",
            "  inflating: phase4/train/3064.png   \n",
            "  inflating: phase4/train/3065.png   \n",
            "  inflating: phase4/train/3066.png   \n",
            "  inflating: phase4/train/3067.png   \n",
            "  inflating: phase4/train/3068.png   \n",
            "  inflating: phase4/train/3069.png   \n",
            "  inflating: phase4/train/3070.png   \n",
            "  inflating: phase4/train/3071.png   \n",
            "  inflating: phase4/train/3072.png   \n",
            "  inflating: phase4/train/3073.png   \n",
            "  inflating: phase4/train/3074.png   \n",
            "  inflating: phase4/train/3075.png   \n",
            "  inflating: phase4/train/3076.png   \n",
            "  inflating: phase4/train/3077.png   \n",
            "  inflating: phase4/train/3078.png   \n",
            "  inflating: phase4/train/3079.png   \n",
            "  inflating: phase4/train/3080.png   \n",
            "  inflating: phase4/train/3081.png   \n",
            "  inflating: phase4/train/3082.png   \n",
            "  inflating: phase4/train/3083.png   \n",
            "  inflating: phase4/train/3084.png   \n",
            "  inflating: phase4/train/3085.png   \n",
            "  inflating: phase4/train/3086.png   \n",
            "  inflating: phase4/train/3087.png   \n",
            "  inflating: phase4/train/3088.png   \n",
            "  inflating: phase4/train/3089.png   \n",
            "  inflating: phase4/train/3090.png   \n",
            "  inflating: phase4/train/3091.png   \n",
            "  inflating: phase4/train/3092.png   \n",
            "  inflating: phase4/train/3093.png   \n",
            "  inflating: phase4/train/3094.png   \n",
            "  inflating: phase4/train/3095.png   \n",
            "  inflating: phase4/train/3096.png   \n",
            "  inflating: phase4/train/3097.png   \n",
            "  inflating: phase4/train/3098.png   \n",
            "  inflating: phase4/train/3099.png   \n",
            "  inflating: phase4/train/3100.png   \n",
            "  inflating: phase4/train/3101.png   \n",
            "  inflating: phase4/train/3102.png   \n",
            "  inflating: phase4/train/3103.png   \n",
            "  inflating: phase4/train/3104.png   \n",
            "  inflating: phase4/train/3105.png   \n",
            "  inflating: phase4/train/3106.png   \n",
            "  inflating: phase4/train/3107.png   \n",
            "  inflating: phase4/train/3108.png   \n",
            "  inflating: phase4/train/3109.png   \n",
            "  inflating: phase4/train/3110.png   \n",
            "  inflating: phase4/train/3111.png   \n",
            "  inflating: phase4/train/3112.png   \n",
            "  inflating: phase4/train/3113.png   \n",
            "  inflating: phase4/train/3114.png   \n",
            "  inflating: phase4/train/3115.png   \n",
            "  inflating: phase4/train/3116.png   \n",
            "  inflating: phase4/train/3117.png   \n",
            "  inflating: phase4/train/3118.png   \n",
            "  inflating: phase4/train/3119.png   \n",
            "  inflating: phase4/train/3120.png   \n",
            "  inflating: phase4/train/3121.png   \n",
            "  inflating: phase4/train/3122.png   \n",
            "  inflating: phase4/train/3123.png   \n",
            "  inflating: phase4/train/3124.png   \n",
            "  inflating: phase4/train/3125.png   \n",
            "  inflating: phase4/train/3126.png   \n",
            "  inflating: phase4/train/3127.png   \n",
            "  inflating: phase4/train/3128.png   \n",
            "  inflating: phase4/train/3129.png   \n",
            "  inflating: phase4/train/3130.png   \n",
            "  inflating: phase4/train/3131.png   \n",
            "  inflating: phase4/train/3132.png   \n",
            "  inflating: phase4/train/3133.png   \n",
            "  inflating: phase4/train/3134.png   \n",
            "  inflating: phase4/train/3135.png   \n",
            "  inflating: phase4/train/3136.png   \n",
            "  inflating: phase4/train/3137.png   \n",
            "  inflating: phase4/train/3138.png   \n",
            "  inflating: phase4/train/3139.png   \n",
            "  inflating: phase4/train/3140.png   \n",
            "  inflating: phase4/train/3141.png   \n",
            "  inflating: phase4/train/3142.png   \n",
            "  inflating: phase4/train/3143.png   \n",
            "  inflating: phase4/train/3144.png   \n",
            "  inflating: phase4/train/3145.png   \n",
            "  inflating: phase4/train/3146.png   \n",
            "  inflating: phase4/train/3147.png   \n",
            "  inflating: phase4/train/3148.png   \n",
            "  inflating: phase4/train/3149.png   \n",
            "  inflating: phase4/train/3150.png   \n",
            "  inflating: phase4/train/3151.png   \n",
            "  inflating: phase4/train/3152.png   \n",
            "  inflating: phase4/train/3153.png   \n",
            "  inflating: phase4/train/3154.png   \n",
            "  inflating: phase4/train/3155.png   \n",
            "  inflating: phase4/train/3156.png   \n",
            "  inflating: phase4/train/3157.png   \n",
            "  inflating: phase4/train/3158.png   \n",
            "  inflating: phase4/train/3159.png   \n",
            "  inflating: phase4/train/3160.png   \n",
            "  inflating: phase4/train/3161.png   \n",
            "  inflating: phase4/train/3162.png   \n",
            "  inflating: phase4/train/3163.png   \n",
            "  inflating: phase4/train/3164.png   \n",
            "  inflating: phase4/train/3165.png   \n",
            "  inflating: phase4/train/3166.png   \n",
            "  inflating: phase4/train/3167.png   \n",
            "  inflating: phase4/train/3168.png   \n",
            "  inflating: phase4/train/3169.png   \n",
            "  inflating: phase4/train/3170.png   \n",
            "  inflating: phase4/train/3171.png   \n",
            "  inflating: phase4/train/3172.png   \n",
            "  inflating: phase4/train/3173.png   \n",
            "  inflating: phase4/train/3174.png   \n",
            "  inflating: phase4/train/3175.png   \n",
            "  inflating: phase4/train/3176.png   \n",
            "  inflating: phase4/train/3177.png   \n",
            "  inflating: phase4/train/3178.png   \n",
            "  inflating: phase4/train/3179.png   \n",
            "  inflating: phase4/train/3180.png   \n",
            "  inflating: phase4/train/3181.png   \n",
            "  inflating: phase4/train/3182.png   \n",
            "  inflating: phase4/train/3183.png   \n",
            "  inflating: phase4/train/3184.png   \n",
            "  inflating: phase4/train/3185.png   \n",
            "  inflating: phase4/train/3186.png   \n",
            "  inflating: phase4/train/3187.png   \n",
            "  inflating: phase4/train/3188.png   \n",
            "  inflating: phase4/train/3189.png   \n",
            "  inflating: phase4/train/3190.png   \n",
            "  inflating: phase4/train/3191.png   \n",
            "  inflating: phase4/train/3192.png   \n",
            "  inflating: phase4/train/3193.png   \n",
            "  inflating: phase4/train/3194.png   \n",
            "  inflating: phase4/train/3195.png   \n",
            "  inflating: phase4/train/3196.png   \n",
            "  inflating: phase4/train/3197.png   \n",
            "  inflating: phase4/train/3198.png   \n",
            "  inflating: phase4/train/3199.png   \n",
            "  inflating: phase4/train/3200.png   \n",
            "  inflating: phase4/train/3201.png   \n",
            "  inflating: phase4/train/3202.png   \n",
            "  inflating: phase4/train/3203.png   \n",
            "  inflating: phase4/train/3204.png   \n",
            "  inflating: phase4/train/3205.png   \n",
            "  inflating: phase4/train/3206.png   \n",
            "  inflating: phase4/train/3207.png   \n",
            "  inflating: phase4/train/3208.png   \n",
            "  inflating: phase4/train/3209.png   \n",
            "  inflating: phase4/train/3210.png   \n",
            "  inflating: phase4/train/3211.png   \n",
            "  inflating: phase4/train/3212.png   \n",
            "  inflating: phase4/train/3213.png   \n",
            "  inflating: phase4/train/3214.png   \n",
            "  inflating: phase4/train/3215.png   \n",
            "  inflating: phase4/train/3216.png   \n",
            "  inflating: phase4/train/3217.png   \n",
            "  inflating: phase4/train/3218.png   \n",
            "  inflating: phase4/train/3219.png   \n",
            "  inflating: phase4/train/3220.png   \n",
            "  inflating: phase4/train/3221.png   \n",
            "  inflating: phase4/train/3222.png   \n",
            "  inflating: phase4/train/3223.png   \n",
            "  inflating: phase4/train/3224.png   \n",
            "  inflating: phase4/train/3225.png   \n",
            "  inflating: phase4/train/3226.png   \n",
            "  inflating: phase4/train/3227.png   \n",
            "  inflating: phase4/train/3228.png   \n",
            "  inflating: phase4/train/3229.png   \n",
            "  inflating: phase4/train/3230.png   \n",
            "  inflating: phase4/train/3231.png   \n",
            "  inflating: phase4/train/3232.png   \n",
            "  inflating: phase4/train/3233.png   \n",
            "  inflating: phase4/train/3234.png   \n",
            "  inflating: phase4/train/3235.png   \n",
            "  inflating: phase4/train/3236.png   \n",
            "  inflating: phase4/train/3237.png   \n",
            "  inflating: phase4/train/3238.png   \n",
            "  inflating: phase4/train/3239.png   \n",
            "  inflating: phase4/train/3240.png   \n",
            "  inflating: phase4/train/3241.png   \n",
            "  inflating: phase4/train/3242.png   \n",
            "  inflating: phase4/train/3243.png   \n",
            "  inflating: phase4/train/3244.png   \n",
            "  inflating: phase4/train/3245.png   \n",
            "  inflating: phase4/train/3246.png   \n",
            "  inflating: phase4/train/3247.png   \n",
            "  inflating: phase4/train/3248.png   \n",
            "  inflating: phase4/train/3249.png   \n",
            "  inflating: phase4/train/3250.png   \n",
            "  inflating: phase4/train/3251.png   \n",
            "  inflating: phase4/train/3252.png   \n",
            "  inflating: phase4/train/3253.png   \n",
            "  inflating: phase4/train/3254.png   \n",
            "  inflating: phase4/train/3255.png   \n",
            "  inflating: phase4/train/3256.png   \n",
            "  inflating: phase4/train/3257.png   \n",
            "  inflating: phase4/train/3258.png   \n",
            "  inflating: phase4/train/3259.png   \n",
            "  inflating: phase4/train/3260.png   \n",
            "  inflating: phase4/train/3261.png   \n",
            "  inflating: phase4/train/3262.png   \n",
            "  inflating: phase4/train/3263.png   \n",
            "  inflating: phase4/train/3264.png   \n",
            "  inflating: phase4/train/3265.png   \n",
            "  inflating: phase4/train/3266.png   \n",
            "  inflating: phase4/train/3267.png   \n",
            "  inflating: phase4/train/3268.png   \n",
            "  inflating: phase4/train/3269.png   \n",
            "  inflating: phase4/train/3270.png   \n",
            "  inflating: phase4/train/3271.png   \n",
            "  inflating: phase4/train/3272.png   \n",
            "  inflating: phase4/train/3273.png   \n",
            "  inflating: phase4/train/3274.png   \n",
            "  inflating: phase4/train/3275.png   \n",
            "  inflating: phase4/train/3276.png   \n",
            "  inflating: phase4/train/3277.png   \n",
            "  inflating: phase4/train/3278.png   \n",
            "  inflating: phase4/train/3279.png   \n",
            "  inflating: phase4/train/3280.png   \n",
            "  inflating: phase4/train/3281.png   \n",
            "  inflating: phase4/train/3282.png   \n",
            "  inflating: phase4/train/3283.png   \n",
            "  inflating: phase4/train/3284.png   \n",
            "  inflating: phase4/train/3285.png   \n",
            "  inflating: phase4/train/3286.png   \n",
            "  inflating: phase4/train/3287.png   \n",
            "  inflating: phase4/train/3288.png   \n",
            "  inflating: phase4/train/3289.png   \n",
            "  inflating: phase4/train/3290.png   \n",
            "  inflating: phase4/train/3291.png   \n",
            "  inflating: phase4/train/3292.png   \n",
            "  inflating: phase4/train/3293.png   \n",
            "  inflating: phase4/train/3294.png   \n",
            "  inflating: phase4/train/3295.png   \n",
            "  inflating: phase4/train/3296.png   \n",
            "  inflating: phase4/train/3297.png   \n",
            "  inflating: phase4/train/3298.png   \n",
            "  inflating: phase4/train/3299.png   \n",
            "  inflating: phase4/train/3300.png   \n",
            "  inflating: phase4/train/3301.png   \n",
            "  inflating: phase4/train/3302.png   \n",
            "  inflating: phase4/train/3303.png   \n",
            "  inflating: phase4/train/3304.png   \n",
            "  inflating: phase4/train/3305.png   \n",
            "  inflating: phase4/train/3306.png   \n",
            "  inflating: phase4/train/3307.png   \n",
            "  inflating: phase4/train/3308.png   \n",
            "  inflating: phase4/train/3309.png   \n",
            "  inflating: phase4/train/3310.png   \n",
            "  inflating: phase4/train/3311.png   \n",
            "  inflating: phase4/train/3312.png   \n",
            "  inflating: phase4/train/3313.png   \n",
            "  inflating: phase4/train/3314.png   \n",
            "  inflating: phase4/train/3315.png   \n",
            "  inflating: phase4/train/3316.png   \n",
            "  inflating: phase4/train/3317.png   \n",
            "  inflating: phase4/train/3318.png   \n",
            "  inflating: phase4/train/3319.png   \n",
            "  inflating: phase4/train/3320.png   \n",
            "  inflating: phase4/train/3321.png   \n",
            "  inflating: phase4/train/3322.png   \n",
            "  inflating: phase4/train/3323.png   \n",
            "  inflating: phase4/train/3324.png   \n",
            "  inflating: phase4/train/3325.png   \n",
            "  inflating: phase4/train/3326.png   \n",
            "  inflating: phase4/train/3327.png   \n",
            "  inflating: phase4/train/3328.png   \n",
            "  inflating: phase4/train/3329.png   \n",
            "  inflating: phase4/train/3330.png   \n",
            "  inflating: phase4/train/3331.png   \n",
            "  inflating: phase4/train/3332.png   \n",
            "  inflating: phase4/train/3333.png   \n",
            "  inflating: phase4/train/3334.png   \n",
            "  inflating: phase4/train/3335.png   \n",
            "  inflating: phase4/train/3336.png   \n",
            "  inflating: phase4/train/3337.png   \n",
            "  inflating: phase4/train/3338.png   \n",
            "  inflating: phase4/train/3339.png   \n",
            "  inflating: phase4/train/3340.png   \n",
            "  inflating: phase4/train/3341.png   \n",
            "  inflating: phase4/train/3342.png   \n",
            "  inflating: phase4/train/3343.png   \n",
            "  inflating: phase4/train/3344.png   \n",
            "  inflating: phase4/train/3345.png   \n",
            "  inflating: phase4/train/3346.png   \n",
            "  inflating: phase4/train/3347.png   \n",
            "  inflating: phase4/train/3348.png   \n",
            "  inflating: phase4/train/3349.png   \n",
            "  inflating: phase4/train/3350.png   \n",
            "  inflating: phase4/train/3351.png   \n",
            "  inflating: phase4/train/3352.png   \n",
            "  inflating: phase4/train/3353.png   \n",
            "  inflating: phase4/train/3354.png   \n",
            "  inflating: phase4/train/3355.png   \n",
            "  inflating: phase4/train/3356.png   \n",
            "  inflating: phase4/train/3357.png   \n",
            "  inflating: phase4/train/3358.png   \n",
            "  inflating: phase4/train/3359.png   \n",
            "  inflating: phase4/train/3360.png   \n",
            "  inflating: phase4/train/3361.png   \n",
            "  inflating: phase4/train/3362.png   \n",
            "  inflating: phase4/train/3363.png   \n",
            "  inflating: phase4/train/3364.png   \n",
            "  inflating: phase4/train/3365.png   \n",
            "  inflating: phase4/train/3366.png   \n",
            "  inflating: phase4/train/3367.png   \n",
            "  inflating: phase4/train/3368.png   \n",
            "  inflating: phase4/train/3369.png   \n",
            "  inflating: phase4/train/3370.png   \n",
            "  inflating: phase4/train/3371.png   \n",
            "  inflating: phase4/train/3372.png   \n",
            "  inflating: phase4/train/3373.png   \n",
            "  inflating: phase4/train/3374.png   \n",
            "  inflating: phase4/train/3375.png   \n",
            "  inflating: phase4/train/3376.png   \n",
            "  inflating: phase4/train/3377.png   \n",
            "  inflating: phase4/train/3378.png   \n",
            "  inflating: phase4/train/3379.png   \n",
            "  inflating: phase4/train/3380.png   \n",
            "  inflating: phase4/train/3381.png   \n",
            "  inflating: phase4/train/3382.png   \n",
            "  inflating: phase4/train/3383.png   \n",
            "  inflating: phase4/train/3384.png   \n",
            "  inflating: phase4/train/3385.png   \n",
            "  inflating: phase4/train/3386.png   \n",
            "  inflating: phase4/train/3387.png   \n",
            "  inflating: phase4/train/3388.png   \n",
            "  inflating: phase4/train/3389.png   \n",
            "  inflating: phase4/train/3390.png   \n",
            "  inflating: phase4/train/3391.png   \n",
            "  inflating: phase4/train/3392.png   \n",
            "  inflating: phase4/train/3393.png   \n",
            "  inflating: phase4/train/3394.png   \n",
            "  inflating: phase4/train/3395.png   \n",
            "  inflating: phase4/train/3396.png   \n",
            "  inflating: phase4/train/3397.png   \n",
            "  inflating: phase4/train/3398.png   \n",
            "  inflating: phase4/train/3399.png   \n",
            "  inflating: phase4/train/3400.png   \n",
            "  inflating: phase4/train/3401.png   \n",
            "  inflating: phase4/train/3402.png   \n",
            "  inflating: phase4/train/3403.png   \n",
            "  inflating: phase4/train/3404.png   \n",
            "  inflating: phase4/train/3405.png   \n",
            "  inflating: phase4/train/3406.png   \n",
            "  inflating: phase4/train/3407.png   \n",
            "  inflating: phase4/train/3408.png   \n",
            "  inflating: phase4/train/3409.png   \n",
            "  inflating: phase4/train/3410.png   \n",
            "  inflating: phase4/train/3411.png   \n",
            "  inflating: phase4/train/3412.png   \n",
            "  inflating: phase4/train/3413.png   \n",
            "  inflating: phase4/train/3414.png   \n",
            "  inflating: phase4/train/3415.png   \n",
            "  inflating: phase4/train/3416.png   \n",
            "  inflating: phase4/train/3417.png   \n",
            "  inflating: phase4/train/3418.png   \n",
            "  inflating: phase4/train/3419.png   \n",
            "  inflating: phase4/train/3420.png   \n",
            "  inflating: phase4/train/3421.png   \n",
            "  inflating: phase4/train/3422.png   \n",
            "  inflating: phase4/train/3423.png   \n",
            "  inflating: phase4/train/3424.png   \n",
            "  inflating: phase4/train/3425.png   \n",
            "  inflating: phase4/train/3426.png   \n",
            "  inflating: phase4/train/3427.png   \n",
            "  inflating: phase4/train/3428.png   \n",
            "  inflating: phase4/train/3429.png   \n",
            "  inflating: phase4/train/3430.png   \n",
            "  inflating: phase4/train/3431.png   \n",
            "  inflating: phase4/train/3432.png   \n",
            "  inflating: phase4/train/3433.png   \n",
            "  inflating: phase4/train/3434.png   \n",
            "  inflating: phase4/train/3435.png   \n",
            "  inflating: phase4/train/3436.png   \n",
            "  inflating: phase4/train/3437.png   \n",
            "  inflating: phase4/train/3438.png   \n",
            "  inflating: phase4/train/3439.png   \n",
            "  inflating: phase4/train/3440.png   \n",
            "  inflating: phase4/train/3441.png   \n",
            "  inflating: phase4/train/3442.png   \n",
            "  inflating: phase4/train/3443.png   \n",
            "  inflating: phase4/train/3444.png   \n",
            "  inflating: phase4/train/3445.png   \n",
            "  inflating: phase4/train/3446.png   \n",
            "  inflating: phase4/train/3447.png   \n",
            "  inflating: phase4/train/3448.png   \n",
            "  inflating: phase4/train/3449.png   \n",
            "  inflating: phase4/train/3450.png   \n",
            "  inflating: phase4/train/3451.png   \n",
            "  inflating: phase4/train/3452.png   \n",
            "  inflating: phase4/train/3453.png   \n",
            "  inflating: phase4/train/3454.png   \n",
            "  inflating: phase4/train/3455.png   \n",
            "  inflating: phase4/train/3456.png   \n",
            "  inflating: phase4/train/3457.png   \n",
            "  inflating: phase4/train/3458.png   \n",
            "  inflating: phase4/train/3459.png   \n",
            "  inflating: phase4/train/3460.png   \n",
            "  inflating: phase4/train/3461.png   \n",
            "  inflating: phase4/train/3462.png   \n",
            "  inflating: phase4/train/3463.png   \n",
            "  inflating: phase4/train/3464.png   \n",
            "  inflating: phase4/train/3465.png   \n",
            "  inflating: phase4/train/3466.png   \n",
            "  inflating: phase4/train/3467.png   \n",
            "  inflating: phase4/train/3468.png   \n",
            "  inflating: phase4/train/3469.png   \n",
            "  inflating: phase4/train/3470.png   \n",
            "  inflating: phase4/train/3471.png   \n",
            "  inflating: phase4/train/3472.png   \n",
            "  inflating: phase4/train/3473.png   \n",
            "  inflating: phase4/train/3474.png   \n",
            "  inflating: phase4/train/3475.png   \n",
            "  inflating: phase4/train/3476.png   \n",
            "  inflating: phase4/train/3477.png   \n",
            "  inflating: phase4/train/3478.png   \n",
            "  inflating: phase4/train/3479.png   \n",
            "  inflating: phase4/train/3480.png   \n",
            "  inflating: phase4/train/3481.png   \n",
            "  inflating: phase4/train/3482.png   \n",
            "  inflating: phase4/train/3483.png   \n",
            "  inflating: phase4/train/3484.png   \n",
            "  inflating: phase4/train/3485.png   \n",
            "  inflating: phase4/train/3486.png   \n",
            "  inflating: phase4/train/3487.png   \n",
            "  inflating: phase4/train/3488.png   \n",
            "  inflating: phase4/train/3489.png   \n",
            "  inflating: phase4/train/3490.png   \n",
            "  inflating: phase4/train/3491.png   \n",
            "  inflating: phase4/train/3492.png   \n",
            "  inflating: phase4/train/3493.png   \n",
            "  inflating: phase4/train/3494.png   \n",
            "  inflating: phase4/train/3495.png   \n",
            "  inflating: phase4/train/3496.png   \n",
            "  inflating: phase4/train/3497.png   \n",
            "  inflating: phase4/train/3498.png   \n",
            "  inflating: phase4/train/3499.png   \n",
            "  inflating: phase4/train/3500.png   \n",
            "  inflating: phase4/train/3501.png   \n",
            "  inflating: phase4/train/3502.png   \n",
            "  inflating: phase4/train/3503.png   \n",
            "  inflating: phase4/train/3504.png   \n",
            "  inflating: phase4/train/3505.png   \n",
            "  inflating: phase4/train/3506.png   \n",
            "  inflating: phase4/train/3507.png   \n",
            "  inflating: phase4/train/3508.png   \n",
            "  inflating: phase4/train/3509.png   \n",
            "  inflating: phase4/train/3510.png   \n",
            "  inflating: phase4/train/3511.png   \n",
            "  inflating: phase4/train/3512.png   \n",
            "  inflating: phase4/train/3513.png   \n",
            "  inflating: phase4/train/3514.png   \n",
            "  inflating: phase4/train/3515.png   \n",
            "  inflating: phase4/train/3516.png   \n",
            "  inflating: phase4/train/3517.png   \n",
            "  inflating: phase4/train/3518.png   \n",
            "  inflating: phase4/train/3519.png   \n",
            "  inflating: phase4/train/3520.png   \n",
            "  inflating: phase4/train/3521.png   \n",
            "  inflating: phase4/train/3522.png   \n",
            "  inflating: phase4/train/3523.png   \n",
            "  inflating: phase4/train/3524.png   \n",
            "  inflating: phase4/train/3525.png   \n",
            "  inflating: phase4/train/3526.png   \n",
            "  inflating: phase4/train/3527.png   \n",
            "  inflating: phase4/train/3528.png   \n",
            "  inflating: phase4/train/3529.png   \n",
            "  inflating: phase4/train/3530.png   \n",
            "  inflating: phase4/train/3531.png   \n",
            "  inflating: phase4/train/3532.png   \n",
            "  inflating: phase4/train/3533.png   \n",
            "  inflating: phase4/train/3534.png   \n",
            "  inflating: phase4/train/3535.png   \n",
            "  inflating: phase4/train/3536.png   \n",
            "  inflating: phase4/train/3537.png   \n",
            "  inflating: phase4/train/3538.png   \n",
            "  inflating: phase4/train/3539.png   \n",
            "  inflating: phase4/train/3540.png   \n",
            "  inflating: phase4/train/3541.png   \n",
            "  inflating: phase4/train/3542.png   \n",
            "  inflating: phase4/train/3543.png   \n",
            "  inflating: phase4/train/3544.png   \n",
            "  inflating: phase4/train/3545.png   \n",
            "  inflating: phase4/train/3546.png   \n",
            "  inflating: phase4/train/3547.png   \n",
            "  inflating: phase4/train/3548.png   \n",
            "  inflating: phase4/train/3549.png   \n",
            "  inflating: phase4/train/3550.png   \n",
            "  inflating: phase4/train/3551.png   \n",
            "  inflating: phase4/train/3552.png   \n",
            "  inflating: phase4/train/3553.png   \n",
            "  inflating: phase4/train/3554.png   \n",
            "  inflating: phase4/train/3555.png   \n",
            "  inflating: phase4/train/3556.png   \n",
            "  inflating: phase4/train/3557.png   \n",
            "  inflating: phase4/train/3558.png   \n",
            "  inflating: phase4/train/3559.png   \n",
            "  inflating: phase4/train/3560.png   \n",
            "  inflating: phase4/train/3561.png   \n",
            "  inflating: phase4/train/3562.png   \n",
            "  inflating: phase4/train/3563.png   \n",
            "  inflating: phase4/train/3564.png   \n",
            "  inflating: phase4/train/3565.png   \n",
            "  inflating: phase4/train/3566.png   \n",
            "  inflating: phase4/train/3567.png   \n",
            "  inflating: phase4/train/3568.png   \n",
            "  inflating: phase4/train/3569.png   \n",
            "  inflating: phase4/train/3570.png   \n",
            "  inflating: phase4/train/3571.png   \n",
            "  inflating: phase4/train/3572.png   \n",
            "  inflating: phase4/train/3573.png   \n",
            "  inflating: phase4/train/3574.png   \n",
            "  inflating: phase4/train/3575.png   \n",
            "  inflating: phase4/train/3576.png   \n",
            "  inflating: phase4/train/3577.png   \n",
            "  inflating: phase4/train/3578.png   \n",
            "  inflating: phase4/train/3579.png   \n",
            "  inflating: phase4/train/3580.png   \n",
            "  inflating: phase4/train/3581.png   \n",
            "  inflating: phase4/train/3582.png   \n",
            "  inflating: phase4/train/3583.png   \n",
            "  inflating: phase4/train/3584.png   \n",
            "  inflating: phase4/train/3585.png   \n",
            "  inflating: phase4/train/3586.png   \n",
            "  inflating: phase4/train/3587.png   \n",
            "  inflating: phase4/train/3588.png   \n",
            "  inflating: phase4/train/3589.png   \n",
            "  inflating: phase4/train/3590.png   \n",
            "  inflating: phase4/train/3591.png   \n",
            "  inflating: phase4/train/3592.png   \n",
            "  inflating: phase4/train/3593.png   \n",
            "  inflating: phase4/train/3594.png   \n",
            "  inflating: phase4/train/3595.png   \n",
            "  inflating: phase4/train/3596.png   \n",
            "  inflating: phase4/train/3597.png   \n",
            "  inflating: phase4/train/3598.png   \n",
            "  inflating: phase4/train/3599.png   \n",
            "  inflating: phase4/train/3600.png   \n",
            "  inflating: phase4/train/3601.png   \n",
            "  inflating: phase4/train/3602.png   \n",
            "  inflating: phase4/train/3603.png   \n",
            "  inflating: phase4/train/3604.png   \n",
            "  inflating: phase4/train/3605.png   \n",
            "  inflating: phase4/train/3606.png   \n",
            "  inflating: phase4/train/3607.png   \n",
            "  inflating: phase4/train/3608.png   \n",
            "  inflating: phase4/train/3609.png   \n",
            "  inflating: phase4/train/3610.png   \n",
            "  inflating: phase4/train/3611.png   \n",
            "  inflating: phase4/train/3612.png   \n",
            "  inflating: phase4/train/3613.png   \n",
            "  inflating: phase4/train/3614.png   \n",
            "  inflating: phase4/train/3615.png   \n",
            "  inflating: phase4/train/3616.png   \n",
            "  inflating: phase4/train/3617.png   \n",
            "  inflating: phase4/train/3618.png   \n",
            "  inflating: phase4/train/3619.png   \n",
            "  inflating: phase4/train/3620.png   \n",
            "  inflating: phase4/train/3621.png   \n",
            "  inflating: phase4/train/3622.png   \n",
            "  inflating: phase4/train/3623.png   \n",
            "  inflating: phase4/train/3624.png   \n",
            "  inflating: phase4/train/3625.png   \n",
            "  inflating: phase4/train/3626.png   \n",
            "  inflating: phase4/train/3627.png   \n",
            "  inflating: phase4/train/3628.png   \n",
            "  inflating: phase4/train/3629.png   \n",
            "  inflating: phase4/train/3630.png   \n",
            "  inflating: phase4/train/3631.png   \n",
            "  inflating: phase4/train/3632.png   \n",
            "  inflating: phase4/train/3633.png   \n",
            "  inflating: phase4/train/3634.png   \n",
            "  inflating: phase4/train/3635.png   \n",
            "  inflating: phase4/train/3636.png   \n",
            "  inflating: phase4/train/3637.png   \n",
            "  inflating: phase4/train/3638.png   \n",
            "  inflating: phase4/train/3639.png   \n",
            "  inflating: phase4/train/3640.png   \n",
            "  inflating: phase4/train/3641.png   \n",
            "  inflating: phase4/train/3642.png   \n",
            "  inflating: phase4/train/3643.png   \n",
            "  inflating: phase4/train/3644.png   \n",
            "  inflating: phase4/train/3645.png   \n",
            "  inflating: phase4/train/3646.png   \n",
            "  inflating: phase4/train/3647.png   \n",
            "  inflating: phase4/train/3648.png   \n",
            "  inflating: phase4/train/3649.png   \n",
            "  inflating: phase4/train/3650.png   \n",
            "  inflating: phase4/train/3651.png   \n",
            "  inflating: phase4/train/3652.png   \n",
            "  inflating: phase4/train/3653.png   \n",
            "  inflating: phase4/train/3654.png   \n",
            "  inflating: phase4/train/3655.png   \n",
            "  inflating: phase4/train/3656.png   \n",
            "  inflating: phase4/train/3657.png   \n",
            "  inflating: phase4/train/3658.png   \n",
            "  inflating: phase4/train/3659.png   \n",
            "  inflating: phase4/train/3660.png   \n",
            "  inflating: phase4/train/3661.png   \n",
            "  inflating: phase4/train/3662.png   \n",
            "  inflating: phase4/train/3663.png   \n",
            "  inflating: phase4/train/3664.png   \n",
            "  inflating: phase4/train/3665.png   \n",
            "  inflating: phase4/train/3666.png   \n",
            "  inflating: phase4/train/3667.png   \n",
            "  inflating: phase4/train/3668.png   \n",
            "  inflating: phase4/train/3669.png   \n",
            "  inflating: phase4/train/3670.png   \n",
            "  inflating: phase4/train/3671.png   \n",
            "  inflating: phase4/train/3672.png   \n",
            "  inflating: phase4/train/3673.png   \n",
            "  inflating: phase4/train/3674.png   \n",
            "  inflating: phase4/train/3675.png   \n",
            "  inflating: phase4/train/3676.png   \n",
            "  inflating: phase4/train/3677.png   \n",
            "  inflating: phase4/train/3678.png   \n",
            "  inflating: phase4/train/3679.png   \n",
            "  inflating: phase4/train/3680.png   \n",
            "  inflating: phase4/train/3681.png   \n",
            "  inflating: phase4/train/3682.png   \n",
            "  inflating: phase4/train/3683.png   \n",
            "  inflating: phase4/train/3684.png   \n",
            "  inflating: phase4/train/3685.png   \n",
            "  inflating: phase4/train/3686.png   \n",
            "  inflating: phase4/train/3687.png   \n",
            "  inflating: phase4/train/3688.png   \n",
            "  inflating: phase4/train/3689.png   \n",
            "  inflating: phase4/train/3690.png   \n",
            "  inflating: phase4/train/3691.png   \n",
            "  inflating: phase4/train/3692.png   \n",
            "  inflating: phase4/train/3693.png   \n",
            "  inflating: phase4/train/3694.png   \n",
            "  inflating: phase4/train/3695.png   \n",
            "  inflating: phase4/train/3696.png   \n",
            "  inflating: phase4/train/3697.png   \n",
            "  inflating: phase4/train/3698.png   \n",
            "  inflating: phase4/train/3699.png   \n",
            "  inflating: phase4/train/3700.png   \n",
            "  inflating: phase4/train/3701.png   \n",
            "  inflating: phase4/train/3702.png   \n",
            "  inflating: phase4/train/3703.png   \n",
            "  inflating: phase4/train/3704.png   \n",
            "  inflating: phase4/train/3705.png   \n",
            "  inflating: phase4/train/3706.png   \n",
            "  inflating: phase4/train/3707.png   \n",
            "  inflating: phase4/train/3708.png   \n",
            "  inflating: phase4/train/3709.png   \n",
            "  inflating: phase4/train/3710.png   \n",
            "  inflating: phase4/train/3711.png   \n",
            "  inflating: phase4/train/3712.png   \n",
            "  inflating: phase4/train/3713.png   \n",
            "  inflating: phase4/train/3714.png   \n",
            "  inflating: phase4/train/3715.png   \n",
            "  inflating: phase4/train/3716.png   \n",
            "  inflating: phase4/train/3717.png   \n",
            "  inflating: phase4/train/3718.png   \n",
            "  inflating: phase4/train/3719.png   \n",
            "  inflating: phase4/train/3720.png   \n",
            "  inflating: phase4/train/3721.png   \n",
            "  inflating: phase4/train/3722.png   \n",
            "  inflating: phase4/train/3723.png   \n",
            "  inflating: phase4/train/3724.png   \n",
            "  inflating: phase4/train/3725.png   \n",
            "  inflating: phase4/train/3726.png   \n",
            "  inflating: phase4/train/3727.png   \n",
            "  inflating: phase4/train/3728.png   \n",
            "  inflating: phase4/train/3729.png   \n",
            "  inflating: phase4/train/3730.png   \n",
            "  inflating: phase4/train/3731.png   \n",
            "  inflating: phase4/train/3732.png   \n",
            "  inflating: phase4/train/3733.png   \n",
            "  inflating: phase4/train/3734.png   \n",
            "  inflating: phase4/train/3735.png   \n",
            "  inflating: phase4/train/3736.png   \n",
            "  inflating: phase4/train/3737.png   \n",
            "  inflating: phase4/train/3738.png   \n",
            "  inflating: phase4/train/3739.png   \n",
            "  inflating: phase4/train/3740.png   \n",
            "  inflating: phase4/train/3741.png   \n",
            "  inflating: phase4/train/3742.png   \n",
            "  inflating: phase4/train/3743.png   \n",
            "  inflating: phase4/train/3744.png   \n",
            "  inflating: phase4/train/3745.png   \n",
            "  inflating: phase4/train/3746.png   \n",
            "  inflating: phase4/train/3747.png   \n",
            "  inflating: phase4/train/3748.png   \n",
            "  inflating: phase4/train/3749.png   \n",
            "  inflating: phase4/train/3750.png   \n",
            "  inflating: phase4/train/3751.png   \n",
            "  inflating: phase4/train/3752.png   \n",
            "  inflating: phase4/train/3753.png   \n",
            "  inflating: phase4/train/3754.png   \n",
            "  inflating: phase4/train/3755.png   \n",
            "  inflating: phase4/train/3756.png   \n",
            "  inflating: phase4/train/3757.png   \n",
            "  inflating: phase4/train/3758.png   \n",
            "  inflating: phase4/train/3759.png   \n",
            "  inflating: phase4/train/3760.png   \n",
            "  inflating: phase4/train/3761.png   \n",
            "  inflating: phase4/train/3762.png   \n",
            "  inflating: phase4/train/3763.png   \n",
            "  inflating: phase4/train/3764.png   \n",
            "  inflating: phase4/train/3765.png   \n",
            "  inflating: phase4/train/3766.png   \n",
            "  inflating: phase4/train/3767.png   \n",
            "  inflating: phase4/train/3768.png   \n",
            "  inflating: phase4/train/3769.png   \n",
            "  inflating: phase4/train/3770.png   \n",
            "  inflating: phase4/train/3771.png   \n",
            "  inflating: phase4/train/3772.png   \n",
            "  inflating: phase4/train/3773.png   \n",
            "  inflating: phase4/train/3774.png   \n",
            "  inflating: phase4/train/3775.png   \n",
            "  inflating: phase4/train/3776.png   \n",
            "  inflating: phase4/train/3777.png   \n",
            "  inflating: phase4/train/3778.png   \n",
            "  inflating: phase4/train/3779.png   \n",
            "  inflating: phase4/train/3780.png   \n",
            "  inflating: phase4/train/3781.png   \n",
            "  inflating: phase4/train/3782.png   \n",
            "  inflating: phase4/train/3783.png   \n",
            "  inflating: phase4/train/3784.png   \n",
            "  inflating: phase4/train/3785.png   \n",
            "  inflating: phase4/train/3786.png   \n",
            "  inflating: phase4/train/3787.png   \n",
            "  inflating: phase4/train/3788.png   \n",
            "  inflating: phase4/train/3789.png   \n",
            "  inflating: phase4/train/3790.png   \n",
            "  inflating: phase4/train/3791.png   \n",
            "  inflating: phase4/train/3792.png   \n",
            "  inflating: phase4/train/3793.png   \n",
            "  inflating: phase4/train/3794.png   \n",
            "  inflating: phase4/train/3795.png   \n",
            "  inflating: phase4/train/3796.png   \n",
            "  inflating: phase4/train/3797.png   \n",
            "  inflating: phase4/train/3798.png   \n",
            "  inflating: phase4/train/3799.png   \n",
            "  inflating: phase4/train/3800.png   \n",
            "  inflating: phase4/train/3801.png   \n",
            "  inflating: phase4/train/3802.png   \n",
            "  inflating: phase4/train/3803.png   \n",
            "  inflating: phase4/train/3804.png   \n",
            "  inflating: phase4/train/3805.png   \n",
            "  inflating: phase4/train/3806.png   \n",
            "  inflating: phase4/train/3807.png   \n",
            "  inflating: phase4/train/3808.png   \n",
            "  inflating: phase4/train/3809.png   \n",
            "  inflating: phase4/train/3810.png   \n",
            "  inflating: phase4/train/3811.png   \n",
            "  inflating: phase4/train/3812.png   \n",
            "  inflating: phase4/train/3813.png   \n",
            "  inflating: phase4/train/3814.png   \n",
            "  inflating: phase4/train/3815.png   \n",
            "  inflating: phase4/train/3816.png   \n",
            "  inflating: phase4/train/3817.png   \n",
            "  inflating: phase4/train/3818.png   \n",
            "  inflating: phase4/train/3819.png   \n",
            "  inflating: phase4/train/3820.png   \n",
            "  inflating: phase4/train/3821.png   \n",
            "  inflating: phase4/train/3822.png   \n",
            "  inflating: phase4/train/3823.png   \n",
            "  inflating: phase4/train/3824.png   \n",
            "  inflating: phase4/train/3825.png   \n",
            "  inflating: phase4/train/3826.png   \n",
            "  inflating: phase4/train/3827.png   \n",
            "  inflating: phase4/train/3828.png   \n",
            "  inflating: phase4/train/3829.png   \n",
            "  inflating: phase4/train/3830.png   \n",
            "  inflating: phase4/train/3831.png   \n",
            "  inflating: phase4/train/3832.png   \n",
            "  inflating: phase4/train/3833.png   \n",
            "  inflating: phase4/train/3834.png   \n",
            "  inflating: phase4/train/3835.png   \n",
            "  inflating: phase4/train/3836.png   \n",
            "  inflating: phase4/train/3837.png   \n",
            "  inflating: phase4/train/3838.png   \n",
            "  inflating: phase4/train/3839.png   \n",
            "  inflating: phase4/train/3840.png   \n",
            "  inflating: phase4/train/3841.png   \n",
            "  inflating: phase4/train/3842.png   \n",
            "  inflating: phase4/train/3843.png   \n",
            "  inflating: phase4/train/3844.png   \n",
            "  inflating: phase4/train/3845.png   \n",
            "  inflating: phase4/train/3846.png   \n",
            "  inflating: phase4/train/3847.png   \n",
            "  inflating: phase4/train/3848.png   \n",
            "  inflating: phase4/train/3849.png   \n",
            "  inflating: phase4/train/3850.png   \n",
            "  inflating: phase4/train/3851.png   \n",
            "  inflating: phase4/train/3852.png   \n",
            "  inflating: phase4/train/3853.png   \n",
            "  inflating: phase4/train/3854.png   \n",
            "  inflating: phase4/train/3855.png   \n",
            "  inflating: phase4/train/3856.png   \n",
            "  inflating: phase4/train/3857.png   \n",
            "  inflating: phase4/train/3858.png   \n",
            "  inflating: phase4/train/3859.png   \n",
            "  inflating: phase4/train/3860.png   \n",
            "  inflating: phase4/train/3861.png   \n",
            "  inflating: phase4/train/3862.png   \n",
            "  inflating: phase4/train/3863.png   \n",
            "  inflating: phase4/train/3864.png   \n",
            "  inflating: phase4/train/3865.png   \n",
            "  inflating: phase4/train/3866.png   \n",
            "  inflating: phase4/train/3867.png   \n",
            "  inflating: phase4/train/3868.png   \n",
            "  inflating: phase4/train/3869.png   \n",
            "  inflating: phase4/train/3870.png   \n",
            "  inflating: phase4/train/3871.png   \n",
            "  inflating: phase4/train/3872.png   \n",
            "  inflating: phase4/train/3873.png   \n",
            "  inflating: phase4/train/3874.png   \n",
            "  inflating: phase4/train/3875.png   \n",
            "  inflating: phase4/train/3876.png   \n",
            "  inflating: phase4/train/3877.png   \n",
            "  inflating: phase4/train/3878.png   \n",
            "  inflating: phase4/train/3879.png   \n",
            "  inflating: phase4/train/3880.png   \n",
            "  inflating: phase4/train/3881.png   \n",
            "  inflating: phase4/train/3882.png   \n",
            "  inflating: phase4/train/3883.png   \n",
            "  inflating: phase4/train/3884.png   \n",
            "  inflating: phase4/train/3885.png   \n",
            "  inflating: phase4/train/3886.png   \n",
            "  inflating: phase4/train/3887.png   \n",
            "  inflating: phase4/train/3888.png   \n",
            "  inflating: phase4/train/3889.png   \n",
            "  inflating: phase4/train/3890.png   \n",
            "  inflating: phase4/train/3891.png   \n",
            "  inflating: phase4/train/3892.png   \n",
            "  inflating: phase4/train/3893.png   \n",
            "  inflating: phase4/train/3894.png   \n",
            "  inflating: phase4/train/3895.png   \n",
            "  inflating: phase4/train/3896.png   \n",
            "  inflating: phase4/train/3897.png   \n",
            "  inflating: phase4/train/3898.png   \n",
            "  inflating: phase4/train/3899.png   \n",
            "  inflating: phase4/train/3900.png   \n",
            "  inflating: phase4/train/3901.png   \n",
            "  inflating: phase4/train/3902.png   \n",
            "  inflating: phase4/train/3903.png   \n",
            "  inflating: phase4/train/3904.png   \n",
            "  inflating: phase4/train/3905.png   \n",
            "  inflating: phase4/train/3906.png   \n",
            "  inflating: phase4/train/3907.png   \n",
            "  inflating: phase4/train/3908.png   \n",
            "  inflating: phase4/train/3909.png   \n",
            "  inflating: phase4/train/3910.png   \n",
            "  inflating: phase4/train/3911.png   \n",
            "  inflating: phase4/train/3912.png   \n",
            "  inflating: phase4/train/3913.png   \n",
            "  inflating: phase4/train/3914.png   \n",
            "  inflating: phase4/train/3915.png   \n",
            "  inflating: phase4/train/3916.png   \n",
            "  inflating: phase4/train/3917.png   \n",
            "  inflating: phase4/train/3918.png   \n",
            "  inflating: phase4/train/3919.png   \n",
            "  inflating: phase4/train/3920.png   \n",
            "  inflating: phase4/train/3921.png   \n",
            "  inflating: phase4/train/3922.png   \n",
            "  inflating: phase4/train/3923.png   \n",
            "  inflating: phase4/train/3924.png   \n",
            "  inflating: phase4/train/3925.png   \n",
            "  inflating: phase4/train/3926.png   \n",
            "  inflating: phase4/train/3927.png   \n",
            "  inflating: phase4/train/3928.png   \n",
            "  inflating: phase4/train/3929.png   \n",
            "  inflating: phase4/train/3930.png   \n",
            "  inflating: phase4/train/3931.png   \n",
            "  inflating: phase4/train/3932.png   \n",
            "  inflating: phase4/train/3933.png   \n",
            "  inflating: phase4/train/3934.png   \n",
            "  inflating: phase4/train/3935.png   \n",
            "  inflating: phase4/train/3936.png   \n",
            "  inflating: phase4/train/3937.png   \n",
            "  inflating: phase4/train/3938.png   \n",
            "  inflating: phase4/train/3939.png   \n",
            "  inflating: phase4/train/3940.png   \n",
            "  inflating: phase4/train/3941.png   \n",
            "  inflating: phase4/train/3942.png   \n",
            "  inflating: phase4/train/3943.png   \n",
            "  inflating: phase4/train/3944.png   \n",
            "  inflating: phase4/train/3945.png   \n",
            "  inflating: phase4/train/3946.png   \n",
            "  inflating: phase4/train/3947.png   \n",
            "  inflating: phase4/train/3948.png   \n",
            "  inflating: phase4/train/3949.png   \n",
            "  inflating: phase4/train/3950.png   \n",
            "  inflating: phase4/train/3951.png   \n",
            "  inflating: phase4/train/3952.png   \n",
            "  inflating: phase4/train/3953.png   \n",
            "  inflating: phase4/train/3954.png   \n",
            "  inflating: phase4/train/3955.png   \n",
            "  inflating: phase4/train/3956.png   \n",
            "  inflating: phase4/train/3957.png   \n",
            "  inflating: phase4/train/3958.png   \n",
            "  inflating: phase4/train/3959.png   \n",
            "  inflating: phase4/train/3960.png   \n",
            "  inflating: phase4/train/3961.png   \n",
            "  inflating: phase4/train/3962.png   \n",
            "  inflating: phase4/train/3963.png   \n",
            "  inflating: phase4/train/3964.png   \n",
            "  inflating: phase4/train/3965.png   \n",
            "  inflating: phase4/train/3966.png   \n",
            "  inflating: phase4/train/3967.png   \n",
            "  inflating: phase4/train/3968.png   \n",
            "  inflating: phase4/train/3969.png   \n",
            "  inflating: phase4/train/3970.png   \n",
            "  inflating: phase4/train/3971.png   \n",
            "  inflating: phase4/train/3972.png   \n",
            "  inflating: phase4/train/3973.png   \n",
            "  inflating: phase4/train/3974.png   \n",
            "  inflating: phase4/train/3975.png   \n",
            "  inflating: phase4/train/3976.png   \n",
            "  inflating: phase4/train/3977.png   \n",
            "  inflating: phase4/train/3978.png   \n",
            "  inflating: phase4/train/3979.png   \n",
            "  inflating: phase4/train/3980.png   \n",
            "  inflating: phase4/train/3981.png   \n",
            "  inflating: phase4/train/3982.png   \n",
            "  inflating: phase4/train/3983.png   \n",
            "  inflating: phase4/train/3984.png   \n",
            "  inflating: phase4/train/3985.png   \n",
            "  inflating: phase4/train/3986.png   \n",
            "  inflating: phase4/train/3987.png   \n",
            "  inflating: phase4/train/3988.png   \n",
            "  inflating: phase4/train/3989.png   \n",
            "  inflating: phase4/train/3990.png   \n",
            "  inflating: phase4/train/3991.png   \n",
            "  inflating: phase4/train/3992.png   \n",
            "  inflating: phase4/train/3993.png   \n",
            "  inflating: phase4/train/3994.png   \n",
            "  inflating: phase4/train/3995.png   \n",
            "  inflating: phase4/train/3996.png   \n",
            "  inflating: phase4/train/3997.png   \n",
            "  inflating: phase4/train/3998.png   \n",
            "  inflating: phase4/train/3999.png   \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TRm-USlsHgEV"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "Pt3igws3eiVp"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.chdir('pytorch-CycleGAN-and-pix2pix/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "z1EySlOXwwoa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e3e7d205-4aa0-4a89-adab-c093b88bfac3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 1)) (1.11.0+cu113)\n",
            "Requirement already satisfied: torchvision>=0.5.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 2)) (0.12.0+cu113)\n",
            "Collecting dominate>=2.4.0\n",
            "  Downloading dominate-2.6.0-py2.py3-none-any.whl (29 kB)\n",
            "Collecting visdom>=0.1.8.8\n",
            "  Downloading visdom-0.1.8.9.tar.gz (676 kB)\n",
            "\u001b[K     |████████████████████████████████| 676 kB 11.1 MB/s \n",
            "\u001b[?25hCollecting wandb\n",
            "  Downloading wandb-0.12.16-py2.py3-none-any.whl (1.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.8 MB 48.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.4.0->-r requirements.txt (line 1)) (4.2.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision>=0.5.0->-r requirements.txt (line 2)) (7.1.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision>=0.5.0->-r requirements.txt (line 2)) (1.21.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchvision>=0.5.0->-r requirements.txt (line 2)) (2.23.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from visdom>=0.1.8.8->-r requirements.txt (line 4)) (1.4.1)\n",
            "Requirement already satisfied: tornado in /usr/local/lib/python3.7/dist-packages (from visdom>=0.1.8.8->-r requirements.txt (line 4)) (5.1.1)\n",
            "Requirement already satisfied: pyzmq in /usr/local/lib/python3.7/dist-packages (from visdom>=0.1.8.8->-r requirements.txt (line 4)) (22.3.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from visdom>=0.1.8.8->-r requirements.txt (line 4)) (1.15.0)\n",
            "Collecting jsonpatch\n",
            "  Downloading jsonpatch-1.32-py2.py3-none-any.whl (12 kB)\n",
            "Collecting torchfile\n",
            "  Downloading torchfile-0.1.0.tar.gz (5.2 kB)\n",
            "Collecting websocket-client\n",
            "  Downloading websocket_client-1.3.2-py3-none-any.whl (54 kB)\n",
            "\u001b[K     |████████████████████████████████| 54 kB 2.8 MB/s \n",
            "\u001b[?25hCollecting pathtools\n",
            "  Downloading pathtools-0.1.2.tar.gz (11 kB)\n",
            "Collecting shortuuid>=0.5.0\n",
            "  Downloading shortuuid-1.0.9-py3-none-any.whl (9.4 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from wandb->-r requirements.txt (line 5)) (57.4.0)\n",
            "Collecting docker-pycreds>=0.4.0\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Requirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.7/dist-packages (from wandb->-r requirements.txt (line 5)) (7.1.2)\n",
            "Requirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.7/dist-packages (from wandb->-r requirements.txt (line 5)) (2.3)\n",
            "Collecting GitPython>=1.0.0\n",
            "  Downloading GitPython-3.1.27-py3-none-any.whl (181 kB)\n",
            "\u001b[K     |████████████████████████████████| 181 kB 68.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from wandb->-r requirements.txt (line 5)) (3.17.3)\n",
            "Collecting setproctitle\n",
            "  Downloading setproctitle-1.2.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (29 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.7/dist-packages (from wandb->-r requirements.txt (line 5)) (2.8.2)\n",
            "Collecting sentry-sdk>=1.0.0\n",
            "  Downloading sentry_sdk-1.5.12-py2.py3-none-any.whl (145 kB)\n",
            "\u001b[K     |████████████████████████████████| 145 kB 69.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb->-r requirements.txt (line 5)) (5.4.8)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from wandb->-r requirements.txt (line 5)) (3.13)\n",
            "Collecting gitdb<5,>=4.0.1\n",
            "  Downloading gitdb-4.0.9-py3-none-any.whl (63 kB)\n",
            "\u001b[K     |████████████████████████████████| 63 kB 2.2 MB/s \n",
            "\u001b[?25hCollecting smmap<6,>=3.0.1\n",
            "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision>=0.5.0->-r requirements.txt (line 2)) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision>=0.5.0->-r requirements.txt (line 2)) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision>=0.5.0->-r requirements.txt (line 2)) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision>=0.5.0->-r requirements.txt (line 2)) (2.10)\n",
            "Collecting jsonpointer>=1.9\n",
            "  Downloading jsonpointer-2.3-py2.py3-none-any.whl (7.8 kB)\n",
            "Building wheels for collected packages: visdom, pathtools, torchfile\n",
            "  Building wheel for visdom (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for visdom: filename=visdom-0.1.8.9-py3-none-any.whl size=655250 sha256=dabedf9b071d06db8d38e9398d85f92a98b753562621571fe615fb1c01555777\n",
            "  Stored in directory: /root/.cache/pip/wheels/2d/d1/9b/cde923274eac9cbb6ff0d8c7c72fe30a3da9095a38fd50bbf1\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8806 sha256=788d04c3ac277cfe51237e86e108618e4c25f70bda45d790c2b8ee397856d9fc\n",
            "  Stored in directory: /root/.cache/pip/wheels/3e/31/09/fa59cef12cdcfecc627b3d24273699f390e71828921b2cbba2\n",
            "  Building wheel for torchfile (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torchfile: filename=torchfile-0.1.0-py3-none-any.whl size=5709 sha256=322d25c942d932ab36fe876929f5a1d52ccd0f0e671d167c80de1943ad6363df\n",
            "  Stored in directory: /root/.cache/pip/wheels/ac/5c/3a/a80e1c65880945c71fd833408cd1e9a8cb7e2f8f37620bb75b\n",
            "Successfully built visdom pathtools torchfile\n",
            "Installing collected packages: smmap, jsonpointer, gitdb, websocket-client, torchfile, shortuuid, setproctitle, sentry-sdk, pathtools, jsonpatch, GitPython, docker-pycreds, wandb, visdom, dominate\n",
            "Successfully installed GitPython-3.1.27 docker-pycreds-0.4.0 dominate-2.6.0 gitdb-4.0.9 jsonpatch-1.32 jsonpointer-2.3 pathtools-0.1.2 sentry-sdk-1.5.12 setproctitle-1.2.3 shortuuid-1.0.9 smmap-5.0.0 torchfile-0.1.0 visdom-0.1.8.9 wandb-0.12.16 websocket-client-1.3.2\n"
          ]
        }
      ],
      "source": [
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8daqlgVhw29P"
      },
      "source": [
        "# Datasets\n",
        "\n",
        "Download one of the official datasets with:\n",
        "\n",
        "-   `bash ./datasets/download_pix2pix_dataset.sh [cityscapes, night2day, edges2handbags, edges2shoes, facades, maps]`\n",
        "\n",
        "Or use your own dataset by creating the appropriate folders and adding in the images. Follow the instructions [here](https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix/blob/master/docs/datasets.md#pix2pix-datasets)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "vrdOettJxaCc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7a7ec008-0964-48ef-9e96-e9ff5da71ae1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Specified [facades]\n",
            "WARNING: timestamping does nothing in combination with -O. See the manual\n",
            "for details.\n",
            "\n",
            "--2022-05-11 07:06:57--  http://efrosgans.eecs.berkeley.edu/pix2pix/datasets/facades.tar.gz\n",
            "Resolving efrosgans.eecs.berkeley.edu (efrosgans.eecs.berkeley.edu)... 128.32.244.190\n",
            "Connecting to efrosgans.eecs.berkeley.edu (efrosgans.eecs.berkeley.edu)|128.32.244.190|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 30168306 (29M) [application/x-gzip]\n",
            "Saving to: ‘./datasets/facades.tar.gz’\n",
            "\n",
            "./datasets/facades. 100%[===================>]  28.77M  3.14MB/s    in 9.7s    \n",
            "\n",
            "2022-05-11 07:07:07 (2.96 MB/s) - ‘./datasets/facades.tar.gz’ saved [30168306/30168306]\n",
            "\n",
            "facades/\n",
            "facades/test/\n",
            "facades/test/27.jpg\n",
            "facades/test/5.jpg\n",
            "facades/test/72.jpg\n",
            "facades/test/1.jpg\n",
            "facades/test/10.jpg\n",
            "facades/test/100.jpg\n",
            "facades/test/101.jpg\n",
            "facades/test/102.jpg\n",
            "facades/test/103.jpg\n",
            "facades/test/104.jpg\n",
            "facades/test/105.jpg\n",
            "facades/test/106.jpg\n",
            "facades/test/11.jpg\n",
            "facades/test/12.jpg\n",
            "facades/test/13.jpg\n",
            "facades/test/14.jpg\n",
            "facades/test/15.jpg\n",
            "facades/test/16.jpg\n",
            "facades/test/17.jpg\n",
            "facades/test/18.jpg\n",
            "facades/test/19.jpg\n",
            "facades/test/2.jpg\n",
            "facades/test/20.jpg\n",
            "facades/test/21.jpg\n",
            "facades/test/22.jpg\n",
            "facades/test/23.jpg\n",
            "facades/test/24.jpg\n",
            "facades/test/25.jpg\n",
            "facades/test/26.jpg\n",
            "facades/test/50.jpg\n",
            "facades/test/51.jpg\n",
            "facades/test/52.jpg\n",
            "facades/test/53.jpg\n",
            "facades/test/54.jpg\n",
            "facades/test/55.jpg\n",
            "facades/test/56.jpg\n",
            "facades/test/57.jpg\n",
            "facades/test/58.jpg\n",
            "facades/test/59.jpg\n",
            "facades/test/6.jpg\n",
            "facades/test/60.jpg\n",
            "facades/test/61.jpg\n",
            "facades/test/62.jpg\n",
            "facades/test/63.jpg\n",
            "facades/test/64.jpg\n",
            "facades/test/65.jpg\n",
            "facades/test/66.jpg\n",
            "facades/test/67.jpg\n",
            "facades/test/68.jpg\n",
            "facades/test/69.jpg\n",
            "facades/test/7.jpg\n",
            "facades/test/70.jpg\n",
            "facades/test/71.jpg\n",
            "facades/test/73.jpg\n",
            "facades/test/74.jpg\n",
            "facades/test/75.jpg\n",
            "facades/test/76.jpg\n",
            "facades/test/77.jpg\n",
            "facades/test/78.jpg\n",
            "facades/test/79.jpg\n",
            "facades/test/8.jpg\n",
            "facades/test/80.jpg\n",
            "facades/test/81.jpg\n",
            "facades/test/82.jpg\n",
            "facades/test/83.jpg\n",
            "facades/test/84.jpg\n",
            "facades/test/85.jpg\n",
            "facades/test/86.jpg\n",
            "facades/test/87.jpg\n",
            "facades/test/88.jpg\n",
            "facades/test/89.jpg\n",
            "facades/test/9.jpg\n",
            "facades/test/90.jpg\n",
            "facades/test/91.jpg\n",
            "facades/test/92.jpg\n",
            "facades/test/93.jpg\n",
            "facades/test/94.jpg\n",
            "facades/test/95.jpg\n",
            "facades/test/96.jpg\n",
            "facades/test/97.jpg\n",
            "facades/test/98.jpg\n",
            "facades/test/99.jpg\n",
            "facades/test/28.jpg\n",
            "facades/test/29.jpg\n",
            "facades/test/3.jpg\n",
            "facades/test/30.jpg\n",
            "facades/test/31.jpg\n",
            "facades/test/32.jpg\n",
            "facades/test/33.jpg\n",
            "facades/test/34.jpg\n",
            "facades/test/35.jpg\n",
            "facades/test/36.jpg\n",
            "facades/test/37.jpg\n",
            "facades/test/38.jpg\n",
            "facades/test/39.jpg\n",
            "facades/test/4.jpg\n",
            "facades/test/40.jpg\n",
            "facades/test/41.jpg\n",
            "facades/test/42.jpg\n",
            "facades/test/43.jpg\n",
            "facades/test/44.jpg\n",
            "facades/test/45.jpg\n",
            "facades/test/46.jpg\n",
            "facades/test/47.jpg\n",
            "facades/test/48.jpg\n",
            "facades/test/49.jpg\n",
            "facades/train/\n",
            "facades/train/1.jpg\n",
            "facades/train/10.jpg\n",
            "facades/train/100.jpg\n",
            "facades/train/101.jpg\n",
            "facades/train/102.jpg\n",
            "facades/train/103.jpg\n",
            "facades/train/104.jpg\n",
            "facades/train/105.jpg\n",
            "facades/train/106.jpg\n",
            "facades/train/107.jpg\n",
            "facades/train/108.jpg\n",
            "facades/train/109.jpg\n",
            "facades/train/11.jpg\n",
            "facades/train/110.jpg\n",
            "facades/train/111.jpg\n",
            "facades/train/112.jpg\n",
            "facades/train/113.jpg\n",
            "facades/train/114.jpg\n",
            "facades/train/115.jpg\n",
            "facades/train/116.jpg\n",
            "facades/train/117.jpg\n",
            "facades/train/118.jpg\n",
            "facades/train/119.jpg\n",
            "facades/train/12.jpg\n",
            "facades/train/120.jpg\n",
            "facades/train/121.jpg\n",
            "facades/train/122.jpg\n",
            "facades/train/123.jpg\n",
            "facades/train/124.jpg\n",
            "facades/train/125.jpg\n",
            "facades/train/126.jpg\n",
            "facades/train/309.jpg\n",
            "facades/train/31.jpg\n",
            "facades/train/310.jpg\n",
            "facades/train/311.jpg\n",
            "facades/train/312.jpg\n",
            "facades/train/313.jpg\n",
            "facades/train/314.jpg\n",
            "facades/train/315.jpg\n",
            "facades/train/316.jpg\n",
            "facades/train/317.jpg\n",
            "facades/train/318.jpg\n",
            "facades/train/319.jpg\n",
            "facades/train/32.jpg\n",
            "facades/train/320.jpg\n",
            "facades/train/321.jpg\n",
            "facades/train/322.jpg\n",
            "facades/train/323.jpg\n",
            "facades/train/324.jpg\n",
            "facades/train/325.jpg\n",
            "facades/train/326.jpg\n",
            "facades/train/327.jpg\n",
            "facades/train/328.jpg\n",
            "facades/train/329.jpg\n",
            "facades/train/390.jpg\n",
            "facades/train/391.jpg\n",
            "facades/train/392.jpg\n",
            "facades/train/393.jpg\n",
            "facades/train/394.jpg\n",
            "facades/train/395.jpg\n",
            "facades/train/396.jpg\n",
            "facades/train/397.jpg\n",
            "facades/train/398.jpg\n",
            "facades/train/399.jpg\n",
            "facades/train/4.jpg\n",
            "facades/train/40.jpg\n",
            "facades/train/400.jpg\n",
            "facades/train/41.jpg\n",
            "facades/train/42.jpg\n",
            "facades/train/43.jpg\n",
            "facades/train/44.jpg\n",
            "facades/train/45.jpg\n",
            "facades/train/46.jpg\n",
            "facades/train/47.jpg\n",
            "facades/train/48.jpg\n",
            "facades/train/49.jpg\n",
            "facades/train/5.jpg\n",
            "facades/train/50.jpg\n",
            "facades/train/51.jpg\n",
            "facades/train/52.jpg\n",
            "facades/train/53.jpg\n",
            "facades/train/54.jpg\n",
            "facades/train/55.jpg\n",
            "facades/train/56.jpg\n",
            "facades/train/57.jpg\n",
            "facades/train/58.jpg\n",
            "facades/train/59.jpg\n",
            "facades/train/6.jpg\n",
            "facades/train/60.jpg\n",
            "facades/train/61.jpg\n",
            "facades/train/222.jpg\n",
            "facades/train/223.jpg\n",
            "facades/train/224.jpg\n",
            "facades/train/225.jpg\n",
            "facades/train/226.jpg\n",
            "facades/train/227.jpg\n",
            "facades/train/228.jpg\n",
            "facades/train/229.jpg\n",
            "facades/train/23.jpg\n",
            "facades/train/230.jpg\n",
            "facades/train/231.jpg\n",
            "facades/train/232.jpg\n",
            "facades/train/233.jpg\n",
            "facades/train/234.jpg\n",
            "facades/train/235.jpg\n",
            "facades/train/236.jpg\n",
            "facades/train/237.jpg\n",
            "facades/train/238.jpg\n",
            "facades/train/239.jpg\n",
            "facades/train/24.jpg\n",
            "facades/train/240.jpg\n",
            "facades/train/241.jpg\n",
            "facades/train/242.jpg\n",
            "facades/train/243.jpg\n",
            "facades/train/244.jpg\n",
            "facades/train/245.jpg\n",
            "facades/train/156.jpg\n",
            "facades/train/157.jpg\n",
            "facades/train/158.jpg\n",
            "facades/train/159.jpg\n",
            "facades/train/16.jpg\n",
            "facades/train/160.jpg\n",
            "facades/train/161.jpg\n",
            "facades/train/162.jpg\n",
            "facades/train/163.jpg\n",
            "facades/train/164.jpg\n",
            "facades/train/165.jpg\n",
            "facades/train/166.jpg\n",
            "facades/train/167.jpg\n",
            "facades/train/168.jpg\n",
            "facades/train/169.jpg\n",
            "facades/train/17.jpg\n",
            "facades/train/170.jpg\n",
            "facades/train/171.jpg\n",
            "facades/train/172.jpg\n",
            "facades/train/173.jpg\n",
            "facades/train/174.jpg\n",
            "facades/train/175.jpg\n",
            "facades/train/176.jpg\n",
            "facades/train/177.jpg\n",
            "facades/train/178.jpg\n",
            "facades/train/179.jpg\n",
            "facades/train/18.jpg\n",
            "facades/train/180.jpg\n",
            "facades/train/181.jpg\n",
            "facades/train/182.jpg\n",
            "facades/train/183.jpg\n",
            "facades/train/184.jpg\n",
            "facades/train/185.jpg\n",
            "facades/train/186.jpg\n",
            "facades/train/187.jpg\n",
            "facades/train/188.jpg\n",
            "facades/train/189.jpg\n",
            "facades/train/19.jpg\n",
            "facades/train/127.jpg\n",
            "facades/train/155.jpg\n",
            "facades/train/190.jpg\n",
            "facades/train/221.jpg\n",
            "facades/train/246.jpg\n",
            "facades/train/27.jpg\n",
            "facades/train/29.jpg\n",
            "facades/train/308.jpg\n",
            "facades/train/33.jpg\n",
            "facades/train/350.jpg\n",
            "facades/train/370.jpg\n",
            "facades/train/39.jpg\n",
            "facades/train/62.jpg\n",
            "facades/train/270.jpg\n",
            "facades/train/271.jpg\n",
            "facades/train/272.jpg\n",
            "facades/train/273.jpg\n",
            "facades/train/274.jpg\n",
            "facades/train/275.jpg\n",
            "facades/train/276.jpg\n",
            "facades/train/277.jpg\n",
            "facades/train/278.jpg\n",
            "facades/train/279.jpg\n",
            "facades/train/28.jpg\n",
            "facades/train/280.jpg\n",
            "facades/train/281.jpg\n",
            "facades/train/282.jpg\n",
            "facades/train/283.jpg\n",
            "facades/train/284.jpg\n",
            "facades/train/285.jpg\n",
            "facades/train/286.jpg\n",
            "facades/train/287.jpg\n",
            "facades/train/288.jpg\n",
            "facades/train/289.jpg\n",
            "facades/train/351.jpg\n",
            "facades/train/352.jpg\n",
            "facades/train/353.jpg\n",
            "facades/train/354.jpg\n",
            "facades/train/355.jpg\n",
            "facades/train/356.jpg\n",
            "facades/train/357.jpg\n",
            "facades/train/358.jpg\n",
            "facades/train/359.jpg\n",
            "facades/train/36.jpg\n",
            "facades/train/360.jpg\n",
            "facades/train/361.jpg\n",
            "facades/train/362.jpg\n",
            "facades/train/363.jpg\n",
            "facades/train/364.jpg\n",
            "facades/train/365.jpg\n",
            "facades/train/366.jpg\n",
            "facades/train/367.jpg\n",
            "facades/train/368.jpg\n",
            "facades/train/369.jpg\n",
            "facades/train/37.jpg\n",
            "facades/train/63.jpg\n",
            "facades/train/64.jpg\n",
            "facades/train/65.jpg\n",
            "facades/train/66.jpg\n",
            "facades/train/67.jpg\n",
            "facades/train/68.jpg\n",
            "facades/train/69.jpg\n",
            "facades/train/7.jpg\n",
            "facades/train/70.jpg\n",
            "facades/train/71.jpg\n",
            "facades/train/72.jpg\n",
            "facades/train/73.jpg\n",
            "facades/train/74.jpg\n",
            "facades/train/75.jpg\n",
            "facades/train/76.jpg\n",
            "facades/train/77.jpg\n",
            "facades/train/78.jpg\n",
            "facades/train/79.jpg\n",
            "facades/train/8.jpg\n",
            "facades/train/80.jpg\n",
            "facades/train/81.jpg\n",
            "facades/train/82.jpg\n",
            "facades/train/83.jpg\n",
            "facades/train/84.jpg\n",
            "facades/train/85.jpg\n",
            "facades/train/86.jpg\n",
            "facades/train/87.jpg\n",
            "facades/train/88.jpg\n",
            "facades/train/89.jpg\n",
            "facades/train/9.jpg\n",
            "facades/train/90.jpg\n",
            "facades/train/91.jpg\n",
            "facades/train/92.jpg\n",
            "facades/train/93.jpg\n",
            "facades/train/94.jpg\n",
            "facades/train/95.jpg\n",
            "facades/train/96.jpg\n",
            "facades/train/97.jpg\n",
            "facades/train/98.jpg\n",
            "facades/train/99.jpg\n",
            "facades/train/128.jpg\n",
            "facades/train/129.jpg\n",
            "facades/train/13.jpg\n",
            "facades/train/130.jpg\n",
            "facades/train/131.jpg\n",
            "facades/train/132.jpg\n",
            "facades/train/133.jpg\n",
            "facades/train/134.jpg\n",
            "facades/train/135.jpg\n",
            "facades/train/136.jpg\n",
            "facades/train/137.jpg\n",
            "facades/train/138.jpg\n",
            "facades/train/139.jpg\n",
            "facades/train/14.jpg\n",
            "facades/train/140.jpg\n",
            "facades/train/141.jpg\n",
            "facades/train/142.jpg\n",
            "facades/train/143.jpg\n",
            "facades/train/144.jpg\n",
            "facades/train/145.jpg\n",
            "facades/train/146.jpg\n",
            "facades/train/147.jpg\n",
            "facades/train/148.jpg\n",
            "facades/train/149.jpg\n",
            "facades/train/15.jpg\n",
            "facades/train/150.jpg\n",
            "facades/train/151.jpg\n",
            "facades/train/152.jpg\n",
            "facades/train/153.jpg\n",
            "facades/train/154.jpg\n",
            "facades/train/191.jpg\n",
            "facades/train/192.jpg\n",
            "facades/train/193.jpg\n",
            "facades/train/194.jpg\n",
            "facades/train/195.jpg\n",
            "facades/train/196.jpg\n",
            "facades/train/197.jpg\n",
            "facades/train/198.jpg\n",
            "facades/train/199.jpg\n",
            "facades/train/2.jpg\n",
            "facades/train/20.jpg\n",
            "facades/train/200.jpg\n",
            "facades/train/201.jpg\n",
            "facades/train/202.jpg\n",
            "facades/train/203.jpg\n",
            "facades/train/204.jpg\n",
            "facades/train/205.jpg\n",
            "facades/train/206.jpg\n",
            "facades/train/207.jpg\n",
            "facades/train/208.jpg\n",
            "facades/train/209.jpg\n",
            "facades/train/21.jpg\n",
            "facades/train/210.jpg\n",
            "facades/train/211.jpg\n",
            "facades/train/212.jpg\n",
            "facades/train/213.jpg\n",
            "facades/train/214.jpg\n",
            "facades/train/215.jpg\n",
            "facades/train/216.jpg\n",
            "facades/train/217.jpg\n",
            "facades/train/218.jpg\n",
            "facades/train/219.jpg\n",
            "facades/train/22.jpg\n",
            "facades/train/220.jpg\n",
            "facades/train/247.jpg\n",
            "facades/train/248.jpg\n",
            "facades/train/249.jpg\n",
            "facades/train/25.jpg\n",
            "facades/train/250.jpg\n",
            "facades/train/251.jpg\n",
            "facades/train/252.jpg\n",
            "facades/train/253.jpg\n",
            "facades/train/254.jpg\n",
            "facades/train/255.jpg\n",
            "facades/train/256.jpg\n",
            "facades/train/257.jpg\n",
            "facades/train/258.jpg\n",
            "facades/train/259.jpg\n",
            "facades/train/26.jpg\n",
            "facades/train/260.jpg\n",
            "facades/train/261.jpg\n",
            "facades/train/262.jpg\n",
            "facades/train/263.jpg\n",
            "facades/train/264.jpg\n",
            "facades/train/265.jpg\n",
            "facades/train/266.jpg\n",
            "facades/train/267.jpg\n",
            "facades/train/268.jpg\n",
            "facades/train/269.jpg\n",
            "facades/train/330.jpg\n",
            "facades/train/331.jpg\n",
            "facades/train/332.jpg\n",
            "facades/train/333.jpg\n",
            "facades/train/334.jpg\n",
            "facades/train/335.jpg\n",
            "facades/train/336.jpg\n",
            "facades/train/337.jpg\n",
            "facades/train/338.jpg\n",
            "facades/train/339.jpg\n",
            "facades/train/34.jpg\n",
            "facades/train/340.jpg\n",
            "facades/train/341.jpg\n",
            "facades/train/342.jpg\n",
            "facades/train/343.jpg\n",
            "facades/train/344.jpg\n",
            "facades/train/345.jpg\n",
            "facades/train/346.jpg\n",
            "facades/train/347.jpg\n",
            "facades/train/348.jpg\n",
            "facades/train/349.jpg\n",
            "facades/train/35.jpg\n",
            "facades/train/290.jpg\n",
            "facades/train/291.jpg\n",
            "facades/train/292.jpg\n",
            "facades/train/293.jpg\n",
            "facades/train/294.jpg\n",
            "facades/train/295.jpg\n",
            "facades/train/296.jpg\n",
            "facades/train/297.jpg\n",
            "facades/train/298.jpg\n",
            "facades/train/299.jpg\n",
            "facades/train/3.jpg\n",
            "facades/train/30.jpg\n",
            "facades/train/300.jpg\n",
            "facades/train/301.jpg\n",
            "facades/train/302.jpg\n",
            "facades/train/303.jpg\n",
            "facades/train/304.jpg\n",
            "facades/train/305.jpg\n",
            "facades/train/306.jpg\n",
            "facades/train/307.jpg\n",
            "facades/train/371.jpg\n",
            "facades/train/372.jpg\n",
            "facades/train/373.jpg\n",
            "facades/train/374.jpg\n",
            "facades/train/375.jpg\n",
            "facades/train/376.jpg\n",
            "facades/train/377.jpg\n",
            "facades/train/378.jpg\n",
            "facades/train/379.jpg\n",
            "facades/train/38.jpg\n",
            "facades/train/380.jpg\n",
            "facades/train/381.jpg\n",
            "facades/train/382.jpg\n",
            "facades/train/383.jpg\n",
            "facades/train/384.jpg\n",
            "facades/train/385.jpg\n",
            "facades/train/386.jpg\n",
            "facades/train/387.jpg\n",
            "facades/train/388.jpg\n",
            "facades/train/389.jpg\n",
            "facades/val/\n",
            "facades/val/30.jpg\n",
            "facades/val/50.jpg\n",
            "facades/val/73.jpg\n",
            "facades/val/1.jpg\n",
            "facades/val/10.jpg\n",
            "facades/val/100.jpg\n",
            "facades/val/11.jpg\n",
            "facades/val/12.jpg\n",
            "facades/val/13.jpg\n",
            "facades/val/14.jpg\n",
            "facades/val/15.jpg\n",
            "facades/val/16.jpg\n",
            "facades/val/17.jpg\n",
            "facades/val/18.jpg\n",
            "facades/val/19.jpg\n",
            "facades/val/2.jpg\n",
            "facades/val/20.jpg\n",
            "facades/val/21.jpg\n",
            "facades/val/22.jpg\n",
            "facades/val/23.jpg\n",
            "facades/val/24.jpg\n",
            "facades/val/25.jpg\n",
            "facades/val/26.jpg\n",
            "facades/val/27.jpg\n",
            "facades/val/28.jpg\n",
            "facades/val/29.jpg\n",
            "facades/val/3.jpg\n",
            "facades/val/51.jpg\n",
            "facades/val/52.jpg\n",
            "facades/val/53.jpg\n",
            "facades/val/54.jpg\n",
            "facades/val/55.jpg\n",
            "facades/val/56.jpg\n",
            "facades/val/57.jpg\n",
            "facades/val/58.jpg\n",
            "facades/val/59.jpg\n",
            "facades/val/6.jpg\n",
            "facades/val/60.jpg\n",
            "facades/val/61.jpg\n",
            "facades/val/62.jpg\n",
            "facades/val/63.jpg\n",
            "facades/val/64.jpg\n",
            "facades/val/65.jpg\n",
            "facades/val/66.jpg\n",
            "facades/val/67.jpg\n",
            "facades/val/68.jpg\n",
            "facades/val/69.jpg\n",
            "facades/val/7.jpg\n",
            "facades/val/70.jpg\n",
            "facades/val/71.jpg\n",
            "facades/val/72.jpg\n",
            "facades/val/74.jpg\n",
            "facades/val/75.jpg\n",
            "facades/val/76.jpg\n",
            "facades/val/77.jpg\n",
            "facades/val/78.jpg\n",
            "facades/val/79.jpg\n",
            "facades/val/8.jpg\n",
            "facades/val/80.jpg\n",
            "facades/val/81.jpg\n",
            "facades/val/82.jpg\n",
            "facades/val/83.jpg\n",
            "facades/val/84.jpg\n",
            "facades/val/85.jpg\n",
            "facades/val/86.jpg\n",
            "facades/val/87.jpg\n",
            "facades/val/88.jpg\n",
            "facades/val/89.jpg\n",
            "facades/val/9.jpg\n",
            "facades/val/90.jpg\n",
            "facades/val/91.jpg\n",
            "facades/val/92.jpg\n",
            "facades/val/93.jpg\n",
            "facades/val/94.jpg\n",
            "facades/val/95.jpg\n",
            "facades/val/96.jpg\n",
            "facades/val/97.jpg\n",
            "facades/val/98.jpg\n",
            "facades/val/99.jpg\n",
            "facades/val/31.jpg\n",
            "facades/val/32.jpg\n",
            "facades/val/33.jpg\n",
            "facades/val/34.jpg\n",
            "facades/val/35.jpg\n",
            "facades/val/36.jpg\n",
            "facades/val/37.jpg\n",
            "facades/val/38.jpg\n",
            "facades/val/39.jpg\n",
            "facades/val/4.jpg\n",
            "facades/val/40.jpg\n",
            "facades/val/41.jpg\n",
            "facades/val/42.jpg\n",
            "facades/val/43.jpg\n",
            "facades/val/44.jpg\n",
            "facades/val/45.jpg\n",
            "facades/val/46.jpg\n",
            "facades/val/47.jpg\n",
            "facades/val/48.jpg\n",
            "facades/val/49.jpg\n",
            "facades/val/5.jpg\n"
          ]
        }
      ],
      "source": [
        "!bash ./datasets/download_pix2pix_dataset.sh facades"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gdUz4116xhpm"
      },
      "source": [
        "# Pretrained models\n",
        "\n",
        "Download one of the official pretrained models with:\n",
        "\n",
        "-   `bash ./scripts/download_pix2pix_model.sh [edges2shoes, sat2map, map2sat, facades_label2photo, and day2night]`\n",
        "\n",
        "Or add your own pretrained model to `./checkpoints/{NAME}_pretrained/latest_net_G.pt`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "GC2DEP4M0OsS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "26dbfd6e-a534-460e-88ae-1500b19fdf01"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Note: available models are edges2shoes, sat2map, map2sat, facades_label2photo, and day2night\n",
            "Specified [facades_label2photo]\n",
            "WARNING: timestamping does nothing in combination with -O. See the manual\n",
            "for details.\n",
            "\n",
            "--2022-05-11 07:07:19--  http://efrosgans.eecs.berkeley.edu/pix2pix/models-pytorch/facades_label2photo.pth\n",
            "Resolving efrosgans.eecs.berkeley.edu (efrosgans.eecs.berkeley.edu)... 128.32.244.190\n",
            "Connecting to efrosgans.eecs.berkeley.edu (efrosgans.eecs.berkeley.edu)|128.32.244.190|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 217704720 (208M)\n",
            "Saving to: ‘./checkpoints/facades_label2photo_pretrained/latest_net_G.pth’\n",
            "\n",
            "./checkpoints/facad 100%[===================>] 207.62M  65.7MB/s    in 3.7s    \n",
            "\n",
            "2022-05-11 07:07:23 (55.8 MB/s) - ‘./checkpoints/facades_label2photo_pretrained/latest_net_G.pth’ saved [217704720/217704720]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!bash ./scripts/download_pix2pix_model.sh facades_label2photo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yFw1kDQBx3LN"
      },
      "source": [
        "# Training\n",
        "\n",
        "-   `python train.py --dataroot ./datasets/facades --name facades_pix2pix --model pix2pix --direction BtoA`\n",
        "\n",
        "Change the `--dataroot` and `--name` to your own dataset's path and model's name. Use `--gpu_ids 0,1,..` to train on multiple GPUs and `--batch_size` to change the batch size. Add `--direction BtoA` if you want to train a model to transfrom from class B to A."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0sp7TCT2x9dB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7147caf1-6111-48c8-e3b4-8762a161309f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43m流式输出内容被截断，只能显示最后 5000 行内容。\u001b[0m\n",
            "(epoch: 31, iters: 2000, time: 0.279, data: 0.003) G_GAN: 4.513 G_L1: 0.892 D_real: 0.027 D_fake: 0.022 \n",
            "(epoch: 31, iters: 2100, time: 0.067, data: 0.002) G_GAN: 2.025 G_L1: 2.139 D_real: 0.286 D_fake: 0.205 \n",
            "(epoch: 31, iters: 2200, time: 0.067, data: 0.002) G_GAN: 6.381 G_L1: 1.156 D_real: 0.001 D_fake: 0.003 \n",
            "(epoch: 31, iters: 2300, time: 0.066, data: 0.002) G_GAN: 0.887 G_L1: 2.418 D_real: 0.771 D_fake: 0.583 \n",
            "(epoch: 31, iters: 2400, time: 0.182, data: 0.003) G_GAN: 5.065 G_L1: 2.706 D_real: 0.221 D_fake: 0.005 \n",
            "(epoch: 31, iters: 2500, time: 0.065, data: 0.002) G_GAN: 0.842 G_L1: 3.702 D_real: 0.776 D_fake: 0.660 \n",
            "(epoch: 31, iters: 2600, time: 0.065, data: 0.003) G_GAN: 4.767 G_L1: 1.223 D_real: 0.220 D_fake: 0.024 \n",
            "(epoch: 31, iters: 2700, time: 0.066, data: 0.004) G_GAN: 1.087 G_L1: 2.871 D_real: 0.390 D_fake: 0.871 \n",
            "(epoch: 31, iters: 2800, time: 0.169, data: 0.002) G_GAN: 2.967 G_L1: 3.505 D_real: 0.164 D_fake: 0.200 \n",
            "(epoch: 31, iters: 2900, time: 0.061, data: 0.016) G_GAN: 0.812 G_L1: 4.655 D_real: 0.800 D_fake: 0.537 \n",
            "(epoch: 31, iters: 3000, time: 0.065, data: 0.006) G_GAN: 1.912 G_L1: 4.784 D_real: 0.425 D_fake: 0.196 \n",
            "(epoch: 31, iters: 3100, time: 0.064, data: 0.003) G_GAN: 0.828 G_L1: 2.018 D_real: 0.370 D_fake: 0.918 \n",
            "(epoch: 31, iters: 3200, time: 0.224, data: 0.002) G_GAN: 0.649 G_L1: 2.618 D_real: 0.440 D_fake: 1.263 \n",
            "(epoch: 31, iters: 3300, time: 0.066, data: 0.011) G_GAN: 1.375 G_L1: 2.178 D_real: 0.626 D_fake: 0.392 \n",
            "(epoch: 31, iters: 3400, time: 0.067, data: 0.002) G_GAN: 2.446 G_L1: 1.335 D_real: 0.033 D_fake: 0.310 \n",
            "(epoch: 31, iters: 3500, time: 0.065, data: 0.002) G_GAN: 1.955 G_L1: 1.468 D_real: 0.416 D_fake: 0.191 \n",
            "(epoch: 31, iters: 3600, time: 0.276, data: 0.004) G_GAN: 5.576 G_L1: 1.848 D_real: 0.001 D_fake: 0.007 \n",
            "(epoch: 31, iters: 3700, time: 0.066, data: 0.011) G_GAN: 1.072 G_L1: 1.604 D_real: 0.933 D_fake: 0.328 \n",
            "(epoch: 31, iters: 3800, time: 0.066, data: 0.003) G_GAN: 2.151 G_L1: 2.715 D_real: 0.626 D_fake: 0.096 \n",
            "(epoch: 31, iters: 3900, time: 0.067, data: 0.003) G_GAN: 2.579 G_L1: 1.318 D_real: 0.015 D_fake: 1.546 \n",
            "(epoch: 31, iters: 4000, time: 0.400, data: 0.005) G_GAN: 1.283 G_L1: 2.076 D_real: 0.517 D_fake: 0.521 \n",
            "End of epoch 31 / 200 \t Time Taken: 172 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "(epoch: 32, iters: 100, time: 0.067, data: 0.159) G_GAN: 7.099 G_L1: 1.302 D_real: 0.000 D_fake: 0.001 \n",
            "(epoch: 32, iters: 200, time: 0.066, data: 0.003) G_GAN: 0.575 G_L1: 4.190 D_real: 0.560 D_fake: 1.329 \n",
            "(epoch: 32, iters: 300, time: 0.066, data: 0.004) G_GAN: 3.720 G_L1: 2.608 D_real: 0.346 D_fake: 0.030 \n",
            "(epoch: 32, iters: 400, time: 0.524, data: 0.002) G_GAN: 0.935 G_L1: 5.192 D_real: 0.584 D_fake: 0.644 \n",
            "(epoch: 32, iters: 500, time: 0.067, data: 0.004) G_GAN: 6.176 G_L1: 1.577 D_real: 0.000 D_fake: 0.003 \n",
            "(epoch: 32, iters: 600, time: 0.066, data: 0.013) G_GAN: 4.807 G_L1: 0.862 D_real: 0.002 D_fake: 0.018 \n",
            "(epoch: 32, iters: 700, time: 0.066, data: 0.005) G_GAN: 3.783 G_L1: 2.018 D_real: 0.057 D_fake: 0.031 \n",
            "(epoch: 32, iters: 800, time: 0.195, data: 0.003) G_GAN: 3.110 G_L1: 1.614 D_real: 0.084 D_fake: 0.386 \n",
            "(epoch: 32, iters: 900, time: 0.067, data: 0.009) G_GAN: 1.766 G_L1: 1.741 D_real: 0.178 D_fake: 0.384 \n",
            "(epoch: 32, iters: 1000, time: 0.066, data: 0.004) G_GAN: 5.070 G_L1: 0.864 D_real: 0.003 D_fake: 0.012 \n",
            "saving the latest model (epoch 32, total_iters 125000)\n",
            "(epoch: 32, iters: 1100, time: 0.067, data: 0.002) G_GAN: 0.927 G_L1: 2.145 D_real: 0.722 D_fake: 0.603 \n",
            "(epoch: 32, iters: 1200, time: 0.173, data: 0.002) G_GAN: 3.622 G_L1: 2.280 D_real: 0.121 D_fake: 0.154 \n",
            "(epoch: 32, iters: 1300, time: 0.066, data: 0.008) G_GAN: 2.124 G_L1: 1.919 D_real: 0.192 D_fake: 0.248 \n",
            "(epoch: 32, iters: 1400, time: 0.066, data: 0.002) G_GAN: 4.737 G_L1: 0.733 D_real: 0.001 D_fake: 0.013 \n",
            "(epoch: 32, iters: 1500, time: 0.066, data: 0.003) G_GAN: 6.004 G_L1: 1.567 D_real: 0.195 D_fake: 0.004 \n",
            "(epoch: 32, iters: 1600, time: 0.225, data: 0.004) G_GAN: 0.863 G_L1: 2.129 D_real: 0.555 D_fake: 0.675 \n",
            "(epoch: 32, iters: 1700, time: 0.066, data: 0.007) G_GAN: 0.684 G_L1: 3.113 D_real: 0.856 D_fake: 0.755 \n",
            "(epoch: 32, iters: 1800, time: 0.067, data: 0.003) G_GAN: 1.209 G_L1: 3.968 D_real: 0.711 D_fake: 0.527 \n",
            "(epoch: 32, iters: 1900, time: 0.067, data: 0.003) G_GAN: 6.956 G_L1: 1.225 D_real: 0.001 D_fake: 0.002 \n",
            "(epoch: 32, iters: 2000, time: 0.326, data: 0.002) G_GAN: 3.989 G_L1: 3.440 D_real: 0.342 D_fake: 0.069 \n",
            "(epoch: 32, iters: 2100, time: 0.067, data: 0.004) G_GAN: 1.046 G_L1: 3.012 D_real: 0.725 D_fake: 0.716 \n",
            "(epoch: 32, iters: 2200, time: 0.066, data: 0.002) G_GAN: 1.921 G_L1: 5.956 D_real: 0.445 D_fake: 0.297 \n",
            "(epoch: 32, iters: 2300, time: 0.066, data: 0.003) G_GAN: 0.772 G_L1: 2.206 D_real: 0.879 D_fake: 0.776 \n",
            "(epoch: 32, iters: 2400, time: 0.179, data: 0.003) G_GAN: 2.934 G_L1: 3.442 D_real: 0.199 D_fake: 0.992 \n",
            "(epoch: 32, iters: 2500, time: 0.066, data: 0.009) G_GAN: 1.775 G_L1: 1.562 D_real: 0.362 D_fake: 0.197 \n",
            "(epoch: 32, iters: 2600, time: 0.066, data: 0.002) G_GAN: 3.326 G_L1: 3.990 D_real: 0.338 D_fake: 0.018 \n",
            "(epoch: 32, iters: 2700, time: 0.066, data: 0.002) G_GAN: 7.892 G_L1: 2.462 D_real: 0.064 D_fake: 0.001 \n",
            "(epoch: 32, iters: 2800, time: 0.183, data: 0.004) G_GAN: 1.816 G_L1: 4.494 D_real: 0.043 D_fake: 0.731 \n",
            "(epoch: 32, iters: 2900, time: 0.067, data: 0.006) G_GAN: 2.933 G_L1: 2.576 D_real: 0.051 D_fake: 0.161 \n",
            "(epoch: 32, iters: 3000, time: 0.066, data: 0.003) G_GAN: 2.186 G_L1: 3.208 D_real: 0.193 D_fake: 0.358 \n",
            "(epoch: 32, iters: 3100, time: 0.066, data: 0.004) G_GAN: 1.119 G_L1: 4.019 D_real: 0.473 D_fake: 0.644 \n",
            "(epoch: 32, iters: 3200, time: 0.157, data: 0.003) G_GAN: 5.284 G_L1: 0.746 D_real: 0.001 D_fake: 0.009 \n",
            "(epoch: 32, iters: 3300, time: 0.067, data: 0.011) G_GAN: 2.047 G_L1: 2.502 D_real: 0.076 D_fake: 0.484 \n",
            "(epoch: 32, iters: 3400, time: 0.066, data: 0.002) G_GAN: 0.890 G_L1: 2.392 D_real: 0.596 D_fake: 0.764 \n",
            "(epoch: 32, iters: 3500, time: 0.066, data: 0.002) G_GAN: 3.224 G_L1: 1.427 D_real: 0.078 D_fake: 0.091 \n",
            "(epoch: 32, iters: 3600, time: 0.180, data: 0.002) G_GAN: 5.169 G_L1: 1.324 D_real: 0.000 D_fake: 0.009 \n",
            "(epoch: 32, iters: 3700, time: 0.067, data: 0.011) G_GAN: 4.916 G_L1: 1.743 D_real: 0.193 D_fake: 0.019 \n",
            "(epoch: 32, iters: 3800, time: 0.066, data: 0.003) G_GAN: 6.807 G_L1: 1.423 D_real: 0.002 D_fake: 0.002 \n",
            "(epoch: 32, iters: 3900, time: 0.066, data: 0.003) G_GAN: 1.944 G_L1: 1.841 D_real: 0.266 D_fake: 0.186 \n",
            "(epoch: 32, iters: 4000, time: 0.331, data: 0.003) G_GAN: 2.474 G_L1: 2.678 D_real: 2.166 D_fake: 0.065 \n",
            "End of epoch 32 / 200 \t Time Taken: 173 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "(epoch: 33, iters: 100, time: 0.066, data: 0.136) G_GAN: 0.958 G_L1: 2.400 D_real: 0.596 D_fake: 0.677 \n",
            "(epoch: 33, iters: 200, time: 0.066, data: 0.005) G_GAN: 4.482 G_L1: 0.576 D_real: 0.001 D_fake: 0.046 \n",
            "(epoch: 33, iters: 300, time: 0.065, data: 0.003) G_GAN: 2.880 G_L1: 3.408 D_real: 0.050 D_fake: 0.240 \n",
            "(epoch: 33, iters: 400, time: 0.751, data: 0.003) G_GAN: 1.180 G_L1: 3.012 D_real: 0.600 D_fake: 0.527 \n",
            "(epoch: 33, iters: 500, time: 0.063, data: 0.005) G_GAN: 6.460 G_L1: 0.938 D_real: 0.000 D_fake: 0.003 \n",
            "(epoch: 33, iters: 600, time: 0.066, data: 0.006) G_GAN: 5.743 G_L1: 1.558 D_real: 0.001 D_fake: 0.005 \n",
            "(epoch: 33, iters: 700, time: 0.066, data: 0.003) G_GAN: 1.458 G_L1: 4.100 D_real: 0.974 D_fake: 0.269 \n",
            "(epoch: 33, iters: 800, time: 0.224, data: 0.002) G_GAN: 1.327 G_L1: 2.428 D_real: 0.452 D_fake: 0.503 \n",
            "(epoch: 33, iters: 900, time: 0.066, data: 0.002) G_GAN: 5.944 G_L1: 1.409 D_real: 0.000 D_fake: 0.004 \n",
            "(epoch: 33, iters: 1000, time: 0.067, data: 0.002) G_GAN: 3.329 G_L1: 5.459 D_real: 0.010 D_fake: 0.646 \n",
            "(epoch: 33, iters: 1100, time: 0.067, data: 0.002) G_GAN: 3.031 G_L1: 2.850 D_real: 0.068 D_fake: 0.075 \n",
            "(epoch: 33, iters: 1200, time: 0.182, data: 0.002) G_GAN: 1.296 G_L1: 3.862 D_real: 0.532 D_fake: 0.342 \n",
            "(epoch: 33, iters: 1300, time: 0.067, data: 0.007) G_GAN: 2.613 G_L1: 2.652 D_real: 0.562 D_fake: 0.455 \n",
            "(epoch: 33, iters: 1400, time: 0.067, data: 0.002) G_GAN: 7.443 G_L1: 0.895 D_real: 0.001 D_fake: 0.001 \n",
            "(epoch: 33, iters: 1500, time: 0.066, data: 0.002) G_GAN: 2.792 G_L1: 1.047 D_real: 0.130 D_fake: 0.645 \n",
            "(epoch: 33, iters: 1600, time: 0.171, data: 0.002) G_GAN: 1.942 G_L1: 1.346 D_real: 0.466 D_fake: 0.330 \n",
            "(epoch: 33, iters: 1700, time: 0.067, data: 0.004) G_GAN: 4.633 G_L1: 3.074 D_real: 0.027 D_fake: 0.016 \n",
            "(epoch: 33, iters: 1800, time: 0.067, data: 0.003) G_GAN: 8.364 G_L1: 1.023 D_real: 0.000 D_fake: 0.001 \n",
            "(epoch: 33, iters: 1900, time: 0.060, data: 0.003) G_GAN: 1.005 G_L1: 2.288 D_real: 0.612 D_fake: 0.579 \n",
            "(epoch: 33, iters: 2000, time: 0.404, data: 0.003) G_GAN: 1.034 G_L1: 2.058 D_real: 0.316 D_fake: 0.867 \n",
            "saving the latest model (epoch 33, total_iters 130000)\n",
            "(epoch: 33, iters: 2100, time: 0.066, data: 0.002) G_GAN: 1.623 G_L1: 3.756 D_real: 0.181 D_fake: 1.475 \n",
            "(epoch: 33, iters: 2200, time: 0.063, data: 0.004) G_GAN: 0.927 G_L1: 1.859 D_real: 0.972 D_fake: 0.641 \n",
            "(epoch: 33, iters: 2300, time: 0.066, data: 0.003) G_GAN: 5.913 G_L1: 1.597 D_real: 0.003 D_fake: 0.008 \n",
            "(epoch: 33, iters: 2400, time: 0.220, data: 0.003) G_GAN: 0.899 G_L1: 1.930 D_real: 0.448 D_fake: 0.969 \n",
            "(epoch: 33, iters: 2500, time: 0.067, data: 0.007) G_GAN: 3.757 G_L1: 1.187 D_real: 0.098 D_fake: 0.080 \n",
            "(epoch: 33, iters: 2600, time: 0.066, data: 0.003) G_GAN: 3.056 G_L1: 4.760 D_real: 0.024 D_fake: 0.103 \n",
            "(epoch: 33, iters: 2700, time: 0.067, data: 0.003) G_GAN: 1.986 G_L1: 1.550 D_real: 0.220 D_fake: 0.281 \n",
            "(epoch: 33, iters: 2800, time: 0.193, data: 0.003) G_GAN: 2.332 G_L1: 4.038 D_real: 0.161 D_fake: 0.764 \n",
            "(epoch: 33, iters: 2900, time: 0.064, data: 0.003) G_GAN: 1.305 G_L1: 2.066 D_real: 0.671 D_fake: 0.263 \n",
            "(epoch: 33, iters: 3000, time: 0.066, data: 0.005) G_GAN: 7.792 G_L1: 3.592 D_real: 0.173 D_fake: 0.001 \n",
            "(epoch: 33, iters: 3100, time: 0.065, data: 0.004) G_GAN: 0.751 G_L1: 3.454 D_real: 0.872 D_fake: 0.595 \n",
            "(epoch: 33, iters: 3200, time: 0.199, data: 0.003) G_GAN: 1.331 G_L1: 2.213 D_real: 0.132 D_fake: 0.934 \n",
            "(epoch: 33, iters: 3300, time: 0.066, data: 0.009) G_GAN: 5.519 G_L1: 1.433 D_real: 0.000 D_fake: 0.006 \n",
            "(epoch: 33, iters: 3400, time: 0.066, data: 0.003) G_GAN: 0.882 G_L1: 2.229 D_real: 1.013 D_fake: 0.661 \n",
            "(epoch: 33, iters: 3500, time: 0.067, data: 0.003) G_GAN: 0.856 G_L1: 4.025 D_real: 0.425 D_fake: 0.816 \n",
            "(epoch: 33, iters: 3600, time: 0.224, data: 0.002) G_GAN: 1.185 G_L1: 2.164 D_real: 0.526 D_fake: 0.432 \n",
            "(epoch: 33, iters: 3700, time: 0.067, data: 0.005) G_GAN: 3.776 G_L1: 0.662 D_real: 0.002 D_fake: 0.058 \n",
            "(epoch: 33, iters: 3800, time: 0.066, data: 0.002) G_GAN: 6.086 G_L1: 0.806 D_real: 0.001 D_fake: 0.003 \n",
            "(epoch: 33, iters: 3900, time: 0.067, data: 0.003) G_GAN: 1.047 G_L1: 2.073 D_real: 1.103 D_fake: 0.340 \n",
            "(epoch: 33, iters: 4000, time: 0.358, data: 0.003) G_GAN: 2.304 G_L1: 6.593 D_real: 0.081 D_fake: 0.216 \n",
            "End of epoch 33 / 200 \t Time Taken: 173 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "(epoch: 34, iters: 100, time: 0.062, data: 0.170) G_GAN: 5.340 G_L1: 1.286 D_real: 0.001 D_fake: 0.008 \n",
            "(epoch: 34, iters: 200, time: 0.067, data: 0.002) G_GAN: 2.781 G_L1: 3.556 D_real: 0.031 D_fake: 0.357 \n",
            "(epoch: 34, iters: 300, time: 0.063, data: 0.002) G_GAN: 0.975 G_L1: 2.181 D_real: 0.512 D_fake: 0.768 \n",
            "(epoch: 34, iters: 400, time: 0.447, data: 0.003) G_GAN: 2.352 G_L1: 2.271 D_real: 0.055 D_fake: 0.556 \n",
            "(epoch: 34, iters: 500, time: 0.066, data: 0.003) G_GAN: 4.648 G_L1: 1.141 D_real: 0.001 D_fake: 0.037 \n",
            "(epoch: 34, iters: 600, time: 0.066, data: 0.004) G_GAN: 2.613 G_L1: 2.309 D_real: 0.078 D_fake: 0.075 \n",
            "(epoch: 34, iters: 700, time: 0.067, data: 0.004) G_GAN: 4.721 G_L1: 0.743 D_real: 0.002 D_fake: 0.014 \n",
            "(epoch: 34, iters: 800, time: 0.164, data: 0.002) G_GAN: 6.681 G_L1: 1.226 D_real: 0.127 D_fake: 0.003 \n",
            "(epoch: 34, iters: 900, time: 0.066, data: 0.002) G_GAN: 6.141 G_L1: 1.110 D_real: 0.022 D_fake: 0.005 \n",
            "(epoch: 34, iters: 1000, time: 0.065, data: 0.003) G_GAN: 1.444 G_L1: 2.297 D_real: 0.667 D_fake: 0.203 \n",
            "(epoch: 34, iters: 1100, time: 0.066, data: 0.002) G_GAN: 2.370 G_L1: 1.956 D_real: 0.088 D_fake: 0.198 \n",
            "(epoch: 34, iters: 1200, time: 0.170, data: 0.002) G_GAN: 1.604 G_L1: 3.429 D_real: 0.465 D_fake: 0.418 \n",
            "(epoch: 34, iters: 1300, time: 0.066, data: 0.016) G_GAN: 0.670 G_L1: 2.713 D_real: 0.588 D_fake: 0.971 \n",
            "(epoch: 34, iters: 1400, time: 0.066, data: 0.004) G_GAN: 1.216 G_L1: 4.399 D_real: 0.520 D_fake: 0.504 \n",
            "(epoch: 34, iters: 1500, time: 0.067, data: 0.002) G_GAN: 2.463 G_L1: 2.251 D_real: 0.130 D_fake: 0.201 \n",
            "(epoch: 34, iters: 1600, time: 0.177, data: 0.003) G_GAN: 4.063 G_L1: 3.397 D_real: 0.173 D_fake: 0.630 \n",
            "(epoch: 34, iters: 1700, time: 0.065, data: 0.013) G_GAN: 2.882 G_L1: 2.878 D_real: 0.915 D_fake: 0.110 \n",
            "(epoch: 34, iters: 1800, time: 0.066, data: 0.004) G_GAN: 5.863 G_L1: 0.666 D_real: 0.001 D_fake: 0.006 \n",
            "(epoch: 34, iters: 1900, time: 0.067, data: 0.005) G_GAN: 2.869 G_L1: 2.438 D_real: 0.706 D_fake: 0.269 \n",
            "(epoch: 34, iters: 2000, time: 0.401, data: 0.003) G_GAN: 2.140 G_L1: 2.155 D_real: 0.018 D_fake: 1.058 \n",
            "(epoch: 34, iters: 2100, time: 0.067, data: 0.003) G_GAN: 7.500 G_L1: 1.294 D_real: 0.006 D_fake: 0.001 \n",
            "(epoch: 34, iters: 2200, time: 0.067, data: 0.003) G_GAN: 0.680 G_L1: 2.423 D_real: 1.302 D_fake: 0.405 \n",
            "(epoch: 34, iters: 2300, time: 0.066, data: 0.002) G_GAN: 5.216 G_L1: 1.069 D_real: 0.000 D_fake: 0.012 \n",
            "(epoch: 34, iters: 2400, time: 0.228, data: 0.002) G_GAN: 1.086 G_L1: 2.506 D_real: 0.518 D_fake: 0.625 \n",
            "(epoch: 34, iters: 2500, time: 0.066, data: 0.008) G_GAN: 0.774 G_L1: 2.200 D_real: 0.424 D_fake: 1.179 \n",
            "(epoch: 34, iters: 2600, time: 0.067, data: 0.002) G_GAN: 6.665 G_L1: 1.164 D_real: 0.010 D_fake: 0.002 \n",
            "(epoch: 34, iters: 2700, time: 0.066, data: 0.003) G_GAN: 0.918 G_L1: 3.840 D_real: 0.951 D_fake: 0.473 \n",
            "(epoch: 34, iters: 2800, time: 0.196, data: 0.003) G_GAN: 2.541 G_L1: 2.570 D_real: 0.330 D_fake: 0.130 \n",
            "(epoch: 34, iters: 2900, time: 0.067, data: 0.005) G_GAN: 0.657 G_L1: 2.585 D_real: 1.392 D_fake: 0.354 \n",
            "(epoch: 34, iters: 3000, time: 0.066, data: 0.004) G_GAN: 3.420 G_L1: 2.453 D_real: 0.057 D_fake: 0.076 \n",
            "saving the latest model (epoch 34, total_iters 135000)\n",
            "(epoch: 34, iters: 3100, time: 0.063, data: 0.002) G_GAN: 0.736 G_L1: 3.560 D_real: 0.869 D_fake: 0.890 \n",
            "(epoch: 34, iters: 3200, time: 0.214, data: 0.004) G_GAN: 0.909 G_L1: 5.142 D_real: 0.824 D_fake: 0.582 \n",
            "(epoch: 34, iters: 3300, time: 0.067, data: 0.012) G_GAN: 5.467 G_L1: 1.988 D_real: 0.030 D_fake: 0.008 \n",
            "(epoch: 34, iters: 3400, time: 0.065, data: 0.002) G_GAN: 2.237 G_L1: 2.077 D_real: 0.050 D_fake: 1.190 \n",
            "(epoch: 34, iters: 3500, time: 0.066, data: 0.003) G_GAN: 2.134 G_L1: 4.228 D_real: 0.530 D_fake: 0.148 \n",
            "(epoch: 34, iters: 3600, time: 0.157, data: 0.003) G_GAN: 4.416 G_L1: 1.387 D_real: 0.002 D_fake: 0.079 \n",
            "(epoch: 34, iters: 3700, time: 0.066, data: 0.003) G_GAN: 3.204 G_L1: 2.666 D_real: 0.299 D_fake: 0.050 \n",
            "(epoch: 34, iters: 3800, time: 0.066, data: 0.003) G_GAN: 5.727 G_L1: 9.625 D_real: 0.182 D_fake: 0.006 \n",
            "(epoch: 34, iters: 3900, time: 0.067, data: 0.003) G_GAN: 5.759 G_L1: 2.900 D_real: 0.362 D_fake: 0.004 \n",
            "(epoch: 34, iters: 4000, time: 0.319, data: 0.002) G_GAN: 2.206 G_L1: 5.433 D_real: 0.454 D_fake: 1.428 \n",
            "End of epoch 34 / 200 \t Time Taken: 173 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "(epoch: 35, iters: 100, time: 0.067, data: 0.184) G_GAN: 2.155 G_L1: 4.562 D_real: 0.358 D_fake: 0.111 \n",
            "(epoch: 35, iters: 200, time: 0.067, data: 0.004) G_GAN: 3.915 G_L1: 1.666 D_real: 0.076 D_fake: 0.037 \n",
            "(epoch: 35, iters: 300, time: 0.062, data: 0.003) G_GAN: 4.286 G_L1: 2.897 D_real: 0.133 D_fake: 0.019 \n",
            "(epoch: 35, iters: 400, time: 0.480, data: 0.002) G_GAN: 4.481 G_L1: 1.512 D_real: 0.006 D_fake: 0.015 \n",
            "(epoch: 35, iters: 500, time: 0.066, data: 0.010) G_GAN: 0.812 G_L1: 2.319 D_real: 0.985 D_fake: 0.855 \n",
            "(epoch: 35, iters: 600, time: 0.060, data: 0.006) G_GAN: 0.789 G_L1: 0.939 D_real: 1.219 D_fake: 0.752 \n",
            "(epoch: 35, iters: 700, time: 0.065, data: 0.003) G_GAN: 2.422 G_L1: 2.720 D_real: 1.195 D_fake: 0.080 \n",
            "(epoch: 35, iters: 800, time: 0.222, data: 0.003) G_GAN: 1.009 G_L1: 2.073 D_real: 0.651 D_fake: 0.508 \n",
            "(epoch: 35, iters: 900, time: 0.066, data: 0.015) G_GAN: 0.945 G_L1: 2.502 D_real: 0.750 D_fake: 0.587 \n",
            "(epoch: 35, iters: 1000, time: 0.067, data: 0.003) G_GAN: 2.611 G_L1: 1.894 D_real: 0.121 D_fake: 0.226 \n",
            "(epoch: 35, iters: 1100, time: 0.066, data: 0.003) G_GAN: 2.589 G_L1: 1.577 D_real: 0.212 D_fake: 0.352 \n",
            "(epoch: 35, iters: 1200, time: 0.217, data: 0.002) G_GAN: 0.872 G_L1: 2.010 D_real: 0.385 D_fake: 0.857 \n",
            "(epoch: 35, iters: 1300, time: 0.067, data: 0.004) G_GAN: 0.901 G_L1: 2.642 D_real: 0.447 D_fake: 0.712 \n",
            "(epoch: 35, iters: 1400, time: 0.066, data: 0.002) G_GAN: 1.016 G_L1: 5.533 D_real: 0.584 D_fake: 0.552 \n",
            "(epoch: 35, iters: 1500, time: 0.066, data: 0.003) G_GAN: 1.324 G_L1: 2.853 D_real: 0.603 D_fake: 0.358 \n",
            "(epoch: 35, iters: 1600, time: 0.194, data: 0.003) G_GAN: 2.708 G_L1: 4.830 D_real: 0.130 D_fake: 0.290 \n",
            "(epoch: 35, iters: 1700, time: 0.066, data: 0.006) G_GAN: 2.062 G_L1: 1.503 D_real: 0.156 D_fake: 0.691 \n",
            "(epoch: 35, iters: 1800, time: 0.067, data: 0.002) G_GAN: 1.419 G_L1: 2.145 D_real: 0.405 D_fake: 0.412 \n",
            "(epoch: 35, iters: 1900, time: 0.063, data: 0.002) G_GAN: 1.986 G_L1: 2.347 D_real: 1.489 D_fake: 0.116 \n",
            "(epoch: 35, iters: 2000, time: 0.359, data: 0.003) G_GAN: 2.691 G_L1: 2.233 D_real: 0.162 D_fake: 1.178 \n",
            "(epoch: 35, iters: 2100, time: 0.066, data: 0.003) G_GAN: 3.249 G_L1: 1.511 D_real: 0.033 D_fake: 0.087 \n",
            "(epoch: 35, iters: 2200, time: 0.066, data: 0.002) G_GAN: 5.167 G_L1: 1.487 D_real: 0.039 D_fake: 0.009 \n",
            "(epoch: 35, iters: 2300, time: 0.067, data: 0.004) G_GAN: 1.268 G_L1: 2.020 D_real: 0.690 D_fake: 0.583 \n",
            "(epoch: 35, iters: 2400, time: 0.167, data: 0.002) G_GAN: 2.358 G_L1: 4.230 D_real: 0.066 D_fake: 1.514 \n",
            "(epoch: 35, iters: 2500, time: 0.065, data: 0.005) G_GAN: 2.145 G_L1: 2.996 D_real: 1.193 D_fake: 0.519 \n",
            "(epoch: 35, iters: 2600, time: 0.065, data: 0.004) G_GAN: 2.118 G_L1: 1.583 D_real: 0.710 D_fake: 0.559 \n",
            "(epoch: 35, iters: 2700, time: 0.067, data: 0.003) G_GAN: 3.471 G_L1: 2.280 D_real: 0.568 D_fake: 0.019 \n",
            "(epoch: 35, iters: 2800, time: 0.171, data: 0.003) G_GAN: 2.538 G_L1: 1.859 D_real: 0.090 D_fake: 0.553 \n",
            "(epoch: 35, iters: 2900, time: 0.065, data: 0.003) G_GAN: 6.644 G_L1: 1.430 D_real: 0.000 D_fake: 0.002 \n",
            "(epoch: 35, iters: 3000, time: 0.066, data: 0.003) G_GAN: 2.468 G_L1: 6.491 D_real: 0.382 D_fake: 0.594 \n",
            "(epoch: 35, iters: 3100, time: 0.066, data: 0.003) G_GAN: 0.845 G_L1: 3.920 D_real: 0.781 D_fake: 0.624 \n",
            "(epoch: 35, iters: 3200, time: 0.235, data: 0.003) G_GAN: 0.881 G_L1: 1.909 D_real: 0.722 D_fake: 0.615 \n",
            "(epoch: 35, iters: 3300, time: 0.059, data: 0.009) G_GAN: 1.869 G_L1: 4.718 D_real: 0.211 D_fake: 0.350 \n",
            "(epoch: 35, iters: 3400, time: 0.065, data: 0.003) G_GAN: 1.207 G_L1: 2.208 D_real: 0.851 D_fake: 0.243 \n",
            "(epoch: 35, iters: 3500, time: 0.067, data: 0.002) G_GAN: 6.897 G_L1: 1.009 D_real: 0.002 D_fake: 0.002 \n",
            "(epoch: 35, iters: 3600, time: 0.171, data: 0.003) G_GAN: 2.559 G_L1: 3.542 D_real: 0.263 D_fake: 0.078 \n",
            "(epoch: 35, iters: 3700, time: 0.066, data: 0.002) G_GAN: 0.979 G_L1: 7.873 D_real: 0.823 D_fake: 0.558 \n",
            "(epoch: 35, iters: 3800, time: 0.066, data: 0.002) G_GAN: 2.506 G_L1: 3.428 D_real: 0.041 D_fake: 1.202 \n",
            "(epoch: 35, iters: 3900, time: 0.067, data: 0.005) G_GAN: 3.593 G_L1: 2.243 D_real: 0.135 D_fake: 0.047 \n",
            "(epoch: 35, iters: 4000, time: 0.341, data: 0.004) G_GAN: 5.343 G_L1: 1.277 D_real: 0.000 D_fake: 0.010 \n",
            "saving the latest model (epoch 35, total_iters 140000)\n",
            "saving the model at the end of epoch 35, iters 140000\n",
            "End of epoch 35 / 200 \t Time Taken: 174 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "(epoch: 36, iters: 100, time: 0.067, data: 0.186) G_GAN: 6.385 G_L1: 1.483 D_real: 0.001 D_fake: 0.002 \n",
            "(epoch: 36, iters: 200, time: 0.066, data: 0.003) G_GAN: 0.952 G_L1: 2.032 D_real: 0.636 D_fake: 0.754 \n",
            "(epoch: 36, iters: 300, time: 0.067, data: 0.002) G_GAN: 0.938 G_L1: 2.119 D_real: 0.708 D_fake: 0.538 \n",
            "(epoch: 36, iters: 400, time: 0.534, data: 0.002) G_GAN: 0.786 G_L1: 4.088 D_real: 0.530 D_fake: 0.958 \n",
            "(epoch: 36, iters: 500, time: 0.067, data: 0.002) G_GAN: 4.103 G_L1: 0.905 D_real: 0.000 D_fake: 0.049 \n",
            "(epoch: 36, iters: 600, time: 0.067, data: 0.003) G_GAN: 0.642 G_L1: 1.885 D_real: 0.346 D_fake: 1.224 \n",
            "(epoch: 36, iters: 700, time: 0.066, data: 0.004) G_GAN: 1.096 G_L1: 2.116 D_real: 0.529 D_fake: 0.540 \n",
            "(epoch: 36, iters: 800, time: 0.163, data: 0.002) G_GAN: 5.287 G_L1: 0.615 D_real: 0.000 D_fake: 0.006 \n",
            "(epoch: 36, iters: 900, time: 0.066, data: 0.005) G_GAN: 5.147 G_L1: 1.687 D_real: 0.225 D_fake: 0.010 \n",
            "(epoch: 36, iters: 1000, time: 0.066, data: 0.003) G_GAN: 4.070 G_L1: 4.057 D_real: 0.158 D_fake: 0.027 \n",
            "(epoch: 36, iters: 1100, time: 0.066, data: 0.002) G_GAN: 1.702 G_L1: 2.323 D_real: 0.721 D_fake: 0.199 \n",
            "(epoch: 36, iters: 1200, time: 0.170, data: 0.003) G_GAN: 2.935 G_L1: 1.800 D_real: 0.050 D_fake: 0.115 \n",
            "(epoch: 36, iters: 1300, time: 0.062, data: 0.002) G_GAN: 7.690 G_L1: 0.913 D_real: 0.005 D_fake: 0.001 \n",
            "(epoch: 36, iters: 1400, time: 0.066, data: 0.002) G_GAN: 2.140 G_L1: 1.858 D_real: 0.183 D_fake: 1.032 \n",
            "(epoch: 36, iters: 1500, time: 0.061, data: 0.003) G_GAN: 6.400 G_L1: 0.730 D_real: 0.002 D_fake: 0.004 \n",
            "(epoch: 36, iters: 1600, time: 0.223, data: 0.003) G_GAN: 0.867 G_L1: 3.847 D_real: 0.633 D_fake: 0.826 \n",
            "(epoch: 36, iters: 1700, time: 0.067, data: 0.012) G_GAN: 3.425 G_L1: 7.276 D_real: 0.130 D_fake: 0.161 \n",
            "(epoch: 36, iters: 1800, time: 0.067, data: 0.002) G_GAN: 8.500 G_L1: 1.359 D_real: 0.001 D_fake: 0.000 \n",
            "(epoch: 36, iters: 1900, time: 0.065, data: 0.002) G_GAN: 0.870 G_L1: 3.869 D_real: 0.422 D_fake: 0.834 \n",
            "(epoch: 36, iters: 2000, time: 0.344, data: 0.002) G_GAN: 3.372 G_L1: 2.307 D_real: 0.203 D_fake: 0.804 \n",
            "(epoch: 36, iters: 2100, time: 0.067, data: 0.004) G_GAN: 2.322 G_L1: 4.372 D_real: 0.658 D_fake: 0.122 \n",
            "(epoch: 36, iters: 2200, time: 0.067, data: 0.003) G_GAN: 2.642 G_L1: 2.180 D_real: 0.109 D_fake: 0.211 \n",
            "(epoch: 36, iters: 2300, time: 0.067, data: 0.002) G_GAN: 2.110 G_L1: 1.776 D_real: 0.041 D_fake: 0.921 \n",
            "(epoch: 36, iters: 2400, time: 0.223, data: 0.003) G_GAN: 1.330 G_L1: 2.172 D_real: 1.405 D_fake: 0.216 \n",
            "(epoch: 36, iters: 2500, time: 0.065, data: 0.002) G_GAN: 7.110 G_L1: 0.633 D_real: 0.002 D_fake: 0.001 \n",
            "(epoch: 36, iters: 2600, time: 0.067, data: 0.004) G_GAN: 6.409 G_L1: 1.144 D_real: 0.001 D_fake: 0.003 \n",
            "(epoch: 36, iters: 2700, time: 0.067, data: 0.002) G_GAN: 4.313 G_L1: 0.765 D_real: 0.014 D_fake: 0.194 \n",
            "(epoch: 36, iters: 2800, time: 0.191, data: 0.002) G_GAN: 1.245 G_L1: 2.231 D_real: 0.490 D_fake: 0.574 \n",
            "(epoch: 36, iters: 2900, time: 0.065, data: 0.003) G_GAN: 0.255 G_L1: 3.734 D_real: 2.792 D_fake: 0.207 \n",
            "(epoch: 36, iters: 3000, time: 0.064, data: 0.003) G_GAN: 2.641 G_L1: 3.097 D_real: 0.436 D_fake: 1.348 \n",
            "(epoch: 36, iters: 3100, time: 0.066, data: 0.004) G_GAN: 4.782 G_L1: 3.717 D_real: 0.069 D_fake: 0.011 \n",
            "(epoch: 36, iters: 3200, time: 0.169, data: 0.004) G_GAN: 7.158 G_L1: 1.415 D_real: 0.001 D_fake: 0.001 \n",
            "(epoch: 36, iters: 3300, time: 0.067, data: 0.002) G_GAN: 1.178 G_L1: 2.804 D_real: 1.021 D_fake: 0.321 \n",
            "(epoch: 36, iters: 3400, time: 0.067, data: 0.002) G_GAN: 7.307 G_L1: 1.674 D_real: 0.001 D_fake: 0.002 \n",
            "(epoch: 36, iters: 3500, time: 0.067, data: 0.003) G_GAN: 6.823 G_L1: 0.923 D_real: 0.001 D_fake: 0.002 \n",
            "(epoch: 36, iters: 3600, time: 0.173, data: 0.003) G_GAN: 4.763 G_L1: 3.975 D_real: 0.223 D_fake: 0.015 \n",
            "(epoch: 36, iters: 3700, time: 0.065, data: 0.003) G_GAN: 1.358 G_L1: 2.033 D_real: 0.523 D_fake: 0.216 \n",
            "(epoch: 36, iters: 3800, time: 0.066, data: 0.003) G_GAN: 0.877 G_L1: 1.301 D_real: 0.733 D_fake: 0.861 \n",
            "(epoch: 36, iters: 3900, time: 0.064, data: 0.003) G_GAN: 0.863 G_L1: 2.006 D_real: 0.645 D_fake: 0.751 \n",
            "(epoch: 36, iters: 4000, time: 0.342, data: 0.002) G_GAN: 8.153 G_L1: 1.378 D_real: 0.001 D_fake: 0.001 \n",
            "End of epoch 36 / 200 \t Time Taken: 172 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "(epoch: 37, iters: 100, time: 0.058, data: 0.170) G_GAN: 1.133 G_L1: 2.179 D_real: 0.659 D_fake: 0.943 \n",
            "(epoch: 37, iters: 200, time: 0.066, data: 0.002) G_GAN: 6.483 G_L1: 1.223 D_real: 0.002 D_fake: 0.003 \n",
            "(epoch: 37, iters: 300, time: 0.063, data: 0.002) G_GAN: 3.374 G_L1: 1.374 D_real: 0.303 D_fake: 0.587 \n",
            "(epoch: 37, iters: 400, time: 0.540, data: 0.002) G_GAN: 2.466 G_L1: 2.453 D_real: 0.246 D_fake: 0.143 \n",
            "(epoch: 37, iters: 500, time: 0.067, data: 0.003) G_GAN: 0.774 G_L1: 2.560 D_real: 0.721 D_fake: 0.743 \n",
            "(epoch: 37, iters: 600, time: 0.067, data: 0.002) G_GAN: 2.381 G_L1: 2.221 D_real: 0.046 D_fake: 0.667 \n",
            "(epoch: 37, iters: 700, time: 0.067, data: 0.003) G_GAN: 1.345 G_L1: 2.235 D_real: 0.352 D_fake: 0.646 \n",
            "(epoch: 37, iters: 800, time: 0.196, data: 0.003) G_GAN: 3.616 G_L1: 1.418 D_real: 0.016 D_fake: 0.062 \n",
            "(epoch: 37, iters: 900, time: 0.066, data: 0.002) G_GAN: 5.145 G_L1: 0.652 D_real: 0.002 D_fake: 0.007 \n",
            "(epoch: 37, iters: 1000, time: 0.065, data: 0.003) G_GAN: 2.948 G_L1: 3.915 D_real: 0.247 D_fake: 0.143 \n",
            "saving the latest model (epoch 37, total_iters 145000)\n",
            "(epoch: 37, iters: 1100, time: 0.067, data: 0.002) G_GAN: 1.265 G_L1: 1.622 D_real: 5.441 D_fake: 0.061 \n",
            "(epoch: 37, iters: 1200, time: 0.221, data: 0.003) G_GAN: 0.888 G_L1: 5.958 D_real: 0.660 D_fake: 0.605 \n",
            "(epoch: 37, iters: 1300, time: 0.067, data: 0.002) G_GAN: 2.685 G_L1: 2.357 D_real: 0.030 D_fake: 1.026 \n",
            "(epoch: 37, iters: 1400, time: 0.067, data: 0.003) G_GAN: 5.983 G_L1: 3.075 D_real: 0.001 D_fake: 0.004 \n",
            "(epoch: 37, iters: 1500, time: 0.066, data: 0.003) G_GAN: 5.894 G_L1: 1.676 D_real: 0.264 D_fake: 0.005 \n",
            "(epoch: 37, iters: 1600, time: 0.161, data: 0.004) G_GAN: 7.175 G_L1: 0.865 D_real: 0.001 D_fake: 0.001 \n",
            "(epoch: 37, iters: 1700, time: 0.067, data: 0.012) G_GAN: 3.644 G_L1: 3.594 D_real: 0.009 D_fake: 0.075 \n",
            "(epoch: 37, iters: 1800, time: 0.066, data: 0.002) G_GAN: 4.954 G_L1: 1.866 D_real: 0.000 D_fake: 0.011 \n",
            "(epoch: 37, iters: 1900, time: 0.063, data: 0.003) G_GAN: 6.157 G_L1: 1.514 D_real: 0.001 D_fake: 0.003 \n",
            "(epoch: 37, iters: 2000, time: 0.332, data: 0.003) G_GAN: 4.036 G_L1: 1.693 D_real: 0.067 D_fake: 0.055 \n",
            "(epoch: 37, iters: 2100, time: 0.067, data: 0.002) G_GAN: 2.790 G_L1: 2.986 D_real: 0.085 D_fake: 0.377 \n",
            "(epoch: 37, iters: 2200, time: 0.067, data: 0.003) G_GAN: 5.541 G_L1: 2.154 D_real: 0.000 D_fake: 0.005 \n",
            "(epoch: 37, iters: 2300, time: 0.065, data: 0.004) G_GAN: 3.540 G_L1: 2.600 D_real: 0.018 D_fake: 0.049 \n",
            "(epoch: 37, iters: 2400, time: 0.230, data: 0.003) G_GAN: 1.535 G_L1: 2.410 D_real: 0.619 D_fake: 0.495 \n",
            "(epoch: 37, iters: 2500, time: 0.065, data: 0.006) G_GAN: 4.883 G_L1: 1.543 D_real: 0.004 D_fake: 0.011 \n",
            "(epoch: 37, iters: 2600, time: 0.060, data: 0.004) G_GAN: 5.267 G_L1: 1.473 D_real: 0.000 D_fake: 0.010 \n",
            "(epoch: 37, iters: 2700, time: 0.065, data: 0.003) G_GAN: 5.465 G_L1: 1.939 D_real: 0.001 D_fake: 0.007 \n",
            "(epoch: 37, iters: 2800, time: 0.168, data: 0.003) G_GAN: 2.431 G_L1: 4.023 D_real: 0.221 D_fake: 0.266 \n",
            "(epoch: 37, iters: 2900, time: 0.060, data: 0.007) G_GAN: 5.112 G_L1: 3.447 D_real: 0.324 D_fake: 0.012 \n",
            "(epoch: 37, iters: 3000, time: 0.067, data: 0.003) G_GAN: 3.555 G_L1: 1.604 D_real: 0.023 D_fake: 0.050 \n",
            "(epoch: 37, iters: 3100, time: 0.067, data: 0.007) G_GAN: 5.901 G_L1: 1.633 D_real: 0.000 D_fake: 0.004 \n",
            "(epoch: 37, iters: 3200, time: 0.162, data: 0.002) G_GAN: 8.442 G_L1: 0.862 D_real: 0.004 D_fake: 0.001 \n",
            "(epoch: 37, iters: 3300, time: 0.066, data: 0.006) G_GAN: 0.868 G_L1: 2.913 D_real: 0.517 D_fake: 0.762 \n",
            "(epoch: 37, iters: 3400, time: 0.065, data: 0.002) G_GAN: 0.812 G_L1: 2.165 D_real: 1.251 D_fake: 0.273 \n",
            "(epoch: 37, iters: 3500, time: 0.064, data: 0.003) G_GAN: 3.176 G_L1: 3.904 D_real: 0.307 D_fake: 0.280 \n",
            "(epoch: 37, iters: 3600, time: 0.174, data: 0.002) G_GAN: 1.030 G_L1: 2.174 D_real: 1.019 D_fake: 0.245 \n",
            "(epoch: 37, iters: 3700, time: 0.067, data: 0.002) G_GAN: 7.693 G_L1: 0.875 D_real: 0.000 D_fake: 0.001 \n",
            "(epoch: 37, iters: 3800, time: 0.067, data: 0.002) G_GAN: 5.608 G_L1: 1.739 D_real: 0.000 D_fake: 0.006 \n",
            "(epoch: 37, iters: 3900, time: 0.065, data: 0.002) G_GAN: 4.108 G_L1: 3.065 D_real: 0.078 D_fake: 0.088 \n",
            "(epoch: 37, iters: 4000, time: 0.329, data: 0.003) G_GAN: 6.765 G_L1: 2.214 D_real: 0.000 D_fake: 0.003 \n",
            "End of epoch 37 / 200 \t Time Taken: 173 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "(epoch: 38, iters: 100, time: 0.065, data: 0.184) G_GAN: 1.527 G_L1: 1.512 D_real: 0.094 D_fake: 1.656 \n",
            "(epoch: 38, iters: 200, time: 0.066, data: 0.003) G_GAN: 1.125 G_L1: 4.721 D_real: 0.898 D_fake: 0.381 \n",
            "(epoch: 38, iters: 300, time: 0.066, data: 0.002) G_GAN: 2.195 G_L1: 2.627 D_real: 0.097 D_fake: 0.197 \n",
            "(epoch: 38, iters: 400, time: 0.453, data: 0.002) G_GAN: 2.265 G_L1: 2.444 D_real: 0.370 D_fake: 0.151 \n",
            "(epoch: 38, iters: 500, time: 0.065, data: 0.004) G_GAN: 2.885 G_L1: 1.545 D_real: 0.126 D_fake: 0.153 \n",
            "(epoch: 38, iters: 600, time: 0.066, data: 0.004) G_GAN: 5.096 G_L1: 2.436 D_real: 0.611 D_fake: 0.037 \n",
            "(epoch: 38, iters: 700, time: 0.064, data: 0.004) G_GAN: 5.145 G_L1: 3.147 D_real: 0.119 D_fake: 0.010 \n",
            "(epoch: 38, iters: 800, time: 0.222, data: 0.003) G_GAN: 0.807 G_L1: 3.372 D_real: 0.713 D_fake: 0.703 \n",
            "(epoch: 38, iters: 900, time: 0.064, data: 0.007) G_GAN: 6.407 G_L1: 0.717 D_real: 0.002 D_fake: 0.003 \n",
            "(epoch: 38, iters: 1000, time: 0.060, data: 0.002) G_GAN: 0.909 G_L1: 1.895 D_real: 0.397 D_fake: 0.965 \n",
            "(epoch: 38, iters: 1100, time: 0.062, data: 0.002) G_GAN: 7.323 G_L1: 1.085 D_real: 0.006 D_fake: 0.001 \n",
            "(epoch: 38, iters: 1200, time: 0.172, data: 0.003) G_GAN: 3.358 G_L1: 2.192 D_real: 0.178 D_fake: 0.073 \n",
            "(epoch: 38, iters: 1300, time: 0.066, data: 0.002) G_GAN: 1.418 G_L1: 2.439 D_real: 0.308 D_fake: 0.912 \n",
            "(epoch: 38, iters: 1400, time: 0.066, data: 0.002) G_GAN: 7.172 G_L1: 1.113 D_real: 0.032 D_fake: 0.001 \n",
            "(epoch: 38, iters: 1500, time: 0.065, data: 0.003) G_GAN: 0.921 G_L1: 4.061 D_real: 0.523 D_fake: 0.794 \n",
            "(epoch: 38, iters: 1600, time: 0.220, data: 0.003) G_GAN: 1.521 G_L1: 2.112 D_real: 0.276 D_fake: 0.680 \n",
            "(epoch: 38, iters: 1700, time: 0.065, data: 0.007) G_GAN: 7.633 G_L1: 2.704 D_real: 0.095 D_fake: 0.001 \n",
            "(epoch: 38, iters: 1800, time: 0.064, data: 0.002) G_GAN: 2.522 G_L1: 2.887 D_real: 0.454 D_fake: 0.115 \n",
            "(epoch: 38, iters: 1900, time: 0.067, data: 0.002) G_GAN: 6.120 G_L1: 1.169 D_real: 0.001 D_fake: 0.004 \n",
            "(epoch: 38, iters: 2000, time: 0.343, data: 0.003) G_GAN: 0.988 G_L1: 1.482 D_real: 0.569 D_fake: 0.790 \n",
            "saving the latest model (epoch 38, total_iters 150000)\n",
            "(epoch: 38, iters: 2100, time: 0.062, data: 0.002) G_GAN: 1.082 G_L1: 2.078 D_real: 0.551 D_fake: 0.695 \n",
            "(epoch: 38, iters: 2200, time: 0.067, data: 0.003) G_GAN: 2.067 G_L1: 2.595 D_real: 0.136 D_fake: 0.622 \n",
            "(epoch: 38, iters: 2300, time: 0.067, data: 0.003) G_GAN: 0.910 G_L1: 3.626 D_real: 0.678 D_fake: 0.541 \n",
            "(epoch: 38, iters: 2400, time: 0.171, data: 0.003) G_GAN: 2.975 G_L1: 2.364 D_real: 0.027 D_fake: 0.092 \n",
            "(epoch: 38, iters: 2500, time: 0.063, data: 0.002) G_GAN: 0.698 G_L1: 3.116 D_real: 0.152 D_fake: 1.918 \n",
            "(epoch: 38, iters: 2600, time: 0.063, data: 0.002) G_GAN: 3.686 G_L1: 2.375 D_real: 0.422 D_fake: 0.165 \n",
            "(epoch: 38, iters: 2700, time: 0.066, data: 0.006) G_GAN: 5.727 G_L1: 0.614 D_real: 0.017 D_fake: 0.400 \n",
            "(epoch: 38, iters: 2800, time: 0.156, data: 0.003) G_GAN: 6.256 G_L1: 0.596 D_real: 0.000 D_fake: 0.003 \n",
            "(epoch: 38, iters: 2900, time: 0.067, data: 0.003) G_GAN: 2.889 G_L1: 1.943 D_real: 0.563 D_fake: 0.066 \n",
            "(epoch: 38, iters: 3000, time: 0.067, data: 0.002) G_GAN: 2.363 G_L1: 3.595 D_real: 0.033 D_fake: 0.347 \n",
            "(epoch: 38, iters: 3100, time: 0.066, data: 0.003) G_GAN: 2.389 G_L1: 1.413 D_real: 0.250 D_fake: 0.638 \n",
            "(epoch: 38, iters: 3200, time: 0.172, data: 0.002) G_GAN: 2.012 G_L1: 2.128 D_real: 0.150 D_fake: 1.779 \n",
            "(epoch: 38, iters: 3300, time: 0.066, data: 0.005) G_GAN: 0.951 G_L1: 2.982 D_real: 0.804 D_fake: 0.750 \n",
            "(epoch: 38, iters: 3400, time: 0.067, data: 0.002) G_GAN: 3.700 G_L1: 2.006 D_real: 0.099 D_fake: 0.038 \n",
            "(epoch: 38, iters: 3500, time: 0.065, data: 0.002) G_GAN: 2.915 G_L1: 1.332 D_real: 0.350 D_fake: 0.320 \n",
            "(epoch: 38, iters: 3600, time: 0.160, data: 0.002) G_GAN: 6.066 G_L1: 1.173 D_real: 0.002 D_fake: 0.004 \n",
            "(epoch: 38, iters: 3700, time: 0.066, data: 0.003) G_GAN: 2.711 G_L1: 6.131 D_real: 0.161 D_fake: 1.312 \n",
            "(epoch: 38, iters: 3800, time: 0.067, data: 0.007) G_GAN: 7.380 G_L1: 0.886 D_real: 0.001 D_fake: 0.002 \n",
            "(epoch: 38, iters: 3900, time: 0.066, data: 0.002) G_GAN: 6.791 G_L1: 0.603 D_real: 0.001 D_fake: 0.002 \n",
            "(epoch: 38, iters: 4000, time: 0.403, data: 0.003) G_GAN: 1.060 G_L1: 2.218 D_real: 0.955 D_fake: 0.548 \n",
            "End of epoch 38 / 200 \t Time Taken: 173 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "(epoch: 39, iters: 100, time: 0.066, data: 0.208) G_GAN: 2.540 G_L1: 2.597 D_real: 0.177 D_fake: 0.124 \n",
            "(epoch: 39, iters: 200, time: 0.066, data: 0.002) G_GAN: 6.708 G_L1: 0.658 D_real: 0.002 D_fake: 0.002 \n",
            "(epoch: 39, iters: 300, time: 0.061, data: 0.002) G_GAN: 0.848 G_L1: 2.438 D_real: 0.819 D_fake: 0.569 \n",
            "(epoch: 39, iters: 400, time: 0.562, data: 0.005) G_GAN: 0.871 G_L1: 4.946 D_real: 0.692 D_fake: 0.599 \n",
            "(epoch: 39, iters: 500, time: 0.066, data: 0.003) G_GAN: 0.891 G_L1: 2.173 D_real: 0.876 D_fake: 0.509 \n",
            "(epoch: 39, iters: 600, time: 0.066, data: 0.003) G_GAN: 0.870 G_L1: 2.689 D_real: 0.744 D_fake: 0.575 \n",
            "(epoch: 39, iters: 700, time: 0.066, data: 0.003) G_GAN: 8.137 G_L1: 0.794 D_real: 0.002 D_fake: 0.001 \n",
            "(epoch: 39, iters: 800, time: 0.157, data: 0.003) G_GAN: 2.477 G_L1: 4.773 D_real: 0.144 D_fake: 0.169 \n",
            "(epoch: 39, iters: 900, time: 0.067, data: 0.003) G_GAN: 6.195 G_L1: 1.837 D_real: 1.456 D_fake: 0.002 \n",
            "(epoch: 39, iters: 1000, time: 0.065, data: 0.002) G_GAN: 2.898 G_L1: 1.433 D_real: 0.014 D_fake: 0.400 \n",
            "(epoch: 39, iters: 1100, time: 0.066, data: 0.002) G_GAN: 0.751 G_L1: 2.368 D_real: 1.264 D_fake: 0.410 \n",
            "(epoch: 39, iters: 1200, time: 0.186, data: 0.002) G_GAN: 2.821 G_L1: 1.346 D_real: 0.062 D_fake: 1.002 \n",
            "(epoch: 39, iters: 1300, time: 0.066, data: 0.002) G_GAN: 2.160 G_L1: 3.908 D_real: 0.061 D_fake: 0.488 \n",
            "(epoch: 39, iters: 1400, time: 0.062, data: 0.004) G_GAN: 3.424 G_L1: 1.795 D_real: 0.039 D_fake: 0.095 \n",
            "(epoch: 39, iters: 1500, time: 0.066, data: 0.003) G_GAN: 5.417 G_L1: 1.878 D_real: 0.000 D_fake: 0.007 \n",
            "(epoch: 39, iters: 1600, time: 0.168, data: 0.004) G_GAN: 2.302 G_L1: 1.651 D_real: 0.094 D_fake: 0.926 \n",
            "(epoch: 39, iters: 1700, time: 0.065, data: 0.002) G_GAN: 0.822 G_L1: 3.257 D_real: 0.762 D_fake: 0.690 \n",
            "(epoch: 39, iters: 1800, time: 0.066, data: 0.002) G_GAN: 0.916 G_L1: 2.007 D_real: 0.343 D_fake: 0.990 \n",
            "(epoch: 39, iters: 1900, time: 0.066, data: 0.003) G_GAN: 0.953 G_L1: 2.979 D_real: 0.674 D_fake: 0.605 \n",
            "(epoch: 39, iters: 2000, time: 0.384, data: 0.004) G_GAN: 4.908 G_L1: 1.533 D_real: 0.114 D_fake: 0.014 \n",
            "(epoch: 39, iters: 2100, time: 0.066, data: 0.003) G_GAN: 2.388 G_L1: 2.192 D_real: 0.031 D_fake: 0.562 \n",
            "(epoch: 39, iters: 2200, time: 0.066, data: 0.002) G_GAN: 4.724 G_L1: 0.800 D_real: 0.003 D_fake: 0.019 \n",
            "(epoch: 39, iters: 2300, time: 0.066, data: 0.002) G_GAN: 3.783 G_L1: 1.329 D_real: 0.000 D_fake: 0.063 \n",
            "(epoch: 39, iters: 2400, time: 0.159, data: 0.002) G_GAN: 5.790 G_L1: 1.039 D_real: 0.001 D_fake: 0.005 \n",
            "(epoch: 39, iters: 2500, time: 0.065, data: 0.010) G_GAN: 3.587 G_L1: 3.637 D_real: 2.816 D_fake: 0.071 \n",
            "(epoch: 39, iters: 2600, time: 0.066, data: 0.002) G_GAN: 1.548 G_L1: 3.355 D_real: 0.491 D_fake: 0.264 \n",
            "(epoch: 39, iters: 2700, time: 0.066, data: 0.004) G_GAN: 2.436 G_L1: 2.493 D_real: 0.905 D_fake: 0.050 \n",
            "(epoch: 39, iters: 2800, time: 0.187, data: 0.004) G_GAN: 5.796 G_L1: 1.975 D_real: 0.003 D_fake: 0.005 \n",
            "(epoch: 39, iters: 2900, time: 0.065, data: 0.008) G_GAN: 6.850 G_L1: 0.986 D_real: 0.004 D_fake: 0.002 \n",
            "(epoch: 39, iters: 3000, time: 0.066, data: 0.003) G_GAN: 0.513 G_L1: 2.374 D_real: 0.209 D_fake: 1.474 \n",
            "saving the latest model (epoch 39, total_iters 155000)\n",
            "(epoch: 39, iters: 3100, time: 0.066, data: 0.003) G_GAN: 2.232 G_L1: 1.671 D_real: 0.095 D_fake: 0.246 \n",
            "(epoch: 39, iters: 3200, time: 0.220, data: 0.003) G_GAN: 0.920 G_L1: 2.314 D_real: 0.755 D_fake: 0.430 \n",
            "(epoch: 39, iters: 3300, time: 0.066, data: 0.003) G_GAN: 4.958 G_L1: 1.705 D_real: 0.002 D_fake: 0.010 \n",
            "(epoch: 39, iters: 3400, time: 0.067, data: 0.003) G_GAN: 3.870 G_L1: 3.619 D_real: 0.164 D_fake: 0.015 \n",
            "(epoch: 39, iters: 3500, time: 0.065, data: 0.003) G_GAN: 6.186 G_L1: 1.443 D_real: 0.001 D_fake: 0.004 \n",
            "(epoch: 39, iters: 3600, time: 0.163, data: 0.002) G_GAN: 3.478 G_L1: 2.109 D_real: 0.765 D_fake: 0.059 \n",
            "(epoch: 39, iters: 3700, time: 0.063, data: 0.005) G_GAN: 5.190 G_L1: 2.833 D_real: 0.181 D_fake: 0.007 \n",
            "(epoch: 39, iters: 3800, time: 0.058, data: 0.006) G_GAN: 7.275 G_L1: 1.019 D_real: 0.001 D_fake: 0.002 \n",
            "(epoch: 39, iters: 3900, time: 0.067, data: 0.002) G_GAN: 2.451 G_L1: 0.645 D_real: 0.310 D_fake: 0.215 \n",
            "(epoch: 39, iters: 4000, time: 0.404, data: 0.003) G_GAN: 0.653 G_L1: 1.839 D_real: 0.399 D_fake: 1.134 \n",
            "End of epoch 39 / 200 \t Time Taken: 173 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "(epoch: 40, iters: 100, time: 0.066, data: 0.162) G_GAN: 0.943 G_L1: 2.040 D_real: 0.814 D_fake: 0.526 \n",
            "(epoch: 40, iters: 200, time: 0.066, data: 0.004) G_GAN: 0.831 G_L1: 1.782 D_real: 0.576 D_fake: 0.850 \n",
            "(epoch: 40, iters: 300, time: 0.067, data: 0.003) G_GAN: 1.821 G_L1: 5.135 D_real: 0.085 D_fake: 0.495 \n",
            "(epoch: 40, iters: 400, time: 0.507, data: 0.006) G_GAN: 2.922 G_L1: 2.256 D_real: 0.210 D_fake: 0.977 \n",
            "(epoch: 40, iters: 500, time: 0.067, data: 0.002) G_GAN: 3.162 G_L1: 1.861 D_real: 2.761 D_fake: 0.009 \n",
            "(epoch: 40, iters: 600, time: 0.063, data: 0.007) G_GAN: 1.585 G_L1: 1.798 D_real: 0.273 D_fake: 0.696 \n",
            "(epoch: 40, iters: 700, time: 0.066, data: 0.003) G_GAN: 2.075 G_L1: 2.095 D_real: 0.353 D_fake: 0.297 \n",
            "(epoch: 40, iters: 800, time: 0.227, data: 0.003) G_GAN: 0.780 G_L1: 3.926 D_real: 0.797 D_fake: 0.726 \n",
            "(epoch: 40, iters: 900, time: 0.066, data: 0.006) G_GAN: 5.974 G_L1: 1.737 D_real: 0.000 D_fake: 0.005 \n",
            "(epoch: 40, iters: 1000, time: 0.066, data: 0.002) G_GAN: 7.033 G_L1: 3.059 D_real: 0.353 D_fake: 0.001 \n",
            "(epoch: 40, iters: 1100, time: 0.066, data: 0.003) G_GAN: 0.728 G_L1: 1.937 D_real: 0.899 D_fake: 0.686 \n",
            "(epoch: 40, iters: 1200, time: 0.224, data: 0.002) G_GAN: 0.814 G_L1: 2.083 D_real: 0.854 D_fake: 0.526 \n",
            "(epoch: 40, iters: 1300, time: 0.067, data: 0.002) G_GAN: 1.352 G_L1: 4.431 D_real: 0.561 D_fake: 0.779 \n",
            "(epoch: 40, iters: 1400, time: 0.066, data: 0.003) G_GAN: 2.461 G_L1: 1.871 D_real: 0.205 D_fake: 1.095 \n",
            "(epoch: 40, iters: 1500, time: 0.066, data: 0.003) G_GAN: 5.117 G_L1: 1.568 D_real: 0.125 D_fake: 0.012 \n",
            "(epoch: 40, iters: 1600, time: 0.189, data: 0.003) G_GAN: 2.958 G_L1: 5.534 D_real: 0.045 D_fake: 0.311 \n",
            "(epoch: 40, iters: 1700, time: 0.067, data: 0.002) G_GAN: 0.828 G_L1: 2.550 D_real: 0.726 D_fake: 0.651 \n",
            "(epoch: 40, iters: 1800, time: 0.066, data: 0.002) G_GAN: 1.073 G_L1: 2.062 D_real: 0.766 D_fake: 0.377 \n",
            "(epoch: 40, iters: 1900, time: 0.066, data: 0.002) G_GAN: 0.859 G_L1: 2.557 D_real: 0.641 D_fake: 0.777 \n",
            "(epoch: 40, iters: 2000, time: 0.347, data: 0.004) G_GAN: 2.651 G_L1: 2.212 D_real: 0.105 D_fake: 0.169 \n",
            "(epoch: 40, iters: 2100, time: 0.066, data: 0.004) G_GAN: 1.924 G_L1: 1.549 D_real: 0.330 D_fake: 0.379 \n",
            "(epoch: 40, iters: 2200, time: 0.066, data: 0.006) G_GAN: 6.860 G_L1: 1.447 D_real: 0.013 D_fake: 0.002 \n",
            "(epoch: 40, iters: 2300, time: 0.067, data: 0.004) G_GAN: 2.923 G_L1: 5.633 D_real: 0.056 D_fake: 0.079 \n",
            "(epoch: 40, iters: 2400, time: 0.162, data: 0.005) G_GAN: 4.902 G_L1: 0.934 D_real: 0.002 D_fake: 0.014 \n",
            "(epoch: 40, iters: 2500, time: 0.066, data: 0.006) G_GAN: 2.756 G_L1: 3.212 D_real: 0.031 D_fake: 0.195 \n",
            "(epoch: 40, iters: 2600, time: 0.066, data: 0.004) G_GAN: 0.837 G_L1: 3.004 D_real: 0.599 D_fake: 0.715 \n",
            "(epoch: 40, iters: 2700, time: 0.066, data: 0.003) G_GAN: 7.656 G_L1: 0.925 D_real: 0.003 D_fake: 0.001 \n",
            "(epoch: 40, iters: 2800, time: 0.156, data: 0.003) G_GAN: 9.980 G_L1: 0.825 D_real: 0.008 D_fake: 0.000 \n",
            "(epoch: 40, iters: 2900, time: 0.066, data: 0.003) G_GAN: 8.587 G_L1: 1.204 D_real: 0.001 D_fake: 0.000 \n",
            "(epoch: 40, iters: 3000, time: 0.067, data: 0.003) G_GAN: 6.416 G_L1: 0.889 D_real: 0.005 D_fake: 0.007 \n",
            "(epoch: 40, iters: 3100, time: 0.067, data: 0.003) G_GAN: 1.557 G_L1: 1.372 D_real: 1.729 D_fake: 0.348 \n",
            "(epoch: 40, iters: 3200, time: 0.169, data: 0.002) G_GAN: 1.654 G_L1: 7.618 D_real: 0.894 D_fake: 0.940 \n",
            "(epoch: 40, iters: 3300, time: 0.066, data: 0.004) G_GAN: 6.298 G_L1: 1.951 D_real: 0.071 D_fake: 0.004 \n",
            "(epoch: 40, iters: 3400, time: 0.062, data: 0.002) G_GAN: 6.666 G_L1: 1.349 D_real: 0.009 D_fake: 0.002 \n",
            "(epoch: 40, iters: 3500, time: 0.066, data: 0.006) G_GAN: 1.989 G_L1: 1.938 D_real: 0.027 D_fake: 1.821 \n",
            "(epoch: 40, iters: 3600, time: 0.177, data: 0.003) G_GAN: 2.077 G_L1: 1.781 D_real: 0.534 D_fake: 0.580 \n",
            "(epoch: 40, iters: 3700, time: 0.066, data: 0.004) G_GAN: 1.264 G_L1: 2.317 D_real: 0.426 D_fake: 0.995 \n",
            "(epoch: 40, iters: 3800, time: 0.066, data: 0.002) G_GAN: 0.821 G_L1: 2.146 D_real: 0.657 D_fake: 0.710 \n",
            "(epoch: 40, iters: 3900, time: 0.066, data: 0.003) G_GAN: 3.426 G_L1: 1.800 D_real: 0.000 D_fake: 0.044 \n",
            "(epoch: 40, iters: 4000, time: 0.410, data: 0.004) G_GAN: 1.007 G_L1: 2.571 D_real: 0.650 D_fake: 0.595 \n",
            "saving the latest model (epoch 40, total_iters 160000)\n",
            "saving the model at the end of epoch 40, iters 160000\n",
            "End of epoch 40 / 200 \t Time Taken: 175 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "(epoch: 41, iters: 100, time: 0.065, data: 0.170) G_GAN: 1.417 G_L1: 1.143 D_real: 0.193 D_fake: 0.721 \n",
            "(epoch: 41, iters: 200, time: 0.065, data: 0.004) G_GAN: 5.385 G_L1: 1.650 D_real: 0.001 D_fake: 0.007 \n",
            "(epoch: 41, iters: 300, time: 0.066, data: 0.002) G_GAN: 8.491 G_L1: 1.041 D_real: 0.003 D_fake: 0.000 \n",
            "(epoch: 41, iters: 400, time: 0.463, data: 0.004) G_GAN: 1.234 G_L1: 2.806 D_real: 0.463 D_fake: 0.287 \n",
            "(epoch: 41, iters: 500, time: 0.066, data: 0.003) G_GAN: 2.409 G_L1: 1.694 D_real: 0.448 D_fake: 0.373 \n",
            "(epoch: 41, iters: 600, time: 0.066, data: 0.002) G_GAN: 1.409 G_L1: 2.307 D_real: 0.693 D_fake: 0.309 \n",
            "(epoch: 41, iters: 700, time: 0.055, data: 0.003) G_GAN: 5.177 G_L1: 1.360 D_real: 0.150 D_fake: 0.009 \n",
            "(epoch: 41, iters: 800, time: 0.155, data: 0.003) G_GAN: 7.988 G_L1: 1.227 D_real: 0.007 D_fake: 0.001 \n",
            "(epoch: 41, iters: 900, time: 0.067, data: 0.004) G_GAN: 0.770 G_L1: 3.298 D_real: 0.746 D_fake: 0.712 \n",
            "(epoch: 41, iters: 1000, time: 0.066, data: 0.002) G_GAN: 0.967 G_L1: 2.936 D_real: 0.856 D_fake: 0.502 \n",
            "(epoch: 41, iters: 1100, time: 0.066, data: 0.003) G_GAN: 2.591 G_L1: 4.199 D_real: 0.173 D_fake: 0.127 \n",
            "(epoch: 41, iters: 1200, time: 0.200, data: 0.002) G_GAN: 3.173 G_L1: 1.947 D_real: 0.120 D_fake: 0.331 \n",
            "(epoch: 41, iters: 1300, time: 0.066, data: 0.002) G_GAN: 1.000 G_L1: 2.247 D_real: 0.604 D_fake: 0.751 \n",
            "(epoch: 41, iters: 1400, time: 0.065, data: 0.002) G_GAN: 1.782 G_L1: 1.693 D_real: 0.278 D_fake: 0.257 \n",
            "(epoch: 41, iters: 1500, time: 0.066, data: 0.004) G_GAN: 3.022 G_L1: 1.789 D_real: 0.123 D_fake: 0.224 \n",
            "(epoch: 41, iters: 1600, time: 0.223, data: 0.002) G_GAN: 1.398 G_L1: 2.186 D_real: 0.857 D_fake: 0.465 \n",
            "(epoch: 41, iters: 1700, time: 0.058, data: 0.002) G_GAN: 4.045 G_L1: 1.937 D_real: 0.006 D_fake: 0.029 \n",
            "(epoch: 41, iters: 1800, time: 0.064, data: 0.003) G_GAN: 0.986 G_L1: 2.088 D_real: 0.701 D_fake: 0.679 \n",
            "(epoch: 41, iters: 1900, time: 0.066, data: 0.003) G_GAN: 1.415 G_L1: 2.152 D_real: 0.740 D_fake: 0.220 \n",
            "(epoch: 41, iters: 2000, time: 0.346, data: 0.003) G_GAN: 3.480 G_L1: 2.093 D_real: 0.222 D_fake: 0.098 \n",
            "(epoch: 41, iters: 2100, time: 0.065, data: 0.003) G_GAN: 0.795 G_L1: 2.715 D_real: 0.363 D_fake: 1.024 \n",
            "(epoch: 41, iters: 2200, time: 0.066, data: 0.005) G_GAN: 1.894 G_L1: 2.314 D_real: 2.237 D_fake: 0.338 \n",
            "(epoch: 41, iters: 2300, time: 0.066, data: 0.003) G_GAN: 4.817 G_L1: 1.549 D_real: 0.001 D_fake: 0.012 \n",
            "(epoch: 41, iters: 2400, time: 0.171, data: 0.006) G_GAN: 2.609 G_L1: 1.930 D_real: 0.016 D_fake: 0.581 \n",
            "(epoch: 41, iters: 2500, time: 0.066, data: 0.010) G_GAN: 5.079 G_L1: 1.722 D_real: 0.000 D_fake: 0.011 \n",
            "(epoch: 41, iters: 2600, time: 0.067, data: 0.002) G_GAN: 2.562 G_L1: 3.814 D_real: 0.356 D_fake: 0.094 \n",
            "(epoch: 41, iters: 2700, time: 0.061, data: 0.005) G_GAN: 1.182 G_L1: 2.115 D_real: 0.386 D_fake: 0.829 \n",
            "(epoch: 41, iters: 2800, time: 0.158, data: 0.002) G_GAN: 7.934 G_L1: 0.767 D_real: 0.053 D_fake: 0.001 \n",
            "(epoch: 41, iters: 2900, time: 0.065, data: 0.010) G_GAN: 3.087 G_L1: 1.299 D_real: 0.119 D_fake: 0.054 \n",
            "(epoch: 41, iters: 3000, time: 0.067, data: 0.004) G_GAN: 1.819 G_L1: 3.510 D_real: 0.197 D_fake: 0.492 \n",
            "(epoch: 41, iters: 3100, time: 0.066, data: 0.002) G_GAN: 5.911 G_L1: 0.773 D_real: 0.000 D_fake: 0.004 \n",
            "(epoch: 41, iters: 3200, time: 0.186, data: 0.003) G_GAN: 2.359 G_L1: 3.682 D_real: 0.060 D_fake: 0.648 \n",
            "(epoch: 41, iters: 3300, time: 0.067, data: 0.002) G_GAN: 2.115 G_L1: 2.373 D_real: 0.683 D_fake: 0.157 \n",
            "(epoch: 41, iters: 3400, time: 0.067, data: 0.002) G_GAN: 0.800 G_L1: 2.088 D_real: 0.464 D_fake: 0.947 \n",
            "(epoch: 41, iters: 3500, time: 0.064, data: 0.002) G_GAN: 6.666 G_L1: 0.872 D_real: 0.000 D_fake: 0.003 \n",
            "(epoch: 41, iters: 3600, time: 0.218, data: 0.002) G_GAN: 0.864 G_L1: 1.989 D_real: 1.084 D_fake: 0.370 \n",
            "(epoch: 41, iters: 3700, time: 0.064, data: 0.005) G_GAN: 3.831 G_L1: 1.127 D_real: 0.447 D_fake: 0.024 \n",
            "(epoch: 41, iters: 3800, time: 0.066, data: 0.003) G_GAN: 0.941 G_L1: 2.342 D_real: 0.830 D_fake: 0.550 \n",
            "(epoch: 41, iters: 3900, time: 0.067, data: 0.003) G_GAN: 6.213 G_L1: 1.210 D_real: 0.001 D_fake: 0.003 \n",
            "(epoch: 41, iters: 4000, time: 0.416, data: 0.002) G_GAN: 2.961 G_L1: 1.639 D_real: 0.031 D_fake: 0.109 \n",
            "End of epoch 41 / 200 \t Time Taken: 172 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "(epoch: 42, iters: 100, time: 0.067, data: 0.181) G_GAN: 5.093 G_L1: 1.982 D_real: 0.004 D_fake: 0.009 \n",
            "(epoch: 42, iters: 200, time: 0.067, data: 0.003) G_GAN: 3.511 G_L1: 1.248 D_real: 0.094 D_fake: 0.071 \n",
            "(epoch: 42, iters: 300, time: 0.067, data: 0.002) G_GAN: 0.948 G_L1: 2.032 D_real: 0.334 D_fake: 1.380 \n",
            "(epoch: 42, iters: 400, time: 0.461, data: 0.007) G_GAN: 6.431 G_L1: 3.127 D_real: 0.882 D_fake: 0.002 \n",
            "(epoch: 42, iters: 500, time: 0.066, data: 0.005) G_GAN: 0.729 G_L1: 7.719 D_real: 0.590 D_fake: 0.879 \n",
            "(epoch: 42, iters: 600, time: 0.067, data: 0.003) G_GAN: 3.087 G_L1: 1.881 D_real: 0.132 D_fake: 0.118 \n",
            "(epoch: 42, iters: 700, time: 0.066, data: 0.004) G_GAN: 0.946 G_L1: 3.360 D_real: 0.608 D_fake: 0.594 \n",
            "(epoch: 42, iters: 800, time: 0.161, data: 0.002) G_GAN: 7.029 G_L1: 0.993 D_real: 0.003 D_fake: 0.001 \n",
            "(epoch: 42, iters: 900, time: 0.064, data: 0.002) G_GAN: 0.854 G_L1: 6.098 D_real: 0.679 D_fake: 0.750 \n",
            "(epoch: 42, iters: 1000, time: 0.066, data: 0.004) G_GAN: 2.393 G_L1: 1.935 D_real: 0.260 D_fake: 0.680 \n",
            "saving the latest model (epoch 42, total_iters 165000)\n",
            "(epoch: 42, iters: 1100, time: 0.064, data: 0.005) G_GAN: 0.930 G_L1: 3.483 D_real: 0.795 D_fake: 0.893 \n",
            "(epoch: 42, iters: 1200, time: 0.218, data: 0.003) G_GAN: 0.972 G_L1: 2.528 D_real: 0.924 D_fake: 0.475 \n",
            "(epoch: 42, iters: 1300, time: 0.066, data: 0.003) G_GAN: 0.764 G_L1: 3.252 D_real: 0.387 D_fake: 1.055 \n",
            "(epoch: 42, iters: 1400, time: 0.063, data: 0.004) G_GAN: 3.989 G_L1: 1.848 D_real: 0.000 D_fake: 0.036 \n",
            "(epoch: 42, iters: 1500, time: 0.067, data: 0.003) G_GAN: 1.176 G_L1: 1.987 D_real: 0.942 D_fake: 0.290 \n",
            "(epoch: 42, iters: 1600, time: 0.177, data: 0.004) G_GAN: 2.491 G_L1: 3.157 D_real: 0.090 D_fake: 0.126 \n",
            "(epoch: 42, iters: 1700, time: 0.067, data: 0.003) G_GAN: 4.267 G_L1: 1.794 D_real: 0.001 D_fake: 0.020 \n",
            "(epoch: 42, iters: 1800, time: 0.066, data: 0.002) G_GAN: 0.810 G_L1: 5.363 D_real: 0.521 D_fake: 0.771 \n",
            "(epoch: 42, iters: 1900, time: 0.066, data: 0.003) G_GAN: 6.331 G_L1: 1.619 D_real: 0.186 D_fake: 0.002 \n",
            "(epoch: 42, iters: 2000, time: 0.325, data: 0.004) G_GAN: 6.395 G_L1: 0.939 D_real: 0.001 D_fake: 0.003 \n",
            "(epoch: 42, iters: 2100, time: 0.067, data: 0.002) G_GAN: 0.975 G_L1: 1.983 D_real: 0.346 D_fake: 0.963 \n",
            "(epoch: 42, iters: 2200, time: 0.067, data: 0.004) G_GAN: 4.490 G_L1: 4.036 D_real: 0.073 D_fake: 0.019 \n",
            "(epoch: 42, iters: 2300, time: 0.066, data: 0.004) G_GAN: 7.074 G_L1: 1.891 D_real: 0.029 D_fake: 0.001 \n",
            "(epoch: 42, iters: 2400, time: 0.168, data: 0.003) G_GAN: 2.418 G_L1: 2.377 D_real: 0.257 D_fake: 0.311 \n",
            "(epoch: 42, iters: 2500, time: 0.066, data: 0.008) G_GAN: 1.002 G_L1: 2.406 D_real: 0.788 D_fake: 0.397 \n",
            "(epoch: 42, iters: 2600, time: 0.065, data: 0.002) G_GAN: 6.494 G_L1: 1.597 D_real: 0.498 D_fake: 0.002 \n",
            "(epoch: 42, iters: 2700, time: 0.066, data: 0.002) G_GAN: 4.449 G_L1: 2.231 D_real: 0.446 D_fake: 0.005 \n",
            "(epoch: 42, iters: 2800, time: 0.222, data: 0.003) G_GAN: 0.865 G_L1: 2.648 D_real: 0.611 D_fake: 0.650 \n",
            "(epoch: 42, iters: 2900, time: 0.067, data: 0.007) G_GAN: 2.151 G_L1: 2.256 D_real: 0.256 D_fake: 0.202 \n",
            "(epoch: 42, iters: 3000, time: 0.066, data: 0.003) G_GAN: 3.202 G_L1: 3.032 D_real: 0.094 D_fake: 0.601 \n",
            "(epoch: 42, iters: 3100, time: 0.067, data: 0.005) G_GAN: 2.387 G_L1: 2.164 D_real: 0.088 D_fake: 0.330 \n",
            "(epoch: 42, iters: 3200, time: 0.152, data: 0.003) G_GAN: 7.474 G_L1: 0.984 D_real: 0.004 D_fake: 0.002 \n",
            "(epoch: 42, iters: 3300, time: 0.066, data: 0.004) G_GAN: 1.693 G_L1: 1.582 D_real: 0.778 D_fake: 0.177 \n",
            "(epoch: 42, iters: 3400, time: 0.066, data: 0.009) G_GAN: 2.892 G_L1: 2.051 D_real: 0.615 D_fake: 0.185 \n",
            "(epoch: 42, iters: 3500, time: 0.067, data: 0.003) G_GAN: 1.687 G_L1: 2.920 D_real: 0.046 D_fake: 0.852 \n",
            "(epoch: 42, iters: 3600, time: 0.168, data: 0.003) G_GAN: 5.062 G_L1: 1.964 D_real: 0.000 D_fake: 0.009 \n",
            "(epoch: 42, iters: 3700, time: 0.066, data: 0.009) G_GAN: 0.804 G_L1: 2.082 D_real: 0.694 D_fake: 1.287 \n",
            "(epoch: 42, iters: 3800, time: 0.066, data: 0.002) G_GAN: 2.066 G_L1: 3.498 D_real: 0.015 D_fake: 0.433 \n",
            "(epoch: 42, iters: 3900, time: 0.066, data: 0.002) G_GAN: 4.156 G_L1: 3.011 D_real: 0.052 D_fake: 0.032 \n",
            "(epoch: 42, iters: 4000, time: 0.321, data: 0.002) G_GAN: 4.838 G_L1: 0.812 D_real: 0.000 D_fake: 0.011 \n",
            "End of epoch 42 / 200 \t Time Taken: 173 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "(epoch: 43, iters: 100, time: 0.066, data: 0.175) G_GAN: 0.686 G_L1: 3.242 D_real: 1.524 D_fake: 0.405 \n",
            "(epoch: 43, iters: 200, time: 0.066, data: 0.002) G_GAN: 2.386 G_L1: 3.536 D_real: 0.136 D_fake: 0.381 \n",
            "(epoch: 43, iters: 300, time: 0.066, data: 0.002) G_GAN: 6.630 G_L1: 1.637 D_real: 0.000 D_fake: 0.003 \n",
            "(epoch: 43, iters: 400, time: 0.470, data: 0.003) G_GAN: 7.895 G_L1: 0.621 D_real: 0.002 D_fake: 0.001 \n",
            "(epoch: 43, iters: 500, time: 0.064, data: 0.003) G_GAN: 1.368 G_L1: 2.204 D_real: 0.467 D_fake: 0.603 \n",
            "(epoch: 43, iters: 600, time: 0.066, data: 0.003) G_GAN: 2.854 G_L1: 3.802 D_real: 0.059 D_fake: 0.374 \n",
            "(epoch: 43, iters: 700, time: 0.064, data: 0.003) G_GAN: 2.903 G_L1: 3.583 D_real: 0.110 D_fake: 0.137 \n",
            "(epoch: 43, iters: 800, time: 0.225, data: 0.004) G_GAN: 0.853 G_L1: 2.884 D_real: 0.794 D_fake: 0.704 \n",
            "(epoch: 43, iters: 900, time: 0.066, data: 0.005) G_GAN: 1.930 G_L1: 1.843 D_real: 0.531 D_fake: 0.117 \n",
            "(epoch: 43, iters: 1000, time: 0.067, data: 0.002) G_GAN: 2.902 G_L1: 0.765 D_real: 0.003 D_fake: 0.119 \n",
            "(epoch: 43, iters: 1100, time: 0.066, data: 0.003) G_GAN: 6.699 G_L1: 1.425 D_real: 0.002 D_fake: 0.002 \n",
            "(epoch: 43, iters: 1200, time: 0.222, data: 0.003) G_GAN: 0.755 G_L1: 2.595 D_real: 0.301 D_fake: 1.029 \n",
            "(epoch: 43, iters: 1300, time: 0.064, data: 0.008) G_GAN: 4.615 G_L1: 1.222 D_real: 0.023 D_fake: 0.018 \n",
            "(epoch: 43, iters: 1400, time: 0.066, data: 0.002) G_GAN: 0.730 G_L1: 3.261 D_real: 0.430 D_fake: 1.038 \n",
            "(epoch: 43, iters: 1500, time: 0.064, data: 0.002) G_GAN: 0.735 G_L1: 2.936 D_real: 0.504 D_fake: 0.895 \n",
            "(epoch: 43, iters: 1600, time: 0.227, data: 0.002) G_GAN: 0.714 G_L1: 2.134 D_real: 0.856 D_fake: 0.857 \n",
            "(epoch: 43, iters: 1700, time: 0.067, data: 0.004) G_GAN: 5.238 G_L1: 1.702 D_real: 0.066 D_fake: 0.007 \n",
            "(epoch: 43, iters: 1800, time: 0.066, data: 0.002) G_GAN: 1.484 G_L1: 1.561 D_real: 0.372 D_fake: 0.315 \n",
            "(epoch: 43, iters: 1900, time: 0.066, data: 0.002) G_GAN: 2.049 G_L1: 2.860 D_real: 0.353 D_fake: 0.621 \n",
            "(epoch: 43, iters: 2000, time: 0.437, data: 0.002) G_GAN: 0.911 G_L1: 4.394 D_real: 0.375 D_fake: 0.844 \n",
            "saving the latest model (epoch 43, total_iters 170000)\n",
            "(epoch: 43, iters: 2100, time: 0.066, data: 0.012) G_GAN: 1.151 G_L1: 1.998 D_real: 0.600 D_fake: 0.570 \n",
            "(epoch: 43, iters: 2200, time: 0.067, data: 0.002) G_GAN: 1.197 G_L1: 2.168 D_real: 0.792 D_fake: 0.433 \n",
            "(epoch: 43, iters: 2300, time: 0.066, data: 0.002) G_GAN: 0.825 G_L1: 2.061 D_real: 0.632 D_fake: 0.848 \n",
            "(epoch: 43, iters: 2400, time: 0.166, data: 0.003) G_GAN: 4.663 G_L1: 2.046 D_real: 0.365 D_fake: 0.028 \n",
            "(epoch: 43, iters: 2500, time: 0.067, data: 0.009) G_GAN: 4.765 G_L1: 1.067 D_real: 0.001 D_fake: 0.018 \n",
            "(epoch: 43, iters: 2600, time: 0.066, data: 0.002) G_GAN: 2.339 G_L1: 1.001 D_real: 0.022 D_fake: 0.548 \n",
            "(epoch: 43, iters: 2700, time: 0.067, data: 0.003) G_GAN: 2.955 G_L1: 4.261 D_real: 0.236 D_fake: 0.105 \n",
            "(epoch: 43, iters: 2800, time: 0.222, data: 0.003) G_GAN: 0.877 G_L1: 4.404 D_real: 0.944 D_fake: 0.640 \n",
            "(epoch: 43, iters: 2900, time: 0.065, data: 0.007) G_GAN: 8.252 G_L1: 1.874 D_real: 0.434 D_fake: 0.001 \n",
            "(epoch: 43, iters: 3000, time: 0.066, data: 0.005) G_GAN: 2.086 G_L1: 2.532 D_real: 0.500 D_fake: 0.110 \n",
            "(epoch: 43, iters: 3100, time: 0.066, data: 0.003) G_GAN: 8.483 G_L1: 1.098 D_real: 0.005 D_fake: 0.001 \n",
            "(epoch: 43, iters: 3200, time: 0.186, data: 0.004) G_GAN: 2.986 G_L1: 1.616 D_real: 0.096 D_fake: 0.090 \n",
            "(epoch: 43, iters: 3300, time: 0.066, data: 0.009) G_GAN: 2.617 G_L1: 5.293 D_real: 0.690 D_fake: 0.138 \n",
            "(epoch: 43, iters: 3400, time: 0.067, data: 0.005) G_GAN: 2.526 G_L1: 4.942 D_real: 0.729 D_fake: 0.052 \n",
            "(epoch: 43, iters: 3500, time: 0.067, data: 0.004) G_GAN: 3.464 G_L1: 0.742 D_real: 0.022 D_fake: 0.155 \n",
            "(epoch: 43, iters: 3600, time: 0.172, data: 0.004) G_GAN: 2.610 G_L1: 2.147 D_real: 0.044 D_fake: 0.305 \n",
            "(epoch: 43, iters: 3700, time: 0.066, data: 0.002) G_GAN: 5.463 G_L1: 1.322 D_real: 0.116 D_fake: 0.006 \n",
            "(epoch: 43, iters: 3800, time: 0.064, data: 0.002) G_GAN: 2.758 G_L1: 1.254 D_real: 0.053 D_fake: 0.379 \n",
            "(epoch: 43, iters: 3900, time: 0.066, data: 0.002) G_GAN: 0.986 G_L1: 1.767 D_real: 0.816 D_fake: 0.584 \n",
            "(epoch: 43, iters: 4000, time: 0.414, data: 0.002) G_GAN: 0.921 G_L1: 2.401 D_real: 0.674 D_fake: 0.584 \n",
            "End of epoch 43 / 200 \t Time Taken: 174 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "(epoch: 44, iters: 100, time: 0.066, data: 0.167) G_GAN: 2.132 G_L1: 2.629 D_real: 0.307 D_fake: 0.327 \n",
            "(epoch: 44, iters: 200, time: 0.066, data: 0.003) G_GAN: 0.822 G_L1: 2.064 D_real: 0.381 D_fake: 0.976 \n",
            "(epoch: 44, iters: 300, time: 0.067, data: 0.003) G_GAN: 2.758 G_L1: 2.563 D_real: 0.061 D_fake: 0.300 \n",
            "(epoch: 44, iters: 400, time: 0.610, data: 0.002) G_GAN: 1.296 G_L1: 5.165 D_real: 0.437 D_fake: 0.441 \n",
            "(epoch: 44, iters: 500, time: 0.067, data: 0.002) G_GAN: 5.282 G_L1: 1.546 D_real: 0.381 D_fake: 0.007 \n",
            "(epoch: 44, iters: 600, time: 0.061, data: 0.002) G_GAN: 3.906 G_L1: 1.264 D_real: 0.071 D_fake: 0.071 \n",
            "(epoch: 44, iters: 700, time: 0.066, data: 0.003) G_GAN: 2.329 G_L1: 2.502 D_real: 0.092 D_fake: 0.511 \n",
            "(epoch: 44, iters: 800, time: 0.173, data: 0.003) G_GAN: 4.293 G_L1: 1.987 D_real: 0.334 D_fake: 0.015 \n",
            "(epoch: 44, iters: 900, time: 0.065, data: 0.015) G_GAN: 8.623 G_L1: 0.731 D_real: 0.001 D_fake: 0.000 \n",
            "(epoch: 44, iters: 1000, time: 0.066, data: 0.003) G_GAN: 8.958 G_L1: 0.602 D_real: 0.017 D_fake: 0.000 \n",
            "(epoch: 44, iters: 1100, time: 0.066, data: 0.002) G_GAN: 8.534 G_L1: 0.808 D_real: 0.013 D_fake: 0.000 \n",
            "(epoch: 44, iters: 1200, time: 0.172, data: 0.004) G_GAN: 5.083 G_L1: 1.673 D_real: 0.000 D_fake: 0.015 \n",
            "(epoch: 44, iters: 1300, time: 0.066, data: 0.003) G_GAN: 4.639 G_L1: 0.685 D_real: 0.001 D_fake: 0.033 \n",
            "(epoch: 44, iters: 1400, time: 0.066, data: 0.002) G_GAN: 3.132 G_L1: 3.483 D_real: 0.190 D_fake: 0.407 \n",
            "(epoch: 44, iters: 1500, time: 0.066, data: 0.003) G_GAN: 7.835 G_L1: 1.157 D_real: 0.001 D_fake: 0.001 \n",
            "(epoch: 44, iters: 1600, time: 0.221, data: 0.003) G_GAN: 0.798 G_L1: 2.480 D_real: 0.764 D_fake: 0.675 \n",
            "(epoch: 44, iters: 1700, time: 0.064, data: 0.003) G_GAN: 1.122 G_L1: 3.279 D_real: 0.382 D_fake: 0.474 \n",
            "(epoch: 44, iters: 1800, time: 0.064, data: 0.004) G_GAN: 4.006 G_L1: 2.395 D_real: 2.375 D_fake: 0.063 \n",
            "(epoch: 44, iters: 1900, time: 0.066, data: 0.012) G_GAN: 5.744 G_L1: 0.550 D_real: 0.000 D_fake: 0.005 \n",
            "(epoch: 44, iters: 2000, time: 0.338, data: 0.003) G_GAN: 6.825 G_L1: 1.060 D_real: 0.002 D_fake: 0.002 \n",
            "(epoch: 44, iters: 2100, time: 0.063, data: 0.003) G_GAN: 1.738 G_L1: 2.020 D_real: 0.237 D_fake: 0.741 \n",
            "(epoch: 44, iters: 2200, time: 0.066, data: 0.006) G_GAN: 4.696 G_L1: 1.951 D_real: 0.014 D_fake: 0.016 \n",
            "(epoch: 44, iters: 2300, time: 0.064, data: 0.003) G_GAN: 0.976 G_L1: 2.452 D_real: 0.616 D_fake: 0.890 \n",
            "(epoch: 44, iters: 2400, time: 0.195, data: 0.003) G_GAN: 2.646 G_L1: 2.377 D_real: 0.015 D_fake: 0.204 \n",
            "(epoch: 44, iters: 2500, time: 0.066, data: 0.002) G_GAN: 2.574 G_L1: 3.093 D_real: 0.078 D_fake: 0.308 \n",
            "(epoch: 44, iters: 2600, time: 0.064, data: 0.006) G_GAN: 2.210 G_L1: 1.689 D_real: 0.173 D_fake: 0.360 \n",
            "(epoch: 44, iters: 2700, time: 0.067, data: 0.006) G_GAN: 2.645 G_L1: 5.917 D_real: 0.157 D_fake: 0.228 \n",
            "(epoch: 44, iters: 2800, time: 0.165, data: 0.003) G_GAN: 0.608 G_L1: 1.676 D_real: 1.440 D_fake: 0.506 \n",
            "(epoch: 44, iters: 2900, time: 0.065, data: 0.002) G_GAN: 5.227 G_L1: 1.934 D_real: 0.000 D_fake: 0.009 \n",
            "(epoch: 44, iters: 3000, time: 0.066, data: 0.003) G_GAN: 7.699 G_L1: 1.224 D_real: 1.202 D_fake: 0.000 \n",
            "saving the latest model (epoch 44, total_iters 175000)\n",
            "(epoch: 44, iters: 3100, time: 0.067, data: 0.002) G_GAN: 3.220 G_L1: 1.242 D_real: 0.095 D_fake: 0.058 \n",
            "(epoch: 44, iters: 3200, time: 0.155, data: 0.003) G_GAN: 5.188 G_L1: 0.756 D_real: 0.002 D_fake: 0.023 \n",
            "(epoch: 44, iters: 3300, time: 0.066, data: 0.010) G_GAN: 4.168 G_L1: 3.875 D_real: 0.463 D_fake: 0.058 \n",
            "(epoch: 44, iters: 3400, time: 0.066, data: 0.004) G_GAN: 8.699 G_L1: 1.035 D_real: 0.074 D_fake: 0.001 \n",
            "(epoch: 44, iters: 3500, time: 0.065, data: 0.005) G_GAN: 9.110 G_L1: 1.019 D_real: 0.019 D_fake: 0.000 \n",
            "(epoch: 44, iters: 3600, time: 0.221, data: 0.004) G_GAN: 0.717 G_L1: 2.987 D_real: 0.483 D_fake: 0.869 \n",
            "(epoch: 44, iters: 3700, time: 0.066, data: 0.005) G_GAN: 2.087 G_L1: 4.753 D_real: 0.124 D_fake: 0.543 \n",
            "(epoch: 44, iters: 3800, time: 0.062, data: 0.002) G_GAN: 5.121 G_L1: 1.777 D_real: 0.000 D_fake: 0.008 \n",
            "(epoch: 44, iters: 3900, time: 0.067, data: 0.003) G_GAN: 6.223 G_L1: 1.731 D_real: 0.000 D_fake: 0.003 \n",
            "(epoch: 44, iters: 4000, time: 0.388, data: 0.002) G_GAN: 2.740 G_L1: 1.969 D_real: 0.104 D_fake: 0.153 \n",
            "End of epoch 44 / 200 \t Time Taken: 173 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "(epoch: 45, iters: 100, time: 0.066, data: 0.215) G_GAN: 0.649 G_L1: 3.347 D_real: 0.538 D_fake: 0.967 \n",
            "(epoch: 45, iters: 200, time: 0.066, data: 0.003) G_GAN: 2.326 G_L1: 3.098 D_real: 1.042 D_fake: 0.127 \n",
            "(epoch: 45, iters: 300, time: 0.066, data: 0.006) G_GAN: 6.488 G_L1: 1.488 D_real: 0.000 D_fake: 0.003 \n",
            "(epoch: 45, iters: 400, time: 1.481, data: 0.003) G_GAN: 4.436 G_L1: 1.852 D_real: 0.084 D_fake: 0.015 \n",
            "(epoch: 45, iters: 500, time: 0.066, data: 0.003) G_GAN: 0.700 G_L1: 3.669 D_real: 0.511 D_fake: 1.112 \n",
            "(epoch: 45, iters: 600, time: 0.066, data: 0.004) G_GAN: 2.078 G_L1: 3.146 D_real: 0.503 D_fake: 0.215 \n",
            "(epoch: 45, iters: 700, time: 0.066, data: 0.002) G_GAN: 1.298 G_L1: 2.832 D_real: 0.544 D_fake: 0.545 \n",
            "(epoch: 45, iters: 800, time: 0.177, data: 0.003) G_GAN: 2.986 G_L1: 2.438 D_real: 0.079 D_fake: 0.075 \n",
            "(epoch: 45, iters: 900, time: 0.063, data: 0.002) G_GAN: 6.195 G_L1: 2.672 D_real: 1.580 D_fake: 0.001 \n",
            "(epoch: 45, iters: 1000, time: 0.066, data: 0.004) G_GAN: 2.393 G_L1: 2.725 D_real: 0.520 D_fake: 0.150 \n",
            "(epoch: 45, iters: 1100, time: 0.064, data: 0.002) G_GAN: 1.468 G_L1: 1.673 D_real: 0.699 D_fake: 1.425 \n",
            "(epoch: 45, iters: 1200, time: 0.188, data: 0.003) G_GAN: 2.200 G_L1: 2.398 D_real: 0.259 D_fake: 0.099 \n",
            "(epoch: 45, iters: 1300, time: 0.066, data: 0.009) G_GAN: 6.179 G_L1: 1.543 D_real: 0.408 D_fake: 0.004 \n",
            "(epoch: 45, iters: 1400, time: 0.067, data: 0.003) G_GAN: 6.160 G_L1: 1.087 D_real: 0.003 D_fake: 0.004 \n",
            "(epoch: 45, iters: 1500, time: 0.065, data: 0.002) G_GAN: 3.921 G_L1: 1.295 D_real: 0.056 D_fake: 0.033 \n",
            "(epoch: 45, iters: 1600, time: 0.223, data: 0.003) G_GAN: 0.848 G_L1: 3.589 D_real: 0.525 D_fake: 0.959 \n",
            "(epoch: 45, iters: 1700, time: 0.067, data: 0.011) G_GAN: 5.975 G_L1: 0.993 D_real: 0.063 D_fake: 0.003 \n",
            "(epoch: 45, iters: 1800, time: 0.066, data: 0.002) G_GAN: 3.118 G_L1: 0.856 D_real: 0.001 D_fake: 0.142 \n",
            "(epoch: 45, iters: 1900, time: 0.066, data: 0.002) G_GAN: 0.751 G_L1: 2.612 D_real: 0.771 D_fake: 0.708 \n",
            "(epoch: 45, iters: 2000, time: 0.372, data: 0.003) G_GAN: 3.032 G_L1: 1.116 D_real: 0.050 D_fake: 1.222 \n",
            "(epoch: 45, iters: 2100, time: 0.064, data: 0.003) G_GAN: 3.064 G_L1: 5.098 D_real: 0.063 D_fake: 0.092 \n",
            "(epoch: 45, iters: 2200, time: 0.066, data: 0.003) G_GAN: 4.471 G_L1: 4.776 D_real: 0.110 D_fake: 0.020 \n",
            "(epoch: 45, iters: 2300, time: 0.066, data: 0.002) G_GAN: 0.797 G_L1: 2.877 D_real: 0.531 D_fake: 0.799 \n",
            "(epoch: 45, iters: 2400, time: 0.172, data: 0.003) G_GAN: 1.642 G_L1: 3.178 D_real: 1.415 D_fake: 0.233 \n",
            "(epoch: 45, iters: 2500, time: 0.066, data: 0.002) G_GAN: 2.649 G_L1: 2.382 D_real: 0.459 D_fake: 0.630 \n",
            "(epoch: 45, iters: 2600, time: 0.067, data: 0.002) G_GAN: 3.414 G_L1: 3.037 D_real: 0.367 D_fake: 0.061 \n",
            "(epoch: 45, iters: 2700, time: 0.065, data: 0.002) G_GAN: 0.818 G_L1: 6.107 D_real: 0.386 D_fake: 0.823 \n",
            "(epoch: 45, iters: 2800, time: 0.168, data: 0.002) G_GAN: 6.447 G_L1: 2.334 D_real: 0.448 D_fake: 0.003 \n",
            "(epoch: 45, iters: 2900, time: 0.065, data: 0.002) G_GAN: 4.733 G_L1: 1.490 D_real: 0.001 D_fake: 0.017 \n",
            "(epoch: 45, iters: 3000, time: 0.066, data: 0.004) G_GAN: 1.368 G_L1: 1.970 D_real: 0.440 D_fake: 0.534 \n",
            "(epoch: 45, iters: 3100, time: 0.066, data: 0.003) G_GAN: 3.217 G_L1: 1.272 D_real: 0.033 D_fake: 0.104 \n",
            "(epoch: 45, iters: 3200, time: 0.172, data: 0.002) G_GAN: 5.509 G_L1: 2.578 D_real: 0.161 D_fake: 0.007 \n",
            "(epoch: 45, iters: 3300, time: 0.066, data: 0.002) G_GAN: 2.578 G_L1: 2.022 D_real: 0.046 D_fake: 0.213 \n",
            "(epoch: 45, iters: 3400, time: 0.066, data: 0.002) G_GAN: 1.261 G_L1: 2.144 D_real: 0.488 D_fake: 0.679 \n",
            "(epoch: 45, iters: 3500, time: 0.065, data: 0.003) G_GAN: 5.490 G_L1: 1.517 D_real: 0.000 D_fake: 0.006 \n",
            "(epoch: 45, iters: 3600, time: 0.167, data: 0.002) G_GAN: 2.080 G_L1: 5.577 D_real: 0.106 D_fake: 0.703 \n",
            "(epoch: 45, iters: 3700, time: 0.065, data: 0.003) G_GAN: 6.099 G_L1: 2.035 D_real: 0.000 D_fake: 0.004 \n",
            "(epoch: 45, iters: 3800, time: 0.067, data: 0.003) G_GAN: 2.639 G_L1: 2.500 D_real: 0.224 D_fake: 0.503 \n",
            "(epoch: 45, iters: 3900, time: 0.067, data: 0.002) G_GAN: 0.588 G_L1: 3.603 D_real: 0.378 D_fake: 1.304 \n",
            "(epoch: 45, iters: 4000, time: 0.321, data: 0.002) G_GAN: 7.477 G_L1: 1.444 D_real: 0.000 D_fake: 0.001 \n",
            "saving the latest model (epoch 45, total_iters 180000)\n",
            "saving the model at the end of epoch 45, iters 180000\n",
            "End of epoch 45 / 200 \t Time Taken: 175 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "(epoch: 46, iters: 100, time: 0.066, data: 0.201) G_GAN: 8.712 G_L1: 0.828 D_real: 0.001 D_fake: 0.000 \n",
            "(epoch: 46, iters: 200, time: 0.067, data: 0.003) G_GAN: 2.386 G_L1: 2.837 D_real: 0.252 D_fake: 0.390 \n",
            "(epoch: 46, iters: 300, time: 0.066, data: 0.002) G_GAN: 0.739 G_L1: 2.017 D_real: 0.607 D_fake: 0.835 \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m A graphql request initiated by the public wandb API timed out (timeout=9 sec). Create a new API with an integer timeout larger than 9, e.g., `api = wandb.Api(timeout=19)` to increase the graphql timeout.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m A graphql request initiated by the public wandb API timed out (timeout=9 sec). Create a new API with an integer timeout larger than 9, e.g., `api = wandb.Api(timeout=19)` to increase the graphql timeout.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m A graphql request initiated by the public wandb API timed out (timeout=9 sec). Create a new API with an integer timeout larger than 9, e.g., `api = wandb.Api(timeout=19)` to increase the graphql timeout.\n",
            "(epoch: 46, iters: 400, time: 30.809, data: 0.002) G_GAN: 1.896 G_L1: 2.217 D_real: 0.124 D_fake: 0.511 \n",
            "(epoch: 46, iters: 500, time: 0.066, data: 0.003) G_GAN: 0.844 G_L1: 2.434 D_real: 0.258 D_fake: 1.118 \n",
            "(epoch: 46, iters: 600, time: 0.067, data: 0.002) G_GAN: 3.374 G_L1: 2.433 D_real: 0.115 D_fake: 0.084 \n",
            "(epoch: 46, iters: 700, time: 0.065, data: 0.005) G_GAN: 1.519 G_L1: 3.251 D_real: 0.279 D_fake: 0.461 \n",
            "(epoch: 46, iters: 800, time: 0.216, data: 0.011) G_GAN: 0.830 G_L1: 2.258 D_real: 0.628 D_fake: 0.719 \n",
            "(epoch: 46, iters: 900, time: 0.066, data: 0.002) G_GAN: 0.906 G_L1: 1.910 D_real: 0.799 D_fake: 0.599 \n",
            "(epoch: 46, iters: 1000, time: 0.063, data: 0.002) G_GAN: 0.775 G_L1: 3.304 D_real: 0.824 D_fake: 0.638 \n",
            "(epoch: 46, iters: 1100, time: 0.066, data: 0.003) G_GAN: 3.116 G_L1: 2.345 D_real: 0.168 D_fake: 0.060 \n",
            "(epoch: 46, iters: 1200, time: 0.219, data: 0.002) G_GAN: 1.052 G_L1: 1.920 D_real: 0.436 D_fake: 1.045 \n",
            "(epoch: 46, iters: 1300, time: 0.067, data: 0.003) G_GAN: 5.697 G_L1: 1.337 D_real: 0.086 D_fake: 0.004 \n",
            "(epoch: 46, iters: 1400, time: 0.067, data: 0.006) G_GAN: 2.897 G_L1: 1.106 D_real: 0.071 D_fake: 0.560 \n",
            "(epoch: 46, iters: 1500, time: 0.063, data: 0.002) G_GAN: 2.331 G_L1: 6.814 D_real: 3.657 D_fake: 0.092 \n",
            "(epoch: 46, iters: 1600, time: 0.293, data: 0.003) G_GAN: 3.474 G_L1: 1.662 D_real: 0.034 D_fake: 0.064 \n",
            "(epoch: 46, iters: 1700, time: 0.067, data: 0.010) G_GAN: 2.619 G_L1: 2.255 D_real: 0.011 D_fake: 0.225 \n",
            "(epoch: 46, iters: 1800, time: 0.066, data: 0.002) G_GAN: 2.362 G_L1: 1.713 D_real: 0.105 D_fake: 0.291 \n",
            "(epoch: 46, iters: 1900, time: 0.066, data: 0.002) G_GAN: 2.090 G_L1: 1.547 D_real: 0.170 D_fake: 0.398 \n",
            "(epoch: 46, iters: 2000, time: 0.342, data: 0.003) G_GAN: 3.272 G_L1: 1.633 D_real: 0.148 D_fake: 0.103 \n",
            "(epoch: 46, iters: 2100, time: 0.067, data: 0.003) G_GAN: 1.683 G_L1: 1.880 D_real: 0.424 D_fake: 0.590 \n",
            "(epoch: 46, iters: 2200, time: 0.067, data: 0.004) G_GAN: 2.940 G_L1: 2.220 D_real: 0.026 D_fake: 0.113 \n",
            "(epoch: 46, iters: 2300, time: 0.066, data: 0.003) G_GAN: 0.882 G_L1: 2.179 D_real: 0.675 D_fake: 0.606 \n",
            "(epoch: 46, iters: 2400, time: 0.180, data: 0.002) G_GAN: 4.854 G_L1: 3.507 D_real: 0.020 D_fake: 0.019 \n",
            "(epoch: 46, iters: 2500, time: 0.066, data: 0.002) G_GAN: 2.744 G_L1: 1.009 D_real: 0.009 D_fake: 0.911 \n",
            "(epoch: 46, iters: 2600, time: 0.066, data: 0.004) G_GAN: 0.923 G_L1: 2.813 D_real: 0.701 D_fake: 0.577 \n",
            "(epoch: 46, iters: 2700, time: 0.067, data: 0.003) G_GAN: 2.209 G_L1: 1.419 D_real: 0.164 D_fake: 0.619 \n",
            "(epoch: 46, iters: 2800, time: 0.172, data: 0.002) G_GAN: 3.712 G_L1: 2.663 D_real: 0.271 D_fake: 0.024 \n",
            "(epoch: 46, iters: 2900, time: 0.065, data: 0.002) G_GAN: 3.963 G_L1: 1.732 D_real: 0.502 D_fake: 0.162 \n",
            "(epoch: 46, iters: 3000, time: 0.067, data: 0.002) G_GAN: 0.802 G_L1: 3.379 D_real: 0.759 D_fake: 1.042 \n",
            "(epoch: 46, iters: 3100, time: 0.066, data: 0.002) G_GAN: 3.032 G_L1: 2.408 D_real: 0.018 D_fake: 0.759 \n",
            "(epoch: 46, iters: 3200, time: 0.220, data: 0.002) G_GAN: 1.449 G_L1: 2.540 D_real: 0.466 D_fake: 0.636 \n",
            "(epoch: 46, iters: 3300, time: 0.066, data: 0.002) G_GAN: 4.030 G_L1: 0.962 D_real: 0.004 D_fake: 0.028 \n",
            "(epoch: 46, iters: 3400, time: 0.066, data: 0.006) G_GAN: 2.084 G_L1: 1.069 D_real: 0.082 D_fake: 0.400 \n",
            "(epoch: 46, iters: 3500, time: 0.067, data: 0.004) G_GAN: 2.519 G_L1: 1.090 D_real: 0.042 D_fake: 0.535 \n",
            "(epoch: 46, iters: 3600, time: 0.219, data: 0.003) G_GAN: 0.983 G_L1: 3.521 D_real: 0.837 D_fake: 0.463 \n",
            "(epoch: 46, iters: 3700, time: 0.066, data: 0.002) G_GAN: 4.791 G_L1: 0.602 D_real: 0.001 D_fake: 0.021 \n",
            "(epoch: 46, iters: 3800, time: 0.067, data: 0.004) G_GAN: 1.094 G_L1: 1.928 D_real: 1.034 D_fake: 0.376 \n",
            "(epoch: 46, iters: 3900, time: 0.067, data: 0.003) G_GAN: 1.040 G_L1: 1.947 D_real: 1.043 D_fake: 0.333 \n",
            "(epoch: 46, iters: 4000, time: 0.434, data: 0.002) G_GAN: 0.920 G_L1: 2.108 D_real: 0.379 D_fake: 0.866 \n",
            "End of epoch 46 / 200 \t Time Taken: 203 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "(epoch: 47, iters: 100, time: 0.067, data: 0.214) G_GAN: 0.908 G_L1: 2.079 D_real: 0.606 D_fake: 0.632 \n",
            "(epoch: 47, iters: 200, time: 0.067, data: 0.003) G_GAN: 7.589 G_L1: 1.469 D_real: 0.000 D_fake: 0.001 \n",
            "(epoch: 47, iters: 300, time: 0.066, data: 0.003) G_GAN: 4.070 G_L1: 1.439 D_real: 0.000 D_fake: 0.032 \n",
            "(epoch: 47, iters: 400, time: 0.540, data: 0.002) G_GAN: 4.627 G_L1: 2.244 D_real: 0.000 D_fake: 0.018 \n",
            "(epoch: 47, iters: 500, time: 0.066, data: 0.003) G_GAN: 4.986 G_L1: 2.592 D_real: 0.135 D_fake: 0.014 \n",
            "(epoch: 47, iters: 600, time: 0.067, data: 0.003) G_GAN: 8.390 G_L1: 0.842 D_real: 0.000 D_fake: 0.001 \n",
            "(epoch: 47, iters: 700, time: 0.066, data: 0.003) G_GAN: 6.584 G_L1: 0.856 D_real: 0.000 D_fake: 0.003 \n",
            "(epoch: 47, iters: 800, time: 0.221, data: 0.002) G_GAN: 0.869 G_L1: 2.209 D_real: 0.811 D_fake: 0.671 \n",
            "(epoch: 47, iters: 900, time: 0.065, data: 0.006) G_GAN: 2.981 G_L1: 8.269 D_real: 0.174 D_fake: 0.060 \n",
            "(epoch: 47, iters: 1000, time: 0.067, data: 0.006) G_GAN: 5.233 G_L1: 2.230 D_real: 0.036 D_fake: 0.008 \n",
            "saving the latest model (epoch 47, total_iters 185000)\n",
            "(epoch: 47, iters: 1100, time: 0.066, data: 0.002) G_GAN: 1.526 G_L1: 3.260 D_real: 0.366 D_fake: 0.240 \n",
            "(epoch: 47, iters: 1200, time: 0.229, data: 0.007) G_GAN: 1.120 G_L1: 2.824 D_real: 0.549 D_fake: 0.567 \n",
            "(epoch: 47, iters: 1300, time: 0.067, data: 0.007) G_GAN: 0.904 G_L1: 2.602 D_real: 1.005 D_fake: 0.410 \n",
            "(epoch: 47, iters: 1400, time: 0.067, data: 0.002) G_GAN: 3.824 G_L1: 0.958 D_real: 0.036 D_fake: 0.039 \n",
            "(epoch: 47, iters: 1500, time: 0.066, data: 0.003) G_GAN: 5.950 G_L1: 1.430 D_real: 0.090 D_fake: 0.007 \n",
            "(epoch: 47, iters: 1600, time: 0.189, data: 0.002) G_GAN: 1.367 G_L1: 1.837 D_real: 0.703 D_fake: 0.187 \n",
            "(epoch: 47, iters: 1700, time: 0.066, data: 0.002) G_GAN: 6.163 G_L1: 0.884 D_real: 0.000 D_fake: 0.004 \n",
            "(epoch: 47, iters: 1800, time: 0.067, data: 0.002) G_GAN: 5.355 G_L1: 1.008 D_real: 0.006 D_fake: 0.010 \n",
            "(epoch: 47, iters: 1900, time: 0.066, data: 0.003) G_GAN: 0.901 G_L1: 2.573 D_real: 0.693 D_fake: 0.566 \n",
            "(epoch: 47, iters: 2000, time: 0.431, data: 0.005) G_GAN: 0.909 G_L1: 1.877 D_real: 0.369 D_fake: 0.931 \n",
            "(epoch: 47, iters: 2100, time: 0.066, data: 0.006) G_GAN: 1.107 G_L1: 2.175 D_real: 0.900 D_fake: 0.397 \n",
            "(epoch: 47, iters: 2200, time: 0.066, data: 0.003) G_GAN: 1.901 G_L1: 1.443 D_real: 0.145 D_fake: 0.395 \n",
            "(epoch: 47, iters: 2300, time: 0.066, data: 0.003) G_GAN: 3.156 G_L1: 3.705 D_real: 0.255 D_fake: 0.128 \n",
            "(epoch: 47, iters: 2400, time: 0.169, data: 0.004) G_GAN: 3.090 G_L1: 1.867 D_real: 0.013 D_fake: 0.744 \n",
            "(epoch: 47, iters: 2500, time: 0.064, data: 0.002) G_GAN: 3.596 G_L1: 3.507 D_real: 0.237 D_fake: 0.055 \n",
            "(epoch: 47, iters: 2600, time: 0.064, data: 0.003) G_GAN: 4.485 G_L1: 2.379 D_real: 0.079 D_fake: 0.014 \n",
            "(epoch: 47, iters: 2700, time: 0.066, data: 0.002) G_GAN: 3.454 G_L1: 3.319 D_real: 0.154 D_fake: 0.747 \n",
            "(epoch: 47, iters: 2800, time: 0.159, data: 0.006) G_GAN: 4.553 G_L1: 0.900 D_real: 0.001 D_fake: 0.029 \n",
            "(epoch: 47, iters: 2900, time: 0.067, data: 0.005) G_GAN: 3.127 G_L1: 2.861 D_real: 2.259 D_fake: 0.081 \n",
            "(epoch: 47, iters: 3000, time: 0.066, data: 0.007) G_GAN: 0.671 G_L1: 2.049 D_real: 1.313 D_fake: 0.746 \n",
            "(epoch: 47, iters: 3100, time: 0.066, data: 0.003) G_GAN: 1.726 G_L1: 2.364 D_real: 0.756 D_fake: 0.141 \n",
            "(epoch: 47, iters: 3200, time: 0.224, data: 0.003) G_GAN: 0.849 G_L1: 1.959 D_real: 0.938 D_fake: 0.803 \n",
            "(epoch: 47, iters: 3300, time: 0.067, data: 0.002) G_GAN: 8.362 G_L1: 0.888 D_real: 0.000 D_fake: 0.000 \n",
            "(epoch: 47, iters: 3400, time: 0.067, data: 0.002) G_GAN: 4.361 G_L1: 3.461 D_real: 0.044 D_fake: 0.018 \n",
            "(epoch: 47, iters: 3500, time: 0.066, data: 0.002) G_GAN: 2.727 G_L1: 3.044 D_real: 0.075 D_fake: 0.207 \n",
            "(epoch: 47, iters: 3600, time: 0.159, data: 0.004) G_GAN: 4.768 G_L1: 0.529 D_real: 0.000 D_fake: 0.016 \n",
            "(epoch: 47, iters: 3700, time: 0.066, data: 0.003) G_GAN: 7.429 G_L1: 0.633 D_real: 0.004 D_fake: 0.001 \n",
            "(epoch: 47, iters: 3800, time: 0.067, data: 0.007) G_GAN: 2.087 G_L1: 2.969 D_real: 0.219 D_fake: 2.041 \n",
            "(epoch: 47, iters: 3900, time: 0.067, data: 0.003) G_GAN: 0.881 G_L1: 3.187 D_real: 0.654 D_fake: 0.874 \n",
            "(epoch: 47, iters: 4000, time: 0.443, data: 0.004) G_GAN: 0.847 G_L1: 3.095 D_real: 0.787 D_fake: 0.533 \n",
            "End of epoch 47 / 200 \t Time Taken: 173 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "(epoch: 48, iters: 100, time: 0.067, data: 0.144) G_GAN: 1.021 G_L1: 2.317 D_real: 0.669 D_fake: 0.559 \n",
            "(epoch: 48, iters: 200, time: 0.067, data: 0.002) G_GAN: 3.730 G_L1: 2.117 D_real: 0.075 D_fake: 0.032 \n",
            "(epoch: 48, iters: 300, time: 0.067, data: 0.003) G_GAN: 3.233 G_L1: 2.071 D_real: 0.057 D_fake: 1.129 \n",
            "(epoch: 48, iters: 400, time: 0.567, data: 0.003) G_GAN: 0.777 G_L1: 2.261 D_real: 0.540 D_fake: 0.837 \n",
            "(epoch: 48, iters: 500, time: 0.066, data: 0.002) G_GAN: 6.760 G_L1: 0.823 D_real: 0.001 D_fake: 0.003 \n",
            "(epoch: 48, iters: 600, time: 0.063, data: 0.002) G_GAN: 5.672 G_L1: 1.519 D_real: 0.000 D_fake: 0.009 \n",
            "(epoch: 48, iters: 700, time: 0.065, data: 0.002) G_GAN: 3.225 G_L1: 1.219 D_real: 0.011 D_fake: 0.260 \n",
            "(epoch: 48, iters: 800, time: 0.223, data: 0.002) G_GAN: 1.673 G_L1: 2.064 D_real: 0.967 D_fake: 0.557 \n",
            "(epoch: 48, iters: 900, time: 0.066, data: 0.005) G_GAN: 1.932 G_L1: 3.783 D_real: 0.682 D_fake: 0.101 \n",
            "(epoch: 48, iters: 1000, time: 0.066, data: 0.005) G_GAN: 1.101 G_L1: 2.272 D_real: 0.693 D_fake: 0.578 \n",
            "(epoch: 48, iters: 1100, time: 0.066, data: 0.004) G_GAN: 2.110 G_L1: 1.228 D_real: 0.115 D_fake: 0.396 \n",
            "(epoch: 48, iters: 1200, time: 0.276, data: 0.002) G_GAN: 2.883 G_L1: 1.202 D_real: 0.128 D_fake: 0.123 \n",
            "(epoch: 48, iters: 1300, time: 0.066, data: 0.002) G_GAN: 0.843 G_L1: 2.633 D_real: 1.098 D_fake: 0.470 \n",
            "(epoch: 48, iters: 1400, time: 0.066, data: 0.004) G_GAN: 2.747 G_L1: 1.642 D_real: 0.031 D_fake: 0.404 \n",
            "(epoch: 48, iters: 1500, time: 0.066, data: 0.004) G_GAN: 1.115 G_L1: 2.192 D_real: 0.425 D_fake: 0.687 \n",
            "(epoch: 48, iters: 1600, time: 0.162, data: 0.005) G_GAN: 2.990 G_L1: 1.774 D_real: 0.097 D_fake: 0.074 \n",
            "(epoch: 48, iters: 1700, time: 0.067, data: 0.006) G_GAN: 2.100 G_L1: 1.450 D_real: 0.473 D_fake: 0.181 \n",
            "(epoch: 48, iters: 1800, time: 0.065, data: 0.004) G_GAN: 5.612 G_L1: 2.017 D_real: 0.336 D_fake: 0.007 \n",
            "(epoch: 48, iters: 1900, time: 0.067, data: 0.002) G_GAN: 6.328 G_L1: 1.674 D_real: 0.000 D_fake: 0.007 \n",
            "(epoch: 48, iters: 2000, time: 0.445, data: 0.003) G_GAN: 0.941 G_L1: 3.463 D_real: 0.514 D_fake: 0.689 \n",
            "saving the latest model (epoch 48, total_iters 190000)\n",
            "(epoch: 48, iters: 2100, time: 0.067, data: 0.007) G_GAN: 8.036 G_L1: 0.844 D_real: 0.013 D_fake: 0.001 \n",
            "(epoch: 48, iters: 2200, time: 0.066, data: 0.003) G_GAN: 5.555 G_L1: 2.223 D_real: 0.030 D_fake: 0.012 \n",
            "(epoch: 48, iters: 2300, time: 0.067, data: 0.004) G_GAN: 0.929 G_L1: 1.887 D_real: 0.470 D_fake: 0.793 \n",
            "(epoch: 48, iters: 2400, time: 0.163, data: 0.004) G_GAN: 2.590 G_L1: 2.703 D_real: 0.117 D_fake: 0.586 \n",
            "(epoch: 48, iters: 2500, time: 0.067, data: 0.005) G_GAN: 3.125 G_L1: 1.822 D_real: 0.057 D_fake: 0.087 \n",
            "(epoch: 48, iters: 2600, time: 0.067, data: 0.003) G_GAN: 0.858 G_L1: 2.625 D_real: 0.679 D_fake: 0.646 \n",
            "(epoch: 48, iters: 2700, time: 0.062, data: 0.003) G_GAN: 5.455 G_L1: 3.553 D_real: 0.227 D_fake: 0.009 \n",
            "(epoch: 48, iters: 2800, time: 0.169, data: 0.003) G_GAN: 2.873 G_L1: 1.509 D_real: 0.020 D_fake: 0.503 \n",
            "(epoch: 48, iters: 2900, time: 0.066, data: 0.002) G_GAN: 5.033 G_L1: 1.787 D_real: 0.134 D_fake: 0.011 \n",
            "(epoch: 48, iters: 3000, time: 0.067, data: 0.005) G_GAN: 6.461 G_L1: 1.844 D_real: 0.000 D_fake: 0.006 \n",
            "(epoch: 48, iters: 3100, time: 0.065, data: 0.002) G_GAN: 5.601 G_L1: 2.829 D_real: 0.163 D_fake: 0.005 \n",
            "(epoch: 48, iters: 3200, time: 0.170, data: 0.003) G_GAN: 3.537 G_L1: 1.966 D_real: 0.182 D_fake: 0.072 \n",
            "(epoch: 48, iters: 3300, time: 0.066, data: 0.002) G_GAN: 4.526 G_L1: 2.087 D_real: 0.330 D_fake: 0.058 \n",
            "(epoch: 48, iters: 3400, time: 0.064, data: 0.002) G_GAN: 4.525 G_L1: 1.569 D_real: 0.089 D_fake: 0.510 \n",
            "(epoch: 48, iters: 3500, time: 0.066, data: 0.003) G_GAN: 6.752 G_L1: 0.749 D_real: 0.003 D_fake: 0.002 \n",
            "(epoch: 48, iters: 3600, time: 0.167, data: 0.002) G_GAN: 3.453 G_L1: 1.032 D_real: 0.103 D_fake: 0.058 \n",
            "(epoch: 48, iters: 3700, time: 0.065, data: 0.006) G_GAN: 0.899 G_L1: 2.027 D_real: 1.061 D_fake: 0.261 \n",
            "(epoch: 48, iters: 3800, time: 0.067, data: 0.003) G_GAN: 1.212 G_L1: 2.494 D_real: 1.294 D_fake: 0.312 \n",
            "(epoch: 48, iters: 3900, time: 0.066, data: 0.004) G_GAN: 3.158 G_L1: 3.475 D_real: 0.088 D_fake: 0.143 \n",
            "(epoch: 48, iters: 4000, time: 0.342, data: 0.003) G_GAN: 8.853 G_L1: 1.282 D_real: 0.000 D_fake: 0.000 \n",
            "End of epoch 48 / 200 \t Time Taken: 174 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "(epoch: 49, iters: 100, time: 0.065, data: 0.206) G_GAN: 1.265 G_L1: 1.896 D_real: 0.325 D_fake: 0.632 \n",
            "(epoch: 49, iters: 200, time: 0.066, data: 0.003) G_GAN: 6.544 G_L1: 2.205 D_real: 0.218 D_fake: 0.003 \n",
            "(epoch: 49, iters: 300, time: 0.065, data: 0.003) G_GAN: 0.633 G_L1: 2.211 D_real: 0.520 D_fake: 0.981 \n",
            "(epoch: 49, iters: 400, time: 0.453, data: 0.002) G_GAN: 8.557 G_L1: 0.902 D_real: 0.000 D_fake: 0.000 \n",
            "(epoch: 49, iters: 500, time: 0.063, data: 0.004) G_GAN: 2.479 G_L1: 1.607 D_real: 0.032 D_fake: 2.525 \n",
            "(epoch: 49, iters: 600, time: 0.067, data: 0.004) G_GAN: 2.712 G_L1: 1.468 D_real: 0.289 D_fake: 0.483 \n",
            "(epoch: 49, iters: 700, time: 0.066, data: 0.003) G_GAN: 0.849 G_L1: 3.583 D_real: 0.712 D_fake: 0.686 \n",
            "(epoch: 49, iters: 800, time: 0.162, data: 0.003) G_GAN: 6.815 G_L1: 0.995 D_real: 0.002 D_fake: 0.002 \n",
            "(epoch: 49, iters: 900, time: 0.067, data: 0.003) G_GAN: 2.839 G_L1: 2.872 D_real: 0.025 D_fake: 1.658 \n",
            "(epoch: 49, iters: 1000, time: 0.064, data: 0.002) G_GAN: 1.101 G_L1: 2.844 D_real: 0.959 D_fake: 0.395 \n",
            "(epoch: 49, iters: 1100, time: 0.065, data: 0.002) G_GAN: 7.374 G_L1: 0.803 D_real: 0.000 D_fake: 0.001 \n",
            "(epoch: 49, iters: 1200, time: 0.224, data: 0.004) G_GAN: 0.795 G_L1: 7.934 D_real: 0.885 D_fake: 0.667 \n",
            "(epoch: 49, iters: 1300, time: 0.066, data: 0.002) G_GAN: 5.095 G_L1: 0.548 D_real: 0.010 D_fake: 0.261 \n",
            "(epoch: 49, iters: 1400, time: 0.066, data: 0.003) G_GAN: 7.593 G_L1: 2.019 D_real: 0.001 D_fake: 0.001 \n",
            "(epoch: 49, iters: 1500, time: 0.066, data: 0.004) G_GAN: 4.550 G_L1: 1.113 D_real: 0.064 D_fake: 0.014 \n",
            "(epoch: 49, iters: 1600, time: 0.177, data: 0.002) G_GAN: 3.481 G_L1: 3.149 D_real: 0.453 D_fake: 0.044 \n",
            "(epoch: 49, iters: 1700, time: 0.065, data: 0.006) G_GAN: 3.285 G_L1: 2.959 D_real: 0.257 D_fake: 0.098 \n",
            "(epoch: 49, iters: 1800, time: 0.065, data: 0.003) G_GAN: 0.888 G_L1: 2.177 D_real: 0.926 D_fake: 0.485 \n",
            "(epoch: 49, iters: 1900, time: 0.061, data: 0.002) G_GAN: 0.841 G_L1: 2.287 D_real: 0.405 D_fake: 0.874 \n",
            "(epoch: 49, iters: 2000, time: 0.382, data: 0.004) G_GAN: 1.025 G_L1: 1.345 D_real: 0.542 D_fake: 0.578 \n",
            "(epoch: 49, iters: 2100, time: 0.065, data: 0.004) G_GAN: 1.542 G_L1: 1.579 D_real: 1.527 D_fake: 0.317 \n",
            "(epoch: 49, iters: 2200, time: 0.066, data: 0.003) G_GAN: 8.216 G_L1: 2.130 D_real: 0.000 D_fake: 0.001 \n",
            "(epoch: 49, iters: 2300, time: 0.066, data: 0.002) G_GAN: 0.991 G_L1: 2.429 D_real: 1.194 D_fake: 0.535 \n",
            "(epoch: 49, iters: 2400, time: 0.194, data: 0.004) G_GAN: 0.851 G_L1: 1.130 D_real: 0.682 D_fake: 0.917 \n",
            "(epoch: 49, iters: 2500, time: 0.066, data: 0.007) G_GAN: 6.111 G_L1: 2.207 D_real: 0.039 D_fake: 0.004 \n",
            "(epoch: 49, iters: 2600, time: 0.066, data: 0.003) G_GAN: 4.973 G_L1: 5.575 D_real: 0.187 D_fake: 0.012 \n",
            "(epoch: 49, iters: 2700, time: 0.067, data: 0.002) G_GAN: 2.449 G_L1: 3.153 D_real: 1.419 D_fake: 0.366 \n",
            "(epoch: 49, iters: 2800, time: 0.217, data: 0.002) G_GAN: 0.705 G_L1: 1.934 D_real: 0.654 D_fake: 0.826 \n",
            "(epoch: 49, iters: 2900, time: 0.064, data: 0.002) G_GAN: 2.589 G_L1: 1.805 D_real: 0.257 D_fake: 0.099 \n",
            "(epoch: 49, iters: 3000, time: 0.067, data: 0.004) G_GAN: 6.871 G_L1: 0.723 D_real: 0.002 D_fake: 0.002 \n",
            "saving the latest model (epoch 49, total_iters 195000)\n",
            "(epoch: 49, iters: 3100, time: 0.066, data: 0.002) G_GAN: 0.831 G_L1: 3.400 D_real: 0.839 D_fake: 0.717 \n",
            "(epoch: 49, iters: 3200, time: 0.182, data: 0.003) G_GAN: 0.991 G_L1: 1.975 D_real: 0.295 D_fake: 1.167 \n",
            "(epoch: 49, iters: 3300, time: 0.066, data: 0.003) G_GAN: 7.286 G_L1: 1.026 D_real: 0.000 D_fake: 0.002 \n",
            "(epoch: 49, iters: 3400, time: 0.066, data: 0.003) G_GAN: 7.716 G_L1: 0.781 D_real: 0.004 D_fake: 0.001 \n",
            "(epoch: 49, iters: 3500, time: 0.067, data: 0.002) G_GAN: 2.575 G_L1: 3.844 D_real: 0.286 D_fake: 0.220 \n",
            "(epoch: 49, iters: 3600, time: 0.175, data: 0.003) G_GAN: 1.608 G_L1: 6.594 D_real: 0.661 D_fake: 0.179 \n",
            "(epoch: 49, iters: 3700, time: 0.065, data: 0.008) G_GAN: 9.643 G_L1: 0.898 D_real: 0.000 D_fake: 0.000 \n",
            "(epoch: 49, iters: 3800, time: 0.067, data: 0.003) G_GAN: 0.794 G_L1: 1.464 D_real: 1.232 D_fake: 0.191 \n",
            "(epoch: 49, iters: 3900, time: 0.062, data: 0.007) G_GAN: 0.835 G_L1: 2.184 D_real: 0.434 D_fake: 0.931 \n",
            "(epoch: 49, iters: 4000, time: 0.376, data: 0.004) G_GAN: 3.283 G_L1: 1.686 D_real: 0.036 D_fake: 0.100 \n",
            "End of epoch 49 / 200 \t Time Taken: 173 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "(epoch: 50, iters: 100, time: 0.066, data: 0.155) G_GAN: 1.051 G_L1: 2.011 D_real: 0.420 D_fake: 0.753 \n",
            "(epoch: 50, iters: 200, time: 0.067, data: 0.004) G_GAN: 3.151 G_L1: 1.704 D_real: 0.032 D_fake: 0.071 \n",
            "(epoch: 50, iters: 300, time: 0.065, data: 0.003) G_GAN: 0.928 G_L1: 2.918 D_real: 0.641 D_fake: 0.653 \n",
            "(epoch: 50, iters: 400, time: 0.632, data: 0.003) G_GAN: 2.060 G_L1: 2.907 D_real: 0.293 D_fake: 0.289 \n",
            "(epoch: 50, iters: 500, time: 0.064, data: 0.002) G_GAN: 5.797 G_L1: 2.235 D_real: 0.684 D_fake: 0.005 \n",
            "(epoch: 50, iters: 600, time: 0.065, data: 0.006) G_GAN: 5.839 G_L1: 1.896 D_real: 0.000 D_fake: 0.006 \n",
            "(epoch: 50, iters: 700, time: 0.066, data: 0.009) G_GAN: 0.758 G_L1: 3.731 D_real: 0.736 D_fake: 0.862 \n",
            "(epoch: 50, iters: 800, time: 0.177, data: 0.002) G_GAN: 6.643 G_L1: 2.030 D_real: 0.000 D_fake: 0.002 \n",
            "(epoch: 50, iters: 900, time: 0.067, data: 0.007) G_GAN: 5.326 G_L1: 6.926 D_real: 0.117 D_fake: 0.009 \n",
            "(epoch: 50, iters: 1000, time: 0.065, data: 0.004) G_GAN: 1.661 G_L1: 2.829 D_real: 0.218 D_fake: 0.331 \n",
            "(epoch: 50, iters: 1100, time: 0.060, data: 0.004) G_GAN: 1.052 G_L1: 3.610 D_real: 0.543 D_fake: 0.544 \n",
            "(epoch: 50, iters: 1200, time: 0.284, data: 0.004) G_GAN: 1.981 G_L1: 2.451 D_real: 0.284 D_fake: 0.849 \n",
            "(epoch: 50, iters: 1300, time: 0.066, data: 0.003) G_GAN: 0.978 G_L1: 3.317 D_real: 0.521 D_fake: 0.661 \n",
            "(epoch: 50, iters: 1400, time: 0.066, data: 0.005) G_GAN: 3.591 G_L1: 1.519 D_real: 0.214 D_fake: 0.034 \n",
            "(epoch: 50, iters: 1500, time: 0.068, data: 0.004) G_GAN: 4.353 G_L1: 1.640 D_real: 0.175 D_fake: 0.114 \n",
            "(epoch: 50, iters: 1600, time: 0.174, data: 0.003) G_GAN: 2.028 G_L1: 2.530 D_real: 0.172 D_fake: 0.363 \n",
            "(epoch: 50, iters: 1700, time: 0.067, data: 0.011) G_GAN: 9.018 G_L1: 0.901 D_real: 0.001 D_fake: 0.000 \n",
            "(epoch: 50, iters: 1800, time: 0.065, data: 0.003) G_GAN: 0.785 G_L1: 2.075 D_real: 0.567 D_fake: 1.111 \n",
            "(epoch: 50, iters: 1900, time: 0.066, data: 0.004) G_GAN: 2.720 G_L1: 2.063 D_real: 0.096 D_fake: 0.310 \n",
            "(epoch: 50, iters: 2000, time: 0.353, data: 0.006) G_GAN: 5.856 G_L1: 0.747 D_real: 0.004 D_fake: 0.007 \n",
            "(epoch: 50, iters: 2100, time: 0.067, data: 0.010) G_GAN: 5.671 G_L1: 1.512 D_real: 0.000 D_fake: 0.006 \n",
            "(epoch: 50, iters: 2200, time: 0.066, data: 0.003) G_GAN: 5.521 G_L1: 2.104 D_real: 0.408 D_fake: 0.011 \n",
            "(epoch: 50, iters: 2300, time: 0.066, data: 0.004) G_GAN: 3.461 G_L1: 2.713 D_real: 1.954 D_fake: 0.551 \n",
            "(epoch: 50, iters: 2400, time: 0.169, data: 0.004) G_GAN: 2.606 G_L1: 5.322 D_real: 0.565 D_fake: 0.421 \n",
            "(epoch: 50, iters: 2500, time: 0.066, data: 0.002) G_GAN: 6.713 G_L1: 0.570 D_real: 0.001 D_fake: 0.002 \n",
            "(epoch: 50, iters: 2600, time: 0.066, data: 0.004) G_GAN: 2.393 G_L1: 2.256 D_real: 0.054 D_fake: 1.152 \n",
            "(epoch: 50, iters: 2700, time: 0.066, data: 0.004) G_GAN: 4.835 G_L1: 1.665 D_real: 0.000 D_fake: 0.016 \n",
            "(epoch: 50, iters: 2800, time: 0.172, data: 0.004) G_GAN: 6.093 G_L1: 1.928 D_real: 0.001 D_fake: 0.004 \n",
            "(epoch: 50, iters: 2900, time: 0.067, data: 0.002) G_GAN: 5.225 G_L1: 1.516 D_real: 0.001 D_fake: 0.008 \n",
            "(epoch: 50, iters: 3000, time: 0.067, data: 0.004) G_GAN: 4.809 G_L1: 2.422 D_real: 0.003 D_fake: 0.019 \n",
            "(epoch: 50, iters: 3100, time: 0.066, data: 0.003) G_GAN: 5.599 G_L1: 1.712 D_real: 0.000 D_fake: 0.005 \n",
            "(epoch: 50, iters: 3200, time: 0.173, data: 0.004) G_GAN: 3.026 G_L1: 2.795 D_real: 1.781 D_fake: 0.054 \n",
            "(epoch: 50, iters: 3300, time: 0.062, data: 0.012) G_GAN: 3.913 G_L1: 4.378 D_real: 0.421 D_fake: 0.032 \n",
            "(epoch: 50, iters: 3400, time: 0.067, data: 0.005) G_GAN: 3.208 G_L1: 2.769 D_real: 0.092 D_fake: 0.058 \n",
            "(epoch: 50, iters: 3500, time: 0.066, data: 0.003) G_GAN: 5.193 G_L1: 3.803 D_real: 0.273 D_fake: 0.007 \n",
            "(epoch: 50, iters: 3600, time: 0.183, data: 0.004) G_GAN: 3.109 G_L1: 3.124 D_real: 0.021 D_fake: 0.081 \n",
            "(epoch: 50, iters: 3700, time: 0.062, data: 0.011) G_GAN: 6.813 G_L1: 0.802 D_real: 0.000 D_fake: 0.002 \n",
            "(epoch: 50, iters: 3800, time: 0.065, data: 0.005) G_GAN: 2.641 G_L1: 3.458 D_real: 0.034 D_fake: 0.563 \n",
            "(epoch: 50, iters: 3900, time: 0.066, data: 0.003) G_GAN: 5.158 G_L1: 1.877 D_real: 1.019 D_fake: 0.005 \n",
            "(epoch: 50, iters: 4000, time: 0.400, data: 0.003) G_GAN: 4.056 G_L1: 4.635 D_real: 1.040 D_fake: 0.628 \n",
            "saving the latest model (epoch 50, total_iters 200000)\n",
            "saving the model at the end of epoch 50, iters 200000\n",
            "End of epoch 50 / 200 \t Time Taken: 175 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "(epoch: 51, iters: 100, time: 0.067, data: 0.198) G_GAN: 3.011 G_L1: 1.424 D_real: 0.065 D_fake: 0.135 \n",
            "(epoch: 51, iters: 200, time: 0.064, data: 0.005) G_GAN: 2.867 G_L1: 2.016 D_real: 0.132 D_fake: 0.083 \n",
            "(epoch: 51, iters: 300, time: 0.066, data: 0.004) G_GAN: 4.463 G_L1: 1.905 D_real: 0.074 D_fake: 0.024 \n",
            "(epoch: 51, iters: 400, time: 0.517, data: 0.004) G_GAN: 2.061 G_L1: 4.745 D_real: 0.383 D_fake: 0.340 \n",
            "(epoch: 51, iters: 500, time: 0.061, data: 0.002) G_GAN: 7.245 G_L1: 1.041 D_real: 0.084 D_fake: 0.001 \n",
            "(epoch: 51, iters: 600, time: 0.066, data: 0.004) G_GAN: 2.400 G_L1: 1.338 D_real: 0.134 D_fake: 1.196 \n",
            "(epoch: 51, iters: 700, time: 0.067, data: 0.005) G_GAN: 1.629 G_L1: 2.194 D_real: 0.319 D_fake: 1.104 \n",
            "(epoch: 51, iters: 800, time: 0.172, data: 0.007) G_GAN: 1.072 G_L1: 2.362 D_real: 0.888 D_fake: 1.305 \n",
            "(epoch: 51, iters: 900, time: 0.066, data: 0.002) G_GAN: 8.101 G_L1: 0.613 D_real: 0.001 D_fake: 0.001 \n",
            "(epoch: 51, iters: 1000, time: 0.066, data: 0.003) G_GAN: 5.666 G_L1: 1.619 D_real: 0.004 D_fake: 0.005 \n",
            "(epoch: 51, iters: 1100, time: 0.063, data: 0.002) G_GAN: 2.042 G_L1: 3.977 D_real: 0.299 D_fake: 1.034 \n",
            "(epoch: 51, iters: 1200, time: 0.170, data: 0.003) G_GAN: 1.609 G_L1: 1.606 D_real: 0.227 D_fake: 0.637 \n",
            "(epoch: 51, iters: 1300, time: 0.064, data: 0.002) G_GAN: 0.943 G_L1: 1.964 D_real: 0.526 D_fake: 0.878 \n",
            "(epoch: 51, iters: 1400, time: 0.065, data: 0.003) G_GAN: 0.931 G_L1: 2.463 D_real: 0.971 D_fake: 0.458 \n",
            "(epoch: 51, iters: 1500, time: 0.063, data: 0.004) G_GAN: 2.799 G_L1: 1.195 D_real: 0.541 D_fake: 0.132 \n",
            "(epoch: 51, iters: 1600, time: 0.174, data: 0.004) G_GAN: 1.932 G_L1: 4.296 D_real: 0.233 D_fake: 0.229 \n",
            "(epoch: 51, iters: 1700, time: 0.067, data: 0.003) G_GAN: 2.394 G_L1: 4.016 D_real: 0.434 D_fake: 0.191 \n",
            "(epoch: 51, iters: 1800, time: 0.066, data: 0.003) G_GAN: 1.864 G_L1: 3.194 D_real: 3.293 D_fake: 0.020 \n",
            "(epoch: 51, iters: 1900, time: 0.066, data: 0.003) G_GAN: 1.354 G_L1: 2.695 D_real: 0.736 D_fake: 0.365 \n",
            "(epoch: 51, iters: 2000, time: 0.379, data: 0.004) G_GAN: 3.201 G_L1: 2.100 D_real: 2.868 D_fake: 0.006 \n",
            "(epoch: 51, iters: 2100, time: 0.066, data: 0.003) G_GAN: 2.887 G_L1: 2.109 D_real: 0.136 D_fake: 0.479 \n",
            "(epoch: 51, iters: 2200, time: 0.067, data: 0.003) G_GAN: 0.847 G_L1: 3.477 D_real: 0.688 D_fake: 0.581 \n",
            "(epoch: 51, iters: 2300, time: 0.066, data: 0.004) G_GAN: 0.755 G_L1: 2.310 D_real: 0.783 D_fake: 0.796 \n",
            "(epoch: 51, iters: 2400, time: 0.171, data: 0.003) G_GAN: 0.822 G_L1: 1.169 D_real: 0.247 D_fake: 0.996 \n",
            "(epoch: 51, iters: 2500, time: 0.067, data: 0.002) G_GAN: 5.648 G_L1: 1.681 D_real: 0.001 D_fake: 0.006 \n",
            "(epoch: 51, iters: 2600, time: 0.065, data: 0.003) G_GAN: 6.709 G_L1: 2.095 D_real: 0.000 D_fake: 0.002 \n",
            "(epoch: 51, iters: 2700, time: 0.066, data: 0.002) G_GAN: 7.119 G_L1: 0.653 D_real: 0.001 D_fake: 0.001 \n",
            "(epoch: 51, iters: 2800, time: 0.220, data: 0.003) G_GAN: 0.845 G_L1: 2.951 D_real: 0.755 D_fake: 0.660 \n",
            "(epoch: 51, iters: 2900, time: 0.065, data: 0.009) G_GAN: 6.725 G_L1: 0.752 D_real: 0.004 D_fake: 0.003 \n",
            "(epoch: 51, iters: 3000, time: 0.066, data: 0.003) G_GAN: 3.620 G_L1: 3.488 D_real: 0.152 D_fake: 0.043 \n",
            "(epoch: 51, iters: 3100, time: 0.062, data: 0.002) G_GAN: 7.851 G_L1: 1.157 D_real: 0.004 D_fake: 0.001 \n",
            "(epoch: 51, iters: 3200, time: 0.191, data: 0.004) G_GAN: 4.003 G_L1: 2.072 D_real: 1.001 D_fake: 0.050 \n",
            "(epoch: 51, iters: 3300, time: 0.066, data: 0.003) G_GAN: 2.637 G_L1: 1.983 D_real: 0.063 D_fake: 0.351 \n",
            "(epoch: 51, iters: 3400, time: 0.066, data: 0.005) G_GAN: 2.115 G_L1: 2.167 D_real: 0.070 D_fake: 1.202 \n",
            "(epoch: 51, iters: 3500, time: 0.065, data: 0.003) G_GAN: 0.637 G_L1: 2.725 D_real: 0.514 D_fake: 0.992 \n",
            "(epoch: 51, iters: 3600, time: 0.168, data: 0.004) G_GAN: 0.749 G_L1: 2.426 D_real: 1.738 D_fake: 0.560 \n",
            "(epoch: 51, iters: 3700, time: 0.065, data: 0.002) G_GAN: 6.795 G_L1: 0.555 D_real: 0.000 D_fake: 0.002 \n",
            "(epoch: 51, iters: 3800, time: 0.066, data: 0.004) G_GAN: 3.426 G_L1: 1.725 D_real: 0.015 D_fake: 0.079 \n",
            "(epoch: 51, iters: 3900, time: 0.067, data: 0.004) G_GAN: 2.479 G_L1: 1.386 D_real: 0.131 D_fake: 0.199 \n",
            "(epoch: 51, iters: 4000, time: 0.452, data: 0.003) G_GAN: 0.839 G_L1: 1.837 D_real: 0.783 D_fake: 0.584 \n",
            "End of epoch 51 / 200 \t Time Taken: 173 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "(epoch: 52, iters: 100, time: 0.067, data: 0.199) G_GAN: 5.237 G_L1: 2.327 D_real: 0.254 D_fake: 0.055 \n",
            "(epoch: 52, iters: 200, time: 0.066, data: 0.003) G_GAN: 1.645 G_L1: 1.478 D_real: 0.836 D_fake: 0.171 \n",
            "(epoch: 52, iters: 300, time: 0.065, data: 0.003) G_GAN: 2.441 G_L1: 6.414 D_real: 0.279 D_fake: 0.740 \n",
            "(epoch: 52, iters: 400, time: 0.477, data: 0.003) G_GAN: 3.290 G_L1: 1.262 D_real: 0.083 D_fake: 0.872 \n",
            "(epoch: 52, iters: 500, time: 0.066, data: 0.003) G_GAN: 2.160 G_L1: 2.304 D_real: 0.290 D_fake: 0.325 \n",
            "(epoch: 52, iters: 600, time: 0.067, data: 0.004) G_GAN: 1.355 G_L1: 2.023 D_real: 0.284 D_fake: 0.599 \n",
            "(epoch: 52, iters: 700, time: 0.066, data: 0.007) G_GAN: 0.879 G_L1: 3.256 D_real: 0.708 D_fake: 0.606 \n",
            "(epoch: 52, iters: 800, time: 0.214, data: 0.003) G_GAN: 1.235 G_L1: 2.070 D_real: 0.685 D_fake: 0.381 \n",
            "(epoch: 52, iters: 900, time: 0.066, data: 0.003) G_GAN: 0.780 G_L1: 5.731 D_real: 0.717 D_fake: 0.953 \n",
            "(epoch: 52, iters: 1000, time: 0.065, data: 0.004) G_GAN: 5.588 G_L1: 2.217 D_real: 0.000 D_fake: 0.006 \n",
            "saving the latest model (epoch 52, total_iters 205000)\n",
            "(epoch: 52, iters: 1100, time: 0.061, data: 0.006) G_GAN: 6.956 G_L1: 1.949 D_real: 0.290 D_fake: 0.001 \n",
            "(epoch: 52, iters: 1200, time: 0.330, data: 0.003) G_GAN: 8.458 G_L1: 1.833 D_real: 0.762 D_fake: 0.000 \n",
            "(epoch: 52, iters: 1300, time: 0.066, data: 0.003) G_GAN: 0.998 G_L1: 3.717 D_real: 0.994 D_fake: 0.401 \n",
            "(epoch: 52, iters: 1400, time: 0.065, data: 0.004) G_GAN: 0.842 G_L1: 1.782 D_real: 0.792 D_fake: 0.651 \n",
            "(epoch: 52, iters: 1500, time: 0.066, data: 0.004) G_GAN: 5.002 G_L1: 1.827 D_real: 0.001 D_fake: 0.013 \n",
            "(epoch: 52, iters: 1600, time: 0.214, data: 0.004) G_GAN: 0.968 G_L1: 1.852 D_real: 0.987 D_fake: 0.258 \n",
            "(epoch: 52, iters: 1700, time: 0.063, data: 0.010) G_GAN: 2.853 G_L1: 2.464 D_real: 0.150 D_fake: 0.283 \n",
            "(epoch: 52, iters: 1800, time: 0.066, data: 0.003) G_GAN: 0.905 G_L1: 2.696 D_real: 1.079 D_fake: 0.411 \n",
            "(epoch: 52, iters: 1900, time: 0.067, data: 0.003) G_GAN: 3.461 G_L1: 2.828 D_real: 0.169 D_fake: 0.028 \n",
            "(epoch: 52, iters: 2000, time: 0.443, data: 0.003) G_GAN: 0.776 G_L1: 6.049 D_real: 0.582 D_fake: 0.751 \n",
            "(epoch: 52, iters: 2100, time: 0.067, data: 0.003) G_GAN: 6.150 G_L1: 1.901 D_real: 0.002 D_fake: 0.003 \n",
            "(epoch: 52, iters: 2200, time: 0.066, data: 0.003) G_GAN: 2.009 G_L1: 5.092 D_real: 0.269 D_fake: 1.252 \n",
            "(epoch: 52, iters: 2300, time: 0.066, data: 0.004) G_GAN: 2.910 G_L1: 4.587 D_real: 0.119 D_fake: 0.925 \n",
            "(epoch: 52, iters: 2400, time: 0.227, data: 0.003) G_GAN: 0.827 G_L1: 2.213 D_real: 0.900 D_fake: 0.559 \n",
            "(epoch: 52, iters: 2500, time: 0.066, data: 0.003) G_GAN: 2.509 G_L1: 1.645 D_real: 0.213 D_fake: 0.150 \n",
            "(epoch: 52, iters: 2600, time: 0.065, data: 0.004) G_GAN: 2.056 G_L1: 3.761 D_real: 0.251 D_fake: 0.879 \n",
            "(epoch: 52, iters: 2700, time: 0.066, data: 0.005) G_GAN: 1.720 G_L1: 1.685 D_real: 0.791 D_fake: 1.033 \n",
            "(epoch: 52, iters: 2800, time: 0.220, data: 0.003) G_GAN: 0.800 G_L1: 4.953 D_real: 0.945 D_fake: 0.617 \n",
            "(epoch: 52, iters: 2900, time: 0.066, data: 0.014) G_GAN: 6.005 G_L1: 1.055 D_real: 0.000 D_fake: 0.005 \n",
            "(epoch: 52, iters: 3000, time: 0.065, data: 0.004) G_GAN: 1.840 G_L1: 1.727 D_real: 1.115 D_fake: 0.413 \n",
            "(epoch: 52, iters: 3100, time: 0.065, data: 0.003) G_GAN: 5.869 G_L1: 1.043 D_real: 0.001 D_fake: 0.006 \n",
            "(epoch: 52, iters: 3200, time: 0.215, data: 0.008) G_GAN: 0.789 G_L1: 5.578 D_real: 0.520 D_fake: 0.999 \n",
            "(epoch: 52, iters: 3300, time: 0.066, data: 0.002) G_GAN: 2.660 G_L1: 1.139 D_real: 0.063 D_fake: 0.151 \n",
            "(epoch: 52, iters: 3400, time: 0.066, data: 0.004) G_GAN: 0.794 G_L1: 1.825 D_real: 0.508 D_fake: 0.961 \n",
            "(epoch: 52, iters: 3500, time: 0.065, data: 0.003) G_GAN: 1.029 G_L1: 3.275 D_real: 0.787 D_fake: 0.449 \n",
            "(epoch: 52, iters: 3600, time: 0.177, data: 0.004) G_GAN: 2.910 G_L1: 1.400 D_real: 0.062 D_fake: 1.022 \n",
            "(epoch: 52, iters: 3700, time: 0.066, data: 0.012) G_GAN: 6.155 G_L1: 1.476 D_real: 0.001 D_fake: 0.003 \n",
            "(epoch: 52, iters: 3800, time: 0.066, data: 0.003) G_GAN: 2.871 G_L1: 1.309 D_real: 0.095 D_fake: 0.093 \n",
            "(epoch: 52, iters: 3900, time: 0.064, data: 0.006) G_GAN: 1.023 G_L1: 2.177 D_real: 0.909 D_fake: 0.418 \n",
            "(epoch: 52, iters: 4000, time: 0.352, data: 0.004) G_GAN: 6.737 G_L1: 1.270 D_real: 0.001 D_fake: 0.002 \n",
            "End of epoch 52 / 200 \t Time Taken: 174 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "(epoch: 53, iters: 100, time: 0.065, data: 0.201) G_GAN: 8.968 G_L1: 0.869 D_real: 0.002 D_fake: 0.000 \n",
            "(epoch: 53, iters: 200, time: 0.066, data: 0.003) G_GAN: 1.128 G_L1: 2.040 D_real: 0.366 D_fake: 0.810 \n",
            "(epoch: 53, iters: 300, time: 0.066, data: 0.003) G_GAN: 0.802 G_L1: 4.345 D_real: 1.140 D_fake: 0.638 \n",
            "(epoch: 53, iters: 400, time: 0.501, data: 0.003) G_GAN: 5.808 G_L1: 2.066 D_real: 0.000 D_fake: 0.005 \n",
            "(epoch: 53, iters: 500, time: 0.065, data: 0.004) G_GAN: 4.527 G_L1: 2.050 D_real: 2.376 D_fake: 0.009 \n",
            "(epoch: 53, iters: 600, time: 0.066, data: 0.003) G_GAN: 2.218 G_L1: 1.226 D_real: 0.203 D_fake: 0.094 \n",
            "(epoch: 53, iters: 700, time: 0.066, data: 0.006) G_GAN: 0.987 G_L1: 3.093 D_real: 0.427 D_fake: 0.575 \n",
            "(epoch: 53, iters: 800, time: 0.156, data: 0.005) G_GAN: 7.533 G_L1: 0.835 D_real: 0.006 D_fake: 0.001 \n",
            "(epoch: 53, iters: 900, time: 0.062, data: 0.003) G_GAN: 0.743 G_L1: 3.300 D_real: 0.650 D_fake: 0.827 \n",
            "(epoch: 53, iters: 1000, time: 0.066, data: 0.003) G_GAN: 6.581 G_L1: 0.845 D_real: 0.005 D_fake: 0.003 \n",
            "(epoch: 53, iters: 1100, time: 0.066, data: 0.004) G_GAN: 6.615 G_L1: 0.590 D_real: 0.002 D_fake: 0.002 \n",
            "(epoch: 53, iters: 1200, time: 0.228, data: 0.003) G_GAN: 0.764 G_L1: 3.469 D_real: 0.891 D_fake: 0.693 \n",
            "(epoch: 53, iters: 1300, time: 0.065, data: 0.006) G_GAN: 5.987 G_L1: 1.738 D_real: 0.000 D_fake: 0.004 \n",
            "(epoch: 53, iters: 1400, time: 0.065, data: 0.003) G_GAN: 2.767 G_L1: 2.049 D_real: 0.042 D_fake: 0.103 \n",
            "(epoch: 53, iters: 1500, time: 0.066, data: 0.004) G_GAN: 4.604 G_L1: 0.940 D_real: 0.006 D_fake: 0.020 \n",
            "(epoch: 53, iters: 1600, time: 0.176, data: 0.006) G_GAN: 3.620 G_L1: 2.654 D_real: 1.122 D_fake: 0.044 \n",
            "(epoch: 53, iters: 1700, time: 0.067, data: 0.002) G_GAN: 0.778 G_L1: 3.072 D_real: 0.646 D_fake: 0.720 \n",
            "(epoch: 53, iters: 1800, time: 0.063, data: 0.003) G_GAN: 0.600 G_L1: 2.352 D_real: 1.247 D_fake: 0.788 \n",
            "(epoch: 53, iters: 1900, time: 0.066, data: 0.004) G_GAN: 6.988 G_L1: 1.202 D_real: 0.020 D_fake: 0.002 \n",
            "(epoch: 53, iters: 2000, time: 0.415, data: 0.014) G_GAN: 2.857 G_L1: 2.484 D_real: 0.042 D_fake: 0.148 \n",
            "saving the latest model (epoch 53, total_iters 210000)\n",
            "(epoch: 53, iters: 2100, time: 0.066, data: 0.002) G_GAN: 5.030 G_L1: 2.792 D_real: 0.193 D_fake: 0.011 \n",
            "(epoch: 53, iters: 2200, time: 0.066, data: 0.002) G_GAN: 2.757 G_L1: 1.487 D_real: 0.631 D_fake: 0.153 \n",
            "(epoch: 53, iters: 2300, time: 0.066, data: 0.004) G_GAN: 3.544 G_L1: 0.928 D_real: 0.001 D_fake: 0.084 \n",
            "(epoch: 53, iters: 2400, time: 0.180, data: 0.003) G_GAN: 5.197 G_L1: 1.934 D_real: 0.037 D_fake: 0.010 \n",
            "(epoch: 53, iters: 2500, time: 0.065, data: 0.003) G_GAN: 1.664 G_L1: 2.749 D_real: 0.226 D_fake: 0.756 \n",
            "(epoch: 53, iters: 2600, time: 0.064, data: 0.004) G_GAN: 5.233 G_L1: 1.602 D_real: 0.650 D_fake: 0.006 \n",
            "(epoch: 53, iters: 2700, time: 0.067, data: 0.004) G_GAN: 9.389 G_L1: 1.712 D_real: 0.004 D_fake: 0.000 \n",
            "(epoch: 53, iters: 2800, time: 0.165, data: 0.004) G_GAN: 2.290 G_L1: 5.853 D_real: 0.359 D_fake: 1.214 \n",
            "(epoch: 53, iters: 2900, time: 0.067, data: 0.002) G_GAN: 5.499 G_L1: 3.461 D_real: 0.071 D_fake: 0.007 \n",
            "(epoch: 53, iters: 3000, time: 0.060, data: 0.003) G_GAN: 3.321 G_L1: 2.060 D_real: 0.096 D_fake: 0.753 \n",
            "(epoch: 53, iters: 3100, time: 0.065, data: 0.003) G_GAN: 2.462 G_L1: 3.061 D_real: 0.279 D_fake: 0.604 \n",
            "(epoch: 53, iters: 3200, time: 0.186, data: 0.004) G_GAN: 0.883 G_L1: 2.169 D_real: 0.376 D_fake: 0.848 \n",
            "(epoch: 53, iters: 3300, time: 0.066, data: 0.007) G_GAN: 3.403 G_L1: 1.220 D_real: 0.093 D_fake: 0.058 \n",
            "(epoch: 53, iters: 3400, time: 0.067, data: 0.003) G_GAN: 5.699 G_L1: 2.349 D_real: 0.043 D_fake: 0.006 \n",
            "(epoch: 53, iters: 3500, time: 0.065, data: 0.002) G_GAN: 0.712 G_L1: 2.618 D_real: 0.465 D_fake: 0.831 \n",
            "(epoch: 53, iters: 3600, time: 0.171, data: 0.004) G_GAN: 2.123 G_L1: 3.956 D_real: 0.266 D_fake: 0.658 \n",
            "(epoch: 53, iters: 3700, time: 0.066, data: 0.004) G_GAN: 2.452 G_L1: 2.792 D_real: 0.968 D_fake: 1.116 \n",
            "(epoch: 53, iters: 3800, time: 0.066, data: 0.003) G_GAN: 1.097 G_L1: 2.245 D_real: 0.365 D_fake: 0.598 \n",
            "(epoch: 53, iters: 3900, time: 0.056, data: 0.004) G_GAN: 4.663 G_L1: 0.936 D_real: 0.000 D_fake: 0.024 \n",
            "(epoch: 53, iters: 4000, time: 0.394, data: 0.004) G_GAN: 6.958 G_L1: 1.917 D_real: 0.178 D_fake: 0.001 \n",
            "End of epoch 53 / 200 \t Time Taken: 174 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "(epoch: 54, iters: 100, time: 0.066, data: 0.342) G_GAN: 1.962 G_L1: 3.672 D_real: 0.119 D_fake: 0.491 \n",
            "(epoch: 54, iters: 200, time: 0.066, data: 0.003) G_GAN: 6.148 G_L1: 1.062 D_real: 0.004 D_fake: 0.007 \n",
            "(epoch: 54, iters: 300, time: 0.066, data: 0.002) G_GAN: 1.334 G_L1: 2.184 D_real: 0.439 D_fake: 0.393 \n",
            "(epoch: 54, iters: 400, time: 0.566, data: 0.003) G_GAN: 0.886 G_L1: 3.048 D_real: 0.584 D_fake: 0.795 \n",
            "(epoch: 54, iters: 500, time: 0.066, data: 0.002) G_GAN: 2.172 G_L1: 2.259 D_real: 0.040 D_fake: 0.401 \n",
            "(epoch: 54, iters: 600, time: 0.063, data: 0.004) G_GAN: 3.758 G_L1: 0.746 D_real: 0.052 D_fake: 0.145 \n",
            "(epoch: 54, iters: 700, time: 0.067, data: 0.003) G_GAN: 2.722 G_L1: 2.270 D_real: 0.025 D_fake: 0.181 \n",
            "(epoch: 54, iters: 800, time: 0.227, data: 0.004) G_GAN: 0.853 G_L1: 4.162 D_real: 0.613 D_fake: 0.706 \n",
            "(epoch: 54, iters: 900, time: 0.065, data: 0.002) G_GAN: 0.486 G_L1: 1.794 D_real: 0.520 D_fake: 1.359 \n",
            "(epoch: 54, iters: 1000, time: 0.066, data: 0.004) G_GAN: 4.226 G_L1: 2.342 D_real: 0.076 D_fake: 0.044 \n",
            "(epoch: 54, iters: 1100, time: 0.066, data: 0.004) G_GAN: 2.599 G_L1: 7.082 D_real: 0.381 D_fake: 0.083 \n",
            "(epoch: 54, iters: 1200, time: 0.221, data: 0.002) G_GAN: 0.546 G_L1: 1.953 D_real: 0.437 D_fake: 1.123 \n",
            "(epoch: 54, iters: 1300, time: 0.066, data: 0.010) G_GAN: 6.248 G_L1: 0.976 D_real: 0.001 D_fake: 0.005 \n",
            "(epoch: 54, iters: 1400, time: 0.066, data: 0.004) G_GAN: 0.875 G_L1: 3.933 D_real: 0.824 D_fake: 0.570 \n",
            "(epoch: 54, iters: 1500, time: 0.067, data: 0.004) G_GAN: 1.036 G_L1: 2.107 D_real: 0.409 D_fake: 0.826 \n",
            "(epoch: 54, iters: 1600, time: 0.188, data: 0.006) G_GAN: 3.505 G_L1: 3.202 D_real: 0.232 D_fake: 0.087 \n",
            "(epoch: 54, iters: 1700, time: 0.063, data: 0.003) G_GAN: 0.837 G_L1: 2.662 D_real: 0.671 D_fake: 0.590 \n",
            "(epoch: 54, iters: 1800, time: 0.066, data: 0.002) G_GAN: 2.393 G_L1: 1.892 D_real: 0.173 D_fake: 0.647 \n",
            "(epoch: 54, iters: 1900, time: 0.066, data: 0.003) G_GAN: 3.956 G_L1: 0.565 D_real: 0.001 D_fake: 0.122 \n",
            "(epoch: 54, iters: 2000, time: 0.461, data: 0.005) G_GAN: 0.963 G_L1: 2.440 D_real: 0.490 D_fake: 0.659 \n",
            "(epoch: 54, iters: 2100, time: 0.067, data: 0.004) G_GAN: 0.732 G_L1: 2.349 D_real: 0.390 D_fake: 1.019 \n",
            "(epoch: 54, iters: 2200, time: 0.066, data: 0.002) G_GAN: 2.392 G_L1: 2.112 D_real: 0.292 D_fake: 0.294 \n",
            "(epoch: 54, iters: 2300, time: 0.066, data: 0.003) G_GAN: 2.625 G_L1: 1.732 D_real: 0.098 D_fake: 0.133 \n",
            "(epoch: 54, iters: 2400, time: 0.168, data: 0.007) G_GAN: 3.536 G_L1: 2.240 D_real: 0.127 D_fake: 0.038 \n",
            "(epoch: 54, iters: 2500, time: 0.055, data: 0.002) G_GAN: 2.612 G_L1: 1.790 D_real: 0.059 D_fake: 0.865 \n",
            "(epoch: 54, iters: 2600, time: 0.066, data: 0.002) G_GAN: 0.970 G_L1: 3.443 D_real: 0.786 D_fake: 0.635 \n",
            "(epoch: 54, iters: 2700, time: 0.066, data: 0.004) G_GAN: 3.216 G_L1: 1.284 D_real: 0.053 D_fake: 0.253 \n",
            "(epoch: 54, iters: 2800, time: 0.161, data: 0.003) G_GAN: 8.518 G_L1: 0.905 D_real: 0.000 D_fake: 0.001 \n",
            "(epoch: 54, iters: 2900, time: 0.064, data: 0.002) G_GAN: 7.171 G_L1: 2.149 D_real: 0.092 D_fake: 0.002 \n",
            "(epoch: 54, iters: 3000, time: 0.060, data: 0.004) G_GAN: 7.334 G_L1: 1.555 D_real: 0.015 D_fake: 0.001 \n",
            "saving the latest model (epoch 54, total_iters 215000)\n",
            "(epoch: 54, iters: 3100, time: 0.066, data: 0.002) G_GAN: 2.382 G_L1: 2.119 D_real: 0.224 D_fake: 0.178 \n",
            "(epoch: 54, iters: 3200, time: 0.177, data: 0.004) G_GAN: 2.388 G_L1: 1.740 D_real: 0.154 D_fake: 0.267 \n",
            "(epoch: 54, iters: 3300, time: 0.066, data: 0.011) G_GAN: 2.412 G_L1: 2.568 D_real: 0.249 D_fake: 0.221 \n",
            "(epoch: 54, iters: 3400, time: 0.067, data: 0.004) G_GAN: 5.495 G_L1: 2.612 D_real: 0.013 D_fake: 0.006 \n",
            "(epoch: 54, iters: 3500, time: 0.063, data: 0.006) G_GAN: 8.593 G_L1: 0.982 D_real: 0.000 D_fake: 0.000 \n",
            "(epoch: 54, iters: 3600, time: 0.169, data: 0.003) G_GAN: 6.187 G_L1: 1.751 D_real: 0.002 D_fake: 0.003 \n",
            "(epoch: 54, iters: 3700, time: 0.065, data: 0.010) G_GAN: 1.783 G_L1: 2.623 D_real: 0.414 D_fake: 0.349 \n",
            "(epoch: 54, iters: 3800, time: 0.066, data: 0.004) G_GAN: 2.489 G_L1: 2.902 D_real: 0.180 D_fake: 0.181 \n",
            "(epoch: 54, iters: 3900, time: 0.066, data: 0.003) G_GAN: 7.383 G_L1: 1.319 D_real: 0.001 D_fake: 0.001 \n",
            "(epoch: 54, iters: 4000, time: 0.406, data: 0.002) G_GAN: 3.917 G_L1: 1.195 D_real: 0.176 D_fake: 0.200 \n",
            "End of epoch 54 / 200 \t Time Taken: 174 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "(epoch: 55, iters: 100, time: 0.065, data: 0.209) G_GAN: 8.270 G_L1: 0.999 D_real: 0.000 D_fake: 0.000 \n",
            "(epoch: 55, iters: 200, time: 0.066, data: 0.003) G_GAN: 6.736 G_L1: 1.430 D_real: 0.004 D_fake: 0.002 \n",
            "(epoch: 55, iters: 300, time: 0.067, data: 0.004) G_GAN: 5.719 G_L1: 0.796 D_real: 0.006 D_fake: 0.005 \n",
            "(epoch: 55, iters: 400, time: 0.508, data: 0.005) G_GAN: 6.261 G_L1: 1.668 D_real: 0.000 D_fake: 0.005 \n",
            "(epoch: 55, iters: 500, time: 0.066, data: 0.010) G_GAN: 2.876 G_L1: 2.545 D_real: 0.017 D_fake: 0.393 \n",
            "(epoch: 55, iters: 600, time: 0.065, data: 0.003) G_GAN: 0.789 G_L1: 2.643 D_real: 0.440 D_fake: 0.959 \n",
            "(epoch: 55, iters: 700, time: 0.066, data: 0.003) G_GAN: 1.342 G_L1: 2.063 D_real: 0.503 D_fake: 0.482 \n",
            "(epoch: 55, iters: 800, time: 0.169, data: 0.003) G_GAN: 3.995 G_L1: 3.634 D_real: 0.218 D_fake: 0.103 \n",
            "(epoch: 55, iters: 900, time: 0.061, data: 0.003) G_GAN: 3.765 G_L1: 1.248 D_real: 0.077 D_fake: 1.365 \n",
            "(epoch: 55, iters: 1000, time: 0.066, data: 0.003) G_GAN: 0.842 G_L1: 2.090 D_real: 0.557 D_fake: 1.140 \n",
            "(epoch: 55, iters: 1100, time: 0.066, data: 0.003) G_GAN: 2.283 G_L1: 2.135 D_real: 0.093 D_fake: 1.542 \n",
            "(epoch: 55, iters: 1200, time: 0.170, data: 0.003) G_GAN: 1.596 G_L1: 1.740 D_real: 0.459 D_fake: 0.330 \n",
            "(epoch: 55, iters: 1300, time: 0.065, data: 0.002) G_GAN: 6.819 G_L1: 1.843 D_real: 0.000 D_fake: 0.002 \n",
            "(epoch: 55, iters: 1400, time: 0.063, data: 0.004) G_GAN: 3.490 G_L1: 6.676 D_real: 1.071 D_fake: 0.235 \n",
            "(epoch: 55, iters: 1500, time: 0.064, data: 0.004) G_GAN: 0.810 G_L1: 2.484 D_real: 0.683 D_fake: 0.847 \n",
            "(epoch: 55, iters: 1600, time: 0.170, data: 0.004) G_GAN: 6.333 G_L1: 1.837 D_real: 0.001 D_fake: 0.004 \n",
            "(epoch: 55, iters: 1700, time: 0.065, data: 0.007) G_GAN: 5.264 G_L1: 3.379 D_real: 0.039 D_fake: 0.007 \n",
            "(epoch: 55, iters: 1800, time: 0.067, data: 0.004) G_GAN: 2.327 G_L1: 2.125 D_real: 0.352 D_fake: 0.101 \n",
            "(epoch: 55, iters: 1900, time: 0.066, data: 0.003) G_GAN: 0.690 G_L1: 2.302 D_real: 0.714 D_fake: 0.820 \n",
            "(epoch: 55, iters: 2000, time: 0.456, data: 0.004) G_GAN: 1.392 G_L1: 2.523 D_real: 0.667 D_fake: 0.438 \n",
            "(epoch: 55, iters: 2100, time: 0.065, data: 0.003) G_GAN: 2.805 G_L1: 3.963 D_real: 0.025 D_fake: 0.791 \n",
            "(epoch: 55, iters: 2200, time: 0.067, data: 0.003) G_GAN: 2.573 G_L1: 4.163 D_real: 1.765 D_fake: 0.148 \n",
            "(epoch: 55, iters: 2300, time: 0.066, data: 0.004) G_GAN: 0.976 G_L1: 2.040 D_real: 0.476 D_fake: 0.626 \n",
            "(epoch: 55, iters: 2400, time: 0.179, data: 0.003) G_GAN: 2.178 G_L1: 3.466 D_real: 0.090 D_fake: 0.727 \n",
            "(epoch: 55, iters: 2500, time: 0.067, data: 0.012) G_GAN: 3.147 G_L1: 3.510 D_real: 0.059 D_fake: 0.298 \n",
            "(epoch: 55, iters: 2600, time: 0.066, data: 0.003) G_GAN: 4.419 G_L1: 3.491 D_real: 0.135 D_fake: 0.021 \n",
            "(epoch: 55, iters: 2700, time: 0.062, data: 0.004) G_GAN: 1.694 G_L1: 4.688 D_real: 0.347 D_fake: 0.704 \n",
            "(epoch: 55, iters: 2800, time: 0.188, data: 0.002) G_GAN: 1.428 G_L1: 2.526 D_real: 0.237 D_fake: 0.094 \n",
            "(epoch: 55, iters: 2900, time: 0.067, data: 0.014) G_GAN: 1.062 G_L1: 2.683 D_real: 0.983 D_fake: 0.368 \n",
            "(epoch: 55, iters: 3000, time: 0.065, data: 0.006) G_GAN: 3.109 G_L1: 9.922 D_real: 0.508 D_fake: 0.146 \n",
            "(epoch: 55, iters: 3100, time: 0.067, data: 0.003) G_GAN: 2.117 G_L1: 1.929 D_real: 0.280 D_fake: 0.862 \n",
            "(epoch: 55, iters: 3200, time: 0.169, data: 0.005) G_GAN: 4.631 G_L1: 1.441 D_real: 0.096 D_fake: 0.018 \n",
            "(epoch: 55, iters: 3300, time: 0.067, data: 0.003) G_GAN: 5.614 G_L1: 1.020 D_real: 0.000 D_fake: 0.006 \n",
            "(epoch: 55, iters: 3400, time: 0.066, data: 0.003) G_GAN: 5.742 G_L1: 0.924 D_real: 0.036 D_fake: 0.005 \n",
            "(epoch: 55, iters: 3500, time: 0.065, data: 0.002) G_GAN: 0.492 G_L1: 2.417 D_real: 0.303 D_fake: 1.410 \n",
            "(epoch: 55, iters: 3600, time: 0.164, data: 0.004) G_GAN: 3.510 G_L1: 1.809 D_real: 0.567 D_fake: 0.039 \n",
            "(epoch: 55, iters: 3700, time: 0.065, data: 0.006) G_GAN: 1.535 G_L1: 2.059 D_real: 0.531 D_fake: 0.422 \n",
            "(epoch: 55, iters: 3800, time: 0.066, data: 0.004) G_GAN: 5.644 G_L1: 1.156 D_real: 0.000 D_fake: 0.006 \n",
            "(epoch: 55, iters: 3900, time: 0.066, data: 0.002) G_GAN: 1.848 G_L1: 2.420 D_real: 0.309 D_fake: 0.958 \n",
            "(epoch: 55, iters: 4000, time: 0.519, data: 0.003) G_GAN: 3.860 G_L1: 5.997 D_real: 0.195 D_fake: 0.026 \n",
            "saving the latest model (epoch 55, total_iters 220000)\n",
            "saving the model at the end of epoch 55, iters 220000\n",
            "End of epoch 55 / 200 \t Time Taken: 176 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "(epoch: 56, iters: 100, time: 0.067, data: 0.162) G_GAN: 0.700 G_L1: 1.988 D_real: 0.727 D_fake: 0.868 \n",
            "(epoch: 56, iters: 200, time: 0.066, data: 0.003) G_GAN: 6.511 G_L1: 1.596 D_real: 0.000 D_fake: 0.002 \n",
            "(epoch: 56, iters: 300, time: 0.066, data: 0.002) G_GAN: 0.834 G_L1: 1.982 D_real: 0.469 D_fake: 0.868 \n",
            "(epoch: 56, iters: 400, time: 0.466, data: 0.006) G_GAN: 5.378 G_L1: 1.217 D_real: 0.000 D_fake: 0.008 \n",
            "(epoch: 56, iters: 500, time: 0.066, data: 0.002) G_GAN: 4.213 G_L1: 3.851 D_real: 0.193 D_fake: 0.035 \n",
            "(epoch: 56, iters: 600, time: 0.064, data: 0.007) G_GAN: 0.881 G_L1: 2.258 D_real: 0.722 D_fake: 0.554 \n",
            "(epoch: 56, iters: 700, time: 0.066, data: 0.003) G_GAN: 5.489 G_L1: 1.097 D_real: 0.000 D_fake: 0.007 \n",
            "(epoch: 56, iters: 800, time: 0.219, data: 0.004) G_GAN: 1.107 G_L1: 2.363 D_real: 0.418 D_fake: 0.723 \n",
            "(epoch: 56, iters: 900, time: 0.066, data: 0.002) G_GAN: 6.240 G_L1: 1.745 D_real: 0.000 D_fake: 0.004 \n",
            "(epoch: 56, iters: 1000, time: 0.066, data: 0.003) G_GAN: 1.929 G_L1: 2.094 D_real: 0.345 D_fake: 0.477 \n",
            "(epoch: 56, iters: 1100, time: 0.066, data: 0.003) G_GAN: 3.194 G_L1: 2.243 D_real: 0.499 D_fake: 0.035 \n",
            "(epoch: 56, iters: 1200, time: 0.174, data: 0.003) G_GAN: 2.437 G_L1: 6.005 D_real: 0.901 D_fake: 0.115 \n",
            "(epoch: 56, iters: 1300, time: 0.066, data: 0.007) G_GAN: 4.747 G_L1: 1.397 D_real: 0.289 D_fake: 0.031 \n",
            "(epoch: 56, iters: 1400, time: 0.066, data: 0.003) G_GAN: 1.521 G_L1: 1.902 D_real: 0.709 D_fake: 0.291 \n",
            "(epoch: 56, iters: 1500, time: 0.066, data: 0.003) G_GAN: 1.175 G_L1: 2.591 D_real: 1.458 D_fake: 0.306 \n",
            "(epoch: 56, iters: 1600, time: 0.171, data: 0.004) G_GAN: 1.851 G_L1: 2.668 D_real: 0.187 D_fake: 0.434 \n",
            "(epoch: 56, iters: 1700, time: 0.065, data: 0.002) G_GAN: 1.024 G_L1: 4.389 D_real: 0.757 D_fake: 0.478 \n",
            "(epoch: 56, iters: 1800, time: 0.065, data: 0.007) G_GAN: 0.814 G_L1: 2.478 D_real: 0.645 D_fake: 0.670 \n",
            "(epoch: 56, iters: 1900, time: 0.066, data: 0.002) G_GAN: 0.762 G_L1: 2.459 D_real: 0.557 D_fake: 0.885 \n",
            "(epoch: 56, iters: 2000, time: 0.468, data: 0.004) G_GAN: 1.207 G_L1: 2.076 D_real: 0.851 D_fake: 0.419 \n",
            "(epoch: 56, iters: 2100, time: 0.064, data: 0.004) G_GAN: 6.060 G_L1: 1.161 D_real: 0.000 D_fake: 0.004 \n",
            "(epoch: 56, iters: 2200, time: 0.066, data: 0.004) G_GAN: 0.686 G_L1: 2.276 D_real: 1.037 D_fake: 0.658 \n",
            "(epoch: 56, iters: 2300, time: 0.066, data: 0.004) G_GAN: 4.947 G_L1: 1.801 D_real: 1.157 D_fake: 0.026 \n",
            "(epoch: 56, iters: 2400, time: 0.217, data: 0.004) G_GAN: 1.130 G_L1: 1.903 D_real: 0.867 D_fake: 0.191 \n",
            "(epoch: 56, iters: 2500, time: 0.067, data: 0.014) G_GAN: 2.546 G_L1: 1.912 D_real: 0.043 D_fake: 0.288 \n",
            "(epoch: 56, iters: 2600, time: 0.067, data: 0.004) G_GAN: 3.211 G_L1: 2.140 D_real: 0.010 D_fake: 0.592 \n",
            "(epoch: 56, iters: 2700, time: 0.066, data: 0.002) G_GAN: 6.108 G_L1: 1.725 D_real: 0.000 D_fake: 0.004 \n",
            "(epoch: 56, iters: 2800, time: 0.204, data: 0.003) G_GAN: 2.382 G_L1: 1.765 D_real: 0.041 D_fake: 1.142 \n",
            "(epoch: 56, iters: 2900, time: 0.067, data: 0.009) G_GAN: 0.724 G_L1: 2.482 D_real: 0.622 D_fake: 0.817 \n",
            "(epoch: 56, iters: 3000, time: 0.066, data: 0.007) G_GAN: 0.535 G_L1: 1.961 D_real: 0.509 D_fake: 1.147 \n",
            "(epoch: 56, iters: 3100, time: 0.066, data: 0.003) G_GAN: 1.482 G_L1: 2.076 D_real: 0.817 D_fake: 0.227 \n",
            "(epoch: 56, iters: 3200, time: 0.188, data: 0.003) G_GAN: 7.484 G_L1: 2.009 D_real: 0.838 D_fake: 0.001 \n",
            "(epoch: 56, iters: 3300, time: 0.067, data: 0.010) G_GAN: 1.575 G_L1: 3.090 D_real: 0.153 D_fake: 1.605 \n",
            "(epoch: 56, iters: 3400, time: 0.067, data: 0.002) G_GAN: 5.437 G_L1: 1.386 D_real: 0.000 D_fake: 0.006 \n",
            "(epoch: 56, iters: 3500, time: 0.066, data: 0.002) G_GAN: 5.280 G_L1: 1.977 D_real: 0.000 D_fake: 0.008 \n",
            "(epoch: 56, iters: 3600, time: 0.163, data: 0.004) G_GAN: 5.869 G_L1: 1.095 D_real: 0.000 D_fake: 0.004 \n",
            "(epoch: 56, iters: 3700, time: 0.067, data: 0.005) G_GAN: 6.285 G_L1: 1.365 D_real: 0.353 D_fake: 0.004 \n",
            "(epoch: 56, iters: 3800, time: 0.066, data: 0.003) G_GAN: 0.760 G_L1: 1.927 D_real: 0.675 D_fake: 0.775 \n",
            "(epoch: 56, iters: 3900, time: 0.066, data: 0.003) G_GAN: 6.648 G_L1: 2.242 D_real: 0.034 D_fake: 0.002 \n",
            "(epoch: 56, iters: 4000, time: 0.457, data: 0.003) G_GAN: 0.648 G_L1: 1.871 D_real: 0.814 D_fake: 0.786 \n",
            "End of epoch 56 / 200 \t Time Taken: 173 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "(epoch: 57, iters: 100, time: 0.066, data: 0.194) G_GAN: 5.196 G_L1: 1.650 D_real: 0.000 D_fake: 0.010 \n",
            "(epoch: 57, iters: 200, time: 0.066, data: 0.004) G_GAN: 2.529 G_L1: 3.614 D_real: 0.294 D_fake: 0.114 \n",
            "(epoch: 57, iters: 300, time: 0.067, data: 0.002) G_GAN: 2.529 G_L1: 1.906 D_real: 0.037 D_fake: 0.193 \n",
            "(epoch: 57, iters: 400, time: 0.535, data: 0.002) G_GAN: 7.377 G_L1: 0.794 D_real: 0.001 D_fake: 0.001 \n",
            "(epoch: 57, iters: 500, time: 0.066, data: 0.007) G_GAN: 6.634 G_L1: 1.555 D_real: 0.000 D_fake: 0.002 \n",
            "(epoch: 57, iters: 600, time: 0.067, data: 0.002) G_GAN: 5.792 G_L1: 2.672 D_real: 0.376 D_fake: 0.002 \n",
            "(epoch: 57, iters: 700, time: 0.065, data: 0.003) G_GAN: 5.669 G_L1: 2.796 D_real: 0.643 D_fake: 0.007 \n",
            "(epoch: 57, iters: 800, time: 0.164, data: 0.008) G_GAN: 2.105 G_L1: 4.628 D_real: 0.015 D_fake: 1.510 \n",
            "(epoch: 57, iters: 900, time: 0.066, data: 0.007) G_GAN: 1.972 G_L1: 7.198 D_real: 0.589 D_fake: 1.050 \n",
            "(epoch: 57, iters: 1000, time: 0.067, data: 0.004) G_GAN: 4.267 G_L1: 3.709 D_real: 0.028 D_fake: 0.021 \n",
            "saving the latest model (epoch 57, total_iters 225000)\n",
            "(epoch: 57, iters: 1100, time: 0.066, data: 0.002) G_GAN: 1.036 G_L1: 3.053 D_real: 0.743 D_fake: 0.485 \n",
            "(epoch: 57, iters: 1200, time: 0.223, data: 0.004) G_GAN: 0.765 G_L1: 3.153 D_real: 0.691 D_fake: 0.711 \n",
            "(epoch: 57, iters: 1300, time: 0.067, data: 0.002) G_GAN: 1.170 G_L1: 2.138 D_real: 0.744 D_fake: 0.483 \n",
            "(epoch: 57, iters: 1400, time: 0.067, data: 0.003) G_GAN: 6.393 G_L1: 2.737 D_real: 0.079 D_fake: 0.004 \n",
            "(epoch: 57, iters: 1500, time: 0.066, data: 0.002) G_GAN: 2.345 G_L1: 1.517 D_real: 0.328 D_fake: 0.429 \n",
            "(epoch: 57, iters: 1600, time: 0.215, data: 0.003) G_GAN: 0.821 G_L1: 3.744 D_real: 0.522 D_fake: 0.840 \n",
            "(epoch: 57, iters: 1700, time: 0.067, data: 0.002) G_GAN: 5.283 G_L1: 1.878 D_real: 0.000 D_fake: 0.009 \n",
            "(epoch: 57, iters: 1800, time: 0.060, data: 0.003) G_GAN: 6.412 G_L1: 1.713 D_real: 0.000 D_fake: 0.002 \n",
            "(epoch: 57, iters: 1900, time: 0.065, data: 0.005) G_GAN: 3.158 G_L1: 1.192 D_real: 0.163 D_fake: 0.081 \n",
            "(epoch: 57, iters: 2000, time: 0.402, data: 0.003) G_GAN: 1.756 G_L1: 1.577 D_real: 0.379 D_fake: 0.248 \n",
            "(epoch: 57, iters: 2100, time: 0.064, data: 0.006) G_GAN: 6.770 G_L1: 1.392 D_real: 0.000 D_fake: 0.002 \n",
            "(epoch: 57, iters: 2200, time: 0.067, data: 0.003) G_GAN: 6.759 G_L1: 1.902 D_real: 0.000 D_fake: 0.002 \n",
            "(epoch: 57, iters: 2300, time: 0.065, data: 0.003) G_GAN: 2.308 G_L1: 1.408 D_real: 0.311 D_fake: 0.244 \n",
            "(epoch: 57, iters: 2400, time: 0.191, data: 0.004) G_GAN: 5.508 G_L1: 2.329 D_real: 0.053 D_fake: 0.007 \n",
            "(epoch: 57, iters: 2500, time: 0.065, data: 0.006) G_GAN: 6.001 G_L1: 2.287 D_real: 0.000 D_fake: 0.003 \n",
            "(epoch: 57, iters: 2600, time: 0.067, data: 0.004) G_GAN: 4.349 G_L1: 2.653 D_real: 0.036 D_fake: 0.023 \n",
            "(epoch: 57, iters: 2700, time: 0.067, data: 0.003) G_GAN: 6.140 G_L1: 1.548 D_real: 0.000 D_fake: 0.004 \n",
            "(epoch: 57, iters: 2800, time: 0.155, data: 0.003) G_GAN: 6.446 G_L1: 1.297 D_real: 0.000 D_fake: 0.003 \n",
            "(epoch: 57, iters: 2900, time: 0.065, data: 0.005) G_GAN: 6.735 G_L1: 1.132 D_real: 0.000 D_fake: 0.002 \n",
            "(epoch: 57, iters: 3000, time: 0.066, data: 0.005) G_GAN: 2.772 G_L1: 1.258 D_real: 0.064 D_fake: 1.095 \n",
            "(epoch: 57, iters: 3100, time: 0.064, data: 0.004) G_GAN: 0.912 G_L1: 2.586 D_real: 0.756 D_fake: 0.565 \n",
            "(epoch: 57, iters: 3200, time: 0.182, data: 0.005) G_GAN: 2.990 G_L1: 2.029 D_real: 0.096 D_fake: 0.083 \n",
            "(epoch: 57, iters: 3300, time: 0.067, data: 0.003) G_GAN: 1.580 G_L1: 2.290 D_real: 0.464 D_fake: 0.443 \n",
            "(epoch: 57, iters: 3400, time: 0.065, data: 0.004) G_GAN: 0.664 G_L1: 2.818 D_real: 0.539 D_fake: 1.110 \n",
            "(epoch: 57, iters: 3500, time: 0.067, data: 0.002) G_GAN: 2.392 G_L1: 2.251 D_real: 0.351 D_fake: 0.250 \n",
            "(epoch: 57, iters: 3600, time: 0.156, data: 0.002) G_GAN: 6.452 G_L1: 1.645 D_real: 0.000 D_fake: 0.002 \n",
            "(epoch: 57, iters: 3700, time: 0.065, data: 0.002) G_GAN: 6.079 G_L1: 1.372 D_real: 0.000 D_fake: 0.004 \n",
            "(epoch: 57, iters: 3800, time: 0.065, data: 0.003) G_GAN: 2.007 G_L1: 1.299 D_real: 0.222 D_fake: 0.359 \n",
            "(epoch: 57, iters: 3900, time: 0.067, data: 0.004) G_GAN: 6.038 G_L1: 1.232 D_real: 0.000 D_fake: 0.004 \n",
            "(epoch: 57, iters: 4000, time: 0.385, data: 0.005) G_GAN: 2.029 G_L1: 2.119 D_real: 0.121 D_fake: 0.355 \n",
            "End of epoch 57 / 200 \t Time Taken: 174 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "(epoch: 58, iters: 100, time: 0.066, data: 0.163) G_GAN: 2.981 G_L1: 2.157 D_real: 0.051 D_fake: 0.102 \n",
            "(epoch: 58, iters: 200, time: 0.067, data: 0.004) G_GAN: 5.593 G_L1: 1.348 D_real: 0.000 D_fake: 0.005 \n",
            "(epoch: 58, iters: 300, time: 0.067, data: 0.003) G_GAN: 1.569 G_L1: 2.036 D_real: 1.211 D_fake: 0.352 \n",
            "(epoch: 58, iters: 400, time: 0.565, data: 0.006) G_GAN: 7.368 G_L1: 3.680 D_real: 0.045 D_fake: 0.001 \n",
            "(epoch: 58, iters: 500, time: 0.066, data: 0.003) G_GAN: 2.008 G_L1: 4.686 D_real: 0.437 D_fake: 0.201 \n",
            "(epoch: 58, iters: 600, time: 0.067, data: 0.004) G_GAN: 0.837 G_L1: 2.659 D_real: 0.555 D_fake: 0.794 \n",
            "(epoch: 58, iters: 700, time: 0.067, data: 0.004) G_GAN: 6.457 G_L1: 1.555 D_real: 0.037 D_fake: 0.002 \n",
            "(epoch: 58, iters: 800, time: 0.164, data: 0.003) G_GAN: 2.135 G_L1: 1.049 D_real: 0.138 D_fake: 0.979 \n",
            "(epoch: 58, iters: 900, time: 0.066, data: 0.010) G_GAN: 5.683 G_L1: 1.150 D_real: 0.000 D_fake: 0.006 \n",
            "(epoch: 58, iters: 1000, time: 0.065, data: 0.002) G_GAN: 3.422 G_L1: 1.447 D_real: 0.036 D_fake: 0.118 \n",
            "(epoch: 58, iters: 1100, time: 0.066, data: 0.007) G_GAN: 3.000 G_L1: 1.847 D_real: 0.222 D_fake: 0.158 \n",
            "(epoch: 58, iters: 1200, time: 0.167, data: 0.004) G_GAN: 4.677 G_L1: 2.263 D_real: 0.191 D_fake: 0.014 \n",
            "(epoch: 58, iters: 1300, time: 0.066, data: 0.003) G_GAN: 7.101 G_L1: 2.123 D_real: 0.255 D_fake: 0.001 \n",
            "(epoch: 58, iters: 1400, time: 0.064, data: 0.005) G_GAN: 6.682 G_L1: 1.377 D_real: 0.000 D_fake: 0.002 \n",
            "(epoch: 58, iters: 1500, time: 0.066, data: 0.006) G_GAN: 0.901 G_L1: 2.710 D_real: 0.937 D_fake: 0.529 \n",
            "(epoch: 58, iters: 1600, time: 0.166, data: 0.004) G_GAN: 1.661 G_L1: 3.353 D_real: 0.594 D_fake: 1.278 \n",
            "(epoch: 58, iters: 1700, time: 0.066, data: 0.002) G_GAN: 3.216 G_L1: 1.270 D_real: 0.072 D_fake: 0.112 \n",
            "(epoch: 58, iters: 1800, time: 0.064, data: 0.003) G_GAN: 1.228 G_L1: 3.116 D_real: 0.343 D_fake: 0.423 \n",
            "(epoch: 58, iters: 1900, time: 0.059, data: 0.003) G_GAN: 0.970 G_L1: 2.256 D_real: 0.984 D_fake: 0.426 \n",
            "(epoch: 58, iters: 2000, time: 0.396, data: 0.003) G_GAN: 6.096 G_L1: 1.972 D_real: 0.000 D_fake: 0.003 \n",
            "saving the latest model (epoch 58, total_iters 230000)\n",
            "(epoch: 58, iters: 2100, time: 0.066, data: 0.002) G_GAN: 0.654 G_L1: 2.122 D_real: 0.487 D_fake: 1.111 \n",
            "(epoch: 58, iters: 2200, time: 0.066, data: 0.002) G_GAN: 3.154 G_L1: 3.467 D_real: 0.073 D_fake: 0.112 \n",
            "(epoch: 58, iters: 2300, time: 0.066, data: 0.004) G_GAN: 3.579 G_L1: 3.166 D_real: 1.190 D_fake: 1.495 \n",
            "(epoch: 58, iters: 2400, time: 0.177, data: 0.002) G_GAN: 6.976 G_L1: 1.488 D_real: 0.650 D_fake: 0.001 \n",
            "(epoch: 58, iters: 2500, time: 0.067, data: 0.002) G_GAN: 3.433 G_L1: 2.639 D_real: 0.224 D_fake: 0.080 \n",
            "(epoch: 58, iters: 2600, time: 0.066, data: 0.002) G_GAN: 5.538 G_L1: 1.553 D_real: 0.001 D_fake: 0.008 \n",
            "(epoch: 58, iters: 2700, time: 0.062, data: 0.002) G_GAN: 5.979 G_L1: 1.433 D_real: 0.004 D_fake: 0.003 \n",
            "(epoch: 58, iters: 2800, time: 0.156, data: 0.004) G_GAN: 6.146 G_L1: 1.494 D_real: 0.000 D_fake: 0.004 \n",
            "(epoch: 58, iters: 2900, time: 0.066, data: 0.016) G_GAN: 3.590 G_L1: 1.194 D_real: 0.345 D_fake: 0.046 \n",
            "(epoch: 58, iters: 3000, time: 0.067, data: 0.003) G_GAN: 0.854 G_L1: 2.065 D_real: 1.049 D_fake: 0.374 \n",
            "(epoch: 58, iters: 3100, time: 0.066, data: 0.002) G_GAN: 3.523 G_L1: 2.054 D_real: 0.106 D_fake: 0.045 \n",
            "(epoch: 58, iters: 3200, time: 0.192, data: 0.002) G_GAN: 3.477 G_L1: 1.368 D_real: 0.007 D_fake: 0.406 \n",
            "(epoch: 58, iters: 3300, time: 0.064, data: 0.002) G_GAN: 6.361 G_L1: 1.266 D_real: 0.000 D_fake: 0.002 \n",
            "(epoch: 58, iters: 3400, time: 0.066, data: 0.003) G_GAN: 0.918 G_L1: 2.516 D_real: 0.654 D_fake: 0.584 \n",
            "(epoch: 58, iters: 3500, time: 0.066, data: 0.002) G_GAN: 4.229 G_L1: 2.422 D_real: 0.533 D_fake: 0.022 \n",
            "(epoch: 58, iters: 3600, time: 0.189, data: 0.002) G_GAN: 2.447 G_L1: 2.448 D_real: 0.198 D_fake: 0.336 \n",
            "(epoch: 58, iters: 3700, time: 0.066, data: 0.002) G_GAN: 2.101 G_L1: 3.299 D_real: 0.889 D_fake: 0.051 \n",
            "(epoch: 58, iters: 3800, time: 0.066, data: 0.004) G_GAN: 0.965 G_L1: 2.012 D_real: 0.627 D_fake: 0.659 \n",
            "(epoch: 58, iters: 3900, time: 0.066, data: 0.003) G_GAN: 6.099 G_L1: 1.629 D_real: 0.000 D_fake: 0.004 \n",
            "(epoch: 58, iters: 4000, time: 0.398, data: 0.003) G_GAN: 5.537 G_L1: 1.780 D_real: 0.000 D_fake: 0.006 \n",
            "End of epoch 58 / 200 \t Time Taken: 174 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "(epoch: 59, iters: 100, time: 0.066, data: 0.188) G_GAN: 1.174 G_L1: 1.605 D_real: 0.615 D_fake: 0.458 \n",
            "(epoch: 59, iters: 200, time: 0.067, data: 0.005) G_GAN: 4.145 G_L1: 2.039 D_real: 1.734 D_fake: 0.129 \n",
            "(epoch: 59, iters: 300, time: 0.066, data: 0.003) G_GAN: 4.163 G_L1: 3.997 D_real: 0.633 D_fake: 0.014 \n",
            "(epoch: 59, iters: 400, time: 0.494, data: 0.003) G_GAN: 5.172 G_L1: 1.498 D_real: 0.000 D_fake: 0.014 \n",
            "(epoch: 59, iters: 500, time: 0.066, data: 0.003) G_GAN: 5.936 G_L1: 1.123 D_real: 0.000 D_fake: 0.004 \n",
            "(epoch: 59, iters: 600, time: 0.067, data: 0.004) G_GAN: 5.071 G_L1: 1.993 D_real: 0.000 D_fake: 0.009 \n",
            "(epoch: 59, iters: 700, time: 0.066, data: 0.003) G_GAN: 0.711 G_L1: 3.110 D_real: 0.650 D_fake: 0.804 \n",
            "(epoch: 59, iters: 800, time: 0.172, data: 0.003) G_GAN: 5.710 G_L1: 1.868 D_real: 0.000 D_fake: 0.004 \n",
            "(epoch: 59, iters: 900, time: 0.066, data: 0.006) G_GAN: 0.928 G_L1: 1.944 D_real: 0.770 D_fake: 0.553 \n",
            "(epoch: 59, iters: 1000, time: 0.062, data: 0.003) G_GAN: 1.977 G_L1: 1.550 D_real: 0.076 D_fake: 0.588 \n",
            "(epoch: 59, iters: 1100, time: 0.066, data: 0.003) G_GAN: 9.225 G_L1: 1.772 D_real: 0.105 D_fake: 0.000 \n",
            "(epoch: 59, iters: 1200, time: 0.157, data: 0.002) G_GAN: 7.040 G_L1: 1.078 D_real: 0.000 D_fake: 0.001 \n",
            "(epoch: 59, iters: 1300, time: 0.066, data: 0.002) G_GAN: 6.269 G_L1: 1.128 D_real: 0.000 D_fake: 0.003 \n",
            "(epoch: 59, iters: 1400, time: 0.065, data: 0.002) G_GAN: 3.077 G_L1: 1.952 D_real: 0.129 D_fake: 0.058 \n",
            "(epoch: 59, iters: 1500, time: 0.066, data: 0.004) G_GAN: 0.781 G_L1: 5.080 D_real: 1.269 D_fake: 0.323 \n",
            "(epoch: 59, iters: 1600, time: 0.218, data: 0.004) G_GAN: 0.521 G_L1: 2.626 D_real: 0.287 D_fake: 1.341 \n",
            "(epoch: 59, iters: 1700, time: 0.066, data: 0.002) G_GAN: 5.898 G_L1: 1.533 D_real: 0.000 D_fake: 0.005 \n",
            "(epoch: 59, iters: 1800, time: 0.066, data: 0.003) G_GAN: 6.724 G_L1: 0.943 D_real: 0.001 D_fake: 0.002 \n",
            "(epoch: 59, iters: 1900, time: 0.066, data: 0.002) G_GAN: 2.682 G_L1: 2.280 D_real: 0.157 D_fake: 0.102 \n",
            "(epoch: 59, iters: 2000, time: 0.411, data: 0.003) G_GAN: 3.546 G_L1: 1.862 D_real: 0.163 D_fake: 1.006 \n",
            "(epoch: 59, iters: 2100, time: 0.066, data: 0.005) G_GAN: 3.820 G_L1: 1.067 D_real: 0.025 D_fake: 0.033 \n",
            "(epoch: 59, iters: 2200, time: 0.066, data: 0.002) G_GAN: 6.692 G_L1: 1.164 D_real: 0.002 D_fake: 0.002 \n",
            "(epoch: 59, iters: 2300, time: 0.064, data: 0.003) G_GAN: 4.891 G_L1: 1.356 D_real: 0.019 D_fake: 0.013 \n",
            "(epoch: 59, iters: 2400, time: 0.181, data: 0.004) G_GAN: 4.740 G_L1: 3.181 D_real: 0.173 D_fake: 0.010 \n",
            "(epoch: 59, iters: 2500, time: 0.062, data: 0.010) G_GAN: 3.606 G_L1: 5.619 D_real: 0.407 D_fake: 0.029 \n",
            "(epoch: 59, iters: 2600, time: 0.066, data: 0.003) G_GAN: 6.174 G_L1: 1.186 D_real: 0.000 D_fake: 0.003 \n",
            "(epoch: 59, iters: 2700, time: 0.067, data: 0.004) G_GAN: 5.024 G_L1: 0.989 D_real: 0.000 D_fake: 0.012 \n",
            "(epoch: 59, iters: 2800, time: 0.297, data: 0.003) G_GAN: 2.885 G_L1: 2.555 D_real: 0.067 D_fake: 0.102 \n",
            "(epoch: 59, iters: 2900, time: 0.064, data: 0.002) G_GAN: 2.922 G_L1: 2.764 D_real: 0.227 D_fake: 0.352 \n",
            "(epoch: 59, iters: 3000, time: 0.066, data: 0.006) G_GAN: 0.663 G_L1: 1.985 D_real: 0.633 D_fake: 0.818 \n",
            "saving the latest model (epoch 59, total_iters 235000)\n",
            "(epoch: 59, iters: 3100, time: 0.066, data: 0.002) G_GAN: 6.881 G_L1: 1.226 D_real: 0.000 D_fake: 0.002 \n",
            "(epoch: 59, iters: 3200, time: 0.179, data: 0.002) G_GAN: 2.300 G_L1: 2.350 D_real: 0.103 D_fake: 0.259 \n",
            "(epoch: 59, iters: 3300, time: 0.066, data: 0.004) G_GAN: 2.916 G_L1: 2.487 D_real: 0.094 D_fake: 0.157 \n",
            "(epoch: 59, iters: 3400, time: 0.066, data: 0.003) G_GAN: 2.194 G_L1: 1.373 D_real: 0.053 D_fake: 0.634 \n",
            "(epoch: 59, iters: 3500, time: 0.067, data: 0.002) G_GAN: 5.488 G_L1: 1.682 D_real: 0.000 D_fake: 0.007 \n",
            "(epoch: 59, iters: 3600, time: 0.165, data: 0.005) G_GAN: 1.714 G_L1: 4.876 D_real: 0.407 D_fake: 0.704 \n",
            "(epoch: 59, iters: 3700, time: 0.067, data: 0.007) G_GAN: 0.762 G_L1: 3.609 D_real: 0.874 D_fake: 0.635 \n",
            "(epoch: 59, iters: 3800, time: 0.066, data: 0.003) G_GAN: 3.218 G_L1: 2.079 D_real: 0.048 D_fake: 0.135 \n",
            "(epoch: 59, iters: 3900, time: 0.066, data: 0.005) G_GAN: 6.821 G_L1: 3.031 D_real: 0.021 D_fake: 0.001 \n",
            "(epoch: 59, iters: 4000, time: 0.415, data: 0.003) G_GAN: 3.286 G_L1: 0.894 D_real: 0.044 D_fake: 0.566 \n",
            "End of epoch 59 / 200 \t Time Taken: 174 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "(epoch: 60, iters: 100, time: 0.066, data: 0.208) G_GAN: 2.944 G_L1: 1.445 D_real: 0.922 D_fake: 0.535 \n",
            "(epoch: 60, iters: 200, time: 0.066, data: 0.004) G_GAN: 3.388 G_L1: 1.679 D_real: 0.379 D_fake: 0.104 \n",
            "(epoch: 60, iters: 300, time: 0.067, data: 0.007) G_GAN: 6.006 G_L1: 1.543 D_real: 0.000 D_fake: 0.005 \n",
            "(epoch: 60, iters: 400, time: 0.808, data: 0.003) G_GAN: 0.683 G_L1: 3.115 D_real: 0.671 D_fake: 0.802 \n",
            "(epoch: 60, iters: 500, time: 0.066, data: 0.005) G_GAN: 0.797 G_L1: 1.865 D_real: 1.052 D_fake: 0.414 \n",
            "(epoch: 60, iters: 600, time: 0.067, data: 0.002) G_GAN: 2.283 G_L1: 2.235 D_real: 0.204 D_fake: 0.294 \n",
            "(epoch: 60, iters: 700, time: 0.065, data: 0.006) G_GAN: 1.788 G_L1: 1.875 D_real: 0.768 D_fake: 0.140 \n",
            "(epoch: 60, iters: 800, time: 0.172, data: 0.007) G_GAN: 2.640 G_L1: 1.922 D_real: 0.097 D_fake: 0.317 \n",
            "(epoch: 60, iters: 900, time: 0.066, data: 0.002) G_GAN: 0.538 G_L1: 1.940 D_real: 1.150 D_fake: 0.284 \n",
            "(epoch: 60, iters: 1000, time: 0.066, data: 0.003) G_GAN: 2.104 G_L1: 2.698 D_real: 0.162 D_fake: 1.062 \n",
            "(epoch: 60, iters: 1100, time: 0.066, data: 0.005) G_GAN: 0.957 G_L1: 2.632 D_real: 0.809 D_fake: 0.487 \n",
            "(epoch: 60, iters: 1200, time: 0.216, data: 0.002) G_GAN: 0.691 G_L1: 3.122 D_real: 0.520 D_fake: 0.885 \n",
            "(epoch: 60, iters: 1300, time: 0.066, data: 0.002) G_GAN: 6.513 G_L1: 1.330 D_real: 0.000 D_fake: 0.003 \n",
            "(epoch: 60, iters: 1400, time: 0.066, data: 0.003) G_GAN: 1.519 G_L1: 2.749 D_real: 0.173 D_fake: 1.143 \n",
            "(epoch: 60, iters: 1500, time: 0.065, data: 0.002) G_GAN: 2.332 G_L1: 4.960 D_real: 0.106 D_fake: 0.335 \n",
            "(epoch: 60, iters: 1600, time: 0.175, data: 0.002) G_GAN: 2.547 G_L1: 1.621 D_real: 0.011 D_fake: 0.496 \n",
            "(epoch: 60, iters: 1700, time: 0.059, data: 0.009) G_GAN: 0.709 G_L1: 2.099 D_real: 0.638 D_fake: 1.042 \n",
            "(epoch: 60, iters: 1800, time: 0.067, data: 0.005) G_GAN: 6.400 G_L1: 1.023 D_real: 0.000 D_fake: 0.002 \n",
            "(epoch: 60, iters: 1900, time: 0.062, data: 0.004) G_GAN: 1.360 G_L1: 2.223 D_real: 0.516 D_fake: 0.708 \n",
            "(epoch: 60, iters: 2000, time: 0.405, data: 0.003) G_GAN: 2.274 G_L1: 1.541 D_real: 0.070 D_fake: 0.391 \n",
            "(epoch: 60, iters: 2100, time: 0.055, data: 0.004) G_GAN: 4.696 G_L1: 1.216 D_real: 1.036 D_fake: 0.002 \n",
            "(epoch: 60, iters: 2200, time: 0.067, data: 0.003) G_GAN: 2.842 G_L1: 2.637 D_real: 0.030 D_fake: 1.293 \n",
            "(epoch: 60, iters: 2300, time: 0.066, data: 0.004) G_GAN: 6.331 G_L1: 1.487 D_real: 0.001 D_fake: 0.003 \n",
            "(epoch: 60, iters: 2400, time: 0.160, data: 0.003) G_GAN: 6.851 G_L1: 1.305 D_real: 0.000 D_fake: 0.002 \n",
            "(epoch: 60, iters: 2500, time: 0.066, data: 0.003) G_GAN: 2.911 G_L1: 4.187 D_real: 0.175 D_fake: 0.059 \n",
            "(epoch: 60, iters: 2600, time: 0.066, data: 0.003) G_GAN: 1.688 G_L1: 2.407 D_real: 0.372 D_fake: 0.088 \n",
            "(epoch: 60, iters: 2700, time: 0.066, data: 0.003) G_GAN: 6.369 G_L1: 2.030 D_real: 0.210 D_fake: 0.003 \n",
            "(epoch: 60, iters: 2800, time: 0.167, data: 0.003) G_GAN: 5.384 G_L1: 1.604 D_real: 0.002 D_fake: 0.006 \n",
            "(epoch: 60, iters: 2900, time: 0.066, data: 0.002) G_GAN: 7.207 G_L1: 1.283 D_real: 0.000 D_fake: 0.001 \n",
            "(epoch: 60, iters: 3000, time: 0.066, data: 0.003) G_GAN: 1.021 G_L1: 1.868 D_real: 0.383 D_fake: 0.906 \n",
            "(epoch: 60, iters: 3100, time: 0.064, data: 0.003) G_GAN: 4.914 G_L1: 1.029 D_real: 0.002 D_fake: 0.012 \n",
            "(epoch: 60, iters: 3200, time: 0.187, data: 0.003) G_GAN: 4.914 G_L1: 3.928 D_real: 0.061 D_fake: 0.009 \n",
            "(epoch: 60, iters: 3300, time: 0.067, data: 0.010) G_GAN: 1.087 G_L1: 2.612 D_real: 0.434 D_fake: 0.613 \n",
            "(epoch: 60, iters: 3400, time: 0.065, data: 0.004) G_GAN: 1.562 G_L1: 2.333 D_real: 0.795 D_fake: 0.526 \n",
            "(epoch: 60, iters: 3500, time: 0.061, data: 0.004) G_GAN: 0.933 G_L1: 1.644 D_real: 1.331 D_fake: 0.223 \n",
            "(epoch: 60, iters: 3600, time: 0.171, data: 0.003) G_GAN: 5.316 G_L1: 0.727 D_real: 0.001 D_fake: 0.009 \n",
            "(epoch: 60, iters: 3700, time: 0.066, data: 0.006) G_GAN: 0.800 G_L1: 3.770 D_real: 0.901 D_fake: 0.548 \n",
            "(epoch: 60, iters: 3800, time: 0.066, data: 0.003) G_GAN: 1.523 G_L1: 2.152 D_real: 0.246 D_fake: 1.047 \n",
            "(epoch: 60, iters: 3900, time: 0.066, data: 0.003) G_GAN: 0.673 G_L1: 2.132 D_real: 0.650 D_fake: 0.817 \n",
            "(epoch: 60, iters: 4000, time: 0.413, data: 0.006) G_GAN: 4.844 G_L1: 1.738 D_real: 0.067 D_fake: 0.014 \n",
            "saving the latest model (epoch 60, total_iters 240000)\n",
            "saving the model at the end of epoch 60, iters 240000\n",
            "End of epoch 60 / 200 \t Time Taken: 175 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "(epoch: 61, iters: 100, time: 0.066, data: 0.177) G_GAN: 0.872 G_L1: 2.789 D_real: 0.803 D_fake: 0.537 \n",
            "(epoch: 61, iters: 200, time: 0.067, data: 0.003) G_GAN: 0.773 G_L1: 2.588 D_real: 0.982 D_fake: 0.757 \n",
            "(epoch: 61, iters: 300, time: 0.066, data: 0.003) G_GAN: 0.795 G_L1: 3.090 D_real: 0.675 D_fake: 0.675 \n",
            "(epoch: 61, iters: 400, time: 0.585, data: 0.002) G_GAN: 5.640 G_L1: 1.742 D_real: 0.000 D_fake: 0.006 \n",
            "(epoch: 61, iters: 500, time: 0.066, data: 0.003) G_GAN: 5.556 G_L1: 1.724 D_real: 0.046 D_fake: 0.006 \n",
            "(epoch: 61, iters: 600, time: 0.065, data: 0.004) G_GAN: 3.507 G_L1: 2.010 D_real: 0.164 D_fake: 0.132 \n",
            "(epoch: 61, iters: 700, time: 0.065, data: 0.002) G_GAN: 3.365 G_L1: 1.490 D_real: 0.469 D_fake: 1.102 \n",
            "(epoch: 61, iters: 800, time: 0.273, data: 0.004) G_GAN: 6.974 G_L1: 1.419 D_real: 0.001 D_fake: 0.002 \n",
            "(epoch: 61, iters: 900, time: 0.066, data: 0.003) G_GAN: 0.804 G_L1: 5.303 D_real: 0.569 D_fake: 0.866 \n",
            "(epoch: 61, iters: 1000, time: 0.065, data: 0.003) G_GAN: 5.188 G_L1: 1.514 D_real: 0.001 D_fake: 0.015 \n",
            "(epoch: 61, iters: 1100, time: 0.067, data: 0.004) G_GAN: 3.803 G_L1: 2.220 D_real: 0.451 D_fake: 0.088 \n",
            "(epoch: 61, iters: 1200, time: 0.223, data: 0.003) G_GAN: 1.166 G_L1: 2.758 D_real: 0.947 D_fake: 0.421 \n",
            "(epoch: 61, iters: 1300, time: 0.066, data: 0.003) G_GAN: 2.168 G_L1: 2.049 D_real: 0.542 D_fake: 0.173 \n",
            "(epoch: 61, iters: 1400, time: 0.067, data: 0.004) G_GAN: 0.700 G_L1: 3.591 D_real: 1.452 D_fake: 0.353 \n",
            "(epoch: 61, iters: 1500, time: 0.067, data: 0.002) G_GAN: 1.078 G_L1: 4.383 D_real: 0.788 D_fake: 0.453 \n",
            "(epoch: 61, iters: 1600, time: 0.168, data: 0.002) G_GAN: 6.297 G_L1: 1.460 D_real: 0.000 D_fake: 0.003 \n",
            "(epoch: 61, iters: 1700, time: 0.064, data: 0.002) G_GAN: 2.020 G_L1: 3.626 D_real: 0.276 D_fake: 0.817 \n",
            "(epoch: 61, iters: 1800, time: 0.067, data: 0.003) G_GAN: 2.302 G_L1: 2.421 D_real: 0.081 D_fake: 0.189 \n",
            "(epoch: 61, iters: 1900, time: 0.066, data: 0.003) G_GAN: 5.211 G_L1: 0.999 D_real: 0.001 D_fake: 0.014 \n",
            "(epoch: 61, iters: 2000, time: 0.393, data: 0.002) G_GAN: 2.437 G_L1: 2.739 D_real: 0.559 D_fake: 0.288 \n",
            "(epoch: 61, iters: 2100, time: 0.067, data: 0.002) G_GAN: 4.058 G_L1: 1.160 D_real: 0.001 D_fake: 0.047 \n",
            "(epoch: 61, iters: 2200, time: 0.066, data: 0.003) G_GAN: 2.969 G_L1: 1.796 D_real: 0.127 D_fake: 0.197 \n",
            "(epoch: 61, iters: 2300, time: 0.066, data: 0.002) G_GAN: 2.632 G_L1: 2.176 D_real: 0.086 D_fake: 0.251 \n",
            "(epoch: 61, iters: 2400, time: 0.158, data: 0.002) G_GAN: 6.874 G_L1: 1.218 D_real: 0.001 D_fake: 0.001 \n",
            "(epoch: 61, iters: 2500, time: 0.066, data: 0.003) G_GAN: 0.858 G_L1: 4.492 D_real: 0.716 D_fake: 0.575 \n",
            "(epoch: 61, iters: 2600, time: 0.066, data: 0.004) G_GAN: 0.854 G_L1: 1.902 D_real: 0.810 D_fake: 0.572 \n",
            "(epoch: 61, iters: 2700, time: 0.067, data: 0.004) G_GAN: 4.335 G_L1: 2.081 D_real: 0.048 D_fake: 0.239 \n",
            "(epoch: 61, iters: 2800, time: 0.226, data: 0.004) G_GAN: 0.735 G_L1: 2.597 D_real: 0.644 D_fake: 0.792 \n",
            "(epoch: 61, iters: 2900, time: 0.066, data: 0.007) G_GAN: 5.945 G_L1: 1.697 D_real: 0.000 D_fake: 0.004 \n",
            "(epoch: 61, iters: 3000, time: 0.066, data: 0.002) G_GAN: 0.859 G_L1: 5.418 D_real: 0.869 D_fake: 0.561 \n",
            "(epoch: 61, iters: 3100, time: 0.067, data: 0.003) G_GAN: 1.424 G_L1: 2.036 D_real: 0.267 D_fake: 0.649 \n",
            "(epoch: 61, iters: 3200, time: 0.177, data: 0.004) G_GAN: 3.044 G_L1: 3.320 D_real: 0.024 D_fake: 0.551 \n",
            "(epoch: 61, iters: 3300, time: 0.065, data: 0.003) G_GAN: 0.761 G_L1: 2.944 D_real: 0.519 D_fake: 0.889 \n",
            "(epoch: 61, iters: 3400, time: 0.066, data: 0.002) G_GAN: 5.761 G_L1: 2.522 D_real: 0.233 D_fake: 0.003 \n",
            "(epoch: 61, iters: 3500, time: 0.065, data: 0.003) G_GAN: 5.927 G_L1: 2.001 D_real: 0.013 D_fake: 0.004 \n",
            "(epoch: 61, iters: 3600, time: 0.190, data: 0.003) G_GAN: 4.530 G_L1: 2.866 D_real: 0.124 D_fake: 0.014 \n",
            "(epoch: 61, iters: 3700, time: 0.066, data: 0.002) G_GAN: 1.794 G_L1: 1.733 D_real: 0.116 D_fake: 1.271 \n",
            "(epoch: 61, iters: 3800, time: 0.066, data: 0.004) G_GAN: 6.445 G_L1: 1.234 D_real: 0.000 D_fake: 0.003 \n",
            "(epoch: 61, iters: 3900, time: 0.061, data: 0.003) G_GAN: 2.221 G_L1: 3.485 D_real: 0.991 D_fake: 0.137 \n",
            "(epoch: 61, iters: 4000, time: 0.474, data: 0.004) G_GAN: 0.799 G_L1: 4.310 D_real: 0.515 D_fake: 0.788 \n",
            "End of epoch 61 / 200 \t Time Taken: 173 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "(epoch: 62, iters: 100, time: 0.065, data: 0.233) G_GAN: 0.868 G_L1: 2.691 D_real: 0.555 D_fake: 0.693 \n",
            "(epoch: 62, iters: 200, time: 0.065, data: 0.004) G_GAN: 6.404 G_L1: 1.559 D_real: 0.005 D_fake: 0.003 \n",
            "(epoch: 62, iters: 300, time: 0.062, data: 0.003) G_GAN: 2.773 G_L1: 1.917 D_real: 0.073 D_fake: 0.257 \n",
            "(epoch: 62, iters: 400, time: 0.605, data: 0.003) G_GAN: 1.230 G_L1: 2.132 D_real: 0.275 D_fake: 0.784 \n",
            "(epoch: 62, iters: 500, time: 0.066, data: 0.003) G_GAN: 3.080 G_L1: 4.150 D_real: 0.202 D_fake: 0.275 \n",
            "(epoch: 62, iters: 600, time: 0.066, data: 0.003) G_GAN: 0.831 G_L1: 2.064 D_real: 0.655 D_fake: 0.784 \n",
            "(epoch: 62, iters: 700, time: 0.066, data: 0.004) G_GAN: 2.078 G_L1: 1.645 D_real: 0.428 D_fake: 0.282 \n",
            "(epoch: 62, iters: 800, time: 0.220, data: 0.004) G_GAN: 0.735 G_L1: 3.432 D_real: 1.133 D_fake: 0.581 \n",
            "(epoch: 62, iters: 900, time: 0.065, data: 0.014) G_GAN: 7.331 G_L1: 1.371 D_real: 0.000 D_fake: 0.001 \n",
            "(epoch: 62, iters: 1000, time: 0.063, data: 0.005) G_GAN: 6.837 G_L1: 0.894 D_real: 0.004 D_fake: 0.003 \n",
            "saving the latest model (epoch 62, total_iters 245000)\n",
            "(epoch: 62, iters: 1100, time: 0.067, data: 0.005) G_GAN: 0.853 G_L1: 2.296 D_real: 0.870 D_fake: 0.547 \n",
            "(epoch: 62, iters: 1200, time: 0.169, data: 0.003) G_GAN: 5.490 G_L1: 3.379 D_real: 1.927 D_fake: 0.002 \n",
            "(epoch: 62, iters: 1300, time: 0.058, data: 0.003) G_GAN: 0.920 G_L1: 1.925 D_real: 0.688 D_fake: 0.646 \n",
            "(epoch: 62, iters: 1400, time: 0.066, data: 0.004) G_GAN: 4.473 G_L1: 1.503 D_real: 0.075 D_fake: 0.021 \n",
            "(epoch: 62, iters: 1500, time: 0.065, data: 0.002) G_GAN: 4.983 G_L1: 1.369 D_real: 0.001 D_fake: 0.013 \n",
            "(epoch: 62, iters: 1600, time: 0.159, data: 0.002) G_GAN: 6.164 G_L1: 1.556 D_real: 0.001 D_fake: 0.003 \n",
            "(epoch: 62, iters: 1700, time: 0.067, data: 0.002) G_GAN: 2.799 G_L1: 2.291 D_real: 0.208 D_fake: 0.216 \n",
            "(epoch: 62, iters: 1800, time: 0.055, data: 0.002) G_GAN: 1.027 G_L1: 3.190 D_real: 0.782 D_fake: 0.432 \n",
            "(epoch: 62, iters: 1900, time: 0.066, data: 0.003) G_GAN: 2.415 G_L1: 1.956 D_real: 0.015 D_fake: 0.270 \n",
            "(epoch: 62, iters: 2000, time: 0.429, data: 0.004) G_GAN: 1.229 G_L1: 1.384 D_real: 2.338 D_fake: 0.288 \n",
            "(epoch: 62, iters: 2100, time: 0.067, data: 0.002) G_GAN: 2.663 G_L1: 2.559 D_real: 0.066 D_fake: 0.560 \n",
            "(epoch: 62, iters: 2200, time: 0.066, data: 0.002) G_GAN: 0.930 G_L1: 2.282 D_real: 0.592 D_fake: 1.407 \n",
            "(epoch: 62, iters: 2300, time: 0.066, data: 0.002) G_GAN: 1.557 G_L1: 1.092 D_real: 0.100 D_fake: 1.346 \n",
            "(epoch: 62, iters: 2400, time: 0.168, data: 0.003) G_GAN: 1.169 G_L1: 1.292 D_real: 0.314 D_fake: 1.493 \n",
            "(epoch: 62, iters: 2500, time: 0.066, data: 0.002) G_GAN: 7.874 G_L1: 1.722 D_real: 0.009 D_fake: 0.001 \n",
            "(epoch: 62, iters: 2600, time: 0.065, data: 0.002) G_GAN: 4.952 G_L1: 1.679 D_real: 0.050 D_fake: 0.011 \n",
            "(epoch: 62, iters: 2700, time: 0.062, data: 0.002) G_GAN: 6.113 G_L1: 1.679 D_real: 0.000 D_fake: 0.004 \n",
            "(epoch: 62, iters: 2800, time: 0.153, data: 0.003) G_GAN: 6.863 G_L1: 1.222 D_real: 0.000 D_fake: 0.002 \n",
            "(epoch: 62, iters: 2900, time: 0.066, data: 0.010) G_GAN: 1.217 G_L1: 1.937 D_real: 0.493 D_fake: 0.665 \n",
            "(epoch: 62, iters: 3000, time: 0.067, data: 0.003) G_GAN: 2.267 G_L1: 1.702 D_real: 0.090 D_fake: 0.974 \n",
            "(epoch: 62, iters: 3100, time: 0.066, data: 0.002) G_GAN: 9.207 G_L1: 1.562 D_real: 0.000 D_fake: 0.000 \n",
            "(epoch: 62, iters: 3200, time: 0.175, data: 0.003) G_GAN: 1.352 G_L1: 3.932 D_real: 0.724 D_fake: 0.569 \n",
            "(epoch: 62, iters: 3300, time: 0.067, data: 0.002) G_GAN: 2.667 G_L1: 2.310 D_real: 0.732 D_fake: 1.809 \n",
            "(epoch: 62, iters: 3400, time: 0.066, data: 0.003) G_GAN: 1.771 G_L1: 2.106 D_real: 0.363 D_fake: 1.099 \n",
            "(epoch: 62, iters: 3500, time: 0.066, data: 0.003) G_GAN: 1.816 G_L1: 3.242 D_real: 0.956 D_fake: 0.006 \n",
            "(epoch: 62, iters: 3600, time: 0.177, data: 0.002) G_GAN: 8.733 G_L1: 1.200 D_real: 0.001 D_fake: 0.000 \n",
            "(epoch: 62, iters: 3700, time: 0.067, data: 0.003) G_GAN: 6.091 G_L1: 1.762 D_real: 0.000 D_fake: 0.004 \n",
            "(epoch: 62, iters: 3800, time: 0.066, data: 0.003) G_GAN: 4.418 G_L1: 2.508 D_real: 0.416 D_fake: 0.012 \n",
            "(epoch: 62, iters: 3900, time: 0.066, data: 0.004) G_GAN: 3.593 G_L1: 1.670 D_real: 0.212 D_fake: 0.029 \n",
            "(epoch: 62, iters: 4000, time: 0.482, data: 0.002) G_GAN: 1.065 G_L1: 1.843 D_real: 1.058 D_fake: 0.268 \n",
            "End of epoch 62 / 200 \t Time Taken: 174 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "(epoch: 63, iters: 100, time: 0.066, data: 0.201) G_GAN: 6.531 G_L1: 1.479 D_real: 0.000 D_fake: 0.002 \n",
            "(epoch: 63, iters: 200, time: 0.066, data: 0.003) G_GAN: 1.641 G_L1: 3.956 D_real: 0.782 D_fake: 0.227 \n",
            "(epoch: 63, iters: 300, time: 0.065, data: 0.004) G_GAN: 0.733 G_L1: 4.125 D_real: 0.639 D_fake: 0.754 \n",
            "(epoch: 63, iters: 400, time: 0.613, data: 0.003) G_GAN: 3.992 G_L1: 1.371 D_real: 0.001 D_fake: 0.065 \n",
            "(epoch: 63, iters: 500, time: 0.067, data: 0.006) G_GAN: 0.754 G_L1: 2.900 D_real: 0.935 D_fake: 0.707 \n",
            "(epoch: 63, iters: 600, time: 0.064, data: 0.003) G_GAN: 7.260 G_L1: 1.293 D_real: 0.000 D_fake: 0.001 \n",
            "(epoch: 63, iters: 700, time: 0.066, data: 0.004) G_GAN: 6.672 G_L1: 1.921 D_real: 0.000 D_fake: 0.002 \n",
            "(epoch: 63, iters: 800, time: 0.220, data: 0.002) G_GAN: 0.952 G_L1: 3.920 D_real: 0.896 D_fake: 0.581 \n",
            "(epoch: 63, iters: 900, time: 0.067, data: 0.002) G_GAN: 0.932 G_L1: 1.857 D_real: 0.355 D_fake: 0.981 \n",
            "(epoch: 63, iters: 1000, time: 0.066, data: 0.005) G_GAN: 5.697 G_L1: 1.555 D_real: 0.001 D_fake: 0.006 \n",
            "(epoch: 63, iters: 1100, time: 0.066, data: 0.004) G_GAN: 6.257 G_L1: 1.669 D_real: 0.000 D_fake: 0.003 \n",
            "(epoch: 63, iters: 1200, time: 0.214, data: 0.002) G_GAN: 1.085 G_L1: 3.814 D_real: 0.981 D_fake: 0.468 \n",
            "(epoch: 63, iters: 1300, time: 0.066, data: 0.004) G_GAN: 3.304 G_L1: 1.713 D_real: 0.122 D_fake: 0.082 \n",
            "(epoch: 63, iters: 1400, time: 0.067, data: 0.004) G_GAN: 0.935 G_L1: 1.821 D_real: 0.506 D_fake: 0.701 \n",
            "(epoch: 63, iters: 1500, time: 0.064, data: 0.002) G_GAN: 2.043 G_L1: 3.324 D_real: 1.203 D_fake: 0.100 \n",
            "(epoch: 63, iters: 1600, time: 0.220, data: 0.002) G_GAN: 0.868 G_L1: 2.307 D_real: 0.980 D_fake: 0.503 \n",
            "(epoch: 63, iters: 1700, time: 0.064, data: 0.007) G_GAN: 0.664 G_L1: 3.372 D_real: 0.285 D_fake: 1.170 \n",
            "(epoch: 63, iters: 1800, time: 0.065, data: 0.002) G_GAN: 4.749 G_L1: 3.147 D_real: 0.053 D_fake: 0.015 \n",
            "(epoch: 63, iters: 1900, time: 0.067, data: 0.002) G_GAN: 1.331 G_L1: 1.930 D_real: 0.309 D_fake: 0.888 \n",
            "(epoch: 63, iters: 2000, time: 0.404, data: 0.004) G_GAN: 5.429 G_L1: 2.479 D_real: 0.115 D_fake: 0.012 \n",
            "saving the latest model (epoch 63, total_iters 250000)\n",
            "(epoch: 63, iters: 2100, time: 0.067, data: 0.002) G_GAN: 0.875 G_L1: 1.436 D_real: 0.358 D_fake: 0.983 \n",
            "(epoch: 63, iters: 2200, time: 0.066, data: 0.004) G_GAN: 5.741 G_L1: 2.598 D_real: 0.050 D_fake: 0.005 \n",
            "(epoch: 63, iters: 2300, time: 0.062, data: 0.003) G_GAN: 6.633 G_L1: 1.445 D_real: 0.000 D_fake: 0.002 \n",
            "(epoch: 63, iters: 2400, time: 0.170, data: 0.003) G_GAN: 4.598 G_L1: 1.671 D_real: 0.188 D_fake: 0.012 \n",
            "(epoch: 63, iters: 2500, time: 0.065, data: 0.003) G_GAN: 0.869 G_L1: 3.247 D_real: 0.867 D_fake: 0.536 \n",
            "(epoch: 63, iters: 2600, time: 0.066, data: 0.004) G_GAN: 1.443 G_L1: 2.744 D_real: 0.552 D_fake: 0.179 \n",
            "(epoch: 63, iters: 2700, time: 0.066, data: 0.006) G_GAN: 1.653 G_L1: 1.764 D_real: 1.055 D_fake: 0.268 \n",
            "(epoch: 63, iters: 2800, time: 0.220, data: 0.003) G_GAN: 0.841 G_L1: 1.821 D_real: 0.573 D_fake: 0.793 \n",
            "(epoch: 63, iters: 2900, time: 0.067, data: 0.005) G_GAN: 0.617 G_L1: 2.077 D_real: 0.340 D_fake: 1.463 \n",
            "(epoch: 63, iters: 3000, time: 0.062, data: 0.005) G_GAN: 7.227 G_L1: 1.542 D_real: 0.013 D_fake: 0.001 \n",
            "(epoch: 63, iters: 3100, time: 0.066, data: 0.002) G_GAN: 6.289 G_L1: 2.189 D_real: 0.148 D_fake: 0.003 \n",
            "(epoch: 63, iters: 3200, time: 0.176, data: 0.003) G_GAN: 4.986 G_L1: 0.672 D_real: 0.000 D_fake: 0.015 \n",
            "(epoch: 63, iters: 3300, time: 0.066, data: 0.002) G_GAN: 3.013 G_L1: 2.035 D_real: 0.095 D_fake: 0.194 \n",
            "(epoch: 63, iters: 3400, time: 0.066, data: 0.003) G_GAN: 2.328 G_L1: 2.447 D_real: 0.100 D_fake: 0.716 \n",
            "(epoch: 63, iters: 3500, time: 0.066, data: 0.002) G_GAN: 2.408 G_L1: 1.575 D_real: 0.100 D_fake: 0.159 \n",
            "(epoch: 63, iters: 3600, time: 0.194, data: 0.003) G_GAN: 5.578 G_L1: 2.047 D_real: 0.039 D_fake: 0.014 \n",
            "(epoch: 63, iters: 3700, time: 0.066, data: 0.003) G_GAN: 3.605 G_L1: 2.431 D_real: 0.094 D_fake: 0.097 \n",
            "(epoch: 63, iters: 3800, time: 0.064, data: 0.007) G_GAN: 2.045 G_L1: 3.225 D_real: 0.557 D_fake: 0.546 \n",
            "(epoch: 63, iters: 3900, time: 0.065, data: 0.004) G_GAN: 6.350 G_L1: 1.454 D_real: 0.002 D_fake: 0.003 \n",
            "(epoch: 63, iters: 4000, time: 0.416, data: 0.003) G_GAN: 3.078 G_L1: 2.669 D_real: 0.103 D_fake: 0.074 \n",
            "End of epoch 63 / 200 \t Time Taken: 174 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "(epoch: 64, iters: 100, time: 0.067, data: 0.200) G_GAN: 2.193 G_L1: 1.292 D_real: 0.306 D_fake: 0.388 \n",
            "(epoch: 64, iters: 200, time: 0.066, data: 0.004) G_GAN: 0.846 G_L1: 1.950 D_real: 0.642 D_fake: 0.668 \n",
            "(epoch: 64, iters: 300, time: 0.066, data: 0.003) G_GAN: 4.630 G_L1: 0.895 D_real: 0.008 D_fake: 0.018 \n",
            "(epoch: 64, iters: 400, time: 0.532, data: 0.002) G_GAN: 1.417 G_L1: 2.000 D_real: 0.841 D_fake: 0.633 \n",
            "(epoch: 64, iters: 500, time: 0.066, data: 0.002) G_GAN: 4.599 G_L1: 2.464 D_real: 0.299 D_fake: 0.014 \n",
            "(epoch: 64, iters: 600, time: 0.066, data: 0.004) G_GAN: 0.881 G_L1: 1.208 D_real: 1.312 D_fake: 0.426 \n",
            "(epoch: 64, iters: 700, time: 0.066, data: 0.003) G_GAN: 0.517 G_L1: 2.658 D_real: 0.481 D_fake: 1.275 \n",
            "(epoch: 64, iters: 800, time: 0.172, data: 0.002) G_GAN: 4.858 G_L1: 3.110 D_real: 0.059 D_fake: 0.013 \n",
            "(epoch: 64, iters: 900, time: 0.065, data: 0.005) G_GAN: 5.296 G_L1: 1.957 D_real: 0.012 D_fake: 0.008 \n",
            "(epoch: 64, iters: 1000, time: 0.066, data: 0.002) G_GAN: 0.788 G_L1: 2.796 D_real: 0.539 D_fake: 0.786 \n",
            "(epoch: 64, iters: 1100, time: 0.066, data: 0.002) G_GAN: 2.983 G_L1: 5.440 D_real: 0.013 D_fake: 1.146 \n",
            "(epoch: 64, iters: 1200, time: 0.170, data: 0.002) G_GAN: 5.845 G_L1: 1.340 D_real: 0.203 D_fake: 0.006 \n",
            "(epoch: 64, iters: 1300, time: 0.066, data: 0.003) G_GAN: 3.390 G_L1: 2.530 D_real: 0.196 D_fake: 0.061 \n",
            "(epoch: 64, iters: 1400, time: 0.067, data: 0.004) G_GAN: 4.845 G_L1: 2.661 D_real: 0.079 D_fake: 0.016 \n",
            "(epoch: 64, iters: 1500, time: 0.067, data: 0.003) G_GAN: 7.103 G_L1: 1.330 D_real: 0.000 D_fake: 0.001 \n",
            "(epoch: 64, iters: 1600, time: 0.185, data: 0.003) G_GAN: 3.916 G_L1: 1.902 D_real: 0.075 D_fake: 0.085 \n",
            "(epoch: 64, iters: 1700, time: 0.065, data: 0.010) G_GAN: 7.444 G_L1: 0.970 D_real: 0.000 D_fake: 0.001 \n",
            "(epoch: 64, iters: 1800, time: 0.065, data: 0.004) G_GAN: 3.490 G_L1: 1.207 D_real: 0.057 D_fake: 0.176 \n",
            "(epoch: 64, iters: 1900, time: 0.066, data: 0.003) G_GAN: 7.323 G_L1: 1.398 D_real: 0.103 D_fake: 0.001 \n",
            "(epoch: 64, iters: 2000, time: 0.414, data: 0.004) G_GAN: 5.779 G_L1: 1.724 D_real: 0.168 D_fake: 0.006 \n",
            "(epoch: 64, iters: 2100, time: 0.066, data: 0.003) G_GAN: 6.682 G_L1: 1.237 D_real: 0.000 D_fake: 0.002 \n",
            "(epoch: 64, iters: 2200, time: 0.060, data: 0.004) G_GAN: 2.950 G_L1: 3.163 D_real: 0.302 D_fake: 0.093 \n",
            "(epoch: 64, iters: 2300, time: 0.065, data: 0.003) G_GAN: 3.708 G_L1: 3.446 D_real: 0.029 D_fake: 0.050 \n",
            "(epoch: 64, iters: 2400, time: 0.189, data: 0.003) G_GAN: 2.742 G_L1: 1.975 D_real: 0.033 D_fake: 1.441 \n",
            "(epoch: 64, iters: 2500, time: 0.067, data: 0.008) G_GAN: 6.967 G_L1: 3.162 D_real: 0.305 D_fake: 0.001 \n",
            "(epoch: 64, iters: 2600, time: 0.066, data: 0.004) G_GAN: 3.700 G_L1: 3.232 D_real: 0.250 D_fake: 0.033 \n",
            "(epoch: 64, iters: 2700, time: 0.067, data: 0.004) G_GAN: 6.212 G_L1: 1.414 D_real: 0.000 D_fake: 0.003 \n",
            "(epoch: 64, iters: 2800, time: 0.189, data: 0.003) G_GAN: 3.402 G_L1: 2.093 D_real: 0.047 D_fake: 0.069 \n",
            "(epoch: 64, iters: 2900, time: 0.066, data: 0.006) G_GAN: 1.032 G_L1: 8.395 D_real: 0.689 D_fake: 0.516 \n",
            "(epoch: 64, iters: 3000, time: 0.066, data: 0.003) G_GAN: 2.367 G_L1: 3.151 D_real: 0.113 D_fake: 0.200 \n",
            "saving the latest model (epoch 64, total_iters 255000)\n",
            "(epoch: 64, iters: 3100, time: 0.067, data: 0.002) G_GAN: 1.010 G_L1: 2.214 D_real: 1.180 D_fake: 0.379 \n",
            "(epoch: 64, iters: 3200, time: 0.167, data: 0.006) G_GAN: 3.093 G_L1: 3.380 D_real: 0.241 D_fake: 0.286 \n",
            "(epoch: 64, iters: 3300, time: 0.065, data: 0.002) G_GAN: 4.873 G_L1: 1.712 D_real: 0.023 D_fake: 0.014 \n",
            "(epoch: 64, iters: 3400, time: 0.067, data: 0.002) G_GAN: 6.486 G_L1: 1.421 D_real: 0.000 D_fake: 0.002 \n",
            "(epoch: 64, iters: 3500, time: 0.065, data: 0.004) G_GAN: 2.482 G_L1: 6.013 D_real: 0.467 D_fake: 0.611 \n",
            "(epoch: 64, iters: 3600, time: 0.158, data: 0.004) G_GAN: 6.800 G_L1: 1.329 D_real: 0.000 D_fake: 0.002 \n",
            "(epoch: 64, iters: 3700, time: 0.066, data: 0.007) G_GAN: 0.929 G_L1: 2.386 D_real: 1.373 D_fake: 0.311 \n",
            "(epoch: 64, iters: 3800, time: 0.066, data: 0.008) G_GAN: 5.276 G_L1: 5.549 D_real: 0.266 D_fake: 0.005 \n",
            "(epoch: 64, iters: 3900, time: 0.066, data: 0.003) G_GAN: 0.772 G_L1: 2.817 D_real: 0.407 D_fake: 0.819 \n",
            "(epoch: 64, iters: 4000, time: 0.396, data: 0.003) G_GAN: 6.891 G_L1: 0.990 D_real: 0.030 D_fake: 0.001 \n",
            "End of epoch 64 / 200 \t Time Taken: 174 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "(epoch: 65, iters: 100, time: 0.067, data: 0.196) G_GAN: 5.394 G_L1: 2.120 D_real: 0.031 D_fake: 0.007 \n",
            "(epoch: 65, iters: 200, time: 0.067, data: 0.009) G_GAN: 6.524 G_L1: 1.522 D_real: 0.000 D_fake: 0.002 \n",
            "(epoch: 65, iters: 300, time: 0.067, data: 0.004) G_GAN: 0.760 G_L1: 3.749 D_real: 0.556 D_fake: 0.871 \n",
            "(epoch: 65, iters: 400, time: 0.530, data: 0.003) G_GAN: 3.509 G_L1: 1.665 D_real: 0.748 D_fake: 0.544 \n",
            "(epoch: 65, iters: 500, time: 0.066, data: 0.004) G_GAN: 3.772 G_L1: 1.721 D_real: 0.012 D_fake: 0.038 \n",
            "(epoch: 65, iters: 600, time: 0.067, data: 0.006) G_GAN: 3.278 G_L1: 3.278 D_real: 0.293 D_fake: 0.225 \n",
            "(epoch: 65, iters: 700, time: 0.066, data: 0.002) G_GAN: 1.758 G_L1: 2.257 D_real: 0.174 D_fake: 0.849 \n",
            "(epoch: 65, iters: 800, time: 0.175, data: 0.002) G_GAN: 3.070 G_L1: 2.686 D_real: 0.161 D_fake: 0.055 \n",
            "(epoch: 65, iters: 900, time: 0.065, data: 0.002) G_GAN: 0.788 G_L1: 2.550 D_real: 0.673 D_fake: 0.711 \n",
            "(epoch: 65, iters: 1000, time: 0.063, data: 0.003) G_GAN: 5.864 G_L1: 0.765 D_real: 0.004 D_fake: 0.005 \n",
            "(epoch: 65, iters: 1100, time: 0.066, data: 0.004) G_GAN: 4.196 G_L1: 2.462 D_real: 0.123 D_fake: 0.024 \n",
            "(epoch: 65, iters: 1200, time: 0.220, data: 0.003) G_GAN: 1.865 G_L1: 2.239 D_real: 0.937 D_fake: 0.155 \n",
            "(epoch: 65, iters: 1300, time: 0.067, data: 0.006) G_GAN: 3.105 G_L1: 3.210 D_real: 0.018 D_fake: 0.150 \n",
            "(epoch: 65, iters: 1400, time: 0.066, data: 0.003) G_GAN: 0.933 G_L1: 2.255 D_real: 1.223 D_fake: 0.377 \n",
            "(epoch: 65, iters: 1500, time: 0.066, data: 0.003) G_GAN: 3.703 G_L1: 2.057 D_real: 0.175 D_fake: 0.037 \n",
            "(epoch: 65, iters: 1600, time: 0.191, data: 0.003) G_GAN: 2.165 G_L1: 1.545 D_real: 0.464 D_fake: 0.061 \n",
            "(epoch: 65, iters: 1700, time: 0.064, data: 0.003) G_GAN: 2.041 G_L1: 1.660 D_real: 0.161 D_fake: 0.930 \n",
            "(epoch: 65, iters: 1800, time: 0.067, data: 0.003) G_GAN: 1.825 G_L1: 5.129 D_real: 0.628 D_fake: 0.173 \n",
            "(epoch: 65, iters: 1900, time: 0.066, data: 0.002) G_GAN: 1.022 G_L1: 1.295 D_real: 0.350 D_fake: 0.637 \n",
            "(epoch: 65, iters: 2000, time: 0.405, data: 0.003) G_GAN: 6.099 G_L1: 1.439 D_real: 0.000 D_fake: 0.003 \n",
            "(epoch: 65, iters: 2100, time: 0.066, data: 0.005) G_GAN: 3.106 G_L1: 1.116 D_real: 0.102 D_fake: 0.083 \n",
            "(epoch: 65, iters: 2200, time: 0.066, data: 0.004) G_GAN: 6.488 G_L1: 0.736 D_real: 0.003 D_fake: 0.003 \n",
            "(epoch: 65, iters: 2300, time: 0.063, data: 0.004) G_GAN: 0.937 G_L1: 3.292 D_real: 0.573 D_fake: 0.613 \n",
            "(epoch: 65, iters: 2400, time: 0.169, data: 0.003) G_GAN: 1.560 G_L1: 2.126 D_real: 0.313 D_fake: 1.480 \n",
            "(epoch: 65, iters: 2500, time: 0.067, data: 0.002) G_GAN: 0.809 G_L1: 2.209 D_real: 0.376 D_fake: 0.987 \n",
            "(epoch: 65, iters: 2600, time: 0.065, data: 0.004) G_GAN: 1.892 G_L1: 1.699 D_real: 0.877 D_fake: 0.190 \n",
            "(epoch: 65, iters: 2700, time: 0.066, data: 0.003) G_GAN: 0.691 G_L1: 2.357 D_real: 0.481 D_fake: 0.879 \n",
            "(epoch: 65, iters: 2800, time: 0.222, data: 0.002) G_GAN: 1.011 G_L1: 2.086 D_real: 0.702 D_fake: 0.549 \n",
            "(epoch: 65, iters: 2900, time: 0.065, data: 0.003) G_GAN: 5.832 G_L1: 1.401 D_real: 0.016 D_fake: 0.005 \n",
            "(epoch: 65, iters: 3000, time: 0.059, data: 0.002) G_GAN: 5.385 G_L1: 1.186 D_real: 0.003 D_fake: 0.012 \n",
            "(epoch: 65, iters: 3100, time: 0.066, data: 0.004) G_GAN: 2.481 G_L1: 2.361 D_real: 0.027 D_fake: 0.321 \n",
            "(epoch: 65, iters: 3200, time: 0.215, data: 0.003) G_GAN: 0.789 G_L1: 1.941 D_real: 0.714 D_fake: 0.935 \n",
            "(epoch: 65, iters: 3300, time: 0.066, data: 0.003) G_GAN: 2.305 G_L1: 1.061 D_real: 0.244 D_fake: 0.146 \n",
            "(epoch: 65, iters: 3400, time: 0.066, data: 0.004) G_GAN: 5.742 G_L1: 3.121 D_real: 0.005 D_fake: 0.007 \n",
            "(epoch: 65, iters: 3500, time: 0.066, data: 0.004) G_GAN: 3.214 G_L1: 1.957 D_real: 0.026 D_fake: 0.137 \n",
            "(epoch: 65, iters: 3600, time: 0.182, data: 0.004) G_GAN: 1.247 G_L1: 4.782 D_real: 0.937 D_fake: 0.439 \n",
            "(epoch: 65, iters: 3700, time: 0.066, data: 0.002) G_GAN: 7.990 G_L1: 0.848 D_real: 0.001 D_fake: 0.001 \n",
            "(epoch: 65, iters: 3800, time: 0.067, data: 0.002) G_GAN: 2.965 G_L1: 3.333 D_real: 0.013 D_fake: 0.158 \n",
            "(epoch: 65, iters: 3900, time: 0.066, data: 0.003) G_GAN: 3.134 G_L1: 1.616 D_real: 0.151 D_fake: 0.050 \n",
            "(epoch: 65, iters: 4000, time: 0.397, data: 0.003) G_GAN: 6.319 G_L1: 1.319 D_real: 0.000 D_fake: 0.002 \n",
            "saving the latest model (epoch 65, total_iters 260000)\n",
            "saving the model at the end of epoch 65, iters 260000\n",
            "End of epoch 65 / 200 \t Time Taken: 175 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "(epoch: 66, iters: 100, time: 0.066, data: 0.254) G_GAN: 0.925 G_L1: 2.376 D_real: 0.296 D_fake: 0.876 \n",
            "(epoch: 66, iters: 200, time: 0.067, data: 0.004) G_GAN: 7.833 G_L1: 1.273 D_real: 0.000 D_fake: 0.001 \n",
            "(epoch: 66, iters: 300, time: 0.067, data: 0.002) G_GAN: 2.687 G_L1: 2.105 D_real: 0.111 D_fake: 0.127 \n",
            "(epoch: 66, iters: 400, time: 0.703, data: 0.004) G_GAN: 1.374 G_L1: 2.095 D_real: 0.708 D_fake: 0.647 \n",
            "(epoch: 66, iters: 500, time: 0.066, data: 0.003) G_GAN: 7.376 G_L1: 1.557 D_real: 0.001 D_fake: 0.001 \n",
            "(epoch: 66, iters: 600, time: 0.067, data: 0.002) G_GAN: 1.519 G_L1: 2.009 D_real: 0.804 D_fake: 0.331 \n",
            "(epoch: 66, iters: 700, time: 0.066, data: 0.004) G_GAN: 6.859 G_L1: 1.407 D_real: 0.000 D_fake: 0.002 \n",
            "(epoch: 66, iters: 800, time: 0.163, data: 0.004) G_GAN: 6.951 G_L1: 1.130 D_real: 0.000 D_fake: 0.001 \n",
            "(epoch: 66, iters: 900, time: 0.065, data: 0.008) G_GAN: 1.605 G_L1: 2.243 D_real: 0.742 D_fake: 0.455 \n",
            "(epoch: 66, iters: 1000, time: 0.065, data: 0.002) G_GAN: 7.435 G_L1: 0.958 D_real: 0.000 D_fake: 0.001 \n",
            "(epoch: 66, iters: 1100, time: 0.063, data: 0.004) G_GAN: 1.028 G_L1: 2.116 D_real: 0.829 D_fake: 0.780 \n",
            "(epoch: 66, iters: 1200, time: 0.221, data: 0.005) G_GAN: 0.776 G_L1: 3.067 D_real: 0.577 D_fake: 0.770 \n",
            "(epoch: 66, iters: 1300, time: 0.067, data: 0.002) G_GAN: 1.411 G_L1: 1.283 D_real: 0.319 D_fake: 0.313 \n",
            "(epoch: 66, iters: 1400, time: 0.066, data: 0.004) G_GAN: 6.521 G_L1: 1.320 D_real: 0.000 D_fake: 0.002 \n",
            "(epoch: 66, iters: 1500, time: 0.066, data: 0.004) G_GAN: 0.607 G_L1: 2.441 D_real: 1.228 D_fake: 0.544 \n",
            "(epoch: 66, iters: 1600, time: 0.172, data: 0.005) G_GAN: 1.996 G_L1: 1.122 D_real: 0.487 D_fake: 1.091 \n",
            "(epoch: 66, iters: 1700, time: 0.066, data: 0.003) G_GAN: 2.438 G_L1: 1.636 D_real: 0.071 D_fake: 0.341 \n",
            "(epoch: 66, iters: 1800, time: 0.066, data: 0.004) G_GAN: 3.440 G_L1: 1.689 D_real: 0.036 D_fake: 0.050 \n",
            "(epoch: 66, iters: 1900, time: 0.067, data: 0.005) G_GAN: 5.065 G_L1: 5.459 D_real: 0.285 D_fake: 0.007 \n",
            "(epoch: 66, iters: 2000, time: 0.412, data: 0.002) G_GAN: 3.036 G_L1: 1.382 D_real: 0.431 D_fake: 0.046 \n",
            "(epoch: 66, iters: 2100, time: 0.067, data: 0.004) G_GAN: 3.189 G_L1: 2.198 D_real: 0.065 D_fake: 0.099 \n",
            "(epoch: 66, iters: 2200, time: 0.066, data: 0.002) G_GAN: 6.136 G_L1: 1.419 D_real: 0.000 D_fake: 0.003 \n",
            "(epoch: 66, iters: 2300, time: 0.066, data: 0.003) G_GAN: 2.826 G_L1: 1.495 D_real: 0.063 D_fake: 0.362 \n",
            "(epoch: 66, iters: 2400, time: 0.173, data: 0.003) G_GAN: 2.627 G_L1: 1.396 D_real: 0.017 D_fake: 0.161 \n",
            "(epoch: 66, iters: 2500, time: 0.067, data: 0.008) G_GAN: 5.842 G_L1: 0.707 D_real: 0.005 D_fake: 0.005 \n",
            "(epoch: 66, iters: 2600, time: 0.063, data: 0.003) G_GAN: 5.159 G_L1: 0.904 D_real: 0.006 D_fake: 0.010 \n",
            "(epoch: 66, iters: 2700, time: 0.066, data: 0.003) G_GAN: 8.817 G_L1: 2.020 D_real: 0.073 D_fake: 0.000 \n",
            "(epoch: 66, iters: 2800, time: 0.192, data: 0.002) G_GAN: 1.531 G_L1: 4.366 D_real: 1.623 D_fake: 0.273 \n",
            "(epoch: 66, iters: 2900, time: 0.067, data: 0.002) G_GAN: 6.507 G_L1: 1.431 D_real: 0.000 D_fake: 0.002 \n",
            "(epoch: 66, iters: 3000, time: 0.065, data: 0.002) G_GAN: 7.975 G_L1: 2.758 D_real: 0.738 D_fake: 0.001 \n",
            "(epoch: 66, iters: 3100, time: 0.064, data: 0.003) G_GAN: 2.455 G_L1: 1.877 D_real: 0.201 D_fake: 0.586 \n",
            "(epoch: 66, iters: 3200, time: 0.172, data: 0.003) G_GAN: 6.336 G_L1: 1.559 D_real: 0.482 D_fake: 0.003 \n",
            "(epoch: 66, iters: 3300, time: 0.066, data: 0.002) G_GAN: 3.392 G_L1: 2.768 D_real: 0.032 D_fake: 0.050 \n",
            "(epoch: 66, iters: 3400, time: 0.066, data: 0.002) G_GAN: 0.752 G_L1: 2.939 D_real: 0.712 D_fake: 0.668 \n",
            "(epoch: 66, iters: 3500, time: 0.067, data: 0.003) G_GAN: 5.884 G_L1: 1.004 D_real: 0.001 D_fake: 0.005 \n",
            "(epoch: 66, iters: 3600, time: 0.177, data: 0.005) G_GAN: 2.096 G_L1: 1.562 D_real: 0.209 D_fake: 0.180 \n",
            "(epoch: 66, iters: 3700, time: 0.060, data: 0.005) G_GAN: 4.306 G_L1: 1.216 D_real: 0.322 D_fake: 0.047 \n",
            "(epoch: 66, iters: 3800, time: 0.067, data: 0.003) G_GAN: 8.166 G_L1: 1.458 D_real: 0.006 D_fake: 0.001 \n",
            "(epoch: 66, iters: 3900, time: 0.066, data: 0.002) G_GAN: 2.223 G_L1: 2.717 D_real: 0.622 D_fake: 0.172 \n",
            "(epoch: 66, iters: 4000, time: 0.446, data: 0.003) G_GAN: 2.912 G_L1: 2.589 D_real: 0.012 D_fake: 1.747 \n",
            "End of epoch 66 / 200 \t Time Taken: 173 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "(epoch: 67, iters: 100, time: 0.061, data: 0.163) G_GAN: 2.310 G_L1: 1.567 D_real: 0.227 D_fake: 0.633 \n",
            "(epoch: 67, iters: 200, time: 0.066, data: 0.002) G_GAN: 4.872 G_L1: 0.770 D_real: 0.003 D_fake: 0.013 \n",
            "(epoch: 67, iters: 300, time: 0.067, data: 0.002) G_GAN: 0.936 G_L1: 2.249 D_real: 0.686 D_fake: 0.640 \n",
            "(epoch: 67, iters: 400, time: 0.564, data: 0.003) G_GAN: 8.072 G_L1: 0.798 D_real: 0.002 D_fake: 0.001 \n",
            "(epoch: 67, iters: 500, time: 0.066, data: 0.005) G_GAN: 3.404 G_L1: 1.205 D_real: 0.039 D_fake: 0.049 \n",
            "(epoch: 67, iters: 600, time: 0.064, data: 0.002) G_GAN: 3.215 G_L1: 5.780 D_real: 0.031 D_fake: 0.096 \n",
            "(epoch: 67, iters: 700, time: 0.066, data: 0.004) G_GAN: 1.402 G_L1: 2.368 D_real: 0.249 D_fake: 0.543 \n",
            "(epoch: 67, iters: 800, time: 0.172, data: 0.004) G_GAN: 1.587 G_L1: 1.419 D_real: 0.186 D_fake: 0.623 \n",
            "(epoch: 67, iters: 900, time: 0.066, data: 0.002) G_GAN: 0.925 G_L1: 2.896 D_real: 1.197 D_fake: 0.537 \n",
            "(epoch: 67, iters: 1000, time: 0.066, data: 0.005) G_GAN: 0.824 G_L1: 5.559 D_real: 0.517 D_fake: 0.778 \n",
            "saving the latest model (epoch 67, total_iters 265000)\n",
            "(epoch: 67, iters: 1100, time: 0.066, data: 0.002) G_GAN: 2.881 G_L1: 1.528 D_real: 0.020 D_fake: 0.298 \n",
            "(epoch: 67, iters: 1200, time: 0.219, data: 0.003) G_GAN: 0.669 G_L1: 2.152 D_real: 0.513 D_fake: 0.972 \n",
            "(epoch: 67, iters: 1300, time: 0.066, data: 0.002) G_GAN: 3.370 G_L1: 1.481 D_real: 2.409 D_fake: 0.014 \n",
            "(epoch: 67, iters: 1400, time: 0.067, data: 0.003) G_GAN: 0.865 G_L1: 3.082 D_real: 0.752 D_fake: 0.609 \n",
            "(epoch: 67, iters: 1500, time: 0.066, data: 0.004) G_GAN: 9.871 G_L1: 0.863 D_real: 0.038 D_fake: 0.000 \n",
            "(epoch: 67, iters: 1600, time: 0.161, data: 0.002) G_GAN: 6.116 G_L1: 0.881 D_real: 0.001 D_fake: 0.005 \n",
            "(epoch: 67, iters: 1700, time: 0.067, data: 0.003) G_GAN: 1.926 G_L1: 1.497 D_real: 0.182 D_fake: 0.529 \n",
            "(epoch: 67, iters: 1800, time: 0.065, data: 0.003) G_GAN: 0.802 G_L1: 1.807 D_real: 0.693 D_fake: 0.713 \n",
            "(epoch: 67, iters: 1900, time: 0.066, data: 0.003) G_GAN: 0.909 G_L1: 2.371 D_real: 0.592 D_fake: 0.613 \n",
            "(epoch: 67, iters: 2000, time: 0.413, data: 0.002) G_GAN: 2.825 G_L1: 2.234 D_real: 0.076 D_fake: 0.558 \n",
            "(epoch: 67, iters: 2100, time: 0.066, data: 0.004) G_GAN: 5.255 G_L1: 1.033 D_real: 0.000 D_fake: 0.008 \n",
            "(epoch: 67, iters: 2200, time: 0.066, data: 0.006) G_GAN: 0.954 G_L1: 2.467 D_real: 0.828 D_fake: 0.500 \n",
            "(epoch: 67, iters: 2300, time: 0.064, data: 0.003) G_GAN: 0.738 G_L1: 3.079 D_real: 0.696 D_fake: 0.803 \n",
            "(epoch: 67, iters: 2400, time: 0.171, data: 0.005) G_GAN: 4.376 G_L1: 5.857 D_real: 0.205 D_fake: 0.019 \n",
            "(epoch: 67, iters: 2500, time: 0.066, data: 0.003) G_GAN: 0.923 G_L1: 1.894 D_real: 0.489 D_fake: 0.778 \n",
            "(epoch: 67, iters: 2600, time: 0.067, data: 0.002) G_GAN: 9.257 G_L1: 0.606 D_real: 0.001 D_fake: 0.000 \n",
            "(epoch: 67, iters: 2700, time: 0.066, data: 0.004) G_GAN: 6.495 G_L1: 3.131 D_real: 0.026 D_fake: 0.002 \n",
            "(epoch: 67, iters: 2800, time: 0.283, data: 0.003) G_GAN: 2.359 G_L1: 1.427 D_real: 0.996 D_fake: 0.130 \n",
            "(epoch: 67, iters: 2900, time: 0.064, data: 0.002) G_GAN: 7.569 G_L1: 1.050 D_real: 0.001 D_fake: 0.001 \n",
            "(epoch: 67, iters: 3000, time: 0.065, data: 0.006) G_GAN: 0.745 G_L1: 3.177 D_real: 0.719 D_fake: 0.690 \n",
            "(epoch: 67, iters: 3100, time: 0.066, data: 0.002) G_GAN: 3.335 G_L1: 2.378 D_real: 0.567 D_fake: 0.332 \n",
            "(epoch: 67, iters: 3200, time: 0.223, data: 0.002) G_GAN: 0.891 G_L1: 3.472 D_real: 0.613 D_fake: 0.654 \n",
            "(epoch: 67, iters: 3300, time: 0.066, data: 0.003) G_GAN: 3.131 G_L1: 1.606 D_real: 0.027 D_fake: 0.507 \n",
            "(epoch: 67, iters: 3400, time: 0.067, data: 0.003) G_GAN: 2.579 G_L1: 1.483 D_real: 0.397 D_fake: 0.078 \n",
            "(epoch: 67, iters: 3500, time: 0.067, data: 0.004) G_GAN: 2.300 G_L1: 2.710 D_real: 0.075 D_fake: 0.311 \n",
            "(epoch: 67, iters: 3600, time: 0.216, data: 0.003) G_GAN: 0.842 G_L1: 3.264 D_real: 0.759 D_fake: 0.657 \n",
            "(epoch: 67, iters: 3700, time: 0.067, data: 0.010) G_GAN: 7.982 G_L1: 0.928 D_real: 0.001 D_fake: 0.001 \n",
            "(epoch: 67, iters: 3800, time: 0.066, data: 0.005) G_GAN: 3.626 G_L1: 1.625 D_real: 1.096 D_fake: 0.061 \n",
            "(epoch: 67, iters: 3900, time: 0.067, data: 0.003) G_GAN: 6.161 G_L1: 0.944 D_real: 0.003 D_fake: 0.005 \n",
            "(epoch: 67, iters: 4000, time: 0.433, data: 0.004) G_GAN: 2.265 G_L1: 2.496 D_real: 0.535 D_fake: 0.080 \n",
            "End of epoch 67 / 200 \t Time Taken: 174 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "(epoch: 68, iters: 100, time: 0.067, data: 0.217) G_GAN: 8.055 G_L1: 1.135 D_real: 0.000 D_fake: 0.001 \n",
            "(epoch: 68, iters: 200, time: 0.066, data: 0.003) G_GAN: 7.962 G_L1: 1.024 D_real: 0.015 D_fake: 0.001 \n",
            "(epoch: 68, iters: 300, time: 0.066, data: 0.003) G_GAN: 1.132 G_L1: 2.081 D_real: 0.645 D_fake: 0.335 \n",
            "(epoch: 68, iters: 400, time: 0.523, data: 0.004) G_GAN: 2.706 G_L1: 1.325 D_real: 0.972 D_fake: 0.180 \n",
            "(epoch: 68, iters: 500, time: 0.066, data: 0.002) G_GAN: 2.132 G_L1: 2.710 D_real: 0.086 D_fake: 0.450 \n",
            "(epoch: 68, iters: 600, time: 0.066, data: 0.003) G_GAN: 1.144 G_L1: 5.072 D_real: 0.539 D_fake: 0.471 \n",
            "(epoch: 68, iters: 700, time: 0.066, data: 0.004) G_GAN: 3.492 G_L1: 6.542 D_real: 0.052 D_fake: 0.100 \n",
            "(epoch: 68, iters: 800, time: 0.196, data: 0.003) G_GAN: 5.285 G_L1: 2.084 D_real: 0.027 D_fake: 0.011 \n",
            "(epoch: 68, iters: 900, time: 0.067, data: 0.003) G_GAN: 3.279 G_L1: 2.462 D_real: 0.206 D_fake: 0.122 \n",
            "(epoch: 68, iters: 1000, time: 0.063, data: 0.002) G_GAN: 5.032 G_L1: 1.224 D_real: 0.214 D_fake: 0.007 \n",
            "(epoch: 68, iters: 1100, time: 0.066, data: 0.002) G_GAN: 2.800 G_L1: 1.840 D_real: 0.218 D_fake: 0.163 \n",
            "(epoch: 68, iters: 1200, time: 0.168, data: 0.004) G_GAN: 5.018 G_L1: 1.281 D_real: 0.117 D_fake: 0.007 \n",
            "(epoch: 68, iters: 1300, time: 0.066, data: 0.002) G_GAN: 3.840 G_L1: 2.633 D_real: 0.095 D_fake: 0.028 \n",
            "(epoch: 68, iters: 1400, time: 0.067, data: 0.007) G_GAN: 6.153 G_L1: 0.716 D_real: 0.001 D_fake: 0.004 \n",
            "(epoch: 68, iters: 1500, time: 0.066, data: 0.003) G_GAN: 1.506 G_L1: 2.236 D_real: 0.759 D_fake: 0.496 \n",
            "(epoch: 68, iters: 1600, time: 0.168, data: 0.003) G_GAN: 5.298 G_L1: 0.860 D_real: 0.007 D_fake: 0.009 \n",
            "(epoch: 68, iters: 1700, time: 0.066, data: 0.003) G_GAN: 0.560 G_L1: 3.292 D_real: 0.285 D_fake: 1.334 \n",
            "(epoch: 68, iters: 1800, time: 0.066, data: 0.003) G_GAN: 3.305 G_L1: 2.556 D_real: 1.289 D_fake: 0.018 \n",
            "(epoch: 68, iters: 1900, time: 0.065, data: 0.004) G_GAN: 2.526 G_L1: 2.755 D_real: 0.598 D_fake: 0.126 \n",
            "(epoch: 68, iters: 2000, time: 0.479, data: 0.002) G_GAN: 0.969 G_L1: 4.453 D_real: 0.537 D_fake: 0.570 \n",
            "saving the latest model (epoch 68, total_iters 270000)\n",
            "(epoch: 68, iters: 2100, time: 0.062, data: 0.002) G_GAN: 1.202 G_L1: 1.233 D_real: 0.924 D_fake: 0.126 \n",
            "(epoch: 68, iters: 2200, time: 0.067, data: 0.003) G_GAN: 2.651 G_L1: 3.371 D_real: 0.041 D_fake: 1.166 \n",
            "(epoch: 68, iters: 2300, time: 0.067, data: 0.004) G_GAN: 3.075 G_L1: 1.513 D_real: 0.069 D_fake: 0.137 \n",
            "(epoch: 68, iters: 2400, time: 0.171, data: 0.003) G_GAN: 1.786 G_L1: 2.489 D_real: 0.372 D_fake: 0.322 \n",
            "(epoch: 68, iters: 2500, time: 0.066, data: 0.007) G_GAN: 6.467 G_L1: 1.177 D_real: 0.062 D_fake: 0.002 \n",
            "(epoch: 68, iters: 2600, time: 0.066, data: 0.006) G_GAN: 3.185 G_L1: 1.452 D_real: 0.601 D_fake: 0.022 \n",
            "(epoch: 68, iters: 2700, time: 0.067, data: 0.002) G_GAN: 1.831 G_L1: 2.113 D_real: 0.331 D_fake: 0.612 \n",
            "(epoch: 68, iters: 2800, time: 0.224, data: 0.004) G_GAN: 1.502 G_L1: 2.303 D_real: 0.454 D_fake: 0.406 \n",
            "(epoch: 68, iters: 2900, time: 0.067, data: 0.009) G_GAN: 2.974 G_L1: 1.544 D_real: 0.028 D_fake: 0.111 \n",
            "(epoch: 68, iters: 3000, time: 0.064, data: 0.003) G_GAN: 3.592 G_L1: 4.172 D_real: 0.016 D_fake: 0.039 \n",
            "(epoch: 68, iters: 3100, time: 0.067, data: 0.004) G_GAN: 3.437 G_L1: 2.030 D_real: 0.137 D_fake: 0.111 \n",
            "(epoch: 68, iters: 3200, time: 0.172, data: 0.006) G_GAN: 8.876 G_L1: 1.422 D_real: 0.001 D_fake: 0.000 \n",
            "(epoch: 68, iters: 3300, time: 0.067, data: 0.008) G_GAN: 3.909 G_L1: 0.947 D_real: 0.190 D_fake: 0.013 \n",
            "(epoch: 68, iters: 3400, time: 0.066, data: 0.002) G_GAN: 2.523 G_L1: 2.671 D_real: 0.018 D_fake: 0.401 \n",
            "(epoch: 68, iters: 3500, time: 0.065, data: 0.004) G_GAN: 2.852 G_L1: 4.392 D_real: 0.041 D_fake: 0.203 \n",
            "(epoch: 68, iters: 3600, time: 0.191, data: 0.002) G_GAN: 2.552 G_L1: 2.309 D_real: 0.100 D_fake: 0.151 \n",
            "(epoch: 68, iters: 3700, time: 0.065, data: 0.008) G_GAN: 4.183 G_L1: 2.067 D_real: 0.242 D_fake: 0.013 \n",
            "(epoch: 68, iters: 3800, time: 0.067, data: 0.003) G_GAN: 8.036 G_L1: 0.901 D_real: 0.003 D_fake: 0.001 \n",
            "(epoch: 68, iters: 3900, time: 0.066, data: 0.005) G_GAN: 3.308 G_L1: 2.737 D_real: 0.024 D_fake: 0.351 \n",
            "(epoch: 68, iters: 4000, time: 0.484, data: 0.004) G_GAN: 0.805 G_L1: 3.848 D_real: 0.664 D_fake: 0.693 \n",
            "End of epoch 68 / 200 \t Time Taken: 175 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "(epoch: 69, iters: 100, time: 0.066, data: 0.211) G_GAN: 0.866 G_L1: 1.992 D_real: 0.466 D_fake: 0.742 \n",
            "(epoch: 69, iters: 200, time: 0.066, data: 0.003) G_GAN: 2.092 G_L1: 2.137 D_real: 0.110 D_fake: 0.714 \n",
            "(epoch: 69, iters: 300, time: 0.066, data: 0.004) G_GAN: 6.617 G_L1: 0.627 D_real: 0.002 D_fake: 0.002 \n",
            "(epoch: 69, iters: 400, time: 0.899, data: 0.004) G_GAN: 2.539 G_L1: 1.335 D_real: 0.285 D_fake: 0.833 \n",
            "(epoch: 69, iters: 500, time: 0.065, data: 0.002) G_GAN: 2.294 G_L1: 1.793 D_real: 0.009 D_fake: 1.019 \n",
            "(epoch: 69, iters: 600, time: 0.066, data: 0.004) G_GAN: 1.887 G_L1: 0.801 D_real: 0.083 D_fake: 0.649 \n",
            "(epoch: 69, iters: 700, time: 0.066, data: 0.003) G_GAN: 0.947 G_L1: 2.078 D_real: 1.117 D_fake: 0.110 \n",
            "(epoch: 69, iters: 800, time: 0.224, data: 0.003) G_GAN: 0.840 G_L1: 2.380 D_real: 0.699 D_fake: 0.627 \n",
            "(epoch: 69, iters: 900, time: 0.066, data: 0.007) G_GAN: 3.500 G_L1: 5.386 D_real: 0.124 D_fake: 0.032 \n",
            "(epoch: 69, iters: 1000, time: 0.063, data: 0.004) G_GAN: 1.454 G_L1: 1.867 D_real: 0.276 D_fake: 0.305 \n",
            "(epoch: 69, iters: 1100, time: 0.067, data: 0.003) G_GAN: 1.848 G_L1: 2.364 D_real: 2.548 D_fake: 0.013 \n",
            "(epoch: 69, iters: 1200, time: 0.166, data: 0.002) G_GAN: 2.145 G_L1: 2.340 D_real: 0.024 D_fake: 0.462 \n",
            "(epoch: 69, iters: 1300, time: 0.067, data: 0.002) G_GAN: 0.878 G_L1: 1.276 D_real: 0.682 D_fake: 0.517 \n",
            "(epoch: 69, iters: 1400, time: 0.066, data: 0.005) G_GAN: 1.027 G_L1: 4.822 D_real: 1.189 D_fake: 0.373 \n",
            "(epoch: 69, iters: 1500, time: 0.066, data: 0.003) G_GAN: 10.558 G_L1: 1.074 D_real: 0.002 D_fake: 0.000 \n",
            "(epoch: 69, iters: 1600, time: 0.171, data: 0.002) G_GAN: 4.033 G_L1: 1.195 D_real: 0.001 D_fake: 0.027 \n",
            "(epoch: 69, iters: 1700, time: 0.066, data: 0.003) G_GAN: 2.415 G_L1: 2.265 D_real: 0.772 D_fake: 0.095 \n",
            "(epoch: 69, iters: 1800, time: 0.066, data: 0.007) G_GAN: 8.324 G_L1: 0.733 D_real: 0.001 D_fake: 0.000 \n",
            "(epoch: 69, iters: 1900, time: 0.066, data: 0.002) G_GAN: 0.826 G_L1: 4.007 D_real: 0.490 D_fake: 0.864 \n",
            "(epoch: 69, iters: 2000, time: 0.408, data: 0.002) G_GAN: 1.907 G_L1: 2.674 D_real: 0.241 D_fake: 0.231 \n",
            "(epoch: 69, iters: 2100, time: 0.066, data: 0.002) G_GAN: 5.986 G_L1: 0.913 D_real: 0.001 D_fake: 0.004 \n",
            "(epoch: 69, iters: 2200, time: 0.066, data: 0.002) G_GAN: 6.737 G_L1: 0.824 D_real: 0.002 D_fake: 0.002 \n",
            "(epoch: 69, iters: 2300, time: 0.067, data: 0.002) G_GAN: 5.678 G_L1: 1.722 D_real: 0.083 D_fake: 0.005 \n",
            "(epoch: 69, iters: 2400, time: 0.176, data: 0.002) G_GAN: 7.439 G_L1: 1.523 D_real: 0.001 D_fake: 0.001 \n",
            "(epoch: 69, iters: 2500, time: 0.067, data: 0.002) G_GAN: 3.892 G_L1: 3.860 D_real: 0.472 D_fake: 0.360 \n",
            "(epoch: 69, iters: 2600, time: 0.066, data: 0.003) G_GAN: 8.937 G_L1: 2.361 D_real: 0.062 D_fake: 0.000 \n",
            "(epoch: 69, iters: 2700, time: 0.066, data: 0.003) G_GAN: 7.686 G_L1: 2.580 D_real: 0.216 D_fake: 0.001 \n",
            "(epoch: 69, iters: 2800, time: 0.239, data: 0.005) G_GAN: 0.781 G_L1: 2.408 D_real: 0.762 D_fake: 0.673 \n",
            "(epoch: 69, iters: 2900, time: 0.065, data: 0.002) G_GAN: 3.489 G_L1: 1.199 D_real: 0.001 D_fake: 0.152 \n",
            "(epoch: 69, iters: 3000, time: 0.065, data: 0.003) G_GAN: 6.501 G_L1: 3.711 D_real: 0.002 D_fake: 0.002 \n",
            "saving the latest model (epoch 69, total_iters 275000)\n",
            "(epoch: 69, iters: 3100, time: 0.066, data: 0.005) G_GAN: 4.607 G_L1: 1.487 D_real: 0.051 D_fake: 0.014 \n",
            "(epoch: 69, iters: 3200, time: 0.161, data: 0.003) G_GAN: 5.085 G_L1: 0.806 D_real: 0.001 D_fake: 0.009 \n",
            "(epoch: 69, iters: 3300, time: 0.067, data: 0.002) G_GAN: 1.023 G_L1: 1.947 D_real: 0.589 D_fake: 0.426 \n",
            "(epoch: 69, iters: 3400, time: 0.064, data: 0.003) G_GAN: 4.206 G_L1: 2.092 D_real: 0.085 D_fake: 0.023 \n",
            "(epoch: 69, iters: 3500, time: 0.067, data: 0.005) G_GAN: 3.184 G_L1: 2.096 D_real: 0.014 D_fake: 0.091 \n",
            "(epoch: 69, iters: 3600, time: 0.161, data: 0.002) G_GAN: 6.395 G_L1: 1.124 D_real: 0.001 D_fake: 0.003 \n",
            "(epoch: 69, iters: 3700, time: 0.065, data: 0.002) G_GAN: 0.974 G_L1: 2.860 D_real: 0.730 D_fake: 0.535 \n",
            "(epoch: 69, iters: 3800, time: 0.066, data: 0.004) G_GAN: 3.871 G_L1: 0.900 D_real: 0.000 D_fake: 0.040 \n",
            "(epoch: 69, iters: 3900, time: 0.065, data: 0.005) G_GAN: 8.215 G_L1: 0.538 D_real: 0.001 D_fake: 0.001 \n",
            "(epoch: 69, iters: 4000, time: 0.430, data: 0.003) G_GAN: 9.234 G_L1: 1.194 D_real: 0.001 D_fake: 0.000 \n",
            "End of epoch 69 / 200 \t Time Taken: 174 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "(epoch: 70, iters: 100, time: 0.066, data: 0.224) G_GAN: 1.533 G_L1: 1.914 D_real: 0.284 D_fake: 0.958 \n",
            "(epoch: 70, iters: 200, time: 0.067, data: 0.005) G_GAN: 0.695 G_L1: 1.976 D_real: 0.233 D_fake: 1.496 \n",
            "(epoch: 70, iters: 300, time: 0.060, data: 0.006) G_GAN: 0.945 G_L1: 3.327 D_real: 0.729 D_fake: 0.530 \n",
            "(epoch: 70, iters: 400, time: 0.621, data: 0.007) G_GAN: 9.052 G_L1: 0.824 D_real: 0.002 D_fake: 0.000 \n",
            "(epoch: 70, iters: 500, time: 0.052, data: 0.005) G_GAN: 2.552 G_L1: 2.674 D_real: 0.077 D_fake: 1.169 \n",
            "(epoch: 70, iters: 600, time: 0.066, data: 0.010) G_GAN: 3.110 G_L1: 3.123 D_real: 0.645 D_fake: 0.082 \n",
            "(epoch: 70, iters: 700, time: 0.064, data: 0.004) G_GAN: 2.346 G_L1: 3.230 D_real: 0.553 D_fake: 0.356 \n",
            "(epoch: 70, iters: 800, time: 0.169, data: 0.003) G_GAN: 5.677 G_L1: 1.352 D_real: 0.053 D_fake: 0.008 \n",
            "(epoch: 70, iters: 900, time: 0.066, data: 0.002) G_GAN: 1.285 G_L1: 4.425 D_real: 1.208 D_fake: 0.248 \n",
            "(epoch: 70, iters: 1000, time: 0.066, data: 0.002) G_GAN: 7.479 G_L1: 0.738 D_real: 0.000 D_fake: 0.001 \n",
            "(epoch: 70, iters: 1100, time: 0.066, data: 0.002) G_GAN: 0.844 G_L1: 2.672 D_real: 0.968 D_fake: 0.565 \n",
            "(epoch: 70, iters: 1200, time: 0.178, data: 0.002) G_GAN: 2.338 G_L1: 3.543 D_real: 0.172 D_fake: 0.973 \n",
            "(epoch: 70, iters: 1300, time: 0.066, data: 0.002) G_GAN: 0.778 G_L1: 3.270 D_real: 0.705 D_fake: 0.674 \n",
            "(epoch: 70, iters: 1400, time: 0.065, data: 0.005) G_GAN: 0.725 G_L1: 2.796 D_real: 0.543 D_fake: 0.894 \n",
            "(epoch: 70, iters: 1500, time: 0.066, data: 0.004) G_GAN: 0.743 G_L1: 1.033 D_real: 0.443 D_fake: 0.862 \n",
            "(epoch: 70, iters: 1600, time: 0.165, data: 0.006) G_GAN: 8.904 G_L1: 0.922 D_real: 0.009 D_fake: 0.000 \n",
            "(epoch: 70, iters: 1700, time: 0.066, data: 0.002) G_GAN: 3.963 G_L1: 1.868 D_real: 0.050 D_fake: 0.047 \n",
            "(epoch: 70, iters: 1800, time: 0.066, data: 0.006) G_GAN: 0.953 G_L1: 4.391 D_real: 0.851 D_fake: 0.521 \n",
            "(epoch: 70, iters: 1900, time: 0.067, data: 0.003) G_GAN: 8.894 G_L1: 1.032 D_real: 0.000 D_fake: 0.000 \n",
            "(epoch: 70, iters: 2000, time: 0.407, data: 0.005) G_GAN: 8.433 G_L1: 0.621 D_real: 0.001 D_fake: 0.000 \n",
            "(epoch: 70, iters: 2100, time: 0.065, data: 0.003) G_GAN: 0.873 G_L1: 2.800 D_real: 0.620 D_fake: 0.611 \n",
            "(epoch: 70, iters: 2200, time: 0.067, data: 0.003) G_GAN: 2.259 G_L1: 2.422 D_real: 0.101 D_fake: 0.449 \n",
            "(epoch: 70, iters: 2300, time: 0.065, data: 0.008) G_GAN: 6.121 G_L1: 0.777 D_real: 0.000 D_fake: 0.004 \n",
            "(epoch: 70, iters: 2400, time: 0.173, data: 0.003) G_GAN: 0.929 G_L1: 1.851 D_real: 1.877 D_fake: 0.322 \n",
            "(epoch: 70, iters: 2500, time: 0.066, data: 0.011) G_GAN: 4.169 G_L1: 2.775 D_real: 0.111 D_fake: 0.019 \n",
            "(epoch: 70, iters: 2600, time: 0.066, data: 0.003) G_GAN: 0.709 G_L1: 2.150 D_real: 0.626 D_fake: 0.774 \n",
            "(epoch: 70, iters: 2700, time: 0.065, data: 0.004) G_GAN: 7.717 G_L1: 1.113 D_real: 0.407 D_fake: 0.001 \n",
            "(epoch: 70, iters: 2800, time: 0.281, data: 0.002) G_GAN: 2.603 G_L1: 2.707 D_real: 0.042 D_fake: 1.517 \n",
            "(epoch: 70, iters: 2900, time: 0.066, data: 0.006) G_GAN: 2.748 G_L1: 1.625 D_real: 0.186 D_fake: 0.461 \n",
            "(epoch: 70, iters: 3000, time: 0.066, data: 0.003) G_GAN: 5.042 G_L1: 0.604 D_real: 0.008 D_fake: 0.015 \n",
            "(epoch: 70, iters: 3100, time: 0.066, data: 0.004) G_GAN: 0.836 G_L1: 1.841 D_real: 0.825 D_fake: 0.815 \n",
            "(epoch: 70, iters: 3200, time: 0.166, data: 0.003) G_GAN: 2.594 G_L1: 2.435 D_real: 0.373 D_fake: 0.085 \n",
            "(epoch: 70, iters: 3300, time: 0.063, data: 0.002) G_GAN: 5.071 G_L1: 0.944 D_real: 0.110 D_fake: 0.009 \n",
            "(epoch: 70, iters: 3400, time: 0.066, data: 0.006) G_GAN: 7.080 G_L1: 0.584 D_real: 0.000 D_fake: 0.001 \n",
            "(epoch: 70, iters: 3500, time: 0.065, data: 0.004) G_GAN: 0.686 G_L1: 2.075 D_real: 0.553 D_fake: 0.813 \n",
            "(epoch: 70, iters: 3600, time: 0.171, data: 0.003) G_GAN: 2.586 G_L1: 2.599 D_real: 0.314 D_fake: 0.074 \n",
            "(epoch: 70, iters: 3700, time: 0.066, data: 0.002) G_GAN: 1.342 G_L1: 2.151 D_real: 1.041 D_fake: 1.442 \n",
            "(epoch: 70, iters: 3800, time: 0.067, data: 0.005) G_GAN: 6.794 G_L1: 0.746 D_real: 0.001 D_fake: 0.003 \n",
            "(epoch: 70, iters: 3900, time: 0.066, data: 0.004) G_GAN: 0.938 G_L1: 2.366 D_real: 1.379 D_fake: 0.350 \n",
            "(epoch: 70, iters: 4000, time: 0.439, data: 0.002) G_GAN: 2.960 G_L1: 2.014 D_real: 0.051 D_fake: 0.116 \n",
            "saving the latest model (epoch 70, total_iters 280000)\n",
            "saving the model at the end of epoch 70, iters 280000\n",
            "End of epoch 70 / 200 \t Time Taken: 176 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "(epoch: 71, iters: 100, time: 0.067, data: 0.235) G_GAN: 0.872 G_L1: 2.470 D_real: 0.537 D_fake: 0.643 \n",
            "(epoch: 71, iters: 200, time: 0.067, data: 0.007) G_GAN: 3.135 G_L1: 1.190 D_real: 0.135 D_fake: 0.185 \n",
            "(epoch: 71, iters: 300, time: 0.066, data: 0.004) G_GAN: 0.816 G_L1: 1.874 D_real: 0.397 D_fake: 0.869 \n",
            "(epoch: 71, iters: 400, time: 0.569, data: 0.004) G_GAN: 2.270 G_L1: 2.812 D_real: 0.402 D_fake: 0.195 \n",
            "(epoch: 71, iters: 500, time: 0.066, data: 0.006) G_GAN: 10.149 G_L1: 1.161 D_real: 0.000 D_fake: 0.000 \n",
            "(epoch: 71, iters: 600, time: 0.066, data: 0.004) G_GAN: 6.218 G_L1: 1.023 D_real: 0.001 D_fake: 0.004 \n",
            "(epoch: 71, iters: 700, time: 0.064, data: 0.002) G_GAN: 8.190 G_L1: 0.623 D_real: 0.000 D_fake: 0.001 \n",
            "(epoch: 71, iters: 800, time: 0.193, data: 0.004) G_GAN: 4.315 G_L1: 3.304 D_real: 0.156 D_fake: 0.043 \n",
            "(epoch: 71, iters: 900, time: 0.067, data: 0.003) G_GAN: 2.939 G_L1: 1.707 D_real: 0.225 D_fake: 0.202 \n",
            "(epoch: 71, iters: 1000, time: 0.067, data: 0.002) G_GAN: 1.429 G_L1: 2.226 D_real: 0.087 D_fake: 1.720 \n",
            "(epoch: 71, iters: 1100, time: 0.066, data: 0.003) G_GAN: 2.068 G_L1: 2.677 D_real: 0.113 D_fake: 0.423 \n",
            "(epoch: 71, iters: 1200, time: 0.170, data: 0.004) G_GAN: 2.447 G_L1: 1.083 D_real: 0.151 D_fake: 1.047 \n",
            "(epoch: 71, iters: 1300, time: 0.066, data: 0.005) G_GAN: 1.534 G_L1: 1.909 D_real: 0.332 D_fake: 0.676 \n",
            "(epoch: 71, iters: 1400, time: 0.067, data: 0.002) G_GAN: 2.338 G_L1: 1.747 D_real: 0.025 D_fake: 1.052 \n",
            "(epoch: 71, iters: 1500, time: 0.066, data: 0.003) G_GAN: 9.633 G_L1: 1.154 D_real: 0.001 D_fake: 0.000 \n",
            "(epoch: 71, iters: 1600, time: 0.183, data: 0.003) G_GAN: 4.699 G_L1: 0.944 D_real: 0.062 D_fake: 0.018 \n",
            "(epoch: 71, iters: 1700, time: 0.066, data: 0.003) G_GAN: 1.972 G_L1: 1.528 D_real: 0.224 D_fake: 0.898 \n",
            "(epoch: 71, iters: 1800, time: 0.066, data: 0.003) G_GAN: 0.939 G_L1: 3.036 D_real: 0.821 D_fake: 0.514 \n",
            "(epoch: 71, iters: 1900, time: 0.067, data: 0.002) G_GAN: 2.194 G_L1: 2.014 D_real: 0.202 D_fake: 0.192 \n",
            "(epoch: 71, iters: 2000, time: 0.508, data: 0.003) G_GAN: 0.755 G_L1: 1.898 D_real: 0.748 D_fake: 0.750 \n",
            "(epoch: 71, iters: 2100, time: 0.066, data: 0.002) G_GAN: 6.402 G_L1: 0.685 D_real: 0.008 D_fake: 1.225 \n",
            "(epoch: 71, iters: 2200, time: 0.067, data: 0.003) G_GAN: 0.691 G_L1: 1.864 D_real: 0.519 D_fake: 0.996 \n",
            "(epoch: 71, iters: 2300, time: 0.067, data: 0.002) G_GAN: 2.273 G_L1: 1.688 D_real: 0.131 D_fake: 0.883 \n",
            "(epoch: 71, iters: 2400, time: 0.191, data: 0.003) G_GAN: 1.462 G_L1: 1.287 D_real: 0.352 D_fake: 0.205 \n",
            "(epoch: 71, iters: 2500, time: 0.065, data: 0.002) G_GAN: 0.877 G_L1: 2.184 D_real: 0.784 D_fake: 0.452 \n",
            "(epoch: 71, iters: 2600, time: 0.067, data: 0.004) G_GAN: 2.342 G_L1: 2.360 D_real: 0.205 D_fake: 0.193 \n",
            "(epoch: 71, iters: 2700, time: 0.066, data: 0.004) G_GAN: 0.843 G_L1: 2.639 D_real: 0.345 D_fake: 0.708 \n",
            "(epoch: 71, iters: 2800, time: 0.170, data: 0.002) G_GAN: 7.441 G_L1: 2.588 D_real: 0.202 D_fake: 0.001 \n",
            "(epoch: 71, iters: 2900, time: 0.066, data: 0.002) G_GAN: 0.917 G_L1: 2.734 D_real: 1.108 D_fake: 0.410 \n",
            "(epoch: 71, iters: 3000, time: 0.066, data: 0.003) G_GAN: 2.187 G_L1: 2.202 D_real: 0.025 D_fake: 0.279 \n",
            "(epoch: 71, iters: 3100, time: 0.067, data: 0.007) G_GAN: 3.023 G_L1: 2.577 D_real: 0.141 D_fake: 0.145 \n",
            "(epoch: 71, iters: 3200, time: 0.222, data: 0.002) G_GAN: 0.959 G_L1: 2.464 D_real: 0.877 D_fake: 0.492 \n",
            "(epoch: 71, iters: 3300, time: 0.066, data: 0.003) G_GAN: 5.470 G_L1: 2.843 D_real: 0.058 D_fake: 0.006 \n",
            "(epoch: 71, iters: 3400, time: 0.063, data: 0.003) G_GAN: 0.849 G_L1: 2.377 D_real: 0.563 D_fake: 0.765 \n",
            "(epoch: 71, iters: 3500, time: 0.066, data: 0.003) G_GAN: 1.532 G_L1: 2.002 D_real: 1.289 D_fake: 0.257 \n",
            "(epoch: 71, iters: 3600, time: 0.166, data: 0.003) G_GAN: 2.648 G_L1: 1.430 D_real: 0.337 D_fake: 0.207 \n",
            "(epoch: 71, iters: 3700, time: 0.067, data: 0.002) G_GAN: 3.214 G_L1: 1.995 D_real: 0.185 D_fake: 0.049 \n",
            "(epoch: 71, iters: 3800, time: 0.066, data: 0.003) G_GAN: 2.369 G_L1: 1.974 D_real: 0.262 D_fake: 0.309 \n",
            "(epoch: 71, iters: 3900, time: 0.067, data: 0.004) G_GAN: 0.938 G_L1: 2.712 D_real: 0.581 D_fake: 0.614 \n",
            "(epoch: 71, iters: 4000, time: 0.448, data: 0.002) G_GAN: 1.171 G_L1: 3.641 D_real: 1.061 D_fake: 0.312 \n",
            "End of epoch 71 / 200 \t Time Taken: 173 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "(epoch: 72, iters: 100, time: 0.066, data: 0.199) G_GAN: 3.100 G_L1: 0.923 D_real: 0.059 D_fake: 0.644 \n",
            "(epoch: 72, iters: 200, time: 0.066, data: 0.003) G_GAN: 1.036 G_L1: 2.706 D_real: 0.280 D_fake: 0.825 \n",
            "(epoch: 72, iters: 300, time: 0.066, data: 0.003) G_GAN: 0.934 G_L1: 1.715 D_real: 0.988 D_fake: 0.559 \n",
            "(epoch: 72, iters: 400, time: 0.619, data: 0.004) G_GAN: 4.122 G_L1: 0.813 D_real: 0.000 D_fake: 0.034 \n",
            "(epoch: 72, iters: 500, time: 0.067, data: 0.003) G_GAN: 0.989 G_L1: 3.542 D_real: 0.918 D_fake: 0.437 \n",
            "(epoch: 72, iters: 600, time: 0.067, data: 0.003) G_GAN: 9.284 G_L1: 0.803 D_real: 0.019 D_fake: 0.000 \n",
            "(epoch: 72, iters: 700, time: 0.065, data: 0.002) G_GAN: 2.140 G_L1: 1.856 D_real: 0.185 D_fake: 0.166 \n",
            "(epoch: 72, iters: 800, time: 0.173, data: 0.004) G_GAN: 9.076 G_L1: 1.125 D_real: 0.005 D_fake: 0.000 \n",
            "(epoch: 72, iters: 900, time: 0.066, data: 0.002) G_GAN: 0.865 G_L1: 2.404 D_real: 0.747 D_fake: 0.682 \n",
            "(epoch: 72, iters: 1000, time: 0.066, data: 0.003) G_GAN: 1.743 G_L1: 2.670 D_real: 0.490 D_fake: 0.472 \n",
            "saving the latest model (epoch 72, total_iters 285000)\n",
            "(epoch: 72, iters: 1100, time: 0.067, data: 0.006) G_GAN: 3.205 G_L1: 2.303 D_real: 0.036 D_fake: 0.507 \n",
            "(epoch: 72, iters: 1200, time: 0.176, data: 0.004) G_GAN: 6.841 G_L1: 0.974 D_real: 0.000 D_fake: 0.005 \n",
            "(epoch: 72, iters: 1300, time: 0.067, data: 0.003) G_GAN: 2.155 G_L1: 1.168 D_real: 0.161 D_fake: 0.301 \n",
            "(epoch: 72, iters: 1400, time: 0.066, data: 0.003) G_GAN: 1.937 G_L1: 2.326 D_real: 0.169 D_fake: 0.577 \n",
            "(epoch: 72, iters: 1500, time: 0.065, data: 0.003) G_GAN: 3.350 G_L1: 3.183 D_real: 0.485 D_fake: 0.504 \n",
            "(epoch: 72, iters: 1600, time: 0.167, data: 0.002) G_GAN: 0.921 G_L1: 1.167 D_real: 0.282 D_fake: 1.753 \n",
            "(epoch: 72, iters: 1700, time: 0.066, data: 0.003) G_GAN: 7.657 G_L1: 1.292 D_real: 0.000 D_fake: 0.001 \n",
            "(epoch: 72, iters: 1800, time: 0.065, data: 0.003) G_GAN: 3.312 G_L1: 2.078 D_real: 0.017 D_fake: 0.480 \n",
            "(epoch: 72, iters: 1900, time: 0.066, data: 0.004) G_GAN: 1.227 G_L1: 2.582 D_real: 0.461 D_fake: 0.150 \n",
            "(epoch: 72, iters: 2000, time: 0.432, data: 0.003) G_GAN: 2.385 G_L1: 1.793 D_real: 0.132 D_fake: 0.582 \n",
            "(epoch: 72, iters: 2100, time: 0.066, data: 0.007) G_GAN: 5.175 G_L1: 2.143 D_real: 0.006 D_fake: 0.009 \n",
            "(epoch: 72, iters: 2200, time: 0.066, data: 0.002) G_GAN: 3.148 G_L1: 2.152 D_real: 0.032 D_fake: 0.122 \n",
            "(epoch: 72, iters: 2300, time: 0.066, data: 0.003) G_GAN: 5.560 G_L1: 0.625 D_real: 0.000 D_fake: 0.009 \n",
            "(epoch: 72, iters: 2400, time: 0.178, data: 0.004) G_GAN: 2.101 G_L1: 1.627 D_real: 0.292 D_fake: 0.816 \n",
            "(epoch: 72, iters: 2500, time: 0.065, data: 0.008) G_GAN: 2.756 G_L1: 0.865 D_real: 0.021 D_fake: 0.257 \n",
            "(epoch: 72, iters: 2600, time: 0.066, data: 0.003) G_GAN: 5.545 G_L1: 2.033 D_real: 0.135 D_fake: 0.012 \n",
            "(epoch: 72, iters: 2700, time: 0.067, data: 0.003) G_GAN: 2.360 G_L1: 1.826 D_real: 0.343 D_fake: 0.116 \n",
            "(epoch: 72, iters: 2800, time: 0.157, data: 0.004) G_GAN: 7.716 G_L1: 0.655 D_real: 0.002 D_fake: 0.001 \n",
            "(epoch: 72, iters: 2900, time: 0.066, data: 0.002) G_GAN: 0.861 G_L1: 1.835 D_real: 0.973 D_fake: 0.618 \n",
            "(epoch: 72, iters: 3000, time: 0.065, data: 0.005) G_GAN: 7.950 G_L1: 1.070 D_real: 0.020 D_fake: 0.001 \n",
            "(epoch: 72, iters: 3100, time: 0.066, data: 0.003) G_GAN: 0.776 G_L1: 1.878 D_real: 0.325 D_fake: 0.948 \n",
            "(epoch: 72, iters: 3200, time: 0.159, data: 0.003) G_GAN: 7.580 G_L1: 0.814 D_real: 0.000 D_fake: 0.001 \n",
            "(epoch: 72, iters: 3300, time: 0.066, data: 0.002) G_GAN: 1.108 G_L1: 2.021 D_real: 0.485 D_fake: 0.631 \n",
            "(epoch: 72, iters: 3400, time: 0.058, data: 0.003) G_GAN: 2.297 G_L1: 2.267 D_real: 0.092 D_fake: 0.262 \n",
            "(epoch: 72, iters: 3500, time: 0.062, data: 0.003) G_GAN: 6.035 G_L1: 1.568 D_real: 0.002 D_fake: 0.004 \n",
            "(epoch: 72, iters: 3600, time: 0.215, data: 0.004) G_GAN: 1.456 G_L1: 2.619 D_real: 1.142 D_fake: 0.220 \n",
            "(epoch: 72, iters: 3700, time: 0.062, data: 0.009) G_GAN: 2.057 G_L1: 1.539 D_real: 0.065 D_fake: 0.733 \n",
            "(epoch: 72, iters: 3800, time: 0.066, data: 0.005) G_GAN: 6.795 G_L1: 0.782 D_real: 0.000 D_fake: 0.002 \n",
            "(epoch: 72, iters: 3900, time: 0.067, data: 0.003) G_GAN: 1.480 G_L1: 1.322 D_real: 0.375 D_fake: 0.419 \n",
            "(epoch: 72, iters: 4000, time: 0.425, data: 0.002) G_GAN: 5.600 G_L1: 1.376 D_real: 0.289 D_fake: 0.006 \n",
            "End of epoch 72 / 200 \t Time Taken: 174 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "(epoch: 73, iters: 100, time: 0.066, data: 0.216) G_GAN: 8.534 G_L1: 0.763 D_real: 0.001 D_fake: 0.001 \n",
            "(epoch: 73, iters: 200, time: 0.064, data: 0.003) G_GAN: 9.751 G_L1: 0.788 D_real: 0.000 D_fake: 0.000 \n",
            "(epoch: 73, iters: 300, time: 0.067, data: 0.002) G_GAN: 6.774 G_L1: 0.584 D_real: 0.001 D_fake: 0.003 \n",
            "(epoch: 73, iters: 400, time: 0.523, data: 0.003) G_GAN: 10.338 G_L1: 0.805 D_real: 0.000 D_fake: 0.000 \n",
            "(epoch: 73, iters: 500, time: 0.066, data: 0.003) G_GAN: 2.685 G_L1: 1.787 D_real: 0.281 D_fake: 1.261 \n",
            "(epoch: 73, iters: 600, time: 0.066, data: 0.003) G_GAN: 3.407 G_L1: 2.811 D_real: 0.023 D_fake: 0.052 \n",
            "(epoch: 73, iters: 700, time: 0.066, data: 0.003) G_GAN: 0.816 G_L1: 2.566 D_real: 0.617 D_fake: 0.720 \n",
            "(epoch: 73, iters: 800, time: 0.189, data: 0.002) G_GAN: 2.768 G_L1: 1.311 D_real: 0.057 D_fake: 0.112 \n",
            "(epoch: 73, iters: 900, time: 0.066, data: 0.002) G_GAN: 5.345 G_L1: 1.887 D_real: 0.174 D_fake: 0.006 \n",
            "(epoch: 73, iters: 1000, time: 0.066, data: 0.004) G_GAN: 3.124 G_L1: 1.444 D_real: 0.256 D_fake: 0.100 \n",
            "(epoch: 73, iters: 1100, time: 0.063, data: 0.003) G_GAN: 0.927 G_L1: 2.813 D_real: 0.753 D_fake: 0.531 \n",
            "(epoch: 73, iters: 1200, time: 0.166, data: 0.003) G_GAN: 6.243 G_L1: 1.766 D_real: 0.838 D_fake: 0.004 \n",
            "(epoch: 73, iters: 1300, time: 0.065, data: 0.005) G_GAN: 0.921 G_L1: 3.148 D_real: 0.574 D_fake: 0.627 \n",
            "(epoch: 73, iters: 1400, time: 0.066, data: 0.005) G_GAN: 6.166 G_L1: 0.736 D_real: 0.000 D_fake: 0.004 \n",
            "(epoch: 73, iters: 1500, time: 0.066, data: 0.002) G_GAN: 7.329 G_L1: 1.301 D_real: 0.001 D_fake: 0.001 \n",
            "(epoch: 73, iters: 1600, time: 0.173, data: 0.003) G_GAN: 4.593 G_L1: 1.133 D_real: 0.001 D_fake: 0.019 \n",
            "(epoch: 73, iters: 1700, time: 0.065, data: 0.009) G_GAN: 1.329 G_L1: 2.008 D_real: 0.354 D_fake: 0.528 \n",
            "(epoch: 73, iters: 1800, time: 0.065, data: 0.005) G_GAN: 9.104 G_L1: 0.872 D_real: 0.003 D_fake: 0.000 \n",
            "(epoch: 73, iters: 1900, time: 0.067, data: 0.003) G_GAN: 7.738 G_L1: 0.862 D_real: 0.000 D_fake: 0.001 \n",
            "(epoch: 73, iters: 2000, time: 0.524, data: 0.003) G_GAN: 0.672 G_L1: 2.895 D_real: 0.862 D_fake: 0.714 \n",
            "saving the latest model (epoch 73, total_iters 290000)\n",
            "(epoch: 73, iters: 2100, time: 0.067, data: 0.002) G_GAN: 1.213 G_L1: 1.917 D_real: 0.634 D_fake: 0.562 \n",
            "(epoch: 73, iters: 2200, time: 0.066, data: 0.003) G_GAN: 0.624 G_L1: 3.118 D_real: 0.642 D_fake: 0.920 \n",
            "(epoch: 73, iters: 2300, time: 0.067, data: 0.003) G_GAN: 8.328 G_L1: 1.260 D_real: 0.001 D_fake: 0.001 \n",
            "(epoch: 73, iters: 2400, time: 0.149, data: 0.005) G_GAN: 2.681 G_L1: 2.262 D_real: 0.266 D_fake: 0.636 \n",
            "(epoch: 73, iters: 2500, time: 0.064, data: 0.003) G_GAN: 7.665 G_L1: 0.966 D_real: 0.177 D_fake: 0.001 \n",
            "(epoch: 73, iters: 2600, time: 0.066, data: 0.002) G_GAN: 3.429 G_L1: 5.603 D_real: 0.232 D_fake: 0.033 \n",
            "(epoch: 73, iters: 2700, time: 0.067, data: 0.003) G_GAN: 9.001 G_L1: 0.923 D_real: 0.006 D_fake: 0.000 \n",
            "(epoch: 73, iters: 2800, time: 0.319, data: 0.002) G_GAN: 0.573 G_L1: 3.002 D_real: 0.442 D_fake: 1.062 \n",
            "(epoch: 73, iters: 2900, time: 0.066, data: 0.002) G_GAN: 7.684 G_L1: 1.064 D_real: 0.001 D_fake: 0.001 \n",
            "(epoch: 73, iters: 3000, time: 0.066, data: 0.003) G_GAN: 4.441 G_L1: 1.580 D_real: 0.256 D_fake: 0.031 \n",
            "(epoch: 73, iters: 3100, time: 0.066, data: 0.002) G_GAN: 1.907 G_L1: 3.006 D_real: 0.071 D_fake: 0.992 \n",
            "(epoch: 73, iters: 3200, time: 0.189, data: 0.003) G_GAN: 2.384 G_L1: 3.353 D_real: 0.126 D_fake: 0.129 \n",
            "(epoch: 73, iters: 3300, time: 0.066, data: 0.006) G_GAN: 9.525 G_L1: 0.782 D_real: 0.000 D_fake: 0.000 \n",
            "(epoch: 73, iters: 3400, time: 0.066, data: 0.003) G_GAN: 7.947 G_L1: 0.572 D_real: 0.003 D_fake: 0.001 \n",
            "(epoch: 73, iters: 3500, time: 0.067, data: 0.006) G_GAN: 2.846 G_L1: 2.463 D_real: 0.155 D_fake: 0.906 \n",
            "(epoch: 73, iters: 3600, time: 0.159, data: 0.003) G_GAN: 4.650 G_L1: 0.468 D_real: 0.002 D_fake: 0.031 \n",
            "(epoch: 73, iters: 3700, time: 0.064, data: 0.003) G_GAN: 0.897 G_L1: 1.899 D_real: 1.309 D_fake: 0.103 \n",
            "(epoch: 73, iters: 3800, time: 0.066, data: 0.005) G_GAN: 0.863 G_L1: 2.608 D_real: 0.776 D_fake: 0.579 \n",
            "(epoch: 73, iters: 3900, time: 0.061, data: 0.002) G_GAN: 0.835 G_L1: 2.960 D_real: 0.804 D_fake: 0.515 \n",
            "(epoch: 73, iters: 4000, time: 0.543, data: 0.002) G_GAN: 0.850 G_L1: 2.978 D_real: 0.547 D_fake: 0.704 \n",
            "End of epoch 73 / 200 \t Time Taken: 175 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "(epoch: 74, iters: 100, time: 0.067, data: 0.202) G_GAN: 4.231 G_L1: 0.720 D_real: 0.002 D_fake: 0.039 \n",
            "(epoch: 74, iters: 200, time: 0.066, data: 0.003) G_GAN: 0.940 G_L1: 1.323 D_real: 0.392 D_fake: 0.632 \n",
            "(epoch: 74, iters: 300, time: 0.059, data: 0.005) G_GAN: 9.370 G_L1: 1.028 D_real: 0.000 D_fake: 0.000 \n",
            "(epoch: 74, iters: 400, time: 0.557, data: 0.005) G_GAN: 4.029 G_L1: 1.947 D_real: 0.551 D_fake: 0.005 \n",
            "(epoch: 74, iters: 500, time: 0.066, data: 0.005) G_GAN: 1.168 G_L1: 1.840 D_real: 0.265 D_fake: 1.045 \n",
            "(epoch: 74, iters: 600, time: 0.066, data: 0.004) G_GAN: 6.146 G_L1: 1.002 D_real: 0.000 D_fake: 0.003 \n",
            "(epoch: 74, iters: 700, time: 0.066, data: 0.003) G_GAN: 1.276 G_L1: 2.813 D_real: 0.234 D_fake: 0.392 \n",
            "(epoch: 74, iters: 800, time: 0.183, data: 0.003) G_GAN: 3.596 G_L1: 1.900 D_real: 0.218 D_fake: 1.511 \n",
            "(epoch: 74, iters: 900, time: 0.067, data: 0.017) G_GAN: 2.048 G_L1: 2.820 D_real: 0.222 D_fake: 0.308 \n",
            "(epoch: 74, iters: 1000, time: 0.061, data: 0.004) G_GAN: 2.626 G_L1: 1.238 D_real: 0.037 D_fake: 0.546 \n",
            "(epoch: 74, iters: 1100, time: 0.066, data: 0.003) G_GAN: 7.582 G_L1: 0.761 D_real: 0.001 D_fake: 0.001 \n",
            "(epoch: 74, iters: 1200, time: 0.166, data: 0.003) G_GAN: 1.617 G_L1: 1.405 D_real: 0.482 D_fake: 1.355 \n",
            "(epoch: 74, iters: 1300, time: 0.067, data: 0.003) G_GAN: 0.692 G_L1: 1.943 D_real: 0.351 D_fake: 1.137 \n",
            "(epoch: 74, iters: 1400, time: 0.066, data: 0.005) G_GAN: 0.719 G_L1: 2.106 D_real: 0.639 D_fake: 0.941 \n",
            "(epoch: 74, iters: 1500, time: 0.067, data: 0.005) G_GAN: 3.020 G_L1: 1.174 D_real: 0.213 D_fake: 0.038 \n",
            "(epoch: 74, iters: 1600, time: 0.166, data: 0.004) G_GAN: 1.689 G_L1: 2.443 D_real: 0.188 D_fake: 0.284 \n",
            "(epoch: 74, iters: 1700, time: 0.066, data: 0.007) G_GAN: 8.867 G_L1: 0.948 D_real: 0.003 D_fake: 0.000 \n",
            "(epoch: 74, iters: 1800, time: 0.063, data: 0.004) G_GAN: 0.688 G_L1: 2.716 D_real: 0.414 D_fake: 1.013 \n",
            "(epoch: 74, iters: 1900, time: 0.064, data: 0.003) G_GAN: 8.822 G_L1: 0.600 D_real: 0.001 D_fake: 0.001 \n",
            "(epoch: 74, iters: 2000, time: 0.429, data: 0.003) G_GAN: 1.765 G_L1: 1.644 D_real: 0.351 D_fake: 0.218 \n",
            "(epoch: 74, iters: 2100, time: 0.066, data: 0.007) G_GAN: 1.087 G_L1: 1.940 D_real: 0.535 D_fake: 0.659 \n",
            "(epoch: 74, iters: 2200, time: 0.066, data: 0.003) G_GAN: 0.973 G_L1: 2.028 D_real: 0.969 D_fake: 0.378 \n",
            "(epoch: 74, iters: 2300, time: 0.065, data: 0.004) G_GAN: 2.759 G_L1: 1.646 D_real: 0.348 D_fake: 0.018 \n",
            "(epoch: 74, iters: 2400, time: 0.168, data: 0.004) G_GAN: 2.684 G_L1: 1.391 D_real: 0.173 D_fake: 0.298 \n",
            "(epoch: 74, iters: 2500, time: 0.066, data: 0.006) G_GAN: 9.251 G_L1: 1.249 D_real: 0.000 D_fake: 0.000 \n",
            "(epoch: 74, iters: 2600, time: 0.066, data: 0.004) G_GAN: 0.964 G_L1: 3.233 D_real: 1.092 D_fake: 0.415 \n",
            "(epoch: 74, iters: 2700, time: 0.063, data: 0.005) G_GAN: 1.032 G_L1: 1.940 D_real: 0.624 D_fake: 0.616 \n",
            "(epoch: 74, iters: 2800, time: 0.160, data: 0.003) G_GAN: 6.627 G_L1: 0.777 D_real: 0.000 D_fake: 0.002 \n",
            "(epoch: 74, iters: 2900, time: 0.063, data: 0.006) G_GAN: 8.231 G_L1: 1.026 D_real: 0.000 D_fake: 0.001 \n",
            "(epoch: 74, iters: 3000, time: 0.066, data: 0.006) G_GAN: 4.397 G_L1: 1.810 D_real: 0.040 D_fake: 0.019 \n",
            "saving the latest model (epoch 74, total_iters 295000)\n",
            "(epoch: 74, iters: 3100, time: 0.066, data: 0.002) G_GAN: 6.388 G_L1: 0.806 D_real: 0.001 D_fake: 0.004 \n",
            "(epoch: 74, iters: 3200, time: 0.219, data: 0.003) G_GAN: 0.885 G_L1: 2.344 D_real: 0.785 D_fake: 0.591 \n",
            "(epoch: 74, iters: 3300, time: 0.067, data: 0.002) G_GAN: 1.509 G_L1: 1.754 D_real: 0.553 D_fake: 0.777 \n",
            "(epoch: 74, iters: 3400, time: 0.066, data: 0.002) G_GAN: 1.559 G_L1: 1.770 D_real: 0.370 D_fake: 0.806 \n",
            "(epoch: 74, iters: 3500, time: 0.066, data: 0.002) G_GAN: 1.782 G_L1: 2.058 D_real: 0.089 D_fake: 0.322 \n",
            "(epoch: 74, iters: 3600, time: 0.192, data: 0.008) G_GAN: 7.552 G_L1: 2.484 D_real: 0.110 D_fake: 0.001 \n",
            "(epoch: 74, iters: 3700, time: 0.067, data: 0.010) G_GAN: 3.176 G_L1: 3.228 D_real: 0.041 D_fake: 0.397 \n",
            "(epoch: 74, iters: 3800, time: 0.066, data: 0.003) G_GAN: 0.989 G_L1: 2.158 D_real: 0.519 D_fake: 0.704 \n",
            "(epoch: 74, iters: 3900, time: 0.066, data: 0.003) G_GAN: 0.730 G_L1: 2.811 D_real: 0.450 D_fake: 1.026 \n",
            "(epoch: 74, iters: 4000, time: 0.410, data: 0.002) G_GAN: 6.536 G_L1: 0.855 D_real: 0.000 D_fake: 0.004 \n",
            "End of epoch 74 / 200 \t Time Taken: 174 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "(epoch: 75, iters: 100, time: 0.066, data: 0.219) G_GAN: 0.786 G_L1: 1.992 D_real: 0.559 D_fake: 0.849 \n",
            "(epoch: 75, iters: 200, time: 0.067, data: 0.011) G_GAN: 2.299 G_L1: 1.377 D_real: 1.911 D_fake: 0.067 \n",
            "(epoch: 75, iters: 300, time: 0.063, data: 0.002) G_GAN: 1.612 G_L1: 1.968 D_real: 0.893 D_fake: 0.231 \n",
            "(epoch: 75, iters: 400, time: 0.680, data: 0.003) G_GAN: 5.267 G_L1: 0.941 D_real: 0.172 D_fake: 0.005 \n",
            "(epoch: 75, iters: 500, time: 0.066, data: 0.003) G_GAN: 2.758 G_L1: 1.684 D_real: 0.043 D_fake: 0.417 \n",
            "(epoch: 75, iters: 600, time: 0.066, data: 0.004) G_GAN: 0.742 G_L1: 2.557 D_real: 0.607 D_fake: 0.821 \n",
            "(epoch: 75, iters: 700, time: 0.067, data: 0.005) G_GAN: 0.806 G_L1: 2.523 D_real: 0.721 D_fake: 0.561 \n",
            "(epoch: 75, iters: 800, time: 0.156, data: 0.002) G_GAN: 9.188 G_L1: 0.745 D_real: 0.000 D_fake: 0.000 \n",
            "(epoch: 75, iters: 900, time: 0.066, data: 0.002) G_GAN: 5.922 G_L1: 3.100 D_real: 0.082 D_fake: 0.005 \n",
            "(epoch: 75, iters: 1000, time: 0.067, data: 0.004) G_GAN: 3.823 G_L1: 1.860 D_real: 0.059 D_fake: 0.832 \n",
            "(epoch: 75, iters: 1100, time: 0.065, data: 0.004) G_GAN: 3.113 G_L1: 1.673 D_real: 0.001 D_fake: 0.188 \n",
            "(epoch: 75, iters: 1200, time: 0.174, data: 0.003) G_GAN: 2.827 G_L1: 1.458 D_real: 0.037 D_fake: 0.523 \n",
            "(epoch: 75, iters: 1300, time: 0.066, data: 0.007) G_GAN: 5.862 G_L1: 0.789 D_real: 0.000 D_fake: 0.004 \n",
            "(epoch: 75, iters: 1400, time: 0.066, data: 0.006) G_GAN: 8.307 G_L1: 0.869 D_real: 0.005 D_fake: 0.001 \n",
            "(epoch: 75, iters: 1500, time: 0.066, data: 0.003) G_GAN: 2.000 G_L1: 1.468 D_real: 0.200 D_fake: 0.716 \n",
            "(epoch: 75, iters: 1600, time: 0.186, data: 0.007) G_GAN: 1.487 G_L1: 1.390 D_real: 1.530 D_fake: 0.141 \n",
            "(epoch: 75, iters: 1700, time: 0.060, data: 0.003) G_GAN: 1.288 G_L1: 1.991 D_real: 0.830 D_fake: 0.974 \n",
            "(epoch: 75, iters: 1800, time: 0.066, data: 0.003) G_GAN: 6.551 G_L1: 0.707 D_real: 0.000 D_fake: 0.002 \n",
            "(epoch: 75, iters: 1900, time: 0.066, data: 0.007) G_GAN: 1.139 G_L1: 2.339 D_real: 0.692 D_fake: 0.677 \n",
            "(epoch: 75, iters: 2000, time: 0.504, data: 0.003) G_GAN: 0.829 G_L1: 1.811 D_real: 1.108 D_fake: 0.394 \n",
            "(epoch: 75, iters: 2100, time: 0.063, data: 0.004) G_GAN: 2.316 G_L1: 1.533 D_real: 0.081 D_fake: 0.500 \n",
            "(epoch: 75, iters: 2200, time: 0.066, data: 0.003) G_GAN: 2.584 G_L1: 1.762 D_real: 0.096 D_fake: 0.668 \n",
            "(epoch: 75, iters: 2300, time: 0.066, data: 0.004) G_GAN: 1.411 G_L1: 2.153 D_real: 0.455 D_fake: 0.375 \n",
            "(epoch: 75, iters: 2400, time: 0.169, data: 0.003) G_GAN: 4.083 G_L1: 1.187 D_real: 2.423 D_fake: 0.036 \n",
            "(epoch: 75, iters: 2500, time: 0.066, data: 0.007) G_GAN: 0.787 G_L1: 2.845 D_real: 0.597 D_fake: 0.686 \n",
            "(epoch: 75, iters: 2600, time: 0.066, data: 0.003) G_GAN: 2.952 G_L1: 4.120 D_real: 0.198 D_fake: 0.324 \n",
            "(epoch: 75, iters: 2700, time: 0.067, data: 0.004) G_GAN: 1.649 G_L1: 2.268 D_real: 0.591 D_fake: 0.556 \n",
            "(epoch: 75, iters: 2800, time: 0.168, data: 0.004) G_GAN: 8.575 G_L1: 1.424 D_real: 0.000 D_fake: 0.000 \n",
            "(epoch: 75, iters: 2900, time: 0.055, data: 0.002) G_GAN: 4.381 G_L1: 2.500 D_real: 0.062 D_fake: 0.031 \n",
            "(epoch: 75, iters: 3000, time: 0.067, data: 0.004) G_GAN: 4.990 G_L1: 2.960 D_real: 0.030 D_fake: 0.014 \n",
            "(epoch: 75, iters: 3100, time: 0.066, data: 0.003) G_GAN: 7.430 G_L1: 1.200 D_real: 0.004 D_fake: 0.001 \n",
            "(epoch: 75, iters: 3200, time: 0.215, data: 0.004) G_GAN: 1.146 G_L1: 2.053 D_real: 0.652 D_fake: 0.410 \n",
            "(epoch: 75, iters: 3300, time: 0.066, data: 0.002) G_GAN: 2.323 G_L1: 1.044 D_real: 0.199 D_fake: 0.537 \n",
            "(epoch: 75, iters: 3400, time: 0.066, data: 0.004) G_GAN: 2.592 G_L1: 1.222 D_real: 0.315 D_fake: 0.152 \n",
            "(epoch: 75, iters: 3500, time: 0.064, data: 0.004) G_GAN: 0.848 G_L1: 2.687 D_real: 1.042 D_fake: 0.485 \n",
            "(epoch: 75, iters: 3600, time: 0.161, data: 0.004) G_GAN: 7.314 G_L1: 0.604 D_real: 0.003 D_fake: 0.002 \n",
            "(epoch: 75, iters: 3700, time: 0.067, data: 0.009) G_GAN: 7.750 G_L1: 3.898 D_real: 0.127 D_fake: 0.001 \n",
            "(epoch: 75, iters: 3800, time: 0.066, data: 0.004) G_GAN: 0.806 G_L1: 5.809 D_real: 0.377 D_fake: 0.857 \n",
            "(epoch: 75, iters: 3900, time: 0.067, data: 0.003) G_GAN: 0.867 G_L1: 0.863 D_real: 0.535 D_fake: 0.645 \n",
            "(epoch: 75, iters: 4000, time: 0.463, data: 0.005) G_GAN: 0.610 G_L1: 1.388 D_real: 0.889 D_fake: 0.803 \n",
            "saving the latest model (epoch 75, total_iters 300000)\n",
            "saving the model at the end of epoch 75, iters 300000\n",
            "End of epoch 75 / 200 \t Time Taken: 176 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "(epoch: 76, iters: 100, time: 0.065, data: 0.290) G_GAN: 3.617 G_L1: 1.718 D_real: 0.196 D_fake: 0.055 \n",
            "(epoch: 76, iters: 200, time: 0.065, data: 0.006) G_GAN: 6.130 G_L1: 1.289 D_real: 0.046 D_fake: 0.003 \n",
            "(epoch: 76, iters: 300, time: 0.066, data: 0.004) G_GAN: 4.525 G_L1: 0.956 D_real: 0.000 D_fake: 0.019 \n",
            "(epoch: 76, iters: 400, time: 0.718, data: 0.002) G_GAN: 8.076 G_L1: 1.798 D_real: 0.001 D_fake: 0.002 \n",
            "(epoch: 76, iters: 500, time: 0.066, data: 0.003) G_GAN: 1.686 G_L1: 2.253 D_real: 0.598 D_fake: 0.484 \n",
            "(epoch: 76, iters: 600, time: 0.067, data: 0.002) G_GAN: 0.853 G_L1: 3.334 D_real: 0.547 D_fake: 0.750 \n",
            "(epoch: 76, iters: 700, time: 0.066, data: 0.006) G_GAN: 2.076 G_L1: 2.607 D_real: 0.723 D_fake: 0.402 \n",
            "(epoch: 76, iters: 800, time: 0.170, data: 0.003) G_GAN: 2.391 G_L1: 1.524 D_real: 0.014 D_fake: 0.434 \n",
            "(epoch: 76, iters: 900, time: 0.066, data: 0.010) G_GAN: 1.737 G_L1: 1.718 D_real: 0.305 D_fake: 0.766 \n",
            "(epoch: 76, iters: 1000, time: 0.063, data: 0.004) G_GAN: 1.011 G_L1: 2.203 D_real: 1.840 D_fake: 0.268 \n",
            "(epoch: 76, iters: 1100, time: 0.067, data: 0.003) G_GAN: 1.733 G_L1: 2.954 D_real: 0.066 D_fake: 1.363 \n",
            "(epoch: 76, iters: 1200, time: 0.221, data: 0.002) G_GAN: 0.987 G_L1: 1.972 D_real: 0.521 D_fake: 0.763 \n",
            "(epoch: 76, iters: 1300, time: 0.067, data: 0.007) G_GAN: 7.163 G_L1: 0.834 D_real: 0.012 D_fake: 0.001 \n",
            "(epoch: 76, iters: 1400, time: 0.067, data: 0.004) G_GAN: 5.827 G_L1: 1.337 D_real: 0.001 D_fake: 0.005 \n",
            "(epoch: 76, iters: 1500, time: 0.067, data: 0.003) G_GAN: 0.778 G_L1: 3.028 D_real: 0.456 D_fake: 0.802 \n",
            "(epoch: 76, iters: 1600, time: 0.172, data: 0.003) G_GAN: 6.509 G_L1: 0.760 D_real: 0.002 D_fake: 0.004 \n",
            "(epoch: 76, iters: 1700, time: 0.066, data: 0.006) G_GAN: 0.726 G_L1: 4.051 D_real: 0.603 D_fake: 0.792 \n",
            "(epoch: 76, iters: 1800, time: 0.066, data: 0.003) G_GAN: 1.737 G_L1: 2.224 D_real: 1.007 D_fake: 0.333 \n",
            "(epoch: 76, iters: 1900, time: 0.066, data: 0.007) G_GAN: 10.061 G_L1: 0.595 D_real: 0.004 D_fake: 0.000 \n",
            "(epoch: 76, iters: 2000, time: 0.546, data: 0.003) G_GAN: 8.262 G_L1: 1.946 D_real: 0.025 D_fake: 0.001 \n",
            "(epoch: 76, iters: 2100, time: 0.067, data: 0.004) G_GAN: 6.230 G_L1: 0.535 D_real: 0.001 D_fake: 0.004 \n",
            "(epoch: 76, iters: 2200, time: 0.065, data: 0.004) G_GAN: 3.347 G_L1: 1.954 D_real: 0.157 D_fake: 0.428 \n",
            "(epoch: 76, iters: 2300, time: 0.066, data: 0.003) G_GAN: 7.613 G_L1: 0.925 D_real: 0.000 D_fake: 0.001 \n",
            "(epoch: 76, iters: 2400, time: 0.168, data: 0.002) G_GAN: 1.513 G_L1: 2.128 D_real: 0.439 D_fake: 0.448 \n",
            "(epoch: 76, iters: 2500, time: 0.066, data: 0.002) G_GAN: 3.795 G_L1: 2.416 D_real: 0.159 D_fake: 0.031 \n",
            "(epoch: 76, iters: 2600, time: 0.067, data: 0.002) G_GAN: 5.569 G_L1: 1.259 D_real: 0.397 D_fake: 0.003 \n",
            "(epoch: 76, iters: 2700, time: 0.067, data: 0.003) G_GAN: 7.506 G_L1: 2.773 D_real: 0.151 D_fake: 0.001 \n",
            "(epoch: 76, iters: 2800, time: 0.171, data: 0.003) G_GAN: 7.517 G_L1: 1.504 D_real: 0.001 D_fake: 0.001 \n",
            "(epoch: 76, iters: 2900, time: 0.067, data: 0.002) G_GAN: 3.143 G_L1: 1.596 D_real: 0.059 D_fake: 0.103 \n",
            "(epoch: 76, iters: 3000, time: 0.066, data: 0.003) G_GAN: 2.496 G_L1: 1.525 D_real: 0.290 D_fake: 0.178 \n",
            "(epoch: 76, iters: 3100, time: 0.066, data: 0.004) G_GAN: 5.272 G_L1: 0.706 D_real: 0.424 D_fake: 0.002 \n",
            "(epoch: 76, iters: 3200, time: 0.222, data: 0.005) G_GAN: 0.853 G_L1: 2.597 D_real: 1.107 D_fake: 0.460 \n",
            "(epoch: 76, iters: 3300, time: 0.066, data: 0.003) G_GAN: 2.880 G_L1: 1.214 D_real: 0.188 D_fake: 0.395 \n",
            "(epoch: 76, iters: 3400, time: 0.066, data: 0.004) G_GAN: 0.658 G_L1: 1.957 D_real: 0.669 D_fake: 0.826 \n",
            "(epoch: 76, iters: 3500, time: 0.067, data: 0.005) G_GAN: 8.680 G_L1: 0.744 D_real: 0.001 D_fake: 0.000 \n",
            "(epoch: 76, iters: 3600, time: 0.183, data: 0.004) G_GAN: 2.213 G_L1: 3.529 D_real: 0.032 D_fake: 0.378 \n",
            "(epoch: 76, iters: 3700, time: 0.066, data: 0.002) G_GAN: 1.097 G_L1: 1.921 D_real: 0.412 D_fake: 0.648 \n",
            "(epoch: 76, iters: 3800, time: 0.066, data: 0.003) G_GAN: 6.206 G_L1: 0.935 D_real: 0.134 D_fake: 0.003 \n",
            "(epoch: 76, iters: 3900, time: 0.065, data: 0.003) G_GAN: 4.326 G_L1: 1.851 D_real: 0.064 D_fake: 0.026 \n",
            "(epoch: 76, iters: 4000, time: 0.455, data: 0.003) G_GAN: 6.555 G_L1: 1.042 D_real: 0.579 D_fake: 0.001 \n",
            "End of epoch 76 / 200 \t Time Taken: 174 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "(epoch: 77, iters: 100, time: 0.067, data: 0.232) G_GAN: 1.284 G_L1: 3.445 D_real: 0.128 D_fake: 0.636 \n",
            "(epoch: 77, iters: 200, time: 0.066, data: 0.004) G_GAN: 0.737 G_L1: 2.636 D_real: 0.673 D_fake: 0.762 \n",
            "(epoch: 77, iters: 300, time: 0.066, data: 0.002) G_GAN: 1.162 G_L1: 2.305 D_real: 0.694 D_fake: 0.358 \n",
            "(epoch: 77, iters: 400, time: 0.584, data: 0.002) G_GAN: 5.056 G_L1: 1.796 D_real: 0.215 D_fake: 0.009 \n",
            "(epoch: 77, iters: 500, time: 0.067, data: 0.006) G_GAN: 0.773 G_L1: 3.800 D_real: 0.618 D_fake: 0.895 \n",
            "(epoch: 77, iters: 600, time: 0.067, data: 0.004) G_GAN: 5.934 G_L1: 1.459 D_real: 0.059 D_fake: 0.004 \n",
            "(epoch: 77, iters: 700, time: 0.067, data: 0.003) G_GAN: 5.869 G_L1: 1.111 D_real: 0.001 D_fake: 0.004 \n",
            "(epoch: 77, iters: 800, time: 0.182, data: 0.004) G_GAN: 1.819 G_L1: 1.619 D_real: 0.353 D_fake: 1.165 \n",
            "(epoch: 77, iters: 900, time: 0.067, data: 0.002) G_GAN: 0.993 G_L1: 1.945 D_real: 0.724 D_fake: 0.672 \n",
            "(epoch: 77, iters: 1000, time: 0.067, data: 0.002) G_GAN: 3.170 G_L1: 4.931 D_real: 0.454 D_fake: 0.076 \n",
            "saving the latest model (epoch 77, total_iters 305000)\n",
            "(epoch: 77, iters: 1100, time: 0.067, data: 0.005) G_GAN: 0.539 G_L1: 2.638 D_real: 0.274 D_fake: 1.441 \n",
            "(epoch: 77, iters: 1200, time: 0.174, data: 0.004) G_GAN: 6.000 G_L1: 1.349 D_real: 0.001 D_fake: 0.005 \n",
            "(epoch: 77, iters: 1300, time: 0.063, data: 0.004) G_GAN: 1.102 G_L1: 1.654 D_real: 0.420 D_fake: 0.634 \n",
            "(epoch: 77, iters: 1400, time: 0.066, data: 0.004) G_GAN: 4.716 G_L1: 3.138 D_real: 0.179 D_fake: 0.044 \n",
            "(epoch: 77, iters: 1500, time: 0.059, data: 0.003) G_GAN: 7.695 G_L1: 0.865 D_real: 0.002 D_fake: 0.001 \n",
            "(epoch: 77, iters: 1600, time: 0.155, data: 0.003) G_GAN: 7.193 G_L1: 0.741 D_real: 0.004 D_fake: 0.001 \n",
            "(epoch: 77, iters: 1700, time: 0.066, data: 0.007) G_GAN: 2.506 G_L1: 3.374 D_real: 1.375 D_fake: 0.353 \n",
            "(epoch: 77, iters: 1800, time: 0.065, data: 0.003) G_GAN: 4.881 G_L1: 1.696 D_real: 0.046 D_fake: 0.012 \n",
            "(epoch: 77, iters: 1900, time: 0.067, data: 0.004) G_GAN: 2.409 G_L1: 2.314 D_real: 0.114 D_fake: 0.919 \n",
            "(epoch: 77, iters: 2000, time: 0.516, data: 0.004) G_GAN: 1.230 G_L1: 1.984 D_real: 0.270 D_fake: 0.531 \n",
            "(epoch: 77, iters: 2100, time: 0.066, data: 0.003) G_GAN: 0.778 G_L1: 3.046 D_real: 0.559 D_fake: 0.775 \n",
            "(epoch: 77, iters: 2200, time: 0.067, data: 0.003) G_GAN: 1.937 G_L1: 2.209 D_real: 0.404 D_fake: 0.183 \n",
            "(epoch: 77, iters: 2300, time: 0.067, data: 0.004) G_GAN: 5.397 G_L1: 2.083 D_real: 0.071 D_fake: 0.005 \n",
            "(epoch: 77, iters: 2400, time: 0.159, data: 0.002) G_GAN: 9.313 G_L1: 0.718 D_real: 0.028 D_fake: 0.000 \n",
            "(epoch: 77, iters: 2500, time: 0.066, data: 0.007) G_GAN: 0.891 G_L1: 2.382 D_real: 0.843 D_fake: 0.570 \n",
            "(epoch: 77, iters: 2600, time: 0.066, data: 0.004) G_GAN: 1.468 G_L1: 2.132 D_real: 0.550 D_fake: 0.329 \n",
            "(epoch: 77, iters: 2700, time: 0.058, data: 0.007) G_GAN: 2.372 G_L1: 1.695 D_real: 0.106 D_fake: 0.209 \n",
            "(epoch: 77, iters: 2800, time: 0.215, data: 0.002) G_GAN: 0.818 G_L1: 2.819 D_real: 0.960 D_fake: 0.466 \n",
            "(epoch: 77, iters: 2900, time: 0.067, data: 0.006) G_GAN: 0.974 G_L1: 1.322 D_real: 0.353 D_fake: 0.882 \n",
            "(epoch: 77, iters: 3000, time: 0.067, data: 0.004) G_GAN: 6.065 G_L1: 1.491 D_real: 0.023 D_fake: 0.004 \n",
            "(epoch: 77, iters: 3100, time: 0.064, data: 0.003) G_GAN: 3.769 G_L1: 1.132 D_real: 0.028 D_fake: 1.417 \n",
            "(epoch: 77, iters: 3200, time: 0.187, data: 0.004) G_GAN: 4.143 G_L1: 0.994 D_real: 2.126 D_fake: 0.006 \n",
            "(epoch: 77, iters: 3300, time: 0.066, data: 0.006) G_GAN: 1.283 G_L1: 1.727 D_real: 0.593 D_fake: 0.536 \n",
            "(epoch: 77, iters: 3400, time: 0.066, data: 0.003) G_GAN: 1.039 G_L1: 2.002 D_real: 0.996 D_fake: 0.417 \n",
            "(epoch: 77, iters: 3500, time: 0.065, data: 0.003) G_GAN: 7.386 G_L1: 1.897 D_real: 0.003 D_fake: 0.001 \n",
            "(epoch: 77, iters: 3600, time: 0.162, data: 0.004) G_GAN: 6.837 G_L1: 0.972 D_real: 0.002 D_fake: 0.002 \n",
            "(epoch: 77, iters: 3700, time: 0.067, data: 0.003) G_GAN: 0.915 G_L1: 2.200 D_real: 0.714 D_fake: 0.651 \n",
            "(epoch: 77, iters: 3800, time: 0.067, data: 0.002) G_GAN: 1.896 G_L1: 2.365 D_real: 0.296 D_fake: 0.459 \n",
            "(epoch: 77, iters: 3900, time: 0.065, data: 0.003) G_GAN: 3.082 G_L1: 1.655 D_real: 0.220 D_fake: 0.077 \n",
            "(epoch: 77, iters: 4000, time: 0.510, data: 0.002) G_GAN: 1.267 G_L1: 3.568 D_real: 1.214 D_fake: 0.263 \n",
            "End of epoch 77 / 200 \t Time Taken: 174 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "(epoch: 78, iters: 100, time: 0.066, data: 0.207) G_GAN: 3.525 G_L1: 2.237 D_real: 0.762 D_fake: 0.040 \n",
            "(epoch: 78, iters: 200, time: 0.065, data: 0.008) G_GAN: 5.909 G_L1: 3.046 D_real: 0.103 D_fake: 0.004 \n",
            "(epoch: 78, iters: 300, time: 0.066, data: 0.005) G_GAN: 1.020 G_L1: 3.266 D_real: 0.515 D_fake: 0.661 \n",
            "(epoch: 78, iters: 400, time: 0.646, data: 0.004) G_GAN: 1.988 G_L1: 0.861 D_real: 0.112 D_fake: 1.042 \n",
            "(epoch: 78, iters: 500, time: 0.067, data: 0.008) G_GAN: 1.938 G_L1: 2.892 D_real: 0.106 D_fake: 0.614 \n",
            "(epoch: 78, iters: 600, time: 0.067, data: 0.007) G_GAN: 1.894 G_L1: 1.463 D_real: 0.133 D_fake: 0.556 \n",
            "(epoch: 78, iters: 700, time: 0.067, data: 0.004) G_GAN: 0.715 G_L1: 2.539 D_real: 0.486 D_fake: 0.941 \n",
            "(epoch: 78, iters: 800, time: 0.217, data: 0.003) G_GAN: 1.018 G_L1: 2.544 D_real: 0.802 D_fake: 0.492 \n",
            "(epoch: 78, iters: 900, time: 0.065, data: 0.002) G_GAN: 3.092 G_L1: 0.875 D_real: 0.015 D_fake: 0.262 \n",
            "(epoch: 78, iters: 1000, time: 0.063, data: 0.003) G_GAN: 2.849 G_L1: 3.517 D_real: 0.136 D_fake: 0.105 \n",
            "(epoch: 78, iters: 1100, time: 0.066, data: 0.004) G_GAN: 5.825 G_L1: 1.326 D_real: 0.787 D_fake: 0.199 \n",
            "(epoch: 78, iters: 1200, time: 0.182, data: 0.003) G_GAN: 2.965 G_L1: 3.002 D_real: 0.021 D_fake: 0.090 \n",
            "(epoch: 78, iters: 1300, time: 0.066, data: 0.003) G_GAN: 1.743 G_L1: 1.945 D_real: 0.053 D_fake: 1.270 \n",
            "(epoch: 78, iters: 1400, time: 0.066, data: 0.003) G_GAN: 9.111 G_L1: 1.293 D_real: 0.001 D_fake: 0.000 \n",
            "(epoch: 78, iters: 1500, time: 0.065, data: 0.003) G_GAN: 1.486 G_L1: 1.936 D_real: 0.288 D_fake: 1.155 \n",
            "(epoch: 78, iters: 1600, time: 0.168, data: 0.003) G_GAN: 1.549 G_L1: 1.397 D_real: 0.888 D_fake: 0.247 \n",
            "(epoch: 78, iters: 1700, time: 0.067, data: 0.009) G_GAN: 2.184 G_L1: 0.894 D_real: 0.167 D_fake: 0.244 \n",
            "(epoch: 78, iters: 1800, time: 0.065, data: 0.004) G_GAN: 2.855 G_L1: 0.670 D_real: 0.023 D_fake: 0.393 \n",
            "(epoch: 78, iters: 1900, time: 0.067, data: 0.003) G_GAN: 5.668 G_L1: 0.540 D_real: 0.001 D_fake: 0.007 \n",
            "(epoch: 78, iters: 2000, time: 0.529, data: 0.004) G_GAN: 0.705 G_L1: 2.285 D_real: 0.989 D_fake: 0.659 \n",
            "saving the latest model (epoch 78, total_iters 310000)\n",
            "(epoch: 78, iters: 2100, time: 0.067, data: 0.002) G_GAN: 6.092 G_L1: 1.223 D_real: 0.012 D_fake: 0.005 \n",
            "(epoch: 78, iters: 2200, time: 0.067, data: 0.004) G_GAN: 0.905 G_L1: 3.996 D_real: 0.807 D_fake: 0.491 \n",
            "(epoch: 78, iters: 2300, time: 0.066, data: 0.005) G_GAN: 4.521 G_L1: 2.668 D_real: 0.064 D_fake: 0.018 \n",
            "(epoch: 78, iters: 2400, time: 0.185, data: 0.003) G_GAN: 5.122 G_L1: 1.414 D_real: 0.029 D_fake: 0.009 \n",
            "(epoch: 78, iters: 2500, time: 0.066, data: 0.002) G_GAN: 2.868 G_L1: 1.762 D_real: 0.088 D_fake: 0.210 \n",
            "(epoch: 78, iters: 2600, time: 0.066, data: 0.003) G_GAN: 4.013 G_L1: 1.146 D_real: 0.004 D_fake: 0.033 \n",
            "(epoch: 78, iters: 2700, time: 0.066, data: 0.003) G_GAN: 2.474 G_L1: 1.767 D_real: 0.166 D_fake: 0.507 \n",
            "(epoch: 78, iters: 2800, time: 0.218, data: 0.002) G_GAN: 0.884 G_L1: 2.029 D_real: 0.885 D_fake: 0.491 \n",
            "(epoch: 78, iters: 2900, time: 0.064, data: 0.003) G_GAN: 8.714 G_L1: 1.118 D_real: 0.000 D_fake: 0.000 \n",
            "(epoch: 78, iters: 3000, time: 0.067, data: 0.004) G_GAN: 5.770 G_L1: 0.663 D_real: 0.000 D_fake: 0.005 \n",
            "(epoch: 78, iters: 3100, time: 0.066, data: 0.004) G_GAN: 0.966 G_L1: 3.075 D_real: 0.744 D_fake: 0.471 \n",
            "(epoch: 78, iters: 3200, time: 0.167, data: 0.004) G_GAN: 2.865 G_L1: 1.165 D_real: 0.021 D_fake: 1.507 \n",
            "(epoch: 78, iters: 3300, time: 0.057, data: 0.016) G_GAN: 2.313 G_L1: 3.226 D_real: 0.015 D_fake: 0.208 \n",
            "(epoch: 78, iters: 3400, time: 0.066, data: 0.004) G_GAN: 0.899 G_L1: 1.949 D_real: 0.506 D_fake: 0.922 \n",
            "(epoch: 78, iters: 3500, time: 0.067, data: 0.005) G_GAN: 1.275 G_L1: 2.034 D_real: 1.324 D_fake: 0.231 \n",
            "(epoch: 78, iters: 3600, time: 0.166, data: 0.006) G_GAN: 2.568 G_L1: 3.208 D_real: 0.981 D_fake: 0.082 \n",
            "(epoch: 78, iters: 3700, time: 0.066, data: 0.006) G_GAN: 2.952 G_L1: 2.495 D_real: 0.167 D_fake: 0.079 \n",
            "(epoch: 78, iters: 3800, time: 0.066, data: 0.005) G_GAN: 1.165 G_L1: 1.992 D_real: 0.543 D_fake: 0.863 \n",
            "(epoch: 78, iters: 3900, time: 0.065, data: 0.002) G_GAN: 2.874 G_L1: 2.935 D_real: 0.559 D_fake: 0.154 \n",
            "(epoch: 78, iters: 4000, time: 0.526, data: 0.003) G_GAN: 0.855 G_L1: 1.742 D_real: 0.416 D_fake: 0.837 \n",
            "End of epoch 78 / 200 \t Time Taken: 175 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "(epoch: 79, iters: 100, time: 0.066, data: 0.223) G_GAN: 1.017 G_L1: 2.299 D_real: 1.091 D_fake: 0.383 \n",
            "(epoch: 79, iters: 200, time: 0.067, data: 0.004) G_GAN: 1.403 G_L1: 2.148 D_real: 0.645 D_fake: 0.396 \n",
            "(epoch: 79, iters: 300, time: 0.066, data: 0.003) G_GAN: 2.668 G_L1: 1.835 D_real: 0.468 D_fake: 0.151 \n",
            "(epoch: 79, iters: 400, time: 0.559, data: 0.003) G_GAN: 5.716 G_L1: 0.696 D_real: 0.000 D_fake: 0.006 \n",
            "(epoch: 79, iters: 500, time: 0.063, data: 0.003) G_GAN: 2.080 G_L1: 2.068 D_real: 0.344 D_fake: 0.260 \n",
            "(epoch: 79, iters: 600, time: 0.065, data: 0.002) G_GAN: 3.029 G_L1: 2.479 D_real: 0.551 D_fake: 0.046 \n",
            "(epoch: 79, iters: 700, time: 0.060, data: 0.002) G_GAN: 4.383 G_L1: 1.593 D_real: 0.416 D_fake: 0.008 \n",
            "(epoch: 79, iters: 800, time: 0.180, data: 0.004) G_GAN: 2.711 G_L1: 2.665 D_real: 1.352 D_fake: 1.451 \n",
            "(epoch: 79, iters: 900, time: 0.066, data: 0.002) G_GAN: 3.167 G_L1: 1.234 D_real: 0.168 D_fake: 0.056 \n",
            "(epoch: 79, iters: 1000, time: 0.063, data: 0.003) G_GAN: 0.234 G_L1: 3.363 D_real: 1.089 D_fake: 0.285 \n",
            "(epoch: 79, iters: 1100, time: 0.067, data: 0.003) G_GAN: 0.794 G_L1: 3.530 D_real: 0.373 D_fake: 0.968 \n",
            "(epoch: 79, iters: 1200, time: 0.162, data: 0.003) G_GAN: 1.668 G_L1: 1.549 D_real: 0.725 D_fake: 0.483 \n",
            "(epoch: 79, iters: 1300, time: 0.064, data: 0.004) G_GAN: 0.689 G_L1: 2.866 D_real: 0.491 D_fake: 0.985 \n",
            "(epoch: 79, iters: 1400, time: 0.065, data: 0.004) G_GAN: 4.118 G_L1: 1.110 D_real: 0.061 D_fake: 0.023 \n",
            "(epoch: 79, iters: 1500, time: 0.066, data: 0.004) G_GAN: 2.196 G_L1: 1.816 D_real: 0.461 D_fake: 0.235 \n",
            "(epoch: 79, iters: 1600, time: 0.182, data: 0.003) G_GAN: 3.693 G_L1: 1.257 D_real: 0.121 D_fake: 0.040 \n",
            "(epoch: 79, iters: 1700, time: 0.066, data: 0.009) G_GAN: 5.702 G_L1: 0.991 D_real: 0.078 D_fake: 0.007 \n",
            "(epoch: 79, iters: 1800, time: 0.067, data: 0.003) G_GAN: 5.478 G_L1: 2.715 D_real: 0.207 D_fake: 0.008 \n",
            "(epoch: 79, iters: 1900, time: 0.066, data: 0.007) G_GAN: 8.111 G_L1: 0.972 D_real: 0.005 D_fake: 0.001 \n",
            "(epoch: 79, iters: 2000, time: 0.633, data: 0.003) G_GAN: 0.635 G_L1: 2.704 D_real: 0.510 D_fake: 0.986 \n",
            "(epoch: 79, iters: 2100, time: 0.065, data: 0.003) G_GAN: 5.280 G_L1: 0.541 D_real: 0.001 D_fake: 0.008 \n",
            "(epoch: 79, iters: 2200, time: 0.066, data: 0.003) G_GAN: 3.426 G_L1: 2.472 D_real: 0.336 D_fake: 0.030 \n",
            "(epoch: 79, iters: 2300, time: 0.066, data: 0.003) G_GAN: 8.929 G_L1: 1.236 D_real: 0.000 D_fake: 0.000 \n",
            "(epoch: 79, iters: 2400, time: 0.178, data: 0.003) G_GAN: 4.280 G_L1: 2.726 D_real: 0.278 D_fake: 0.043 \n",
            "(epoch: 79, iters: 2500, time: 0.066, data: 0.002) G_GAN: 2.743 G_L1: 2.905 D_real: 0.095 D_fake: 0.157 \n",
            "(epoch: 79, iters: 2600, time: 0.066, data: 0.006) G_GAN: 6.117 G_L1: 0.989 D_real: 0.000 D_fake: 0.004 \n",
            "(epoch: 79, iters: 2700, time: 0.067, data: 0.004) G_GAN: 2.477 G_L1: 1.247 D_real: 0.605 D_fake: 0.194 \n",
            "(epoch: 79, iters: 2800, time: 0.157, data: 0.004) G_GAN: 9.406 G_L1: 0.683 D_real: 0.000 D_fake: 0.000 \n",
            "(epoch: 79, iters: 2900, time: 0.066, data: 0.002) G_GAN: 6.876 G_L1: 1.238 D_real: 0.419 D_fake: 0.001 \n",
            "(epoch: 79, iters: 3000, time: 0.066, data: 0.004) G_GAN: 8.889 G_L1: 0.581 D_real: 0.001 D_fake: 0.000 \n",
            "saving the latest model (epoch 79, total_iters 315000)\n",
            "(epoch: 79, iters: 3100, time: 0.067, data: 0.002) G_GAN: 0.898 G_L1: 3.270 D_real: 0.612 D_fake: 0.640 \n",
            "(epoch: 79, iters: 3200, time: 0.164, data: 0.003) G_GAN: 5.543 G_L1: 1.661 D_real: 0.000 D_fake: 0.006 \n",
            "(epoch: 79, iters: 3300, time: 0.066, data: 0.002) G_GAN: 6.880 G_L1: 0.523 D_real: 0.002 D_fake: 0.002 \n",
            "(epoch: 79, iters: 3400, time: 0.066, data: 0.002) G_GAN: 0.925 G_L1: 4.191 D_real: 0.850 D_fake: 0.553 \n",
            "(epoch: 79, iters: 3500, time: 0.067, data: 0.004) G_GAN: 7.854 G_L1: 1.386 D_real: 0.001 D_fake: 0.001 \n",
            "(epoch: 79, iters: 3600, time: 0.220, data: 0.002) G_GAN: 0.806 G_L1: 3.427 D_real: 0.779 D_fake: 0.630 \n",
            "(epoch: 79, iters: 3700, time: 0.066, data: 0.002) G_GAN: 1.192 G_L1: 4.137 D_real: 0.095 D_fake: 3.668 \n",
            "(epoch: 79, iters: 3800, time: 0.066, data: 0.004) G_GAN: 1.573 G_L1: 2.001 D_real: 0.479 D_fake: 0.397 \n",
            "(epoch: 79, iters: 3900, time: 0.066, data: 0.003) G_GAN: 0.755 G_L1: 2.543 D_real: 0.657 D_fake: 0.886 \n",
            "(epoch: 79, iters: 4000, time: 0.464, data: 0.003) G_GAN: 2.923 G_L1: 1.101 D_real: 0.245 D_fake: 0.141 \n",
            "End of epoch 79 / 200 \t Time Taken: 175 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "(epoch: 80, iters: 100, time: 0.067, data: 0.184) G_GAN: 0.809 G_L1: 1.976 D_real: 0.638 D_fake: 0.737 \n",
            "(epoch: 80, iters: 200, time: 0.062, data: 0.003) G_GAN: 3.363 G_L1: 1.872 D_real: 0.065 D_fake: 0.085 \n",
            "(epoch: 80, iters: 300, time: 0.066, data: 0.004) G_GAN: 4.478 G_L1: 1.851 D_real: 0.062 D_fake: 0.021 \n",
            "(epoch: 80, iters: 400, time: 0.535, data: 0.004) G_GAN: 4.601 G_L1: 0.531 D_real: 0.000 D_fake: 0.015 \n",
            "(epoch: 80, iters: 500, time: 0.058, data: 0.002) G_GAN: 7.905 G_L1: 0.877 D_real: 0.000 D_fake: 0.001 \n",
            "(epoch: 80, iters: 600, time: 0.066, data: 0.003) G_GAN: 1.411 G_L1: 2.943 D_real: 0.264 D_fake: 0.542 \n",
            "(epoch: 80, iters: 700, time: 0.065, data: 0.002) G_GAN: 0.894 G_L1: 2.911 D_real: 1.249 D_fake: 0.415 \n",
            "(epoch: 80, iters: 800, time: 0.177, data: 0.003) G_GAN: 3.399 G_L1: 1.107 D_real: 0.120 D_fake: 0.293 \n",
            "(epoch: 80, iters: 900, time: 0.066, data: 0.002) G_GAN: 7.472 G_L1: 1.412 D_real: 0.001 D_fake: 0.001 \n",
            "(epoch: 80, iters: 1000, time: 0.064, data: 0.005) G_GAN: 3.338 G_L1: 1.782 D_real: 0.075 D_fake: 0.177 \n",
            "(epoch: 80, iters: 1100, time: 0.066, data: 0.003) G_GAN: 4.499 G_L1: 0.544 D_real: 0.001 D_fake: 0.023 \n",
            "(epoch: 80, iters: 1200, time: 0.174, data: 0.004) G_GAN: 1.357 G_L1: 1.665 D_real: 0.708 D_fake: 0.955 \n",
            "(epoch: 80, iters: 1300, time: 0.061, data: 0.002) G_GAN: 1.705 G_L1: 1.642 D_real: 0.010 D_fake: 0.793 \n",
            "(epoch: 80, iters: 1400, time: 0.066, data: 0.003) G_GAN: 0.961 G_L1: 7.246 D_real: 0.692 D_fake: 0.475 \n",
            "(epoch: 80, iters: 1500, time: 0.066, data: 0.002) G_GAN: 0.893 G_L1: 1.936 D_real: 0.836 D_fake: 0.586 \n",
            "(epoch: 80, iters: 1600, time: 0.157, data: 0.004) G_GAN: 7.779 G_L1: 1.037 D_real: 0.002 D_fake: 0.001 \n",
            "(epoch: 80, iters: 1700, time: 0.066, data: 0.007) G_GAN: 5.013 G_L1: 0.656 D_real: 0.001 D_fake: 0.017 \n",
            "(epoch: 80, iters: 1800, time: 0.065, data: 0.003) G_GAN: 0.885 G_L1: 2.914 D_real: 0.775 D_fake: 0.572 \n",
            "(epoch: 80, iters: 1900, time: 0.058, data: 0.004) G_GAN: 5.299 G_L1: 2.425 D_real: 0.407 D_fake: 0.012 \n",
            "(epoch: 80, iters: 2000, time: 0.508, data: 0.004) G_GAN: 1.304 G_L1: 1.755 D_real: 0.672 D_fake: 0.303 \n",
            "(epoch: 80, iters: 2100, time: 0.066, data: 0.003) G_GAN: 4.452 G_L1: 1.671 D_real: 0.372 D_fake: 0.007 \n",
            "(epoch: 80, iters: 2200, time: 0.055, data: 0.003) G_GAN: 6.201 G_L1: 1.296 D_real: 0.034 D_fake: 0.003 \n",
            "(epoch: 80, iters: 2300, time: 0.066, data: 0.003) G_GAN: 4.159 G_L1: 0.697 D_real: 0.000 D_fake: 0.028 \n",
            "(epoch: 80, iters: 2400, time: 0.171, data: 0.004) G_GAN: 7.474 G_L1: 2.606 D_real: 1.393 D_fake: 0.001 \n",
            "(epoch: 80, iters: 2500, time: 0.066, data: 0.003) G_GAN: 2.542 G_L1: 5.225 D_real: 0.152 D_fake: 0.125 \n",
            "(epoch: 80, iters: 2600, time: 0.067, data: 0.003) G_GAN: 2.065 G_L1: 2.231 D_real: 0.189 D_fake: 0.472 \n",
            "(epoch: 80, iters: 2700, time: 0.067, data: 0.004) G_GAN: 0.668 G_L1: 2.256 D_real: 0.547 D_fake: 0.907 \n",
            "(epoch: 80, iters: 2800, time: 0.217, data: 0.003) G_GAN: 0.771 G_L1: 1.970 D_real: 0.751 D_fake: 0.697 \n",
            "(epoch: 80, iters: 2900, time: 0.066, data: 0.002) G_GAN: 7.778 G_L1: 1.327 D_real: 0.121 D_fake: 0.001 \n",
            "(epoch: 80, iters: 3000, time: 0.066, data: 0.003) G_GAN: 3.181 G_L1: 1.224 D_real: 0.662 D_fake: 0.062 \n",
            "(epoch: 80, iters: 3100, time: 0.066, data: 0.003) G_GAN: 2.264 G_L1: 1.089 D_real: 0.191 D_fake: 0.387 \n",
            "(epoch: 80, iters: 3200, time: 0.176, data: 0.004) G_GAN: 5.461 G_L1: 1.298 D_real: 0.000 D_fake: 0.007 \n",
            "(epoch: 80, iters: 3300, time: 0.066, data: 0.004) G_GAN: 4.864 G_L1: 0.468 D_real: 0.002 D_fake: 0.017 \n",
            "(epoch: 80, iters: 3400, time: 0.067, data: 0.005) G_GAN: 0.812 G_L1: 2.842 D_real: 0.718 D_fake: 0.613 \n",
            "(epoch: 80, iters: 3500, time: 0.067, data: 0.003) G_GAN: 7.453 G_L1: 0.700 D_real: 0.001 D_fake: 0.001 \n",
            "(epoch: 80, iters: 3600, time: 0.215, data: 0.004) G_GAN: 0.840 G_L1: 3.382 D_real: 0.865 D_fake: 0.677 \n",
            "(epoch: 80, iters: 3700, time: 0.067, data: 0.002) G_GAN: 0.766 G_L1: 2.689 D_real: 0.943 D_fake: 0.739 \n",
            "(epoch: 80, iters: 3800, time: 0.067, data: 0.004) G_GAN: 1.031 G_L1: 1.966 D_real: 0.387 D_fake: 0.920 \n",
            "(epoch: 80, iters: 3900, time: 0.066, data: 0.002) G_GAN: 4.993 G_L1: 0.991 D_real: 0.000 D_fake: 0.014 \n",
            "(epoch: 80, iters: 4000, time: 0.550, data: 0.005) G_GAN: 1.451 G_L1: 1.700 D_real: 1.284 D_fake: 0.268 \n",
            "saving the latest model (epoch 80, total_iters 320000)\n",
            "saving the model at the end of epoch 80, iters 320000\n",
            "End of epoch 80 / 200 \t Time Taken: 176 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "(epoch: 81, iters: 100, time: 0.067, data: 0.241) G_GAN: 2.632 G_L1: 1.705 D_real: 0.053 D_fake: 0.172 \n",
            "(epoch: 81, iters: 200, time: 0.066, data: 0.002) G_GAN: 6.753 G_L1: 2.359 D_real: 0.119 D_fake: 0.003 \n",
            "(epoch: 81, iters: 300, time: 0.066, data: 0.005) G_GAN: 1.318 G_L1: 3.543 D_real: 0.975 D_fake: 0.377 \n",
            "(epoch: 81, iters: 400, time: 0.647, data: 0.004) G_GAN: 0.797 G_L1: 1.743 D_real: 0.608 D_fake: 0.674 \n",
            "(epoch: 81, iters: 500, time: 0.066, data: 0.003) G_GAN: 1.559 G_L1: 2.136 D_real: 0.136 D_fake: 1.073 \n",
            "(epoch: 81, iters: 600, time: 0.066, data: 0.004) G_GAN: 0.810 G_L1: 1.947 D_real: 0.568 D_fake: 0.686 \n",
            "(epoch: 81, iters: 700, time: 0.066, data: 0.003) G_GAN: 2.417 G_L1: 2.616 D_real: 0.210 D_fake: 0.193 \n",
            "(epoch: 81, iters: 800, time: 0.170, data: 0.003) G_GAN: 1.590 G_L1: 3.752 D_real: 0.364 D_fake: 0.850 \n",
            "(epoch: 81, iters: 900, time: 0.066, data: 0.002) G_GAN: 2.509 G_L1: 6.287 D_real: 0.067 D_fake: 0.221 \n",
            "(epoch: 81, iters: 1000, time: 0.060, data: 0.003) G_GAN: 1.736 G_L1: 1.601 D_real: 0.370 D_fake: 0.339 \n",
            "(epoch: 81, iters: 1100, time: 0.066, data: 0.003) G_GAN: 0.799 G_L1: 2.502 D_real: 0.788 D_fake: 0.656 \n",
            "(epoch: 81, iters: 1200, time: 0.162, data: 0.004) G_GAN: 1.571 G_L1: 2.228 D_real: 0.276 D_fake: 0.524 \n",
            "(epoch: 81, iters: 1300, time: 0.066, data: 0.006) G_GAN: 4.804 G_L1: 1.313 D_real: 0.095 D_fake: 0.013 \n",
            "(epoch: 81, iters: 1400, time: 0.067, data: 0.004) G_GAN: 2.504 G_L1: 2.756 D_real: 0.057 D_fake: 0.290 \n",
            "(epoch: 81, iters: 1500, time: 0.066, data: 0.002) G_GAN: 2.173 G_L1: 1.244 D_real: 0.390 D_fake: 0.801 \n",
            "(epoch: 81, iters: 1600, time: 0.164, data: 0.003) G_GAN: 2.943 G_L1: 2.389 D_real: 0.044 D_fake: 0.136 \n",
            "(epoch: 81, iters: 1700, time: 0.066, data: 0.003) G_GAN: 3.076 G_L1: 1.631 D_real: 0.034 D_fake: 1.774 \n",
            "(epoch: 81, iters: 1800, time: 0.067, data: 0.005) G_GAN: 0.790 G_L1: 0.788 D_real: 1.447 D_fake: 0.485 \n",
            "(epoch: 81, iters: 1900, time: 0.067, data: 0.003) G_GAN: 1.518 G_L1: 1.399 D_real: 0.255 D_fake: 0.934 \n",
            "(epoch: 81, iters: 2000, time: 0.533, data: 0.003) G_GAN: 0.885 G_L1: 1.957 D_real: 0.707 D_fake: 0.692 \n",
            "(epoch: 81, iters: 2100, time: 0.063, data: 0.006) G_GAN: 5.914 G_L1: 2.769 D_real: 0.089 D_fake: 0.004 \n",
            "(epoch: 81, iters: 2200, time: 0.064, data: 0.004) G_GAN: 5.301 G_L1: 2.119 D_real: 0.074 D_fake: 0.007 \n",
            "(epoch: 81, iters: 2300, time: 0.061, data: 0.003) G_GAN: 2.609 G_L1: 2.464 D_real: 0.038 D_fake: 0.159 \n",
            "(epoch: 81, iters: 2400, time: 0.158, data: 0.004) G_GAN: 6.654 G_L1: 0.564 D_real: 0.002 D_fake: 0.003 \n",
            "(epoch: 81, iters: 2500, time: 0.066, data: 0.003) G_GAN: 0.741 G_L1: 2.423 D_real: 0.453 D_fake: 0.938 \n",
            "(epoch: 81, iters: 2600, time: 0.067, data: 0.004) G_GAN: 0.961 G_L1: 1.886 D_real: 0.489 D_fake: 0.661 \n",
            "(epoch: 81, iters: 2700, time: 0.065, data: 0.003) G_GAN: 1.923 G_L1: 2.097 D_real: 0.246 D_fake: 1.323 \n",
            "(epoch: 81, iters: 2800, time: 0.186, data: 0.004) G_GAN: 2.779 G_L1: 1.358 D_real: 0.107 D_fake: 0.912 \n",
            "(epoch: 81, iters: 2900, time: 0.066, data: 0.008) G_GAN: 8.936 G_L1: 3.249 D_real: 0.133 D_fake: 0.000 \n",
            "(epoch: 81, iters: 3000, time: 0.064, data: 0.005) G_GAN: 4.512 G_L1: 0.934 D_real: 0.050 D_fake: 0.018 \n",
            "(epoch: 81, iters: 3100, time: 0.066, data: 0.005) G_GAN: 9.036 G_L1: 0.954 D_real: 0.000 D_fake: 0.000 \n",
            "(epoch: 81, iters: 3200, time: 0.175, data: 0.009) G_GAN: 4.724 G_L1: 1.454 D_real: 0.101 D_fake: 0.012 \n",
            "(epoch: 81, iters: 3300, time: 0.066, data: 0.002) G_GAN: 1.000 G_L1: 4.059 D_real: 1.142 D_fake: 0.413 \n",
            "(epoch: 81, iters: 3400, time: 0.066, data: 0.004) G_GAN: 3.743 G_L1: 1.165 D_real: 0.160 D_fake: 0.061 \n",
            "(epoch: 81, iters: 3500, time: 0.066, data: 0.002) G_GAN: 2.040 G_L1: 1.075 D_real: 0.260 D_fake: 0.976 \n",
            "(epoch: 81, iters: 3600, time: 0.171, data: 0.003) G_GAN: 4.913 G_L1: 1.104 D_real: 0.100 D_fake: 0.011 \n",
            "(epoch: 81, iters: 3700, time: 0.066, data: 0.005) G_GAN: 0.886 G_L1: 2.402 D_real: 0.723 D_fake: 0.694 \n",
            "(epoch: 81, iters: 3800, time: 0.062, data: 0.003) G_GAN: 0.774 G_L1: 2.427 D_real: 0.657 D_fake: 0.717 \n",
            "(epoch: 81, iters: 3900, time: 0.066, data: 0.002) G_GAN: 3.084 G_L1: 4.017 D_real: 0.082 D_fake: 0.241 \n",
            "(epoch: 81, iters: 4000, time: 0.447, data: 0.002) G_GAN: 3.012 G_L1: 1.393 D_real: 0.205 D_fake: 0.084 \n",
            "End of epoch 81 / 200 \t Time Taken: 174 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "(epoch: 82, iters: 100, time: 0.064, data: 0.202) G_GAN: 3.098 G_L1: 1.616 D_real: 0.052 D_fake: 0.182 \n",
            "(epoch: 82, iters: 200, time: 0.066, data: 0.003) G_GAN: 0.937 G_L1: 2.904 D_real: 0.676 D_fake: 0.566 \n",
            "(epoch: 82, iters: 300, time: 0.064, data: 0.003) G_GAN: 4.344 G_L1: 7.728 D_real: 0.193 D_fake: 0.020 \n",
            "(epoch: 82, iters: 400, time: 0.567, data: 0.003) G_GAN: 2.957 G_L1: 5.209 D_real: 0.030 D_fake: 0.125 \n",
            "(epoch: 82, iters: 500, time: 0.067, data: 0.005) G_GAN: 0.908 G_L1: 2.228 D_real: 0.797 D_fake: 0.563 \n",
            "(epoch: 82, iters: 600, time: 0.066, data: 0.004) G_GAN: 1.215 G_L1: 2.346 D_real: 0.404 D_fake: 0.501 \n",
            "(epoch: 82, iters: 700, time: 0.066, data: 0.002) G_GAN: 1.610 G_L1: 1.063 D_real: 0.352 D_fake: 0.799 \n",
            "(epoch: 82, iters: 800, time: 0.286, data: 0.003) G_GAN: 3.176 G_L1: 1.654 D_real: 0.018 D_fake: 1.147 \n",
            "(epoch: 82, iters: 900, time: 0.067, data: 0.003) G_GAN: 7.265 G_L1: 1.872 D_real: 0.499 D_fake: 0.001 \n",
            "(epoch: 82, iters: 1000, time: 0.065, data: 0.002) G_GAN: 2.705 G_L1: 1.978 D_real: 0.042 D_fake: 0.115 \n",
            "saving the latest model (epoch 82, total_iters 325000)\n",
            "(epoch: 82, iters: 1100, time: 0.067, data: 0.002) G_GAN: 1.027 G_L1: 2.473 D_real: 1.265 D_fake: 0.363 \n",
            "(epoch: 82, iters: 1200, time: 0.167, data: 0.002) G_GAN: 2.413 G_L1: 1.506 D_real: 0.196 D_fake: 0.143 \n",
            "(epoch: 82, iters: 1300, time: 0.066, data: 0.003) G_GAN: 2.205 G_L1: 2.342 D_real: 0.430 D_fake: 0.425 \n",
            "(epoch: 82, iters: 1400, time: 0.065, data: 0.004) G_GAN: 0.901 G_L1: 1.860 D_real: 0.309 D_fake: 1.218 \n",
            "(epoch: 82, iters: 1500, time: 0.065, data: 0.003) G_GAN: 1.663 G_L1: 1.999 D_real: 0.370 D_fake: 0.669 \n",
            "(epoch: 82, iters: 1600, time: 0.170, data: 0.004) G_GAN: 6.704 G_L1: 0.973 D_real: 0.000 D_fake: 0.002 \n",
            "(epoch: 82, iters: 1700, time: 0.067, data: 0.010) G_GAN: 9.073 G_L1: 0.683 D_real: 0.001 D_fake: 0.000 \n",
            "(epoch: 82, iters: 1800, time: 0.066, data: 0.004) G_GAN: 0.757 G_L1: 2.255 D_real: 0.709 D_fake: 0.690 \n",
            "(epoch: 82, iters: 1900, time: 0.067, data: 0.003) G_GAN: 2.790 G_L1: 3.984 D_real: 0.052 D_fake: 1.040 \n",
            "(epoch: 82, iters: 2000, time: 0.437, data: 0.004) G_GAN: 6.992 G_L1: 1.875 D_real: 0.000 D_fake: 0.002 \n",
            "(epoch: 82, iters: 2100, time: 0.065, data: 0.009) G_GAN: 4.688 G_L1: 3.501 D_real: 0.124 D_fake: 0.009 \n",
            "(epoch: 82, iters: 2200, time: 0.066, data: 0.007) G_GAN: 2.796 G_L1: 1.212 D_real: 0.056 D_fake: 0.093 \n",
            "(epoch: 82, iters: 2300, time: 0.063, data: 0.003) G_GAN: 0.819 G_L1: 2.012 D_real: 0.672 D_fake: 0.746 \n",
            "(epoch: 82, iters: 2400, time: 0.184, data: 0.003) G_GAN: 4.683 G_L1: 1.449 D_real: 0.039 D_fake: 0.032 \n",
            "(epoch: 82, iters: 2500, time: 0.062, data: 0.007) G_GAN: 1.660 G_L1: 1.540 D_real: 0.627 D_fake: 0.916 \n",
            "(epoch: 82, iters: 2600, time: 0.067, data: 0.004) G_GAN: 5.354 G_L1: 2.446 D_real: 0.098 D_fake: 0.005 \n",
            "(epoch: 82, iters: 2700, time: 0.066, data: 0.008) G_GAN: 4.588 G_L1: 2.030 D_real: 0.465 D_fake: 0.009 \n",
            "(epoch: 82, iters: 2800, time: 0.187, data: 0.004) G_GAN: 3.911 G_L1: 1.758 D_real: 0.023 D_fake: 0.058 \n",
            "(epoch: 82, iters: 2900, time: 0.066, data: 0.002) G_GAN: 0.744 G_L1: 1.935 D_real: 0.675 D_fake: 0.705 \n",
            "(epoch: 82, iters: 3000, time: 0.066, data: 0.002) G_GAN: 7.930 G_L1: 1.173 D_real: 0.001 D_fake: 0.001 \n",
            "(epoch: 82, iters: 3100, time: 0.066, data: 0.004) G_GAN: 4.827 G_L1: 1.419 D_real: 0.076 D_fake: 0.012 \n",
            "(epoch: 82, iters: 3200, time: 0.163, data: 0.005) G_GAN: 5.446 G_L1: 0.904 D_real: 0.001 D_fake: 0.009 \n",
            "(epoch: 82, iters: 3300, time: 0.065, data: 0.002) G_GAN: 6.025 G_L1: 0.990 D_real: 0.000 D_fake: 0.006 \n",
            "(epoch: 82, iters: 3400, time: 0.065, data: 0.003) G_GAN: 0.942 G_L1: 3.306 D_real: 1.092 D_fake: 0.403 \n",
            "(epoch: 82, iters: 3500, time: 0.065, data: 0.003) G_GAN: 3.992 G_L1: 5.696 D_real: 0.134 D_fake: 0.034 \n",
            "(epoch: 82, iters: 3600, time: 0.160, data: 0.003) G_GAN: 7.443 G_L1: 0.777 D_real: 0.002 D_fake: 0.002 \n",
            "(epoch: 82, iters: 3700, time: 0.066, data: 0.002) G_GAN: 0.849 G_L1: 2.207 D_real: 0.767 D_fake: 0.677 \n",
            "(epoch: 82, iters: 3800, time: 0.066, data: 0.003) G_GAN: 2.345 G_L1: 1.856 D_real: 0.195 D_fake: 0.756 \n",
            "(epoch: 82, iters: 3900, time: 0.066, data: 0.004) G_GAN: 7.333 G_L1: 0.910 D_real: 0.001 D_fake: 0.002 \n",
            "(epoch: 82, iters: 4000, time: 0.458, data: 0.003) G_GAN: 6.514 G_L1: 1.568 D_real: 0.031 D_fake: 0.003 \n",
            "End of epoch 82 / 200 \t Time Taken: 174 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "(epoch: 83, iters: 100, time: 0.066, data: 0.235) G_GAN: 0.727 G_L1: 2.859 D_real: 0.677 D_fake: 0.771 \n",
            "(epoch: 83, iters: 200, time: 0.066, data: 0.003) G_GAN: 1.500 G_L1: 1.725 D_real: 0.441 D_fake: 0.517 \n",
            "(epoch: 83, iters: 300, time: 0.066, data: 0.003) G_GAN: 6.777 G_L1: 1.381 D_real: 0.001 D_fake: 0.007 \n",
            "(epoch: 83, iters: 400, time: 0.672, data: 0.002) G_GAN: 1.273 G_L1: 1.813 D_real: 0.612 D_fake: 0.409 \n",
            "(epoch: 83, iters: 500, time: 0.067, data: 0.003) G_GAN: 7.921 G_L1: 1.920 D_real: 0.143 D_fake: 0.001 \n",
            "(epoch: 83, iters: 600, time: 0.065, data: 0.004) G_GAN: 2.757 G_L1: 2.570 D_real: 0.149 D_fake: 0.514 \n",
            "(epoch: 83, iters: 700, time: 0.065, data: 0.002) G_GAN: 2.551 G_L1: 1.875 D_real: 0.631 D_fake: 0.071 \n",
            "(epoch: 83, iters: 800, time: 0.168, data: 0.003) G_GAN: 6.312 G_L1: 0.796 D_real: 0.001 D_fake: 0.003 \n",
            "(epoch: 83, iters: 900, time: 0.061, data: 0.006) G_GAN: 8.445 G_L1: 0.894 D_real: 0.000 D_fake: 0.001 \n",
            "(epoch: 83, iters: 1000, time: 0.066, data: 0.003) G_GAN: 0.714 G_L1: 3.374 D_real: 0.634 D_fake: 0.987 \n",
            "(epoch: 83, iters: 1100, time: 0.067, data: 0.006) G_GAN: 1.783 G_L1: 1.068 D_real: 0.246 D_fake: 1.282 \n",
            "(epoch: 83, iters: 1200, time: 0.217, data: 0.003) G_GAN: 0.771 G_L1: 2.680 D_real: 0.565 D_fake: 0.749 \n",
            "(epoch: 83, iters: 1300, time: 0.066, data: 0.006) G_GAN: 2.122 G_L1: 1.478 D_real: 0.127 D_fake: 1.084 \n",
            "(epoch: 83, iters: 1400, time: 0.066, data: 0.004) G_GAN: 0.731 G_L1: 3.080 D_real: 0.654 D_fake: 0.731 \n",
            "(epoch: 83, iters: 1500, time: 0.067, data: 0.003) G_GAN: 0.777 G_L1: 2.035 D_real: 0.669 D_fake: 0.738 \n",
            "(epoch: 83, iters: 1600, time: 0.164, data: 0.003) G_GAN: 3.413 G_L1: 1.071 D_real: 0.242 D_fake: 0.048 \n",
            "(epoch: 83, iters: 1700, time: 0.067, data: 0.002) G_GAN: 8.162 G_L1: 2.506 D_real: 0.023 D_fake: 0.000 \n",
            "(epoch: 83, iters: 1800, time: 0.066, data: 0.003) G_GAN: 0.995 G_L1: 0.893 D_real: 0.939 D_fake: 0.409 \n",
            "(epoch: 83, iters: 1900, time: 0.066, data: 0.004) G_GAN: 3.591 G_L1: 3.252 D_real: 0.012 D_fake: 1.117 \n",
            "(epoch: 83, iters: 2000, time: 0.561, data: 0.002) G_GAN: 0.749 G_L1: 2.117 D_real: 0.496 D_fake: 0.831 \n",
            "saving the latest model (epoch 83, total_iters 330000)\n",
            "(epoch: 83, iters: 2100, time: 0.067, data: 0.002) G_GAN: 5.288 G_L1: 2.415 D_real: 0.202 D_fake: 0.007 \n",
            "(epoch: 83, iters: 2200, time: 0.067, data: 0.003) G_GAN: 6.818 G_L1: 0.685 D_real: 0.001 D_fake: 0.004 \n",
            "(epoch: 83, iters: 2300, time: 0.067, data: 0.003) G_GAN: 0.778 G_L1: 3.591 D_real: 0.506 D_fake: 0.823 \n",
            "(epoch: 83, iters: 2400, time: 0.175, data: 0.005) G_GAN: 0.953 G_L1: 3.584 D_real: 0.563 D_fake: 0.852 \n",
            "(epoch: 83, iters: 2500, time: 0.066, data: 0.002) G_GAN: 2.641 G_L1: 0.909 D_real: 0.323 D_fake: 0.094 \n",
            "(epoch: 83, iters: 2600, time: 0.065, data: 0.004) G_GAN: 7.171 G_L1: 3.896 D_real: 0.471 D_fake: 0.001 \n",
            "(epoch: 83, iters: 2700, time: 0.066, data: 0.003) G_GAN: 0.881 G_L1: 2.462 D_real: 0.623 D_fake: 0.670 \n",
            "(epoch: 83, iters: 2800, time: 0.253, data: 0.003) G_GAN: 6.701 G_L1: 0.936 D_real: 0.002 D_fake: 0.003 \n",
            "(epoch: 83, iters: 2900, time: 0.064, data: 0.003) G_GAN: 1.276 G_L1: 1.645 D_real: 0.293 D_fake: 0.559 \n",
            "(epoch: 83, iters: 3000, time: 0.067, data: 0.003) G_GAN: 2.295 G_L1: 2.120 D_real: 0.868 D_fake: 0.419 \n",
            "(epoch: 83, iters: 3100, time: 0.065, data: 0.003) G_GAN: 0.848 G_L1: 2.418 D_real: 0.816 D_fake: 0.561 \n",
            "(epoch: 83, iters: 3200, time: 0.189, data: 0.004) G_GAN: 4.990 G_L1: 2.470 D_real: 0.027 D_fake: 0.016 \n",
            "(epoch: 83, iters: 3300, time: 0.066, data: 0.007) G_GAN: 0.882 G_L1: 2.382 D_real: 0.768 D_fake: 0.578 \n",
            "(epoch: 83, iters: 3400, time: 0.066, data: 0.004) G_GAN: 2.235 G_L1: 2.041 D_real: 0.126 D_fake: 0.571 \n",
            "(epoch: 83, iters: 3500, time: 0.066, data: 0.006) G_GAN: 7.071 G_L1: 1.512 D_real: 0.000 D_fake: 0.002 \n",
            "(epoch: 83, iters: 3600, time: 0.168, data: 0.004) G_GAN: 2.926 G_L1: 3.402 D_real: 0.048 D_fake: 0.189 \n",
            "(epoch: 83, iters: 3700, time: 0.066, data: 0.007) G_GAN: 1.489 G_L1: 1.949 D_real: 0.617 D_fake: 0.364 \n",
            "(epoch: 83, iters: 3800, time: 0.065, data: 0.008) G_GAN: 1.153 G_L1: 1.679 D_real: 0.461 D_fake: 0.759 \n",
            "(epoch: 83, iters: 3900, time: 0.066, data: 0.004) G_GAN: 2.346 G_L1: 1.338 D_real: 0.146 D_fake: 0.708 \n",
            "(epoch: 83, iters: 4000, time: 0.475, data: 0.002) G_GAN: 6.558 G_L1: 0.730 D_real: 0.000 D_fake: 0.003 \n",
            "End of epoch 83 / 200 \t Time Taken: 175 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "(epoch: 84, iters: 100, time: 0.066, data: 0.228) G_GAN: 3.494 G_L1: 0.839 D_real: 0.120 D_fake: 0.115 \n",
            "(epoch: 84, iters: 200, time: 0.066, data: 0.003) G_GAN: 8.536 G_L1: 1.712 D_real: 0.011 D_fake: 0.000 \n",
            "(epoch: 84, iters: 300, time: 0.067, data: 0.003) G_GAN: 0.807 G_L1: 1.827 D_real: 0.634 D_fake: 0.690 \n",
            "(epoch: 84, iters: 400, time: 0.651, data: 0.003) G_GAN: 0.877 G_L1: 1.992 D_real: 0.270 D_fake: 1.194 \n",
            "(epoch: 84, iters: 500, time: 0.066, data: 0.003) G_GAN: 1.106 G_L1: 1.667 D_real: 1.814 D_fake: 0.162 \n",
            "(epoch: 84, iters: 600, time: 0.064, data: 0.003) G_GAN: 4.582 G_L1: 1.027 D_real: 0.008 D_fake: 0.019 \n",
            "(epoch: 84, iters: 700, time: 0.066, data: 0.003) G_GAN: 8.575 G_L1: 1.715 D_real: 0.001 D_fake: 0.000 \n",
            "(epoch: 84, iters: 800, time: 0.157, data: 0.002) G_GAN: 3.727 G_L1: 1.542 D_real: 0.087 D_fake: 0.030 \n",
            "(epoch: 84, iters: 900, time: 0.066, data: 0.002) G_GAN: 2.549 G_L1: 2.777 D_real: 0.095 D_fake: 0.220 \n",
            "(epoch: 84, iters: 1000, time: 0.066, data: 0.004) G_GAN: 0.869 G_L1: 2.789 D_real: 0.481 D_fake: 0.667 \n",
            "(epoch: 84, iters: 1100, time: 0.061, data: 0.003) G_GAN: 8.388 G_L1: 1.004 D_real: 0.008 D_fake: 0.000 \n",
            "(epoch: 84, iters: 1200, time: 0.224, data: 0.003) G_GAN: 1.082 G_L1: 5.848 D_real: 0.832 D_fake: 0.394 \n",
            "(epoch: 84, iters: 1300, time: 0.066, data: 0.005) G_GAN: 0.730 G_L1: 2.371 D_real: 0.497 D_fake: 0.855 \n",
            "(epoch: 84, iters: 1400, time: 0.066, data: 0.003) G_GAN: 6.536 G_L1: 0.751 D_real: 0.002 D_fake: 0.003 \n",
            "(epoch: 84, iters: 1500, time: 0.066, data: 0.004) G_GAN: 0.915 G_L1: 4.000 D_real: 0.744 D_fake: 0.546 \n",
            "(epoch: 84, iters: 1600, time: 0.166, data: 0.004) G_GAN: 5.724 G_L1: 0.673 D_real: 0.000 D_fake: 0.006 \n",
            "(epoch: 84, iters: 1700, time: 0.065, data: 0.003) G_GAN: 4.584 G_L1: 2.064 D_real: 0.045 D_fake: 0.714 \n",
            "(epoch: 84, iters: 1800, time: 0.066, data: 0.003) G_GAN: 0.882 G_L1: 1.812 D_real: 0.793 D_fake: 0.488 \n",
            "(epoch: 84, iters: 1900, time: 0.066, data: 0.006) G_GAN: 1.127 G_L1: 1.992 D_real: 1.000 D_fake: 0.185 \n",
            "(epoch: 84, iters: 2000, time: 0.482, data: 0.004) G_GAN: 2.558 G_L1: 3.536 D_real: 0.023 D_fake: 0.126 \n",
            "(epoch: 84, iters: 2100, time: 0.066, data: 0.005) G_GAN: 5.157 G_L1: 0.969 D_real: 0.000 D_fake: 0.017 \n",
            "(epoch: 84, iters: 2200, time: 0.065, data: 0.003) G_GAN: 4.530 G_L1: 2.270 D_real: 0.099 D_fake: 0.014 \n",
            "(epoch: 84, iters: 2300, time: 0.066, data: 0.005) G_GAN: 1.026 G_L1: 2.148 D_real: 0.747 D_fake: 0.545 \n",
            "(epoch: 84, iters: 2400, time: 0.155, data: 0.007) G_GAN: 2.454 G_L1: 1.006 D_real: 0.193 D_fake: 0.163 \n",
            "(epoch: 84, iters: 2500, time: 0.066, data: 0.003) G_GAN: 8.914 G_L1: 1.055 D_real: 0.000 D_fake: 0.000 \n",
            "(epoch: 84, iters: 2600, time: 0.066, data: 0.004) G_GAN: 0.762 G_L1: 2.675 D_real: 0.504 D_fake: 0.818 \n",
            "(epoch: 84, iters: 2700, time: 0.066, data: 0.004) G_GAN: 0.762 G_L1: 2.497 D_real: 0.802 D_fake: 0.597 \n",
            "(epoch: 84, iters: 2800, time: 0.194, data: 0.003) G_GAN: 4.869 G_L1: 2.678 D_real: 0.226 D_fake: 0.012 \n",
            "(epoch: 84, iters: 2900, time: 0.066, data: 0.002) G_GAN: 7.351 G_L1: 2.150 D_real: 0.000 D_fake: 0.002 \n",
            "(epoch: 84, iters: 3000, time: 0.067, data: 0.006) G_GAN: 1.736 G_L1: 2.561 D_real: 0.225 D_fake: 0.662 \n",
            "saving the latest model (epoch 84, total_iters 335000)\n",
            "(epoch: 84, iters: 3100, time: 0.061, data: 0.003) G_GAN: 7.930 G_L1: 0.861 D_real: 0.000 D_fake: 0.001 \n",
            "(epoch: 84, iters: 3200, time: 0.221, data: 0.004) G_GAN: 0.836 G_L1: 3.131 D_real: 0.763 D_fake: 0.581 \n",
            "(epoch: 84, iters: 3300, time: 0.066, data: 0.002) G_GAN: 1.149 G_L1: 4.104 D_real: 0.817 D_fake: 0.343 \n",
            "(epoch: 84, iters: 3400, time: 0.064, data: 0.003) G_GAN: 4.068 G_L1: 1.591 D_real: 0.110 D_fake: 0.036 \n",
            "(epoch: 84, iters: 3500, time: 0.065, data: 0.003) G_GAN: 7.825 G_L1: 0.799 D_real: 0.013 D_fake: 0.001 \n",
            "(epoch: 84, iters: 3600, time: 0.167, data: 0.004) G_GAN: 2.593 G_L1: 1.506 D_real: 0.256 D_fake: 0.505 \n",
            "(epoch: 84, iters: 3700, time: 0.066, data: 0.002) G_GAN: 2.411 G_L1: 1.089 D_real: 0.210 D_fake: 0.327 \n",
            "(epoch: 84, iters: 3800, time: 0.067, data: 0.003) G_GAN: 6.708 G_L1: 1.936 D_real: 0.059 D_fake: 0.002 \n",
            "(epoch: 84, iters: 3900, time: 0.066, data: 0.005) G_GAN: 3.872 G_L1: 1.500 D_real: 0.123 D_fake: 0.063 \n",
            "(epoch: 84, iters: 4000, time: 0.540, data: 0.002) G_GAN: 0.750 G_L1: 2.843 D_real: 0.621 D_fake: 0.791 \n",
            "End of epoch 84 / 200 \t Time Taken: 175 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "(epoch: 85, iters: 100, time: 0.064, data: 0.218) G_GAN: 1.629 G_L1: 0.922 D_real: 0.601 D_fake: 0.197 \n",
            "(epoch: 85, iters: 200, time: 0.066, data: 0.003) G_GAN: 3.197 G_L1: 3.168 D_real: 0.061 D_fake: 0.061 \n",
            "(epoch: 85, iters: 300, time: 0.064, data: 0.007) G_GAN: 1.061 G_L1: 1.848 D_real: 0.781 D_fake: 0.414 \n",
            "(epoch: 85, iters: 400, time: 0.657, data: 0.003) G_GAN: 6.395 G_L1: 0.917 D_real: 0.000 D_fake: 0.003 \n",
            "(epoch: 85, iters: 500, time: 0.066, data: 0.004) G_GAN: 5.633 G_L1: 1.454 D_real: 1.597 D_fake: 0.003 \n",
            "(epoch: 85, iters: 600, time: 0.065, data: 0.004) G_GAN: 0.832 G_L1: 2.610 D_real: 0.714 D_fake: 0.638 \n",
            "(epoch: 85, iters: 700, time: 0.067, data: 0.003) G_GAN: 5.859 G_L1: 1.566 D_real: 0.183 D_fake: 0.003 \n",
            "(epoch: 85, iters: 800, time: 0.167, data: 0.003) G_GAN: 7.686 G_L1: 0.554 D_real: 0.007 D_fake: 0.001 \n",
            "(epoch: 85, iters: 900, time: 0.066, data: 0.002) G_GAN: 0.890 G_L1: 3.227 D_real: 0.756 D_fake: 0.523 \n",
            "(epoch: 85, iters: 1000, time: 0.066, data: 0.006) G_GAN: 0.839 G_L1: 3.073 D_real: 1.014 D_fake: 0.494 \n",
            "(epoch: 85, iters: 1100, time: 0.066, data: 0.005) G_GAN: 6.093 G_L1: 0.568 D_real: 0.011 D_fake: 0.003 \n",
            "(epoch: 85, iters: 1200, time: 0.187, data: 0.004) G_GAN: 3.784 G_L1: 2.435 D_real: 0.502 D_fake: 0.007 \n",
            "(epoch: 85, iters: 1300, time: 0.066, data: 0.002) G_GAN: 5.729 G_L1: 0.601 D_real: 0.001 D_fake: 0.005 \n",
            "(epoch: 85, iters: 1400, time: 0.066, data: 0.006) G_GAN: 1.171 G_L1: 1.957 D_real: 0.544 D_fake: 0.511 \n",
            "(epoch: 85, iters: 1500, time: 0.064, data: 0.002) G_GAN: 2.013 G_L1: 1.757 D_real: 0.167 D_fake: 0.882 \n",
            "(epoch: 85, iters: 1600, time: 0.175, data: 0.003) G_GAN: 0.934 G_L1: 1.142 D_real: 1.333 D_fake: 1.255 \n",
            "(epoch: 85, iters: 1700, time: 0.066, data: 0.003) G_GAN: 0.715 G_L1: 4.268 D_real: 0.475 D_fake: 0.874 \n",
            "(epoch: 85, iters: 1800, time: 0.066, data: 0.003) G_GAN: 5.922 G_L1: 1.593 D_real: 0.883 D_fake: 0.003 \n",
            "(epoch: 85, iters: 1900, time: 0.066, data: 0.002) G_GAN: 2.407 G_L1: 2.452 D_real: 0.478 D_fake: 0.286 \n",
            "(epoch: 85, iters: 2000, time: 0.456, data: 0.002) G_GAN: 7.419 G_L1: 0.606 D_real: 0.016 D_fake: 0.002 \n",
            "(epoch: 85, iters: 2100, time: 0.066, data: 0.004) G_GAN: 2.050 G_L1: 1.130 D_real: 1.360 D_fake: 0.046 \n",
            "(epoch: 85, iters: 2200, time: 0.066, data: 0.006) G_GAN: 1.549 G_L1: 2.746 D_real: 0.557 D_fake: 0.316 \n",
            "(epoch: 85, iters: 2300, time: 0.065, data: 0.003) G_GAN: 1.753 G_L1: 1.349 D_real: 0.290 D_fake: 0.115 \n",
            "(epoch: 85, iters: 2400, time: 0.183, data: 0.005) G_GAN: 1.997 G_L1: 1.918 D_real: 0.266 D_fake: 0.436 \n",
            "(epoch: 85, iters: 2500, time: 0.064, data: 0.002) G_GAN: 0.722 G_L1: 2.069 D_real: 0.621 D_fake: 0.763 \n",
            "(epoch: 85, iters: 2600, time: 0.066, data: 0.004) G_GAN: 6.620 G_L1: 0.585 D_real: 0.017 D_fake: 0.002 \n",
            "(epoch: 85, iters: 2700, time: 0.067, data: 0.003) G_GAN: 0.641 G_L1: 2.730 D_real: 0.479 D_fake: 1.031 \n",
            "(epoch: 85, iters: 2800, time: 0.185, data: 0.003) G_GAN: 6.488 G_L1: 1.848 D_real: 0.505 D_fake: 0.001 \n",
            "(epoch: 85, iters: 2900, time: 0.066, data: 0.003) G_GAN: 0.769 G_L1: 2.008 D_real: 0.256 D_fake: 1.146 \n",
            "(epoch: 85, iters: 3000, time: 0.066, data: 0.003) G_GAN: 3.685 G_L1: 1.070 D_real: 0.058 D_fake: 0.039 \n",
            "(epoch: 85, iters: 3100, time: 0.066, data: 0.004) G_GAN: 5.280 G_L1: 0.992 D_real: 0.017 D_fake: 0.009 \n",
            "(epoch: 85, iters: 3200, time: 0.205, data: 0.005) G_GAN: 1.429 G_L1: 1.176 D_real: 2.365 D_fake: 0.030 \n",
            "(epoch: 85, iters: 3300, time: 0.061, data: 0.007) G_GAN: 3.722 G_L1: 2.289 D_real: 0.001 D_fake: 0.058 \n",
            "(epoch: 85, iters: 3400, time: 0.065, data: 0.002) G_GAN: 1.479 G_L1: 1.964 D_real: 0.520 D_fake: 0.326 \n",
            "(epoch: 85, iters: 3500, time: 0.067, data: 0.003) G_GAN: 6.198 G_L1: 2.098 D_real: 0.001 D_fake: 0.005 \n",
            "(epoch: 85, iters: 3600, time: 0.168, data: 0.004) G_GAN: 2.091 G_L1: 1.336 D_real: 0.158 D_fake: 0.831 \n",
            "(epoch: 85, iters: 3700, time: 0.067, data: 0.005) G_GAN: 6.081 G_L1: 1.403 D_real: 0.023 D_fake: 0.004 \n",
            "(epoch: 85, iters: 3800, time: 0.067, data: 0.003) G_GAN: 3.211 G_L1: 2.784 D_real: 0.227 D_fake: 0.030 \n",
            "(epoch: 85, iters: 3900, time: 0.066, data: 0.004) G_GAN: 1.495 G_L1: 6.040 D_real: 2.119 D_fake: 0.075 \n",
            "(epoch: 85, iters: 4000, time: 0.500, data: 0.006) G_GAN: 0.637 G_L1: 3.569 D_real: 2.242 D_fake: 0.124 \n",
            "saving the latest model (epoch 85, total_iters 340000)\n",
            "saving the model at the end of epoch 85, iters 340000\n",
            "End of epoch 85 / 200 \t Time Taken: 176 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "(epoch: 86, iters: 100, time: 0.067, data: 0.297) G_GAN: 2.958 G_L1: 1.329 D_real: 0.063 D_fake: 0.823 \n",
            "(epoch: 86, iters: 200, time: 0.066, data: 0.003) G_GAN: 7.013 G_L1: 1.159 D_real: 0.000 D_fake: 0.001 \n",
            "(epoch: 86, iters: 300, time: 0.065, data: 0.004) G_GAN: 6.048 G_L1: 0.743 D_real: 0.000 D_fake: 0.004 \n",
            "(epoch: 86, iters: 400, time: 0.641, data: 0.003) G_GAN: 0.784 G_L1: 2.501 D_real: 0.772 D_fake: 0.616 \n",
            "(epoch: 86, iters: 500, time: 0.066, data: 0.003) G_GAN: 4.021 G_L1: 2.003 D_real: 0.052 D_fake: 0.062 \n",
            "(epoch: 86, iters: 600, time: 0.065, data: 0.007) G_GAN: 1.425 G_L1: 2.183 D_real: 0.508 D_fake: 0.527 \n",
            "(epoch: 86, iters: 700, time: 0.066, data: 0.003) G_GAN: 0.649 G_L1: 2.567 D_real: 0.412 D_fake: 1.015 \n",
            "(epoch: 86, iters: 800, time: 0.158, data: 0.004) G_GAN: 8.662 G_L1: 0.969 D_real: 0.001 D_fake: 0.000 \n",
            "(epoch: 86, iters: 900, time: 0.063, data: 0.006) G_GAN: 7.893 G_L1: 1.643 D_real: 0.030 D_fake: 0.001 \n",
            "(epoch: 86, iters: 1000, time: 0.067, data: 0.004) G_GAN: 1.723 G_L1: 1.932 D_real: 1.474 D_fake: 0.249 \n",
            "(epoch: 86, iters: 1100, time: 0.066, data: 0.003) G_GAN: 6.290 G_L1: 3.292 D_real: 0.083 D_fake: 0.003 \n",
            "(epoch: 86, iters: 1200, time: 0.223, data: 0.003) G_GAN: 0.818 G_L1: 2.020 D_real: 0.736 D_fake: 0.610 \n",
            "(epoch: 86, iters: 1300, time: 0.067, data: 0.007) G_GAN: 8.414 G_L1: 1.257 D_real: 0.000 D_fake: 0.000 \n",
            "(epoch: 86, iters: 1400, time: 0.064, data: 0.003) G_GAN: 4.341 G_L1: 1.807 D_real: 0.011 D_fake: 0.023 \n",
            "(epoch: 86, iters: 1500, time: 0.064, data: 0.004) G_GAN: 3.225 G_L1: 1.100 D_real: 0.059 D_fake: 0.137 \n",
            "(epoch: 86, iters: 1600, time: 0.173, data: 0.004) G_GAN: 5.972 G_L1: 1.458 D_real: 0.000 D_fake: 0.004 \n",
            "(epoch: 86, iters: 1700, time: 0.066, data: 0.002) G_GAN: 0.881 G_L1: 2.908 D_real: 0.875 D_fake: 0.509 \n",
            "(epoch: 86, iters: 1800, time: 0.067, data: 0.003) G_GAN: 8.360 G_L1: 2.478 D_real: 0.020 D_fake: 0.000 \n",
            "(epoch: 86, iters: 1900, time: 0.066, data: 0.004) G_GAN: 0.170 G_L1: 1.208 D_real: 1.030 D_fake: 0.176 \n",
            "(epoch: 86, iters: 2000, time: 0.558, data: 0.003) G_GAN: 5.210 G_L1: 0.484 D_real: 0.001 D_fake: 0.012 \n",
            "(epoch: 86, iters: 2100, time: 0.066, data: 0.007) G_GAN: 5.124 G_L1: 1.167 D_real: 0.052 D_fake: 0.011 \n",
            "(epoch: 86, iters: 2200, time: 0.067, data: 0.002) G_GAN: 1.003 G_L1: 1.841 D_real: 0.856 D_fake: 0.404 \n",
            "(epoch: 86, iters: 2300, time: 0.067, data: 0.003) G_GAN: 6.651 G_L1: 0.515 D_real: 0.003 D_fake: 0.002 \n",
            "(epoch: 86, iters: 2400, time: 0.169, data: 0.004) G_GAN: 1.568 G_L1: 1.983 D_real: 1.924 D_fake: 0.147 \n",
            "(epoch: 86, iters: 2500, time: 0.066, data: 0.002) G_GAN: 7.074 G_L1: 1.345 D_real: 0.782 D_fake: 0.002 \n",
            "(epoch: 86, iters: 2600, time: 0.066, data: 0.004) G_GAN: 1.072 G_L1: 2.976 D_real: 0.561 D_fake: 0.504 \n",
            "(epoch: 86, iters: 2700, time: 0.066, data: 0.004) G_GAN: 8.934 G_L1: 0.787 D_real: 0.003 D_fake: 0.000 \n",
            "(epoch: 86, iters: 2800, time: 0.221, data: 0.004) G_GAN: 0.864 G_L1: 3.580 D_real: 0.527 D_fake: 0.646 \n",
            "(epoch: 86, iters: 2900, time: 0.066, data: 0.007) G_GAN: 4.224 G_L1: 1.301 D_real: 0.032 D_fake: 0.024 \n",
            "(epoch: 86, iters: 3000, time: 0.067, data: 0.004) G_GAN: 3.507 G_L1: 2.280 D_real: 0.040 D_fake: 0.305 \n",
            "(epoch: 86, iters: 3100, time: 0.065, data: 0.002) G_GAN: 0.697 G_L1: 3.164 D_real: 0.586 D_fake: 0.811 \n",
            "(epoch: 86, iters: 3200, time: 0.210, data: 0.004) G_GAN: 0.997 G_L1: 1.972 D_real: 0.521 D_fake: 0.754 \n",
            "(epoch: 86, iters: 3300, time: 0.067, data: 0.002) G_GAN: 7.555 G_L1: 1.098 D_real: 0.052 D_fake: 0.001 \n",
            "(epoch: 86, iters: 3400, time: 0.067, data: 0.004) G_GAN: 0.736 G_L1: 2.047 D_real: 0.664 D_fake: 0.704 \n",
            "(epoch: 86, iters: 3500, time: 0.067, data: 0.004) G_GAN: 3.574 G_L1: 1.795 D_real: 0.080 D_fake: 0.062 \n",
            "(epoch: 86, iters: 3600, time: 0.173, data: 0.006) G_GAN: 3.627 G_L1: 1.627 D_real: 0.136 D_fake: 0.043 \n",
            "(epoch: 86, iters: 3700, time: 0.067, data: 0.002) G_GAN: 5.835 G_L1: 1.578 D_real: 0.000 D_fake: 0.004 \n",
            "(epoch: 86, iters: 3800, time: 0.066, data: 0.004) G_GAN: 9.232 G_L1: 1.257 D_real: 0.007 D_fake: 0.000 \n",
            "(epoch: 86, iters: 3900, time: 0.066, data: 0.003) G_GAN: 0.916 G_L1: 1.875 D_real: 0.710 D_fake: 0.495 \n",
            "(epoch: 86, iters: 4000, time: 0.526, data: 0.002) G_GAN: 4.819 G_L1: 1.357 D_real: 0.007 D_fake: 0.011 \n",
            "End of epoch 86 / 200 \t Time Taken: 174 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "(epoch: 87, iters: 100, time: 0.067, data: 0.277) G_GAN: 6.386 G_L1: 1.802 D_real: 0.906 D_fake: 0.006 \n",
            "(epoch: 87, iters: 200, time: 0.067, data: 0.003) G_GAN: 5.901 G_L1: 1.514 D_real: 0.944 D_fake: 0.002 \n",
            "(epoch: 87, iters: 300, time: 0.066, data: 0.003) G_GAN: 0.828 G_L1: 2.307 D_real: 0.995 D_fake: 0.464 \n",
            "(epoch: 87, iters: 400, time: 0.561, data: 0.004) G_GAN: 6.821 G_L1: 2.691 D_real: 0.030 D_fake: 0.002 \n",
            "(epoch: 87, iters: 500, time: 0.065, data: 0.003) G_GAN: 2.145 G_L1: 1.839 D_real: 0.328 D_fake: 0.494 \n",
            "(epoch: 87, iters: 600, time: 0.066, data: 0.004) G_GAN: 1.143 G_L1: 3.383 D_real: 0.367 D_fake: 0.522 \n",
            "(epoch: 87, iters: 700, time: 0.066, data: 0.003) G_GAN: 8.738 G_L1: 0.837 D_real: 0.002 D_fake: 0.000 \n",
            "(epoch: 87, iters: 800, time: 0.164, data: 0.003) G_GAN: 7.092 G_L1: 1.168 D_real: 0.133 D_fake: 0.002 \n",
            "(epoch: 87, iters: 900, time: 0.061, data: 0.005) G_GAN: 2.420 G_L1: 1.727 D_real: 0.382 D_fake: 0.276 \n",
            "(epoch: 87, iters: 1000, time: 0.066, data: 0.003) G_GAN: 2.614 G_L1: 1.126 D_real: 0.325 D_fake: 2.043 \n",
            "saving the latest model (epoch 87, total_iters 345000)\n",
            "(epoch: 87, iters: 1100, time: 0.066, data: 0.002) G_GAN: 7.513 G_L1: 0.649 D_real: 0.016 D_fake: 0.001 \n",
            "(epoch: 87, iters: 1200, time: 0.220, data: 0.003) G_GAN: 0.737 G_L1: 2.013 D_real: 0.806 D_fake: 0.712 \n",
            "(epoch: 87, iters: 1300, time: 0.067, data: 0.002) G_GAN: 1.926 G_L1: 2.209 D_real: 0.525 D_fake: 0.410 \n",
            "(epoch: 87, iters: 1400, time: 0.066, data: 0.005) G_GAN: 1.820 G_L1: 1.435 D_real: 0.606 D_fake: 0.217 \n",
            "(epoch: 87, iters: 1500, time: 0.066, data: 0.003) G_GAN: 3.671 G_L1: 2.989 D_real: 0.124 D_fake: 0.054 \n",
            "(epoch: 87, iters: 1600, time: 0.203, data: 0.003) G_GAN: 1.474 G_L1: 4.662 D_real: 0.786 D_fake: 0.683 \n",
            "(epoch: 87, iters: 1700, time: 0.066, data: 0.013) G_GAN: 1.177 G_L1: 5.492 D_real: 0.684 D_fake: 0.383 \n",
            "(epoch: 87, iters: 1800, time: 0.067, data: 0.003) G_GAN: 3.524 G_L1: 2.070 D_real: 0.143 D_fake: 1.556 \n",
            "(epoch: 87, iters: 1900, time: 0.067, data: 0.003) G_GAN: 8.335 G_L1: 0.834 D_real: 0.002 D_fake: 0.000 \n",
            "(epoch: 87, iters: 2000, time: 0.498, data: 0.004) G_GAN: 2.561 G_L1: 2.149 D_real: 0.167 D_fake: 0.108 \n",
            "(epoch: 87, iters: 2100, time: 0.067, data: 0.007) G_GAN: 2.494 G_L1: 5.719 D_real: 0.357 D_fake: 0.092 \n",
            "(epoch: 87, iters: 2200, time: 0.066, data: 0.005) G_GAN: 0.829 G_L1: 2.747 D_real: 1.042 D_fake: 0.466 \n",
            "(epoch: 87, iters: 2300, time: 0.066, data: 0.003) G_GAN: 2.676 G_L1: 1.152 D_real: 0.193 D_fake: 0.263 \n",
            "(epoch: 87, iters: 2400, time: 0.179, data: 0.004) G_GAN: 2.805 G_L1: 1.621 D_real: 0.131 D_fake: 0.192 \n",
            "(epoch: 87, iters: 2500, time: 0.066, data: 0.003) G_GAN: 3.604 G_L1: 2.259 D_real: 0.040 D_fake: 2.287 \n",
            "(epoch: 87, iters: 2600, time: 0.066, data: 0.004) G_GAN: 2.293 G_L1: 3.165 D_real: 0.198 D_fake: 0.341 \n",
            "(epoch: 87, iters: 2700, time: 0.067, data: 0.003) G_GAN: 1.800 G_L1: 1.822 D_real: 0.261 D_fake: 0.633 \n",
            "(epoch: 87, iters: 2800, time: 0.173, data: 0.004) G_GAN: 4.637 G_L1: 1.732 D_real: 0.153 D_fake: 0.017 \n",
            "(epoch: 87, iters: 2900, time: 0.066, data: 0.009) G_GAN: 1.632 G_L1: 2.164 D_real: 0.791 D_fake: 0.371 \n",
            "(epoch: 87, iters: 3000, time: 0.066, data: 0.004) G_GAN: 3.858 G_L1: 0.984 D_real: 0.001 D_fake: 0.111 \n",
            "(epoch: 87, iters: 3100, time: 0.065, data: 0.003) G_GAN: 1.021 G_L1: 2.026 D_real: 0.798 D_fake: 0.323 \n",
            "(epoch: 87, iters: 3200, time: 0.183, data: 0.002) G_GAN: 4.100 G_L1: 4.299 D_real: 0.060 D_fake: 1.777 \n",
            "(epoch: 87, iters: 3300, time: 0.063, data: 0.006) G_GAN: 2.276 G_L1: 1.958 D_real: 0.530 D_fake: 0.103 \n",
            "(epoch: 87, iters: 3400, time: 0.066, data: 0.004) G_GAN: 7.817 G_L1: 1.245 D_real: 0.001 D_fake: 0.001 \n",
            "(epoch: 87, iters: 3500, time: 0.067, data: 0.004) G_GAN: 9.336 G_L1: 1.398 D_real: 0.000 D_fake: 0.000 \n",
            "(epoch: 87, iters: 3600, time: 0.306, data: 0.004) G_GAN: 2.290 G_L1: 1.310 D_real: 0.243 D_fake: 0.153 \n",
            "(epoch: 87, iters: 3700, time: 0.067, data: 0.006) G_GAN: 8.674 G_L1: 1.682 D_real: 0.069 D_fake: 0.000 \n",
            "(epoch: 87, iters: 3800, time: 0.060, data: 0.003) G_GAN: 4.409 G_L1: 1.218 D_real: 0.001 D_fake: 0.030 \n",
            "(epoch: 87, iters: 3900, time: 0.067, data: 0.003) G_GAN: 2.821 G_L1: 1.366 D_real: 0.114 D_fake: 0.069 \n",
            "(epoch: 87, iters: 4000, time: 0.482, data: 0.004) G_GAN: 2.211 G_L1: 1.347 D_real: 1.085 D_fake: 0.046 \n",
            "End of epoch 87 / 200 \t Time Taken: 175 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "(epoch: 88, iters: 100, time: 0.067, data: 0.193) G_GAN: 6.624 G_L1: 0.813 D_real: 0.004 D_fake: 0.002 \n",
            "(epoch: 88, iters: 200, time: 0.065, data: 0.003) G_GAN: 1.335 G_L1: 1.983 D_real: 0.398 D_fake: 0.508 \n",
            "(epoch: 88, iters: 300, time: 0.065, data: 0.004) G_GAN: 4.737 G_L1: 0.916 D_real: 0.000 D_fake: 0.016 \n",
            "(epoch: 88, iters: 400, time: 0.605, data: 0.005) G_GAN: 1.828 G_L1: 2.070 D_real: 0.308 D_fake: 0.148 \n",
            "(epoch: 88, iters: 500, time: 0.067, data: 0.003) G_GAN: 3.009 G_L1: 1.433 D_real: 0.082 D_fake: 0.092 \n",
            "(epoch: 88, iters: 600, time: 0.062, data: 0.003) G_GAN: 1.721 G_L1: 2.025 D_real: 0.242 D_fake: 1.182 \n",
            "(epoch: 88, iters: 700, time: 0.067, data: 0.002) G_GAN: 8.031 G_L1: 1.440 D_real: 0.004 D_fake: 0.001 \n",
            "(epoch: 88, iters: 800, time: 0.155, data: 0.004) G_GAN: 7.741 G_L1: 0.679 D_real: 0.001 D_fake: 0.001 \n",
            "(epoch: 88, iters: 900, time: 0.061, data: 0.008) G_GAN: 5.123 G_L1: 2.932 D_real: 0.063 D_fake: 0.012 \n",
            "(epoch: 88, iters: 1000, time: 0.066, data: 0.002) G_GAN: 1.251 G_L1: 1.135 D_real: 0.255 D_fake: 1.785 \n",
            "(epoch: 88, iters: 1100, time: 0.065, data: 0.004) G_GAN: 0.808 G_L1: 2.157 D_real: 1.250 D_fake: 0.398 \n",
            "(epoch: 88, iters: 1200, time: 0.184, data: 0.002) G_GAN: 1.040 G_L1: 1.571 D_real: 0.718 D_fake: 0.368 \n",
            "(epoch: 88, iters: 1300, time: 0.066, data: 0.002) G_GAN: 0.723 G_L1: 2.708 D_real: 0.963 D_fake: 0.562 \n",
            "(epoch: 88, iters: 1400, time: 0.067, data: 0.003) G_GAN: 2.424 G_L1: 1.444 D_real: 0.160 D_fake: 0.118 \n",
            "(epoch: 88, iters: 1500, time: 0.066, data: 0.003) G_GAN: 3.991 G_L1: 0.691 D_real: 0.000 D_fake: 0.027 \n",
            "(epoch: 88, iters: 1600, time: 0.214, data: 0.004) G_GAN: 0.770 G_L1: 2.838 D_real: 0.677 D_fake: 0.723 \n",
            "(epoch: 88, iters: 1700, time: 0.064, data: 0.005) G_GAN: 3.096 G_L1: 0.949 D_real: 0.199 D_fake: 0.217 \n",
            "(epoch: 88, iters: 1800, time: 0.066, data: 0.002) G_GAN: 1.178 G_L1: 1.893 D_real: 0.416 D_fake: 0.744 \n",
            "(epoch: 88, iters: 1900, time: 0.066, data: 0.004) G_GAN: 2.964 G_L1: 4.021 D_real: 0.021 D_fake: 0.251 \n",
            "(epoch: 88, iters: 2000, time: 0.477, data: 0.004) G_GAN: 5.141 G_L1: 2.149 D_real: 0.000 D_fake: 0.010 \n",
            "saving the latest model (epoch 88, total_iters 350000)\n",
            "(epoch: 88, iters: 2100, time: 0.066, data: 0.002) G_GAN: 2.457 G_L1: 1.503 D_real: 0.124 D_fake: 0.147 \n",
            "(epoch: 88, iters: 2200, time: 0.066, data: 0.006) G_GAN: 3.163 G_L1: 2.973 D_real: 0.292 D_fake: 0.048 \n",
            "(epoch: 88, iters: 2300, time: 0.066, data: 0.003) G_GAN: 2.025 G_L1: 2.077 D_real: 0.192 D_fake: 0.991 \n",
            "(epoch: 88, iters: 2400, time: 0.162, data: 0.004) G_GAN: 8.307 G_L1: 0.936 D_real: 0.001 D_fake: 0.000 \n",
            "(epoch: 88, iters: 2500, time: 0.067, data: 0.002) G_GAN: 0.714 G_L1: 3.228 D_real: 0.586 D_fake: 0.978 \n",
            "(epoch: 88, iters: 2600, time: 0.066, data: 0.007) G_GAN: 1.868 G_L1: 1.937 D_real: 0.192 D_fake: 0.723 \n",
            "(epoch: 88, iters: 2700, time: 0.066, data: 0.004) G_GAN: 1.985 G_L1: 1.618 D_real: 0.236 D_fake: 0.247 \n",
            "(epoch: 88, iters: 2800, time: 0.155, data: 0.003) G_GAN: 5.433 G_L1: 0.564 D_real: 0.010 D_fake: 0.010 \n",
            "(epoch: 88, iters: 2900, time: 0.056, data: 0.007) G_GAN: 3.941 G_L1: 2.114 D_real: 0.054 D_fake: 0.030 \n",
            "(epoch: 88, iters: 3000, time: 0.066, data: 0.004) G_GAN: 1.006 G_L1: 1.964 D_real: 1.576 D_fake: 0.253 \n",
            "(epoch: 88, iters: 3100, time: 0.067, data: 0.003) G_GAN: 6.184 G_L1: 0.904 D_real: 0.004 D_fake: 0.004 \n",
            "(epoch: 88, iters: 3200, time: 0.174, data: 0.004) G_GAN: 2.599 G_L1: 2.543 D_real: 0.377 D_fake: 0.070 \n",
            "(epoch: 88, iters: 3300, time: 0.066, data: 0.002) G_GAN: 0.842 G_L1: 2.628 D_real: 0.589 D_fake: 0.615 \n",
            "(epoch: 88, iters: 3400, time: 0.066, data: 0.003) G_GAN: 9.964 G_L1: 0.834 D_real: 0.001 D_fake: 0.000 \n",
            "(epoch: 88, iters: 3500, time: 0.067, data: 0.007) G_GAN: 3.035 G_L1: 0.974 D_real: 0.029 D_fake: 0.074 \n",
            "(epoch: 88, iters: 3600, time: 0.171, data: 0.002) G_GAN: 7.557 G_L1: 2.744 D_real: 0.510 D_fake: 0.000 \n",
            "(epoch: 88, iters: 3700, time: 0.065, data: 0.005) G_GAN: 0.932 G_L1: 1.988 D_real: 0.266 D_fake: 1.025 \n",
            "(epoch: 88, iters: 3800, time: 0.065, data: 0.004) G_GAN: 7.333 G_L1: 1.207 D_real: 0.001 D_fake: 0.002 \n",
            "(epoch: 88, iters: 3900, time: 0.065, data: 0.003) G_GAN: 0.811 G_L1: 2.425 D_real: 0.682 D_fake: 0.632 \n",
            "(epoch: 88, iters: 4000, time: 0.456, data: 0.002) G_GAN: 1.869 G_L1: 2.973 D_real: 0.440 D_fake: 0.420 \n",
            "End of epoch 88 / 200 \t Time Taken: 175 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "(epoch: 89, iters: 100, time: 0.066, data: 0.183) G_GAN: 7.950 G_L1: 1.481 D_real: 0.376 D_fake: 0.001 \n",
            "(epoch: 89, iters: 200, time: 0.066, data: 0.002) G_GAN: 0.840 G_L1: 2.146 D_real: 0.711 D_fake: 0.617 \n",
            "(epoch: 89, iters: 300, time: 0.067, data: 0.003) G_GAN: 2.912 G_L1: 2.674 D_real: 0.295 D_fake: 0.077 \n",
            "(epoch: 89, iters: 400, time: 0.702, data: 0.003) G_GAN: 9.749 G_L1: 1.641 D_real: 0.000 D_fake: 0.000 \n",
            "(epoch: 89, iters: 500, time: 0.067, data: 0.006) G_GAN: 2.280 G_L1: 1.387 D_real: 0.058 D_fake: 0.323 \n",
            "(epoch: 89, iters: 600, time: 0.066, data: 0.002) G_GAN: 3.902 G_L1: 2.188 D_real: 0.189 D_fake: 0.613 \n",
            "(epoch: 89, iters: 700, time: 0.066, data: 0.004) G_GAN: 3.290 G_L1: 2.187 D_real: 0.097 D_fake: 0.170 \n",
            "(epoch: 89, iters: 800, time: 0.216, data: 0.007) G_GAN: 0.555 G_L1: 1.973 D_real: 0.234 D_fake: 1.541 \n",
            "(epoch: 89, iters: 900, time: 0.066, data: 0.003) G_GAN: 5.148 G_L1: 3.079 D_real: 0.031 D_fake: 0.009 \n",
            "(epoch: 89, iters: 1000, time: 0.058, data: 0.003) G_GAN: 0.792 G_L1: 2.067 D_real: 0.578 D_fake: 0.772 \n",
            "(epoch: 89, iters: 1100, time: 0.066, data: 0.003) G_GAN: 10.367 G_L1: 0.753 D_real: 0.010 D_fake: 0.000 \n",
            "(epoch: 89, iters: 1200, time: 0.190, data: 0.002) G_GAN: 2.005 G_L1: 1.123 D_real: 0.423 D_fake: 0.617 \n",
            "(epoch: 89, iters: 1300, time: 0.065, data: 0.002) G_GAN: 7.069 G_L1: 1.352 D_real: 2.109 D_fake: 0.001 \n",
            "(epoch: 89, iters: 1400, time: 0.066, data: 0.004) G_GAN: 0.941 G_L1: 2.002 D_real: 1.106 D_fake: 0.406 \n",
            "(epoch: 89, iters: 1500, time: 0.066, data: 0.003) G_GAN: 2.115 G_L1: 4.996 D_real: 0.877 D_fake: 0.359 \n",
            "(epoch: 89, iters: 1600, time: 0.189, data: 0.005) G_GAN: 1.970 G_L1: 2.127 D_real: 0.164 D_fake: 0.982 \n",
            "(epoch: 89, iters: 1700, time: 0.066, data: 0.002) G_GAN: 0.869 G_L1: 1.814 D_real: 0.473 D_fake: 0.717 \n",
            "(epoch: 89, iters: 1800, time: 0.067, data: 0.003) G_GAN: 0.747 G_L1: 2.898 D_real: 0.510 D_fake: 0.782 \n",
            "(epoch: 89, iters: 1900, time: 0.065, data: 0.005) G_GAN: 3.796 G_L1: 2.564 D_real: 0.102 D_fake: 0.023 \n",
            "(epoch: 89, iters: 2000, time: 0.511, data: 0.002) G_GAN: 6.562 G_L1: 1.586 D_real: 0.000 D_fake: 0.003 \n",
            "(epoch: 89, iters: 2100, time: 0.063, data: 0.007) G_GAN: 0.810 G_L1: 2.108 D_real: 0.478 D_fake: 0.824 \n",
            "(epoch: 89, iters: 2200, time: 0.065, data: 0.004) G_GAN: 2.694 G_L1: 1.631 D_real: 0.177 D_fake: 0.093 \n",
            "(epoch: 89, iters: 2300, time: 0.062, data: 0.006) G_GAN: 2.921 G_L1: 3.181 D_real: 0.152 D_fake: 1.181 \n",
            "(epoch: 89, iters: 2400, time: 0.166, data: 0.003) G_GAN: 5.702 G_L1: 0.462 D_real: 0.001 D_fake: 0.005 \n",
            "(epoch: 89, iters: 2500, time: 0.067, data: 0.002) G_GAN: 3.002 G_L1: 1.040 D_real: 0.168 D_fake: 0.169 \n",
            "(epoch: 89, iters: 2600, time: 0.066, data: 0.004) G_GAN: 2.524 G_L1: 1.119 D_real: 0.411 D_fake: 0.109 \n",
            "(epoch: 89, iters: 2700, time: 0.065, data: 0.003) G_GAN: 0.880 G_L1: 1.914 D_real: 0.824 D_fake: 0.731 \n",
            "(epoch: 89, iters: 2800, time: 0.167, data: 0.003) G_GAN: 2.324 G_L1: 1.781 D_real: 0.092 D_fake: 2.296 \n",
            "(epoch: 89, iters: 2900, time: 0.065, data: 0.002) G_GAN: 3.085 G_L1: 2.793 D_real: 0.129 D_fake: 0.478 \n",
            "(epoch: 89, iters: 3000, time: 0.067, data: 0.004) G_GAN: 0.826 G_L1: 2.631 D_real: 0.747 D_fake: 0.646 \n",
            "saving the latest model (epoch 89, total_iters 355000)\n",
            "(epoch: 89, iters: 3100, time: 0.066, data: 0.002) G_GAN: 0.699 G_L1: 1.747 D_real: 0.602 D_fake: 0.855 \n",
            "(epoch: 89, iters: 3200, time: 0.211, data: 0.004) G_GAN: 0.712 G_L1: 2.039 D_real: 0.690 D_fake: 0.854 \n",
            "(epoch: 89, iters: 3300, time: 0.066, data: 0.002) G_GAN: 8.413 G_L1: 1.122 D_real: 0.001 D_fake: 0.000 \n",
            "(epoch: 89, iters: 3400, time: 0.066, data: 0.004) G_GAN: 2.235 G_L1: 1.756 D_real: 0.252 D_fake: 0.144 \n",
            "(epoch: 89, iters: 3500, time: 0.066, data: 0.003) G_GAN: 5.815 G_L1: 1.626 D_real: 0.068 D_fake: 0.003 \n",
            "(epoch: 89, iters: 3600, time: 0.185, data: 0.003) G_GAN: 3.857 G_L1: 0.871 D_real: 0.123 D_fake: 0.024 \n",
            "(epoch: 89, iters: 3700, time: 0.066, data: 0.005) G_GAN: 2.907 G_L1: 3.316 D_real: 0.902 D_fake: 0.157 \n",
            "(epoch: 89, iters: 3800, time: 0.053, data: 0.004) G_GAN: 5.871 G_L1: 1.170 D_real: 0.001 D_fake: 0.006 \n",
            "(epoch: 89, iters: 3900, time: 0.067, data: 0.008) G_GAN: 8.680 G_L1: 0.875 D_real: 0.001 D_fake: 0.000 \n",
            "(epoch: 89, iters: 4000, time: 0.540, data: 0.004) G_GAN: 0.937 G_L1: 1.831 D_real: 0.599 D_fake: 0.502 \n",
            "End of epoch 89 / 200 \t Time Taken: 175 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "(epoch: 90, iters: 100, time: 0.066, data: 0.238) G_GAN: 1.314 G_L1: 1.976 D_real: 0.455 D_fake: 0.367 \n",
            "(epoch: 90, iters: 200, time: 0.066, data: 0.002) G_GAN: 1.262 G_L1: 2.074 D_real: 0.175 D_fake: 1.292 \n",
            "(epoch: 90, iters: 300, time: 0.067, data: 0.003) G_GAN: 2.385 G_L1: 1.949 D_real: 0.191 D_fake: 1.389 \n",
            "(epoch: 90, iters: 400, time: 0.694, data: 0.004) G_GAN: 7.854 G_L1: 2.039 D_real: 0.130 D_fake: 0.001 \n",
            "(epoch: 90, iters: 500, time: 0.067, data: 0.003) G_GAN: 3.491 G_L1: 1.225 D_real: 0.079 D_fake: 0.679 \n",
            "(epoch: 90, iters: 600, time: 0.059, data: 0.003) G_GAN: 7.898 G_L1: 1.156 D_real: 0.000 D_fake: 0.001 \n",
            "(epoch: 90, iters: 700, time: 0.067, data: 0.005) G_GAN: 3.145 G_L1: 1.225 D_real: 0.090 D_fake: 0.195 \n",
            "(epoch: 90, iters: 800, time: 0.188, data: 0.003) G_GAN: 2.543 G_L1: 2.162 D_real: 0.223 D_fake: 0.094 \n",
            "(epoch: 90, iters: 900, time: 0.067, data: 0.002) G_GAN: 2.234 G_L1: 2.331 D_real: 0.159 D_fake: 0.249 \n",
            "(epoch: 90, iters: 1000, time: 0.066, data: 0.005) G_GAN: 2.193 G_L1: 1.729 D_real: 0.224 D_fake: 0.304 \n",
            "(epoch: 90, iters: 1100, time: 0.066, data: 0.002) G_GAN: 4.056 G_L1: 0.891 D_real: 0.000 D_fake: 0.035 \n",
            "(epoch: 90, iters: 1200, time: 0.159, data: 0.003) G_GAN: 5.515 G_L1: 0.929 D_real: 0.001 D_fake: 0.009 \n",
            "(epoch: 90, iters: 1300, time: 0.066, data: 0.006) G_GAN: 1.847 G_L1: 1.923 D_real: 0.205 D_fake: 1.843 \n",
            "(epoch: 90, iters: 1400, time: 0.064, data: 0.004) G_GAN: 3.428 G_L1: 1.969 D_real: 0.031 D_fake: 0.056 \n",
            "(epoch: 90, iters: 1500, time: 0.067, data: 0.004) G_GAN: 2.713 G_L1: 2.132 D_real: 0.094 D_fake: 0.310 \n",
            "(epoch: 90, iters: 1600, time: 0.214, data: 0.003) G_GAN: 0.784 G_L1: 2.755 D_real: 0.476 D_fake: 0.824 \n",
            "(epoch: 90, iters: 1700, time: 0.065, data: 0.003) G_GAN: 4.690 G_L1: 1.459 D_real: 0.044 D_fake: 0.013 \n",
            "(epoch: 90, iters: 1800, time: 0.067, data: 0.005) G_GAN: 0.689 G_L1: 2.897 D_real: 0.489 D_fake: 0.888 \n",
            "(epoch: 90, iters: 1900, time: 0.066, data: 0.004) G_GAN: 0.759 G_L1: 1.706 D_real: 0.559 D_fake: 0.846 \n",
            "(epoch: 90, iters: 2000, time: 0.614, data: 0.003) G_GAN: 2.403 G_L1: 1.993 D_real: 0.034 D_fake: 0.271 \n",
            "(epoch: 90, iters: 2100, time: 0.065, data: 0.004) G_GAN: 6.380 G_L1: 4.366 D_real: 0.072 D_fake: 0.004 \n",
            "(epoch: 90, iters: 2200, time: 0.067, data: 0.004) G_GAN: 0.757 G_L1: 2.012 D_real: 0.788 D_fake: 0.661 \n",
            "(epoch: 90, iters: 2300, time: 0.067, data: 0.007) G_GAN: 0.929 G_L1: 2.035 D_real: 0.690 D_fake: 0.620 \n",
            "(epoch: 90, iters: 2400, time: 0.169, data: 0.003) G_GAN: 3.949 G_L1: 1.321 D_real: 0.276 D_fake: 0.055 \n",
            "(epoch: 90, iters: 2500, time: 0.060, data: 0.006) G_GAN: 1.416 G_L1: 4.307 D_real: 0.527 D_fake: 0.156 \n",
            "(epoch: 90, iters: 2600, time: 0.067, data: 0.004) G_GAN: 3.477 G_L1: 1.293 D_real: 0.047 D_fake: 0.436 \n",
            "(epoch: 90, iters: 2700, time: 0.066, data: 0.005) G_GAN: 6.532 G_L1: 1.108 D_real: 0.000 D_fake: 0.003 \n",
            "(epoch: 90, iters: 2800, time: 0.174, data: 0.004) G_GAN: 4.917 G_L1: 2.668 D_real: 0.038 D_fake: 0.011 \n",
            "(epoch: 90, iters: 2900, time: 0.065, data: 0.005) G_GAN: 1.742 G_L1: 2.557 D_real: 0.822 D_fake: 0.035 \n",
            "(epoch: 90, iters: 3000, time: 0.066, data: 0.002) G_GAN: 2.309 G_L1: 1.977 D_real: 0.097 D_fake: 0.378 \n",
            "(epoch: 90, iters: 3100, time: 0.063, data: 0.003) G_GAN: 0.830 G_L1: 1.710 D_real: 0.603 D_fake: 0.635 \n",
            "(epoch: 90, iters: 3200, time: 0.213, data: 0.003) G_GAN: 0.775 G_L1: 3.593 D_real: 0.769 D_fake: 0.638 \n",
            "(epoch: 90, iters: 3300, time: 0.066, data: 0.003) G_GAN: 3.486 G_L1: 1.119 D_real: 0.258 D_fake: 0.442 \n",
            "(epoch: 90, iters: 3400, time: 0.067, data: 0.006) G_GAN: 3.245 G_L1: 4.916 D_real: 0.704 D_fake: 0.030 \n",
            "(epoch: 90, iters: 3500, time: 0.067, data: 0.004) G_GAN: 9.349 G_L1: 0.839 D_real: 0.000 D_fake: 0.000 \n",
            "(epoch: 90, iters: 3600, time: 0.224, data: 0.003) G_GAN: 0.645 G_L1: 1.817 D_real: 1.050 D_fake: 0.806 \n",
            "(epoch: 90, iters: 3700, time: 0.066, data: 0.007) G_GAN: 3.249 G_L1: 2.990 D_real: 0.030 D_fake: 0.419 \n",
            "(epoch: 90, iters: 3800, time: 0.067, data: 0.004) G_GAN: 3.454 G_L1: 3.609 D_real: 0.038 D_fake: 0.060 \n",
            "(epoch: 90, iters: 3900, time: 0.067, data: 0.004) G_GAN: 7.583 G_L1: 0.807 D_real: 0.003 D_fake: 0.001 \n",
            "(epoch: 90, iters: 4000, time: 0.513, data: 0.004) G_GAN: 3.881 G_L1: 1.317 D_real: 0.097 D_fake: 0.046 \n",
            "saving the latest model (epoch 90, total_iters 360000)\n",
            "saving the model at the end of epoch 90, iters 360000\n",
            "End of epoch 90 / 200 \t Time Taken: 177 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "(epoch: 91, iters: 100, time: 0.067, data: 0.190) G_GAN: 6.311 G_L1: 0.609 D_real: 0.001 D_fake: 0.003 \n",
            "(epoch: 91, iters: 200, time: 0.066, data: 0.002) G_GAN: 1.346 G_L1: 2.114 D_real: 0.418 D_fake: 1.126 \n",
            "(epoch: 91, iters: 300, time: 0.067, data: 0.004) G_GAN: 6.035 G_L1: 0.714 D_real: 0.003 D_fake: 0.007 \n",
            "(epoch: 91, iters: 400, time: 0.642, data: 0.003) G_GAN: 2.386 G_L1: 1.281 D_real: 0.037 D_fake: 0.579 \n",
            "(epoch: 91, iters: 500, time: 0.065, data: 0.003) G_GAN: 2.147 G_L1: 1.277 D_real: 0.105 D_fake: 0.595 \n",
            "(epoch: 91, iters: 600, time: 0.067, data: 0.008) G_GAN: 0.733 G_L1: 2.122 D_real: 0.821 D_fake: 0.751 \n",
            "(epoch: 91, iters: 700, time: 0.067, data: 0.004) G_GAN: 2.079 G_L1: 1.137 D_real: 0.034 D_fake: 0.417 \n",
            "(epoch: 91, iters: 800, time: 0.212, data: 0.004) G_GAN: 0.935 G_L1: 2.424 D_real: 0.794 D_fake: 0.508 \n",
            "(epoch: 91, iters: 900, time: 0.066, data: 0.005) G_GAN: 3.548 G_L1: 0.461 D_real: 0.000 D_fake: 0.187 \n",
            "(epoch: 91, iters: 1000, time: 0.067, data: 0.004) G_GAN: 2.767 G_L1: 2.761 D_real: 0.174 D_fake: 0.092 \n",
            "(epoch: 91, iters: 1100, time: 0.065, data: 0.002) G_GAN: 1.273 G_L1: 1.605 D_real: 0.998 D_fake: 0.540 \n",
            "(epoch: 91, iters: 1200, time: 0.169, data: 0.002) G_GAN: 2.075 G_L1: 1.522 D_real: 0.274 D_fake: 0.513 \n",
            "(epoch: 91, iters: 1300, time: 0.067, data: 0.002) G_GAN: 7.819 G_L1: 0.710 D_real: 0.113 D_fake: 0.001 \n",
            "(epoch: 91, iters: 1400, time: 0.065, data: 0.003) G_GAN: 1.791 G_L1: 2.229 D_real: 0.179 D_fake: 0.296 \n",
            "(epoch: 91, iters: 1500, time: 0.064, data: 0.003) G_GAN: 4.301 G_L1: 2.219 D_real: 0.040 D_fake: 0.024 \n",
            "(epoch: 91, iters: 1600, time: 0.235, data: 0.003) G_GAN: 0.874 G_L1: 2.274 D_real: 0.767 D_fake: 0.530 \n",
            "(epoch: 91, iters: 1700, time: 0.066, data: 0.004) G_GAN: 3.886 G_L1: 3.042 D_real: 0.053 D_fake: 1.840 \n",
            "(epoch: 91, iters: 1800, time: 0.063, data: 0.003) G_GAN: 4.106 G_L1: 1.192 D_real: 0.232 D_fake: 0.022 \n",
            "(epoch: 91, iters: 1900, time: 0.067, data: 0.003) G_GAN: 8.501 G_L1: 0.835 D_real: 0.001 D_fake: 0.000 \n",
            "(epoch: 91, iters: 2000, time: 0.567, data: 0.003) G_GAN: 0.830 G_L1: 3.647 D_real: 0.779 D_fake: 0.653 \n",
            "(epoch: 91, iters: 2100, time: 0.067, data: 0.006) G_GAN: 1.677 G_L1: 1.287 D_real: 1.285 D_fake: 0.337 \n",
            "(epoch: 91, iters: 2200, time: 0.059, data: 0.004) G_GAN: 1.554 G_L1: 1.927 D_real: 0.635 D_fake: 0.316 \n",
            "(epoch: 91, iters: 2300, time: 0.066, data: 0.002) G_GAN: 1.075 G_L1: 2.361 D_real: 1.121 D_fake: 0.609 \n",
            "(epoch: 91, iters: 2400, time: 0.170, data: 0.004) G_GAN: 1.972 G_L1: 2.708 D_real: 0.300 D_fake: 0.217 \n",
            "(epoch: 91, iters: 2500, time: 0.067, data: 0.002) G_GAN: 3.534 G_L1: 1.258 D_real: 0.116 D_fake: 0.079 \n",
            "(epoch: 91, iters: 2600, time: 0.067, data: 0.004) G_GAN: 9.504 G_L1: 0.880 D_real: 0.000 D_fake: 0.000 \n",
            "(epoch: 91, iters: 2700, time: 0.066, data: 0.004) G_GAN: 0.931 G_L1: 1.765 D_real: 0.374 D_fake: 0.665 \n",
            "(epoch: 91, iters: 2800, time: 0.183, data: 0.004) G_GAN: 3.827 G_L1: 1.664 D_real: 0.211 D_fake: 0.174 \n",
            "(epoch: 91, iters: 2900, time: 0.065, data: 0.006) G_GAN: 4.841 G_L1: 1.502 D_real: 0.067 D_fake: 0.010 \n",
            "(epoch: 91, iters: 3000, time: 0.067, data: 0.003) G_GAN: 5.587 G_L1: 2.625 D_real: 0.079 D_fake: 0.007 \n",
            "(epoch: 91, iters: 3100, time: 0.064, data: 0.002) G_GAN: 7.064 G_L1: 0.823 D_real: 0.004 D_fake: 0.001 \n",
            "(epoch: 91, iters: 3200, time: 0.171, data: 0.004) G_GAN: 1.552 G_L1: 2.066 D_real: 0.277 D_fake: 0.349 \n",
            "(epoch: 91, iters: 3300, time: 0.066, data: 0.003) G_GAN: 6.102 G_L1: 1.077 D_real: 0.009 D_fake: 0.004 \n",
            "(epoch: 91, iters: 3400, time: 0.066, data: 0.002) G_GAN: 4.656 G_L1: 4.662 D_real: 0.040 D_fake: 0.016 \n",
            "(epoch: 91, iters: 3500, time: 0.066, data: 0.003) G_GAN: 8.755 G_L1: 0.676 D_real: 0.000 D_fake: 0.000 \n",
            "(epoch: 91, iters: 3600, time: 0.303, data: 0.004) G_GAN: 2.807 G_L1: 1.406 D_real: 0.058 D_fake: 0.170 \n",
            "(epoch: 91, iters: 3700, time: 0.066, data: 0.004) G_GAN: 3.447 G_L1: 6.087 D_real: 0.080 D_fake: 0.061 \n",
            "(epoch: 91, iters: 3800, time: 0.065, data: 0.002) G_GAN: 7.756 G_L1: 0.686 D_real: 0.000 D_fake: 0.001 \n",
            "(epoch: 91, iters: 3900, time: 0.067, data: 0.002) G_GAN: 1.572 G_L1: 1.801 D_real: 1.517 D_fake: 0.103 \n",
            "(epoch: 91, iters: 4000, time: 0.500, data: 0.003) G_GAN: 0.255 G_L1: 1.693 D_real: 2.252 D_fake: 0.192 \n",
            "End of epoch 91 / 200 \t Time Taken: 174 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "(epoch: 92, iters: 100, time: 0.065, data: 0.227) G_GAN: 6.033 G_L1: 0.984 D_real: 0.000 D_fake: 0.004 \n",
            "(epoch: 92, iters: 200, time: 0.065, data: 0.004) G_GAN: 0.839 G_L1: 5.862 D_real: 0.520 D_fake: 0.691 \n",
            "(epoch: 92, iters: 300, time: 0.067, data: 0.004) G_GAN: 0.803 G_L1: 2.051 D_real: 0.697 D_fake: 0.799 \n",
            "(epoch: 92, iters: 400, time: 0.599, data: 0.005) G_GAN: 6.026 G_L1: 1.177 D_real: 0.001 D_fake: 0.005 \n",
            "(epoch: 92, iters: 500, time: 0.066, data: 0.003) G_GAN: 2.308 G_L1: 3.013 D_real: 0.341 D_fake: 0.167 \n",
            "(epoch: 92, iters: 600, time: 0.066, data: 0.003) G_GAN: 0.503 G_L1: 1.140 D_real: 0.985 D_fake: 0.947 \n",
            "(epoch: 92, iters: 700, time: 0.066, data: 0.004) G_GAN: 2.961 G_L1: 2.777 D_real: 0.022 D_fake: 0.106 \n",
            "(epoch: 92, iters: 800, time: 0.161, data: 0.002) G_GAN: 8.833 G_L1: 0.598 D_real: 0.001 D_fake: 0.000 \n",
            "(epoch: 92, iters: 900, time: 0.066, data: 0.002) G_GAN: 7.053 G_L1: 0.944 D_real: 0.000 D_fake: 0.001 \n",
            "(epoch: 92, iters: 1000, time: 0.067, data: 0.004) G_GAN: 2.978 G_L1: 3.381 D_real: 0.018 D_fake: 0.468 \n",
            "saving the latest model (epoch 92, total_iters 365000)\n",
            "(epoch: 92, iters: 1100, time: 0.067, data: 0.002) G_GAN: 4.249 G_L1: 0.993 D_real: 0.056 D_fake: 0.019 \n",
            "(epoch: 92, iters: 1200, time: 0.196, data: 0.006) G_GAN: 2.171 G_L1: 2.821 D_real: 0.147 D_fake: 1.029 \n",
            "(epoch: 92, iters: 1300, time: 0.060, data: 0.004) G_GAN: 0.852 G_L1: 2.614 D_real: 0.962 D_fake: 0.458 \n",
            "(epoch: 92, iters: 1400, time: 0.066, data: 0.002) G_GAN: 3.611 G_L1: 3.256 D_real: 0.635 D_fake: 0.019 \n",
            "(epoch: 92, iters: 1500, time: 0.066, data: 0.004) G_GAN: 1.024 G_L1: 1.293 D_real: 0.453 D_fake: 0.793 \n",
            "(epoch: 92, iters: 1600, time: 0.219, data: 0.003) G_GAN: 0.870 G_L1: 1.897 D_real: 1.086 D_fake: 0.196 \n",
            "(epoch: 92, iters: 1700, time: 0.065, data: 0.002) G_GAN: 0.778 G_L1: 2.529 D_real: 0.708 D_fake: 0.546 \n",
            "(epoch: 92, iters: 1800, time: 0.066, data: 0.004) G_GAN: 3.244 G_L1: 3.055 D_real: 0.062 D_fake: 1.361 \n",
            "(epoch: 92, iters: 1900, time: 0.065, data: 0.006) G_GAN: 2.615 G_L1: 5.613 D_real: 0.087 D_fake: 0.195 \n",
            "(epoch: 92, iters: 2000, time: 0.477, data: 0.002) G_GAN: 2.883 G_L1: 2.934 D_real: 0.137 D_fake: 1.050 \n",
            "(epoch: 92, iters: 2100, time: 0.065, data: 0.002) G_GAN: 0.721 G_L1: 2.653 D_real: 0.530 D_fake: 0.881 \n",
            "(epoch: 92, iters: 2200, time: 0.066, data: 0.008) G_GAN: 0.944 G_L1: 3.443 D_real: 0.563 D_fake: 0.621 \n",
            "(epoch: 92, iters: 2300, time: 0.066, data: 0.005) G_GAN: 8.337 G_L1: 1.488 D_real: 0.053 D_fake: 0.000 \n",
            "(epoch: 92, iters: 2400, time: 0.170, data: 0.004) G_GAN: 0.868 G_L1: 1.753 D_real: 0.384 D_fake: 0.722 \n",
            "(epoch: 92, iters: 2500, time: 0.066, data: 0.009) G_GAN: 6.775 G_L1: 1.682 D_real: 0.508 D_fake: 0.001 \n",
            "(epoch: 92, iters: 2600, time: 0.066, data: 0.003) G_GAN: 3.595 G_L1: 2.076 D_real: 0.078 D_fake: 0.865 \n",
            "(epoch: 92, iters: 2700, time: 0.066, data: 0.007) G_GAN: 1.429 G_L1: 2.512 D_real: 0.712 D_fake: 0.375 \n",
            "(epoch: 92, iters: 2800, time: 0.156, data: 0.004) G_GAN: 8.201 G_L1: 1.093 D_real: 0.000 D_fake: 0.001 \n",
            "(epoch: 92, iters: 2900, time: 0.066, data: 0.002) G_GAN: 1.148 G_L1: 2.051 D_real: 0.484 D_fake: 0.532 \n",
            "(epoch: 92, iters: 3000, time: 0.064, data: 0.004) G_GAN: 0.915 G_L1: 2.024 D_real: 0.763 D_fake: 0.565 \n",
            "(epoch: 92, iters: 3100, time: 0.065, data: 0.002) G_GAN: 9.536 G_L1: 1.101 D_real: 0.002 D_fake: 0.000 \n",
            "(epoch: 92, iters: 3200, time: 0.189, data: 0.009) G_GAN: 1.230 G_L1: 3.903 D_real: 0.375 D_fake: 0.498 \n",
            "(epoch: 92, iters: 3300, time: 0.067, data: 0.002) G_GAN: 1.193 G_L1: 1.520 D_real: 0.899 D_fake: 0.296 \n",
            "(epoch: 92, iters: 3400, time: 0.066, data: 0.004) G_GAN: 7.620 G_L1: 1.520 D_real: 0.001 D_fake: 0.001 \n",
            "(epoch: 92, iters: 3500, time: 0.065, data: 0.004) G_GAN: 0.519 G_L1: 2.473 D_real: 0.467 D_fake: 1.434 \n",
            "(epoch: 92, iters: 3600, time: 0.174, data: 0.003) G_GAN: 1.493 G_L1: 2.932 D_real: 0.175 D_fake: 1.638 \n",
            "(epoch: 92, iters: 3700, time: 0.067, data: 0.003) G_GAN: 1.025 G_L1: 1.951 D_real: 0.805 D_fake: 0.570 \n",
            "(epoch: 92, iters: 3800, time: 0.067, data: 0.003) G_GAN: 7.492 G_L1: 0.935 D_real: 0.001 D_fake: 0.001 \n",
            "(epoch: 92, iters: 3900, time: 0.066, data: 0.002) G_GAN: 5.594 G_L1: 2.509 D_real: 0.145 D_fake: 0.012 \n",
            "(epoch: 92, iters: 4000, time: 0.473, data: 0.008) G_GAN: 7.284 G_L1: 1.470 D_real: 0.000 D_fake: 0.001 \n",
            "End of epoch 92 / 200 \t Time Taken: 175 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "(epoch: 93, iters: 100, time: 0.058, data: 0.214) G_GAN: 6.966 G_L1: 0.799 D_real: 0.000 D_fake: 0.002 \n",
            "(epoch: 93, iters: 200, time: 0.067, data: 0.006) G_GAN: 9.001 G_L1: 0.827 D_real: 0.000 D_fake: 0.000 \n",
            "(epoch: 93, iters: 300, time: 0.066, data: 0.003) G_GAN: 0.845 G_L1: 1.431 D_real: 0.287 D_fake: 1.034 \n",
            "(epoch: 93, iters: 400, time: 0.671, data: 0.003) G_GAN: 10.414 G_L1: 0.778 D_real: 0.002 D_fake: 0.000 \n",
            "(epoch: 93, iters: 500, time: 0.067, data: 0.003) G_GAN: 3.637 G_L1: 2.264 D_real: 0.145 D_fake: 0.024 \n",
            "(epoch: 93, iters: 600, time: 0.066, data: 0.003) G_GAN: 4.981 G_L1: 1.571 D_real: 0.951 D_fake: 0.045 \n",
            "(epoch: 93, iters: 700, time: 0.067, data: 0.005) G_GAN: 0.795 G_L1: 2.121 D_real: 0.508 D_fake: 0.837 \n",
            "(epoch: 93, iters: 800, time: 0.193, data: 0.006) G_GAN: 2.372 G_L1: 1.136 D_real: 0.182 D_fake: 0.461 \n",
            "(epoch: 93, iters: 900, time: 0.066, data: 0.003) G_GAN: 3.872 G_L1: 1.001 D_real: 0.383 D_fake: 0.063 \n",
            "(epoch: 93, iters: 1000, time: 0.066, data: 0.006) G_GAN: 8.689 G_L1: 0.969 D_real: 0.000 D_fake: 0.001 \n",
            "(epoch: 93, iters: 1100, time: 0.065, data: 0.005) G_GAN: 7.130 G_L1: 1.470 D_real: 0.790 D_fake: 0.001 \n",
            "(epoch: 93, iters: 1200, time: 0.176, data: 0.003) G_GAN: 2.250 G_L1: 1.224 D_real: 0.038 D_fake: 0.035 \n",
            "(epoch: 93, iters: 1300, time: 0.066, data: 0.014) G_GAN: 1.119 G_L1: 2.016 D_real: 0.448 D_fake: 0.937 \n",
            "(epoch: 93, iters: 1400, time: 0.067, data: 0.003) G_GAN: 0.696 G_L1: 2.844 D_real: 0.489 D_fake: 1.001 \n",
            "(epoch: 93, iters: 1500, time: 0.066, data: 0.003) G_GAN: 0.793 G_L1: 2.174 D_real: 0.610 D_fake: 0.674 \n",
            "(epoch: 93, iters: 1600, time: 0.179, data: 0.006) G_GAN: 5.155 G_L1: 2.717 D_real: 0.041 D_fake: 0.565 \n",
            "(epoch: 93, iters: 1700, time: 0.064, data: 0.006) G_GAN: 0.770 G_L1: 2.050 D_real: 0.809 D_fake: 0.565 \n",
            "(epoch: 93, iters: 1800, time: 0.062, data: 0.004) G_GAN: 2.748 G_L1: 1.278 D_real: 0.050 D_fake: 0.140 \n",
            "(epoch: 93, iters: 1900, time: 0.066, data: 0.002) G_GAN: 3.001 G_L1: 1.525 D_real: 0.250 D_fake: 0.097 \n",
            "(epoch: 93, iters: 2000, time: 0.485, data: 0.004) G_GAN: 2.369 G_L1: 1.668 D_real: 0.047 D_fake: 0.230 \n",
            "saving the latest model (epoch 93, total_iters 370000)\n",
            "(epoch: 93, iters: 2100, time: 0.067, data: 0.002) G_GAN: 6.407 G_L1: 0.952 D_real: 0.002 D_fake: 0.007 \n",
            "(epoch: 93, iters: 2200, time: 0.065, data: 0.004) G_GAN: 4.097 G_L1: 1.684 D_real: 0.398 D_fake: 0.018 \n",
            "(epoch: 93, iters: 2300, time: 0.063, data: 0.004) G_GAN: 7.557 G_L1: 0.719 D_real: 0.000 D_fake: 0.001 \n",
            "(epoch: 93, iters: 2400, time: 0.179, data: 0.004) G_GAN: 2.950 G_L1: 3.404 D_real: 0.074 D_fake: 0.127 \n",
            "(epoch: 93, iters: 2500, time: 0.066, data: 0.007) G_GAN: 5.750 G_L1: 1.872 D_real: 0.151 D_fake: 0.005 \n",
            "(epoch: 93, iters: 2600, time: 0.065, data: 0.002) G_GAN: 4.713 G_L1: 0.776 D_real: 0.000 D_fake: 0.009 \n",
            "(epoch: 93, iters: 2700, time: 0.067, data: 0.003) G_GAN: 1.067 G_L1: 1.355 D_real: 0.609 D_fake: 0.719 \n",
            "(epoch: 93, iters: 2800, time: 0.181, data: 0.003) G_GAN: 3.706 G_L1: 2.051 D_real: 0.138 D_fake: 0.279 \n",
            "(epoch: 93, iters: 2900, time: 0.065, data: 0.005) G_GAN: 5.164 G_L1: 0.963 D_real: 0.004 D_fake: 0.032 \n",
            "(epoch: 93, iters: 3000, time: 0.067, data: 0.003) G_GAN: 5.477 G_L1: 0.919 D_real: 0.001 D_fake: 0.006 \n",
            "(epoch: 93, iters: 3100, time: 0.067, data: 0.002) G_GAN: 2.670 G_L1: 1.788 D_real: 0.091 D_fake: 0.897 \n",
            "(epoch: 93, iters: 3200, time: 0.177, data: 0.004) G_GAN: 1.377 G_L1: 1.373 D_real: 0.975 D_fake: 0.135 \n",
            "(epoch: 93, iters: 3300, time: 0.067, data: 0.002) G_GAN: 0.852 G_L1: 2.235 D_real: 0.352 D_fake: 0.863 \n",
            "(epoch: 93, iters: 3400, time: 0.067, data: 0.004) G_GAN: 1.978 G_L1: 2.949 D_real: 0.450 D_fake: 0.964 \n",
            "(epoch: 93, iters: 3500, time: 0.066, data: 0.003) G_GAN: 1.359 G_L1: 1.808 D_real: 1.019 D_fake: 0.277 \n",
            "(epoch: 93, iters: 3600, time: 0.227, data: 0.004) G_GAN: 0.928 G_L1: 2.967 D_real: 1.045 D_fake: 0.357 \n",
            "(epoch: 93, iters: 3700, time: 0.066, data: 0.003) G_GAN: 7.879 G_L1: 0.601 D_real: 0.001 D_fake: 0.001 \n",
            "(epoch: 93, iters: 3800, time: 0.065, data: 0.004) G_GAN: 5.393 G_L1: 0.879 D_real: 0.000 D_fake: 0.013 \n",
            "(epoch: 93, iters: 3900, time: 0.066, data: 0.006) G_GAN: 4.955 G_L1: 1.157 D_real: 0.000 D_fake: 0.012 \n",
            "(epoch: 93, iters: 4000, time: 0.501, data: 0.003) G_GAN: 8.740 G_L1: 2.644 D_real: 0.114 D_fake: 0.000 \n",
            "End of epoch 93 / 200 \t Time Taken: 175 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "(epoch: 94, iters: 100, time: 0.067, data: 0.208) G_GAN: 1.056 G_L1: 1.845 D_real: 0.818 D_fake: 0.370 \n",
            "(epoch: 94, iters: 200, time: 0.067, data: 0.002) G_GAN: 2.153 G_L1: 2.588 D_real: 0.087 D_fake: 0.677 \n",
            "(epoch: 94, iters: 300, time: 0.066, data: 0.003) G_GAN: 3.314 G_L1: 2.616 D_real: 0.103 D_fake: 0.664 \n",
            "(epoch: 94, iters: 400, time: 0.644, data: 0.003) G_GAN: 1.075 G_L1: 2.881 D_real: 1.149 D_fake: 0.279 \n",
            "(epoch: 94, iters: 500, time: 0.063, data: 0.003) G_GAN: 9.261 G_L1: 1.018 D_real: 0.000 D_fake: 0.000 \n",
            "(epoch: 94, iters: 600, time: 0.065, data: 0.004) G_GAN: 7.723 G_L1: 0.947 D_real: 0.000 D_fake: 0.001 \n",
            "(epoch: 94, iters: 700, time: 0.065, data: 0.004) G_GAN: 5.412 G_L1: 1.330 D_real: 0.063 D_fake: 0.006 \n",
            "(epoch: 94, iters: 800, time: 0.186, data: 0.003) G_GAN: 6.380 G_L1: 1.274 D_real: 0.621 D_fake: 0.009 \n",
            "(epoch: 94, iters: 900, time: 0.065, data: 0.006) G_GAN: 2.304 G_L1: 2.314 D_real: 0.023 D_fake: 1.381 \n",
            "(epoch: 94, iters: 1000, time: 0.066, data: 0.003) G_GAN: 1.559 G_L1: 2.088 D_real: 0.345 D_fake: 0.467 \n",
            "(epoch: 94, iters: 1100, time: 0.067, data: 0.003) G_GAN: 2.812 G_L1: 1.168 D_real: 0.132 D_fake: 0.995 \n",
            "(epoch: 94, iters: 1200, time: 0.214, data: 0.002) G_GAN: 0.922 G_L1: 2.858 D_real: 0.795 D_fake: 0.549 \n",
            "(epoch: 94, iters: 1300, time: 0.061, data: 0.003) G_GAN: 7.990 G_L1: 3.736 D_real: 1.355 D_fake: 0.000 \n",
            "(epoch: 94, iters: 1400, time: 0.066, data: 0.002) G_GAN: 8.605 G_L1: 0.863 D_real: 0.003 D_fake: 0.001 \n",
            "(epoch: 94, iters: 1500, time: 0.066, data: 0.004) G_GAN: 6.559 G_L1: 0.774 D_real: 0.000 D_fake: 0.003 \n",
            "(epoch: 94, iters: 1600, time: 0.188, data: 0.003) G_GAN: 7.548 G_L1: 1.253 D_real: 0.014 D_fake: 0.001 \n",
            "(epoch: 94, iters: 1700, time: 0.059, data: 0.002) G_GAN: 5.028 G_L1: 0.785 D_real: 0.001 D_fake: 0.013 \n",
            "(epoch: 94, iters: 1800, time: 0.066, data: 0.003) G_GAN: 2.333 G_L1: 1.418 D_real: 1.060 D_fake: 0.473 \n",
            "(epoch: 94, iters: 1900, time: 0.066, data: 0.004) G_GAN: 5.560 G_L1: 0.970 D_real: 0.001 D_fake: 0.005 \n",
            "(epoch: 94, iters: 2000, time: 0.699, data: 0.003) G_GAN: 0.835 G_L1: 2.378 D_real: 0.454 D_fake: 0.808 \n",
            "(epoch: 94, iters: 2100, time: 0.067, data: 0.003) G_GAN: 1.117 G_L1: 3.416 D_real: 1.247 D_fake: 0.146 \n",
            "(epoch: 94, iters: 2200, time: 0.065, data: 0.002) G_GAN: 7.264 G_L1: 0.981 D_real: 0.001 D_fake: 0.001 \n",
            "(epoch: 94, iters: 2300, time: 0.066, data: 0.004) G_GAN: 0.963 G_L1: 1.985 D_real: 0.283 D_fake: 0.936 \n",
            "(epoch: 94, iters: 2400, time: 0.224, data: 0.003) G_GAN: 0.937 G_L1: 2.013 D_real: 0.898 D_fake: 0.431 \n",
            "(epoch: 94, iters: 2500, time: 0.066, data: 0.002) G_GAN: 1.226 G_L1: 2.427 D_real: 0.298 D_fake: 1.175 \n",
            "(epoch: 94, iters: 2600, time: 0.066, data: 0.003) G_GAN: 9.123 G_L1: 1.158 D_real: 0.003 D_fake: 0.000 \n",
            "(epoch: 94, iters: 2700, time: 0.065, data: 0.003) G_GAN: 3.742 G_L1: 1.584 D_real: 0.434 D_fake: 0.085 \n",
            "(epoch: 94, iters: 2800, time: 0.210, data: 0.006) G_GAN: 0.969 G_L1: 1.806 D_real: 0.578 D_fake: 0.696 \n",
            "(epoch: 94, iters: 2900, time: 0.067, data: 0.003) G_GAN: 2.262 G_L1: 1.880 D_real: 0.113 D_fake: 0.289 \n",
            "(epoch: 94, iters: 3000, time: 0.066, data: 0.003) G_GAN: 3.081 G_L1: 1.389 D_real: 0.076 D_fake: 0.073 \n",
            "saving the latest model (epoch 94, total_iters 375000)\n",
            "(epoch: 94, iters: 3100, time: 0.066, data: 0.006) G_GAN: 1.033 G_L1: 1.886 D_real: 0.512 D_fake: 0.557 \n",
            "(epoch: 94, iters: 3200, time: 0.166, data: 0.006) G_GAN: 5.876 G_L1: 0.937 D_real: 0.007 D_fake: 0.008 \n",
            "(epoch: 94, iters: 3300, time: 0.066, data: 0.002) G_GAN: 7.610 G_L1: 1.618 D_real: 0.128 D_fake: 0.001 \n",
            "(epoch: 94, iters: 3400, time: 0.066, data: 0.005) G_GAN: 1.318 G_L1: 1.838 D_real: 0.641 D_fake: 0.336 \n",
            "(epoch: 94, iters: 3500, time: 0.067, data: 0.003) G_GAN: 1.948 G_L1: 1.067 D_real: 0.139 D_fake: 0.294 \n",
            "(epoch: 94, iters: 3600, time: 0.157, data: 0.007) G_GAN: 9.442 G_L1: 1.055 D_real: 0.000 D_fake: 0.000 \n",
            "(epoch: 94, iters: 3700, time: 0.066, data: 0.002) G_GAN: 3.583 G_L1: 2.913 D_real: 0.016 D_fake: 0.151 \n",
            "(epoch: 94, iters: 3800, time: 0.066, data: 0.004) G_GAN: 0.770 G_L1: 2.483 D_real: 1.012 D_fake: 0.376 \n",
            "(epoch: 94, iters: 3900, time: 0.065, data: 0.002) G_GAN: 5.551 G_L1: 1.371 D_real: 0.021 D_fake: 0.006 \n",
            "(epoch: 94, iters: 4000, time: 0.459, data: 0.002) G_GAN: 6.719 G_L1: 0.873 D_real: 0.000 D_fake: 0.003 \n",
            "End of epoch 94 / 200 \t Time Taken: 175 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "(epoch: 95, iters: 100, time: 0.065, data: 0.223) G_GAN: 2.735 G_L1: 2.318 D_real: 0.086 D_fake: 0.144 \n",
            "(epoch: 95, iters: 200, time: 0.065, data: 0.002) G_GAN: 9.557 G_L1: 0.567 D_real: 0.000 D_fake: 0.000 \n",
            "(epoch: 95, iters: 300, time: 0.066, data: 0.004) G_GAN: 2.710 G_L1: 2.028 D_real: 0.410 D_fake: 0.318 \n",
            "(epoch: 95, iters: 400, time: 0.603, data: 0.004) G_GAN: 4.568 G_L1: 1.643 D_real: 0.105 D_fake: 0.027 \n",
            "(epoch: 95, iters: 500, time: 0.066, data: 0.003) G_GAN: 1.912 G_L1: 1.976 D_real: 0.029 D_fake: 0.407 \n",
            "(epoch: 95, iters: 600, time: 0.066, data: 0.006) G_GAN: 2.451 G_L1: 2.090 D_real: 0.390 D_fake: 0.096 \n",
            "(epoch: 95, iters: 700, time: 0.065, data: 0.004) G_GAN: 3.341 G_L1: 1.861 D_real: 0.152 D_fake: 0.041 \n",
            "(epoch: 95, iters: 800, time: 0.181, data: 0.004) G_GAN: 3.271 G_L1: 0.800 D_real: 0.706 D_fake: 0.085 \n",
            "(epoch: 95, iters: 900, time: 0.066, data: 0.005) G_GAN: 0.786 G_L1: 3.609 D_real: 0.586 D_fake: 0.743 \n",
            "(epoch: 95, iters: 1000, time: 0.066, data: 0.004) G_GAN: 0.937 G_L1: 1.891 D_real: 0.594 D_fake: 0.740 \n",
            "(epoch: 95, iters: 1100, time: 0.066, data: 0.004) G_GAN: 9.092 G_L1: 1.501 D_real: 0.002 D_fake: 0.000 \n",
            "(epoch: 95, iters: 1200, time: 0.178, data: 0.007) G_GAN: 1.667 G_L1: 1.129 D_real: 0.510 D_fake: 0.327 \n",
            "(epoch: 95, iters: 1300, time: 0.065, data: 0.002) G_GAN: 8.072 G_L1: 0.484 D_real: 0.001 D_fake: 0.001 \n",
            "(epoch: 95, iters: 1400, time: 0.066, data: 0.006) G_GAN: 5.869 G_L1: 1.058 D_real: 0.060 D_fake: 0.010 \n",
            "(epoch: 95, iters: 1500, time: 0.067, data: 0.003) G_GAN: 0.991 G_L1: 4.346 D_real: 0.510 D_fake: 0.574 \n",
            "(epoch: 95, iters: 1600, time: 0.160, data: 0.003) G_GAN: 4.056 G_L1: 2.022 D_real: 0.179 D_fake: 0.047 \n",
            "(epoch: 95, iters: 1700, time: 0.058, data: 0.002) G_GAN: 4.433 G_L1: 1.349 D_real: 0.000 D_fake: 0.022 \n",
            "(epoch: 95, iters: 1800, time: 0.066, data: 0.004) G_GAN: 1.149 G_L1: 3.018 D_real: 0.513 D_fake: 0.406 \n",
            "(epoch: 95, iters: 1900, time: 0.066, data: 0.004) G_GAN: 7.639 G_L1: 0.474 D_real: 0.003 D_fake: 0.001 \n",
            "(epoch: 95, iters: 2000, time: 0.557, data: 0.004) G_GAN: 0.795 G_L1: 3.755 D_real: 1.404 D_fake: 0.172 \n",
            "(epoch: 95, iters: 2100, time: 0.064, data: 0.003) G_GAN: 0.892 G_L1: 2.307 D_real: 0.364 D_fake: 1.031 \n",
            "(epoch: 95, iters: 2200, time: 0.066, data: 0.003) G_GAN: 4.265 G_L1: 0.607 D_real: 0.003 D_fake: 0.046 \n",
            "(epoch: 95, iters: 2300, time: 0.064, data: 0.005) G_GAN: 8.960 G_L1: 0.692 D_real: 0.003 D_fake: 0.000 \n",
            "(epoch: 95, iters: 2400, time: 0.231, data: 0.007) G_GAN: 0.913 G_L1: 1.905 D_real: 0.479 D_fake: 0.778 \n",
            "(epoch: 95, iters: 2500, time: 0.067, data: 0.007) G_GAN: 4.911 G_L1: 1.812 D_real: 0.421 D_fake: 0.004 \n",
            "(epoch: 95, iters: 2600, time: 0.067, data: 0.008) G_GAN: 6.408 G_L1: 0.738 D_real: 0.003 D_fake: 0.003 \n",
            "(epoch: 95, iters: 2700, time: 0.067, data: 0.004) G_GAN: 2.568 G_L1: 1.524 D_real: 0.316 D_fake: 0.158 \n",
            "(epoch: 95, iters: 2800, time: 0.197, data: 0.004) G_GAN: 3.649 G_L1: 1.411 D_real: 0.029 D_fake: 0.084 \n",
            "(epoch: 95, iters: 2900, time: 0.063, data: 0.002) G_GAN: 6.902 G_L1: 0.715 D_real: 0.000 D_fake: 0.001 \n",
            "(epoch: 95, iters: 3000, time: 0.066, data: 0.003) G_GAN: 1.572 G_L1: 2.672 D_real: 0.708 D_fake: 0.683 \n",
            "(epoch: 95, iters: 3100, time: 0.065, data: 0.003) G_GAN: 0.989 G_L1: 2.637 D_real: 0.605 D_fake: 0.546 \n",
            "(epoch: 95, iters: 3200, time: 0.298, data: 0.004) G_GAN: 5.503 G_L1: 1.692 D_real: 0.351 D_fake: 0.002 \n",
            "(epoch: 95, iters: 3300, time: 0.065, data: 0.002) G_GAN: 4.284 G_L1: 2.948 D_real: 0.822 D_fake: 0.033 \n",
            "(epoch: 95, iters: 3400, time: 0.066, data: 0.004) G_GAN: 1.412 G_L1: 2.739 D_real: 0.556 D_fake: 0.245 \n",
            "(epoch: 95, iters: 3500, time: 0.066, data: 0.004) G_GAN: 8.088 G_L1: 2.231 D_real: 0.135 D_fake: 0.000 \n",
            "(epoch: 95, iters: 3600, time: 0.194, data: 0.003) G_GAN: 7.639 G_L1: 1.231 D_real: 0.061 D_fake: 0.001 \n",
            "(epoch: 95, iters: 3700, time: 0.066, data: 0.002) G_GAN: 2.512 G_L1: 1.635 D_real: 0.241 D_fake: 0.581 \n",
            "(epoch: 95, iters: 3800, time: 0.066, data: 0.004) G_GAN: 2.172 G_L1: 4.731 D_real: 0.247 D_fake: 0.303 \n",
            "(epoch: 95, iters: 3900, time: 0.065, data: 0.002) G_GAN: 1.210 G_L1: 3.630 D_real: 0.885 D_fake: 0.204 \n",
            "(epoch: 95, iters: 4000, time: 0.480, data: 0.003) G_GAN: 4.583 G_L1: 1.218 D_real: 0.040 D_fake: 0.016 \n",
            "saving the latest model (epoch 95, total_iters 380000)\n",
            "saving the model at the end of epoch 95, iters 380000\n",
            "End of epoch 95 / 200 \t Time Taken: 177 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "(epoch: 96, iters: 100, time: 0.066, data: 0.159) G_GAN: 7.822 G_L1: 1.169 D_real: 0.000 D_fake: 0.001 \n",
            "(epoch: 96, iters: 200, time: 0.066, data: 0.003) G_GAN: 1.389 G_L1: 2.587 D_real: 0.437 D_fake: 0.396 \n",
            "(epoch: 96, iters: 300, time: 0.067, data: 0.003) G_GAN: 3.102 G_L1: 3.335 D_real: 0.101 D_fake: 0.117 \n",
            "(epoch: 96, iters: 400, time: 0.901, data: 0.002) G_GAN: 2.271 G_L1: 0.997 D_real: 0.354 D_fake: 0.232 \n",
            "(epoch: 96, iters: 500, time: 0.066, data: 0.003) G_GAN: 1.655 G_L1: 1.254 D_real: 0.331 D_fake: 0.796 \n",
            "(epoch: 96, iters: 600, time: 0.066, data: 0.003) G_GAN: 0.943 G_L1: 2.489 D_real: 0.667 D_fake: 0.683 \n",
            "(epoch: 96, iters: 700, time: 0.066, data: 0.012) G_GAN: 8.250 G_L1: 0.601 D_real: 0.002 D_fake: 0.001 \n",
            "(epoch: 96, iters: 800, time: 0.181, data: 0.003) G_GAN: 0.318 G_L1: 3.853 D_real: 0.836 D_fake: 0.415 \n",
            "(epoch: 96, iters: 900, time: 0.066, data: 0.006) G_GAN: 6.634 G_L1: 0.670 D_real: 0.000 D_fake: 0.002 \n",
            "(epoch: 96, iters: 1000, time: 0.066, data: 0.003) G_GAN: 2.788 G_L1: 1.101 D_real: 0.076 D_fake: 0.173 \n",
            "(epoch: 96, iters: 1100, time: 0.066, data: 0.004) G_GAN: 3.387 G_L1: 1.663 D_real: 0.279 D_fake: 0.116 \n",
            "(epoch: 96, iters: 1200, time: 0.165, data: 0.004) G_GAN: 3.350 G_L1: 1.331 D_real: 0.974 D_fake: 0.400 \n",
            "(epoch: 96, iters: 1300, time: 0.065, data: 0.006) G_GAN: 7.938 G_L1: 0.535 D_real: 0.001 D_fake: 0.001 \n",
            "(epoch: 96, iters: 1400, time: 0.061, data: 0.002) G_GAN: 2.176 G_L1: 2.259 D_real: 0.285 D_fake: 0.171 \n",
            "(epoch: 96, iters: 1500, time: 0.067, data: 0.002) G_GAN: 3.049 G_L1: 3.831 D_real: 0.097 D_fake: 0.096 \n",
            "(epoch: 96, iters: 1600, time: 0.174, data: 0.004) G_GAN: 4.715 G_L1: 1.888 D_real: 0.119 D_fake: 0.012 \n",
            "(epoch: 96, iters: 1700, time: 0.067, data: 0.002) G_GAN: 9.517 G_L1: 0.824 D_real: 0.002 D_fake: 0.000 \n",
            "(epoch: 96, iters: 1800, time: 0.060, data: 0.002) G_GAN: 3.663 G_L1: 2.603 D_real: 0.300 D_fake: 0.049 \n",
            "(epoch: 96, iters: 1900, time: 0.065, data: 0.003) G_GAN: 6.013 G_L1: 0.674 D_real: 0.002 D_fake: 0.008 \n",
            "(epoch: 96, iters: 2000, time: 0.489, data: 0.005) G_GAN: 2.877 G_L1: 2.268 D_real: 0.091 D_fake: 1.646 \n",
            "(epoch: 96, iters: 2100, time: 0.066, data: 0.003) G_GAN: 1.278 G_L1: 1.861 D_real: 0.297 D_fake: 0.546 \n",
            "(epoch: 96, iters: 2200, time: 0.067, data: 0.006) G_GAN: 2.329 G_L1: 1.239 D_real: 0.136 D_fake: 0.279 \n",
            "(epoch: 96, iters: 2300, time: 0.064, data: 0.003) G_GAN: 2.508 G_L1: 3.869 D_real: 0.034 D_fake: 0.473 \n",
            "(epoch: 96, iters: 2400, time: 0.164, data: 0.005) G_GAN: 2.720 G_L1: 1.305 D_real: 0.280 D_fake: 0.210 \n",
            "(epoch: 96, iters: 2500, time: 0.067, data: 0.002) G_GAN: 6.077 G_L1: 0.731 D_real: 0.000 D_fake: 0.005 \n",
            "(epoch: 96, iters: 2600, time: 0.067, data: 0.002) G_GAN: 1.179 G_L1: 2.625 D_real: 0.995 D_fake: 0.645 \n",
            "(epoch: 96, iters: 2700, time: 0.067, data: 0.003) G_GAN: 3.319 G_L1: 1.886 D_real: 0.012 D_fake: 0.096 \n",
            "(epoch: 96, iters: 2800, time: 0.164, data: 0.004) G_GAN: 2.682 G_L1: 5.535 D_real: 0.640 D_fake: 0.365 \n",
            "(epoch: 96, iters: 2900, time: 0.066, data: 0.002) G_GAN: 2.376 G_L1: 1.119 D_real: 0.077 D_fake: 0.598 \n",
            "(epoch: 96, iters: 3000, time: 0.064, data: 0.003) G_GAN: 2.618 G_L1: 1.277 D_real: 0.071 D_fake: 0.442 \n",
            "(epoch: 96, iters: 3100, time: 0.064, data: 0.003) G_GAN: 7.028 G_L1: 0.685 D_real: 0.000 D_fake: 0.002 \n",
            "(epoch: 96, iters: 3200, time: 0.170, data: 0.003) G_GAN: 2.136 G_L1: 2.440 D_real: 0.116 D_fake: 1.181 \n",
            "(epoch: 96, iters: 3300, time: 0.066, data: 0.005) G_GAN: 3.212 G_L1: 1.367 D_real: 0.178 D_fake: 0.096 \n",
            "(epoch: 96, iters: 3400, time: 0.067, data: 0.006) G_GAN: 2.022 G_L1: 2.029 D_real: 0.119 D_fake: 0.440 \n",
            "(epoch: 96, iters: 3500, time: 0.066, data: 0.002) G_GAN: 3.946 G_L1: 1.110 D_real: 0.082 D_fake: 0.032 \n",
            "(epoch: 96, iters: 3600, time: 0.178, data: 0.004) G_GAN: 4.332 G_L1: 1.227 D_real: 2.714 D_fake: 0.115 \n",
            "(epoch: 96, iters: 3700, time: 0.067, data: 0.003) G_GAN: 0.636 G_L1: 2.442 D_real: 0.999 D_fake: 0.288 \n",
            "(epoch: 96, iters: 3800, time: 0.066, data: 0.002) G_GAN: 1.690 G_L1: 3.020 D_real: 0.214 D_fake: 0.323 \n",
            "(epoch: 96, iters: 3900, time: 0.064, data: 0.004) G_GAN: 2.531 G_L1: 2.822 D_real: 0.134 D_fake: 0.470 \n",
            "(epoch: 96, iters: 4000, time: 0.483, data: 0.002) G_GAN: 3.001 G_L1: 3.706 D_real: 0.018 D_fake: 1.057 \n",
            "End of epoch 96 / 200 \t Time Taken: 174 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "(epoch: 97, iters: 100, time: 0.067, data: 0.177) G_GAN: 3.533 G_L1: 1.997 D_real: 0.812 D_fake: 0.050 \n",
            "(epoch: 97, iters: 200, time: 0.061, data: 0.002) G_GAN: 1.674 G_L1: 6.288 D_real: 0.401 D_fake: 0.207 \n",
            "(epoch: 97, iters: 300, time: 0.066, data: 0.004) G_GAN: 0.675 G_L1: 3.733 D_real: 2.053 D_fake: 0.780 \n",
            "(epoch: 97, iters: 400, time: 0.704, data: 0.003) G_GAN: 1.496 G_L1: 1.900 D_real: 0.154 D_fake: 0.791 \n",
            "(epoch: 97, iters: 500, time: 0.066, data: 0.003) G_GAN: 7.976 G_L1: 0.745 D_real: 0.000 D_fake: 0.001 \n",
            "(epoch: 97, iters: 600, time: 0.065, data: 0.003) G_GAN: 3.102 G_L1: 1.326 D_real: 0.257 D_fake: 0.153 \n",
            "(epoch: 97, iters: 700, time: 0.067, data: 0.003) G_GAN: 1.276 G_L1: 2.306 D_real: 1.181 D_fake: 0.100 \n",
            "(epoch: 97, iters: 800, time: 0.212, data: 0.002) G_GAN: 1.273 G_L1: 2.078 D_real: 0.938 D_fake: 0.152 \n",
            "(epoch: 97, iters: 900, time: 0.066, data: 0.006) G_GAN: 1.419 G_L1: 2.715 D_real: 0.039 D_fake: 2.376 \n",
            "(epoch: 97, iters: 1000, time: 0.066, data: 0.003) G_GAN: 1.109 G_L1: 2.367 D_real: 0.294 D_fake: 0.699 \n",
            "saving the latest model (epoch 97, total_iters 385000)\n",
            "(epoch: 97, iters: 1100, time: 0.067, data: 0.002) G_GAN: 2.035 G_L1: 1.180 D_real: 0.154 D_fake: 0.442 \n",
            "(epoch: 97, iters: 1200, time: 0.156, data: 0.004) G_GAN: 8.144 G_L1: 0.567 D_real: 0.000 D_fake: 0.001 \n",
            "(epoch: 97, iters: 1300, time: 0.066, data: 0.003) G_GAN: 1.567 G_L1: 1.749 D_real: 0.305 D_fake: 0.289 \n",
            "(epoch: 97, iters: 1400, time: 0.066, data: 0.003) G_GAN: 0.863 G_L1: 1.917 D_real: 0.676 D_fake: 0.376 \n",
            "(epoch: 97, iters: 1500, time: 0.066, data: 0.007) G_GAN: 2.734 G_L1: 0.991 D_real: 0.066 D_fake: 0.325 \n",
            "(epoch: 97, iters: 1600, time: 0.171, data: 0.003) G_GAN: 2.844 G_L1: 1.855 D_real: 0.077 D_fake: 0.117 \n",
            "(epoch: 97, iters: 1700, time: 0.067, data: 0.009) G_GAN: 1.642 G_L1: 2.092 D_real: 0.155 D_fake: 0.575 \n",
            "(epoch: 97, iters: 1800, time: 0.066, data: 0.008) G_GAN: 3.523 G_L1: 1.617 D_real: 0.060 D_fake: 0.043 \n",
            "(epoch: 97, iters: 1900, time: 0.066, data: 0.004) G_GAN: 2.855 G_L1: 1.416 D_real: 1.965 D_fake: 0.049 \n",
            "(epoch: 97, iters: 2000, time: 0.481, data: 0.003) G_GAN: 7.307 G_L1: 0.653 D_real: 0.003 D_fake: 0.003 \n",
            "(epoch: 97, iters: 2100, time: 0.067, data: 0.003) G_GAN: 0.974 G_L1: 2.339 D_real: 0.734 D_fake: 0.191 \n",
            "(epoch: 97, iters: 2200, time: 0.067, data: 0.005) G_GAN: 4.774 G_L1: 0.730 D_real: 0.001 D_fake: 0.013 \n",
            "(epoch: 97, iters: 2300, time: 0.066, data: 0.003) G_GAN: 1.404 G_L1: 2.150 D_real: 0.417 D_fake: 0.322 \n",
            "(epoch: 97, iters: 2400, time: 0.157, data: 0.004) G_GAN: 4.263 G_L1: 0.616 D_real: 0.001 D_fake: 0.028 \n",
            "(epoch: 97, iters: 2500, time: 0.066, data: 0.007) G_GAN: 3.791 G_L1: 1.833 D_real: 0.002 D_fake: 0.323 \n",
            "(epoch: 97, iters: 2600, time: 0.066, data: 0.002) G_GAN: 2.333 G_L1: 1.721 D_real: 0.268 D_fake: 0.881 \n",
            "(epoch: 97, iters: 2700, time: 0.066, data: 0.003) G_GAN: 4.613 G_L1: 1.200 D_real: 0.123 D_fake: 0.759 \n",
            "(epoch: 97, iters: 2800, time: 0.175, data: 0.003) G_GAN: 2.788 G_L1: 1.378 D_real: 0.136 D_fake: 0.331 \n",
            "(epoch: 97, iters: 2900, time: 0.064, data: 0.007) G_GAN: 10.153 G_L1: 0.879 D_real: 0.001 D_fake: 0.000 \n",
            "(epoch: 97, iters: 3000, time: 0.066, data: 0.003) G_GAN: 1.293 G_L1: 1.877 D_real: 0.390 D_fake: 0.583 \n",
            "(epoch: 97, iters: 3100, time: 0.066, data: 0.004) G_GAN: 1.204 G_L1: 1.057 D_real: 1.703 D_fake: 0.303 \n",
            "(epoch: 97, iters: 3200, time: 0.188, data: 0.002) G_GAN: 2.178 G_L1: 1.999 D_real: 0.090 D_fake: 0.772 \n",
            "(epoch: 97, iters: 3300, time: 0.067, data: 0.008) G_GAN: 3.027 G_L1: 3.278 D_real: 0.010 D_fake: 0.363 \n",
            "(epoch: 97, iters: 3400, time: 0.066, data: 0.002) G_GAN: 9.430 G_L1: 0.821 D_real: 0.004 D_fake: 0.000 \n",
            "(epoch: 97, iters: 3500, time: 0.066, data: 0.003) G_GAN: 2.042 G_L1: 1.891 D_real: 0.483 D_fake: 0.369 \n",
            "(epoch: 97, iters: 3600, time: 0.165, data: 0.003) G_GAN: 4.070 G_L1: 2.461 D_real: 0.100 D_fake: 0.024 \n",
            "(epoch: 97, iters: 3700, time: 0.067, data: 0.002) G_GAN: 1.520 G_L1: 2.149 D_real: 0.391 D_fake: 0.443 \n",
            "(epoch: 97, iters: 3800, time: 0.067, data: 0.005) G_GAN: 9.318 G_L1: 0.881 D_real: 0.000 D_fake: 0.000 \n",
            "(epoch: 97, iters: 3900, time: 0.066, data: 0.004) G_GAN: 3.103 G_L1: 1.214 D_real: 0.041 D_fake: 0.147 \n",
            "(epoch: 97, iters: 4000, time: 0.486, data: 0.003) G_GAN: 11.490 G_L1: 0.818 D_real: 0.002 D_fake: 0.000 \n",
            "End of epoch 97 / 200 \t Time Taken: 175 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "(epoch: 98, iters: 100, time: 0.066, data: 0.186) G_GAN: 6.469 G_L1: 1.360 D_real: 0.243 D_fake: 0.003 \n",
            "(epoch: 98, iters: 200, time: 0.064, data: 0.004) G_GAN: 3.734 G_L1: 1.221 D_real: 0.059 D_fake: 0.034 \n",
            "(epoch: 98, iters: 300, time: 0.067, data: 0.004) G_GAN: 0.931 G_L1: 2.281 D_real: 0.576 D_fake: 0.285 \n",
            "(epoch: 98, iters: 400, time: 0.600, data: 0.002) G_GAN: 1.970 G_L1: 1.003 D_real: 0.318 D_fake: 0.507 \n",
            "(epoch: 98, iters: 500, time: 0.067, data: 0.002) G_GAN: 1.234 G_L1: 2.466 D_real: 0.461 D_fake: 0.338 \n",
            "(epoch: 98, iters: 600, time: 0.066, data: 0.003) G_GAN: 5.141 G_L1: 0.574 D_real: 0.001 D_fake: 0.055 \n",
            "(epoch: 98, iters: 700, time: 0.067, data: 0.004) G_GAN: 5.316 G_L1: 1.082 D_real: 0.001 D_fake: 0.014 \n",
            "(epoch: 98, iters: 800, time: 0.342, data: 0.004) G_GAN: 1.815 G_L1: 2.639 D_real: 0.177 D_fake: 0.622 \n",
            "(epoch: 98, iters: 900, time: 0.067, data: 0.003) G_GAN: 5.255 G_L1: 2.192 D_real: 0.108 D_fake: 0.007 \n",
            "(epoch: 98, iters: 1000, time: 0.064, data: 0.004) G_GAN: 2.733 G_L1: 1.119 D_real: 0.878 D_fake: 0.115 \n",
            "(epoch: 98, iters: 1100, time: 0.066, data: 0.006) G_GAN: 2.090 G_L1: 1.081 D_real: 0.055 D_fake: 1.267 \n",
            "(epoch: 98, iters: 1200, time: 0.223, data: 0.006) G_GAN: 1.635 G_L1: 1.940 D_real: 0.204 D_fake: 0.361 \n",
            "(epoch: 98, iters: 1300, time: 0.067, data: 0.006) G_GAN: 3.745 G_L1: 1.877 D_real: 0.048 D_fake: 0.058 \n",
            "(epoch: 98, iters: 1400, time: 0.060, data: 0.006) G_GAN: 6.499 G_L1: 0.935 D_real: 0.000 D_fake: 0.004 \n",
            "(epoch: 98, iters: 1500, time: 0.067, data: 0.003) G_GAN: 10.443 G_L1: 1.280 D_real: 0.063 D_fake: 0.000 \n",
            "(epoch: 98, iters: 1600, time: 0.170, data: 0.004) G_GAN: 3.356 G_L1: 1.419 D_real: 0.038 D_fake: 0.698 \n",
            "(epoch: 98, iters: 1700, time: 0.066, data: 0.003) G_GAN: 2.927 G_L1: 1.867 D_real: 0.182 D_fake: 0.107 \n",
            "(epoch: 98, iters: 1800, time: 0.066, data: 0.006) G_GAN: 4.203 G_L1: 3.904 D_real: 0.021 D_fake: 0.025 \n",
            "(epoch: 98, iters: 1900, time: 0.064, data: 0.004) G_GAN: 9.506 G_L1: 0.895 D_real: 0.002 D_fake: 0.000 \n",
            "(epoch: 98, iters: 2000, time: 0.538, data: 0.003) G_GAN: 2.747 G_L1: 1.150 D_real: 0.321 D_fake: 2.562 \n",
            "saving the latest model (epoch 98, total_iters 390000)\n",
            "(epoch: 98, iters: 2100, time: 0.065, data: 0.002) G_GAN: 2.220 G_L1: 1.750 D_real: 0.052 D_fake: 0.830 \n",
            "(epoch: 98, iters: 2200, time: 0.066, data: 0.004) G_GAN: 7.542 G_L1: 0.757 D_real: 0.001 D_fake: 0.001 \n",
            "(epoch: 98, iters: 2300, time: 0.066, data: 0.003) G_GAN: 1.743 G_L1: 1.887 D_real: 0.689 D_fake: 0.138 \n",
            "(epoch: 98, iters: 2400, time: 0.184, data: 0.004) G_GAN: 3.127 G_L1: 1.577 D_real: 0.162 D_fake: 0.052 \n",
            "(epoch: 98, iters: 2500, time: 0.065, data: 0.007) G_GAN: 1.437 G_L1: 1.834 D_real: 0.093 D_fake: 0.791 \n",
            "(epoch: 98, iters: 2600, time: 0.066, data: 0.013) G_GAN: 8.014 G_L1: 1.007 D_real: 0.001 D_fake: 0.001 \n",
            "(epoch: 98, iters: 2700, time: 0.065, data: 0.002) G_GAN: 2.437 G_L1: 1.306 D_real: 0.104 D_fake: 0.195 \n",
            "(epoch: 98, iters: 2800, time: 0.244, data: 0.004) G_GAN: 0.554 G_L1: 2.251 D_real: 1.689 D_fake: 0.268 \n",
            "(epoch: 98, iters: 2900, time: 0.066, data: 0.003) G_GAN: 2.362 G_L1: 2.051 D_real: 0.453 D_fake: 0.154 \n",
            "(epoch: 98, iters: 3000, time: 0.067, data: 0.003) G_GAN: 3.014 G_L1: 2.581 D_real: 0.561 D_fake: 0.052 \n",
            "(epoch: 98, iters: 3100, time: 0.067, data: 0.004) G_GAN: 1.268 G_L1: 3.016 D_real: 0.098 D_fake: 1.860 \n",
            "(epoch: 98, iters: 3200, time: 0.189, data: 0.003) G_GAN: 2.892 G_L1: 1.948 D_real: 0.043 D_fake: 0.460 \n",
            "(epoch: 98, iters: 3300, time: 0.067, data: 0.003) G_GAN: 4.414 G_L1: 0.889 D_real: 0.002 D_fake: 0.086 \n",
            "(epoch: 98, iters: 3400, time: 0.066, data: 0.003) G_GAN: 2.188 G_L1: 0.911 D_real: 0.511 D_fake: 0.152 \n",
            "(epoch: 98, iters: 3500, time: 0.062, data: 0.003) G_GAN: 7.022 G_L1: 1.280 D_real: 0.378 D_fake: 0.001 \n",
            "(epoch: 98, iters: 3600, time: 0.156, data: 0.004) G_GAN: 6.613 G_L1: 0.857 D_real: 0.002 D_fake: 0.002 \n",
            "(epoch: 98, iters: 3700, time: 0.066, data: 0.002) G_GAN: 3.676 G_L1: 3.053 D_real: 0.115 D_fake: 0.059 \n",
            "(epoch: 98, iters: 3800, time: 0.065, data: 0.003) G_GAN: 4.410 G_L1: 1.067 D_real: 0.067 D_fake: 0.016 \n",
            "(epoch: 98, iters: 3900, time: 0.067, data: 0.003) G_GAN: 4.150 G_L1: 1.309 D_real: 0.074 D_fake: 0.023 \n",
            "(epoch: 98, iters: 4000, time: 0.492, data: 0.003) G_GAN: 3.116 G_L1: 0.695 D_real: 0.104 D_fake: 0.147 \n",
            "End of epoch 98 / 200 \t Time Taken: 175 sec\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "(epoch: 99, iters: 100, time: 0.067, data: 0.220) G_GAN: 7.855 G_L1: 1.628 D_real: 0.000 D_fake: 0.001 \n",
            "(epoch: 99, iters: 200, time: 0.066, data: 0.003) G_GAN: 6.940 G_L1: 0.816 D_real: 0.006 D_fake: 0.002 \n",
            "(epoch: 99, iters: 300, time: 0.067, data: 0.003) G_GAN: 3.303 G_L1: 1.494 D_real: 0.210 D_fake: 0.452 \n",
            "(epoch: 99, iters: 400, time: 0.606, data: 0.006) G_GAN: 1.757 G_L1: 1.476 D_real: 0.778 D_fake: 0.706 \n",
            "(epoch: 99, iters: 500, time: 0.064, data: 0.003) G_GAN: 1.381 G_L1: 1.991 D_real: 0.248 D_fake: 0.594 \n",
            "(epoch: 99, iters: 600, time: 0.067, data: 0.004) G_GAN: 4.190 G_L1: 2.098 D_real: 0.120 D_fake: 0.028 \n",
            "(epoch: 99, iters: 700, time: 0.066, data: 0.004) G_GAN: 6.972 G_L1: 0.544 D_real: 0.031 D_fake: 0.002 \n",
            "(epoch: 99, iters: 800, time: 0.214, data: 0.004) G_GAN: 1.546 G_L1: 1.890 D_real: 0.377 D_fake: 0.284 \n",
            "(epoch: 99, iters: 900, time: 0.063, data: 0.007) G_GAN: 1.481 G_L1: 2.552 D_real: 0.155 D_fake: 1.159 \n",
            "(epoch: 99, iters: 1000, time: 0.066, data: 0.004) G_GAN: 1.523 G_L1: 1.901 D_real: 0.186 D_fake: 1.126 \n",
            "(epoch: 99, iters: 1100, time: 0.066, data: 0.004) G_GAN: 4.678 G_L1: 1.804 D_real: 0.122 D_fake: 0.015 \n",
            "(epoch: 99, iters: 1200, time: 0.165, data: 0.005) G_GAN: 1.711 G_L1: 2.031 D_real: 0.045 D_fake: 1.254 \n",
            "(epoch: 99, iters: 1300, time: 0.061, data: 0.003) G_GAN: 1.425 G_L1: 1.882 D_real: 0.214 D_fake: 0.669 \n",
            "(epoch: 99, iters: 1400, time: 0.066, data: 0.005) G_GAN: 9.462 G_L1: 1.066 D_real: 0.000 D_fake: 0.000 \n",
            "(epoch: 99, iters: 1500, time: 0.062, data: 0.004) G_GAN: 2.438 G_L1: 1.960 D_real: 5.271 D_fake: 0.012 \n",
            "(epoch: 99, iters: 1600, time: 0.171, data: 0.004) G_GAN: 2.931 G_L1: 1.364 D_real: 0.091 D_fake: 0.168 \n",
            "(epoch: 99, iters: 1700, time: 0.067, data: 0.002) G_GAN: 1.986 G_L1: 7.107 D_real: 0.172 D_fake: 0.726 \n",
            "(epoch: 99, iters: 1800, time: 0.067, data: 0.004) G_GAN: 10.766 G_L1: 0.586 D_real: 0.000 D_fake: 0.000 \n",
            "(epoch: 99, iters: 1900, time: 0.066, data: 0.004) G_GAN: 2.420 G_L1: 1.568 D_real: 0.038 D_fake: 0.488 \n",
            "(epoch: 99, iters: 2000, time: 0.589, data: 0.004) G_GAN: 1.980 G_L1: 3.871 D_real: 0.010 D_fake: 0.933 \n",
            "(epoch: 99, iters: 2100, time: 0.066, data: 0.002) G_GAN: 3.208 G_L1: 1.106 D_real: 0.025 D_fake: 0.223 \n",
            "(epoch: 99, iters: 2200, time: 0.066, data: 0.003) G_GAN: 0.280 G_L1: 1.941 D_real: 0.023 D_fake: 4.779 \n",
            "(epoch: 99, iters: 2300, time: 0.066, data: 0.002) G_GAN: 4.886 G_L1: 1.870 D_real: 0.010 D_fake: 2.108 \n",
            "(epoch: 99, iters: 2400, time: 0.190, data: 0.002) G_GAN: 2.734 G_L1: 2.018 D_real: 0.108 D_fake: 0.314 \n",
            "(epoch: 99, iters: 2500, time: 0.067, data: 0.002) G_GAN: 1.864 G_L1: 2.160 D_real: 0.158 D_fake: 0.274 \n",
            "(epoch: 99, iters: 2600, time: 0.067, data: 0.003) G_GAN: 4.086 G_L1: 1.314 D_real: 0.170 D_fake: 0.743 \n",
            "(epoch: 99, iters: 2700, time: 0.066, data: 0.004) G_GAN: 2.884 G_L1: 1.980 D_real: 0.114 D_fake: 0.597 \n",
            "(epoch: 99, iters: 2800, time: 0.222, data: 0.008) G_GAN: 2.206 G_L1: 2.721 D_real: 0.332 D_fake: 0.130 \n",
            "(epoch: 99, iters: 2900, time: 0.064, data: 0.003) G_GAN: 1.471 G_L1: 2.018 D_real: 0.525 D_fake: 0.677 \n",
            "(epoch: 99, iters: 3000, time: 0.067, data: 0.008) G_GAN: 8.350 G_L1: 0.951 D_real: 0.204 D_fake: 0.006 \n",
            "saving the latest model (epoch 99, total_iters 395000)\n",
            "(epoch: 99, iters: 3100, time: 0.066, data: 0.002) G_GAN: 3.615 G_L1: 2.692 D_real: 0.292 D_fake: 0.043 \n",
            "(epoch: 99, iters: 3200, time: 0.218, data: 0.003) G_GAN: 2.795 G_L1: 1.803 D_real: 1.022 D_fake: 0.036 \n",
            "(epoch: 99, iters: 3300, time: 0.066, data: 0.009) G_GAN: 4.988 G_L1: 0.754 D_real: 0.002 D_fake: 0.011 \n",
            "(epoch: 99, iters: 3400, time: 0.067, data: 0.004) G_GAN: 4.777 G_L1: 0.598 D_real: 0.001 D_fake: 0.017 \n",
            "(epoch: 99, iters: 3500, time: 0.066, data: 0.003) G_GAN: 1.478 G_L1: 2.189 D_real: 0.488 D_fake: 0.411 \n",
            "(epoch: 99, iters: 3600, time: 0.192, data: 0.003) G_GAN: 2.718 G_L1: 1.271 D_real: 0.193 D_fake: 0.262 \n",
            "(epoch: 99, iters: 3700, time: 0.067, data: 0.003) G_GAN: 1.398 G_L1: 1.918 D_real: 0.450 D_fake: 0.493 \n",
            "(epoch: 99, iters: 3800, time: 0.066, data: 0.004) G_GAN: 2.151 G_L1: 2.286 D_real: 0.139 D_fake: 1.183 \n",
            "(epoch: 99, iters: 3900, time: 0.061, data: 0.003) G_GAN: 2.205 G_L1: 2.252 D_real: 0.101 D_fake: 1.653 \n",
            "(epoch: 99, iters: 4000, time: 0.514, data: 0.003) G_GAN: 2.639 G_L1: 2.237 D_real: 0.194 D_fake: 0.191 \n",
            "End of epoch 99 / 200 \t Time Taken: 175 sec\n",
            "learning rate 0.0002000 -> 0.0001980\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "(epoch: 100, iters: 100, time: 0.067, data: 0.184) G_GAN: 2.658 G_L1: 1.472 D_real: 0.225 D_fake: 0.097 \n",
            "(epoch: 100, iters: 200, time: 0.064, data: 0.003) G_GAN: 2.774 G_L1: 4.258 D_real: 0.178 D_fake: 0.260 \n",
            "(epoch: 100, iters: 300, time: 0.067, data: 0.003) G_GAN: 8.073 G_L1: 0.595 D_real: 0.001 D_fake: 0.001 \n",
            "(epoch: 100, iters: 400, time: 0.860, data: 0.003) G_GAN: 1.770 G_L1: 2.172 D_real: 0.670 D_fake: 0.197 \n",
            "(epoch: 100, iters: 500, time: 0.066, data: 0.005) G_GAN: 4.982 G_L1: 4.883 D_real: 0.417 D_fake: 0.008 \n",
            "(epoch: 100, iters: 600, time: 0.064, data: 0.002) G_GAN: 1.800 G_L1: 1.837 D_real: 0.175 D_fake: 0.667 \n",
            "(epoch: 100, iters: 700, time: 0.066, data: 0.004) G_GAN: 6.172 G_L1: 0.818 D_real: 0.018 D_fake: 0.005 \n",
            "(epoch: 100, iters: 800, time: 0.157, data: 0.004) G_GAN: 9.876 G_L1: 0.604 D_real: 0.008 D_fake: 0.000 \n",
            "(epoch: 100, iters: 900, time: 0.066, data: 0.007) G_GAN: 1.789 G_L1: 3.044 D_real: 0.304 D_fake: 0.174 \n",
            "(epoch: 100, iters: 1000, time: 0.058, data: 0.004) G_GAN: 3.941 G_L1: 2.306 D_real: 0.578 D_fake: 0.065 \n",
            "(epoch: 100, iters: 1100, time: 0.067, data: 0.004) G_GAN: 2.138 G_L1: 3.053 D_real: 0.305 D_fake: 0.738 \n",
            "(epoch: 100, iters: 1200, time: 0.177, data: 0.004) G_GAN: 1.906 G_L1: 4.509 D_real: 0.173 D_fake: 0.584 \n",
            "(epoch: 100, iters: 1300, time: 0.064, data: 0.009) G_GAN: 1.832 G_L1: 1.888 D_real: 0.149 D_fake: 0.471 \n",
            "(epoch: 100, iters: 1400, time: 0.066, data: 0.006) G_GAN: 9.166 G_L1: 1.745 D_real: 0.121 D_fake: 0.000 \n",
            "(epoch: 100, iters: 1500, time: 0.066, data: 0.004) G_GAN: 7.889 G_L1: 1.597 D_real: 0.000 D_fake: 0.001 \n",
            "(epoch: 100, iters: 1600, time: 0.185, data: 0.006) G_GAN: 1.766 G_L1: 1.311 D_real: 0.129 D_fake: 0.735 \n",
            "(epoch: 100, iters: 1700, time: 0.066, data: 0.002) G_GAN: 7.149 G_L1: 1.734 D_real: 0.000 D_fake: 0.001 \n",
            "(epoch: 100, iters: 1800, time: 0.065, data: 0.002) G_GAN: 9.382 G_L1: 0.656 D_real: 0.001 D_fake: 0.000 \n",
            "(epoch: 100, iters: 1900, time: 0.064, data: 0.004) G_GAN: 8.969 G_L1: 0.770 D_real: 0.001 D_fake: 0.000 \n",
            "(epoch: 100, iters: 2000, time: 0.505, data: 0.006) G_GAN: 1.571 G_L1: 2.382 D_real: 0.553 D_fake: 0.195 \n",
            "(epoch: 100, iters: 2100, time: 0.065, data: 0.006) G_GAN: 0.979 G_L1: 1.865 D_real: 0.178 D_fake: 1.565 \n",
            "(epoch: 100, iters: 2200, time: 0.066, data: 0.003) G_GAN: 5.851 G_L1: 3.001 D_real: 0.052 D_fake: 0.005 \n",
            "(epoch: 100, iters: 2300, time: 0.063, data: 0.005) G_GAN: 2.070 G_L1: 1.755 D_real: 0.048 D_fake: 1.464 \n",
            "(epoch: 100, iters: 2400, time: 0.186, data: 0.008) G_GAN: 3.108 G_L1: 2.387 D_real: 0.029 D_fake: 0.973 \n",
            "(epoch: 100, iters: 2500, time: 0.067, data: 0.003) G_GAN: 9.307 G_L1: 1.068 D_real: 0.002 D_fake: 0.000 \n",
            "(epoch: 100, iters: 2600, time: 0.067, data: 0.003) G_GAN: 8.221 G_L1: 0.786 D_real: 0.001 D_fake: 0.001 \n",
            "(epoch: 100, iters: 2700, time: 0.067, data: 0.004) G_GAN: 1.167 G_L1: 3.192 D_real: 0.432 D_fake: 0.179 \n",
            "(epoch: 100, iters: 2800, time: 0.186, data: 0.004) G_GAN: 2.689 G_L1: 1.194 D_real: 0.083 D_fake: 0.256 \n",
            "(epoch: 100, iters: 2900, time: 0.065, data: 0.002) G_GAN: 3.907 G_L1: 1.500 D_real: 0.045 D_fake: 0.079 \n",
            "(epoch: 100, iters: 3000, time: 0.065, data: 0.002) G_GAN: 3.794 G_L1: 1.646 D_real: 0.117 D_fake: 0.021 \n",
            "(epoch: 100, iters: 3100, time: 0.066, data: 0.004) G_GAN: 5.060 G_L1: 2.016 D_real: 0.048 D_fake: 0.011 \n",
            "(epoch: 100, iters: 3200, time: 0.170, data: 0.002) G_GAN: 2.671 G_L1: 2.427 D_real: 0.462 D_fake: 0.148 \n",
            "(epoch: 100, iters: 3300, time: 0.066, data: 0.005) G_GAN: 3.167 G_L1: 3.608 D_real: 0.015 D_fake: 0.170 \n",
            "(epoch: 100, iters: 3400, time: 0.066, data: 0.003) G_GAN: 1.706 G_L1: 2.617 D_real: 0.209 D_fake: 0.288 \n",
            "(epoch: 100, iters: 3500, time: 0.063, data: 0.004) G_GAN: 2.097 G_L1: 2.440 D_real: 0.138 D_fake: 0.339 \n",
            "(epoch: 100, iters: 3600, time: 0.217, data: 0.004) G_GAN: 0.525 G_L1: 4.520 D_real: 0.704 D_fake: 0.344 \n",
            "(epoch: 100, iters: 3700, time: 0.066, data: 0.003) G_GAN: 6.286 G_L1: 1.088 D_real: 0.013 D_fake: 0.003 \n",
            "(epoch: 100, iters: 3800, time: 0.066, data: 0.003) G_GAN: 5.359 G_L1: 2.847 D_real: 0.292 D_fake: 0.010 \n",
            "(epoch: 100, iters: 3900, time: 0.065, data: 0.004) G_GAN: 1.202 G_L1: 2.976 D_real: 0.103 D_fake: 1.710 \n",
            "(epoch: 100, iters: 4000, time: 0.666, data: 0.004) G_GAN: 1.252 G_L1: 1.764 D_real: 0.272 D_fake: 0.697 \n",
            "saving the latest model (epoch 100, total_iters 400000)\n",
            "saving the model at the end of epoch 100, iters 400000\n",
            "End of epoch 100 / 200 \t Time Taken: 177 sec\n",
            "learning rate 0.0001980 -> 0.0001960\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "(epoch: 101, iters: 100, time: 0.066, data: 0.149) G_GAN: 3.466 G_L1: 1.720 D_real: 0.102 D_fake: 1.005 \n",
            "(epoch: 101, iters: 200, time: 0.067, data: 0.002) G_GAN: 3.234 G_L1: 1.359 D_real: 0.238 D_fake: 0.789 \n",
            "(epoch: 101, iters: 300, time: 0.065, data: 0.003) G_GAN: 4.330 G_L1: 1.412 D_real: 1.184 D_fake: 0.011 \n",
            "(epoch: 101, iters: 400, time: 0.599, data: 0.006) G_GAN: 3.174 G_L1: 2.049 D_real: 5.409 D_fake: 0.557 \n",
            "(epoch: 101, iters: 500, time: 0.066, data: 0.004) G_GAN: 1.591 G_L1: 1.805 D_real: 0.406 D_fake: 0.928 \n",
            "(epoch: 101, iters: 600, time: 0.065, data: 0.006) G_GAN: 0.996 G_L1: 2.888 D_real: 0.608 D_fake: 0.724 \n",
            "(epoch: 101, iters: 700, time: 0.066, data: 0.002) G_GAN: 3.032 G_L1: 1.196 D_real: 0.044 D_fake: 0.263 \n",
            "(epoch: 101, iters: 800, time: 0.217, data: 0.003) G_GAN: 1.546 G_L1: 3.051 D_real: 1.158 D_fake: 0.070 \n",
            "(epoch: 101, iters: 900, time: 0.065, data: 0.002) G_GAN: 2.833 G_L1: 1.911 D_real: 0.469 D_fake: 0.116 \n",
            "(epoch: 101, iters: 1000, time: 0.064, data: 0.003) G_GAN: 1.531 G_L1: 2.378 D_real: 0.379 D_fake: 0.265 \n",
            "(epoch: 101, iters: 1100, time: 0.067, data: 0.003) G_GAN: 8.561 G_L1: 0.821 D_real: 0.000 D_fake: 0.000 \n",
            "(epoch: 101, iters: 1200, time: 0.178, data: 0.003) G_GAN: 3.803 G_L1: 2.070 D_real: 0.501 D_fake: 0.015 \n",
            "(epoch: 101, iters: 1300, time: 0.066, data: 0.006) G_GAN: 7.630 G_L1: 1.279 D_real: 0.000 D_fake: 0.001 \n",
            "(epoch: 101, iters: 1400, time: 0.063, data: 0.002) G_GAN: 3.964 G_L1: 2.684 D_real: 0.475 D_fake: 0.019 \n",
            "(epoch: 101, iters: 1500, time: 0.067, data: 0.004) G_GAN: 1.342 G_L1: 1.576 D_real: 0.434 D_fake: 0.518 \n",
            "(epoch: 101, iters: 1600, time: 0.163, data: 0.003) G_GAN: 11.110 G_L1: 0.828 D_real: 0.002 D_fake: 0.000 \n",
            "(epoch: 101, iters: 1700, time: 0.065, data: 0.002) G_GAN: 10.617 G_L1: 0.762 D_real: 0.006 D_fake: 0.000 \n",
            "(epoch: 101, iters: 1800, time: 0.066, data: 0.006) G_GAN: 3.165 G_L1: 1.946 D_real: 0.115 D_fake: 0.067 \n",
            "(epoch: 101, iters: 1900, time: 0.065, data: 0.003) G_GAN: 2.261 G_L1: 2.434 D_real: 0.172 D_fake: 0.453 \n",
            "(epoch: 101, iters: 2000, time: 0.496, data: 0.003) G_GAN: 4.397 G_L1: 2.581 D_real: 0.152 D_fake: 0.026 \n",
            "(epoch: 101, iters: 2100, time: 0.064, data: 0.003) G_GAN: 1.563 G_L1: 2.663 D_real: 1.834 D_fake: 0.037 \n",
            "(epoch: 101, iters: 2200, time: 0.067, data: 0.003) G_GAN: 1.790 G_L1: 0.947 D_real: 0.430 D_fake: 0.645 \n",
            "(epoch: 101, iters: 2300, time: 0.066, data: 0.003) G_GAN: 6.067 G_L1: 0.776 D_real: 0.000 D_fake: 0.005 \n",
            "(epoch: 101, iters: 2400, time: 0.192, data: 0.003) G_GAN: 3.136 G_L1: 4.008 D_real: 0.252 D_fake: 0.065 \n",
            "(epoch: 101, iters: 2500, time: 0.066, data: 0.004) G_GAN: 2.305 G_L1: 2.076 D_real: 0.677 D_fake: 0.096 \n",
            "(epoch: 101, iters: 2600, time: 0.067, data: 0.008) G_GAN: 2.105 G_L1: 1.461 D_real: 0.450 D_fake: 0.719 \n",
            "(epoch: 101, iters: 2700, time: 0.066, data: 0.002) G_GAN: 2.846 G_L1: 3.032 D_real: 0.157 D_fake: 0.129 \n",
            "(epoch: 101, iters: 2800, time: 0.175, data: 0.004) G_GAN: 10.556 G_L1: 0.997 D_real: 0.002 D_fake: 0.000 \n",
            "(epoch: 101, iters: 2900, time: 0.066, data: 0.002) G_GAN: 1.725 G_L1: 1.164 D_real: 0.694 D_fake: 0.174 \n",
            "(epoch: 101, iters: 3000, time: 0.067, data: 0.004) G_GAN: 3.689 G_L1: 1.837 D_real: 0.780 D_fake: 0.173 \n",
            "(epoch: 101, iters: 3100, time: 0.066, data: 0.004) G_GAN: 1.686 G_L1: 2.237 D_real: 0.227 D_fake: 0.548 \n",
            "(epoch: 101, iters: 3200, time: 0.172, data: 0.003) G_GAN: 4.706 G_L1: 1.977 D_real: 0.187 D_fake: 0.012 \n",
            "(epoch: 101, iters: 3300, time: 0.067, data: 0.003) G_GAN: 4.859 G_L1: 2.101 D_real: 0.215 D_fake: 0.006 \n",
            "(epoch: 101, iters: 3400, time: 0.066, data: 0.003) G_GAN: 4.351 G_L1: 1.377 D_real: 0.090 D_fake: 0.044 \n",
            "(epoch: 101, iters: 3500, time: 0.064, data: 0.002) G_GAN: 1.682 G_L1: 1.868 D_real: 0.104 D_fake: 1.084 \n",
            "(epoch: 101, iters: 3600, time: 0.173, data: 0.002) G_GAN: 3.463 G_L1: 1.281 D_real: 2.043 D_fake: 0.040 \n",
            "(epoch: 101, iters: 3700, time: 0.057, data: 0.002) G_GAN: 2.075 G_L1: 3.735 D_real: 0.081 D_fake: 0.533 \n",
            "(epoch: 101, iters: 3800, time: 0.066, data: 0.006) G_GAN: 4.609 G_L1: 1.005 D_real: 0.000 D_fake: 0.028 \n",
            "(epoch: 101, iters: 3900, time: 0.065, data: 0.004) G_GAN: 9.293 G_L1: 0.773 D_real: 0.000 D_fake: 0.000 \n",
            "(epoch: 101, iters: 4000, time: 0.545, data: 0.003) G_GAN: 3.932 G_L1: 1.757 D_real: 0.236 D_fake: 0.037 \n",
            "End of epoch 101 / 200 \t Time Taken: 174 sec\n",
            "learning rate 0.0001960 -> 0.0001941\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "(epoch: 102, iters: 100, time: 0.065, data: 0.189) G_GAN: 4.512 G_L1: 1.634 D_real: 0.871 D_fake: 0.013 \n",
            "(epoch: 102, iters: 200, time: 0.066, data: 0.004) G_GAN: 6.833 G_L1: 0.867 D_real: 0.000 D_fake: 0.002 \n",
            "(epoch: 102, iters: 300, time: 0.060, data: 0.004) G_GAN: 1.259 G_L1: 1.957 D_real: 1.115 D_fake: 0.172 \n",
            "(epoch: 102, iters: 400, time: 0.752, data: 0.003) G_GAN: 1.910 G_L1: 1.276 D_real: 0.050 D_fake: 0.951 \n",
            "(epoch: 102, iters: 500, time: 0.066, data: 0.002) G_GAN: 2.726 G_L1: 1.467 D_real: 0.210 D_fake: 0.289 \n",
            "(epoch: 102, iters: 600, time: 0.065, data: 0.004) G_GAN: 3.269 G_L1: 2.401 D_real: 0.103 D_fake: 0.330 \n",
            "(epoch: 102, iters: 700, time: 0.067, data: 0.005) G_GAN: 7.457 G_L1: 1.319 D_real: 0.001 D_fake: 0.002 \n",
            "(epoch: 102, iters: 800, time: 0.188, data: 0.003) G_GAN: 3.421 G_L1: 3.551 D_real: 0.043 D_fake: 0.102 \n",
            "(epoch: 102, iters: 900, time: 0.063, data: 0.003) G_GAN: 1.661 G_L1: 4.184 D_real: 0.169 D_fake: 0.390 \n",
            "(epoch: 102, iters: 1000, time: 0.067, data: 0.003) G_GAN: 3.754 G_L1: 1.933 D_real: 0.006 D_fake: 1.603 \n",
            "saving the latest model (epoch 102, total_iters 405000)\n",
            "(epoch: 102, iters: 1100, time: 0.064, data: 0.004) G_GAN: 5.628 G_L1: 1.585 D_real: 0.094 D_fake: 0.007 \n",
            "(epoch: 102, iters: 1200, time: 0.211, data: 0.004) G_GAN: 1.464 G_L1: 1.797 D_real: 0.567 D_fake: 0.350 \n",
            "(epoch: 102, iters: 1300, time: 0.067, data: 0.003) G_GAN: 4.822 G_L1: 3.422 D_real: 0.048 D_fake: 0.014 \n",
            "(epoch: 102, iters: 1400, time: 0.061, data: 0.003) G_GAN: 10.579 G_L1: 0.763 D_real: 0.006 D_fake: 0.000 \n",
            "(epoch: 102, iters: 1500, time: 0.066, data: 0.005) G_GAN: 8.873 G_L1: 0.734 D_real: 0.001 D_fake: 0.000 \n",
            "(epoch: 102, iters: 1600, time: 0.159, data: 0.004) G_GAN: 9.939 G_L1: 1.366 D_real: 0.001 D_fake: 0.000 \n",
            "(epoch: 102, iters: 1700, time: 0.066, data: 0.002) G_GAN: 5.773 G_L1: 2.329 D_real: 0.164 D_fake: 0.008 \n",
            "(epoch: 102, iters: 1800, time: 0.066, data: 0.006) G_GAN: 1.933 G_L1: 2.600 D_real: 0.088 D_fake: 0.472 \n",
            "(epoch: 102, iters: 1900, time: 0.065, data: 0.004) G_GAN: 1.815 G_L1: 2.353 D_real: 1.260 D_fake: 0.020 \n",
            "(epoch: 102, iters: 2000, time: 0.601, data: 0.006) G_GAN: 1.254 G_L1: 3.150 D_real: 1.492 D_fake: 0.067 \n",
            "(epoch: 102, iters: 2100, time: 0.067, data: 0.003) G_GAN: 4.550 G_L1: 2.090 D_real: 0.018 D_fake: 0.020 \n",
            "(epoch: 102, iters: 2200, time: 0.066, data: 0.004) G_GAN: 5.978 G_L1: 2.361 D_real: 0.271 D_fake: 0.003 \n",
            "(epoch: 102, iters: 2300, time: 0.066, data: 0.004) G_GAN: 2.446 G_L1: 1.854 D_real: 0.919 D_fake: 0.070 \n",
            "(epoch: 102, iters: 2400, time: 0.157, data: 0.003) G_GAN: 8.969 G_L1: 0.702 D_real: 0.000 D_fake: 0.000 \n",
            "(epoch: 102, iters: 2500, time: 0.064, data: 0.007) G_GAN: 8.895 G_L1: 0.898 D_real: 0.000 D_fake: 0.001 \n",
            "(epoch: 102, iters: 2600, time: 0.065, data: 0.003) G_GAN: 4.568 G_L1: 1.217 D_real: 0.172 D_fake: 0.016 \n",
            "(epoch: 102, iters: 2700, time: 0.067, data: 0.003) G_GAN: 2.444 G_L1: 1.146 D_real: 0.129 D_fake: 0.425 \n",
            "(epoch: 102, iters: 2800, time: 0.185, data: 0.003) G_GAN: 1.854 G_L1: 0.819 D_real: 0.193 D_fake: 0.824 \n",
            "(epoch: 102, iters: 2900, time: 0.065, data: 0.002) G_GAN: 8.782 G_L1: 0.777 D_real: 0.001 D_fake: 0.000 \n",
            "(epoch: 102, iters: 3000, time: 0.067, data: 0.008) G_GAN: 3.368 G_L1: 2.743 D_real: 0.060 D_fake: 0.089 \n",
            "(epoch: 102, iters: 3100, time: 0.067, data: 0.003) G_GAN: 1.707 G_L1: 1.377 D_real: 0.774 D_fake: 0.082 \n",
            "(epoch: 102, iters: 3200, time: 0.156, data: 0.004) G_GAN: 6.123 G_L1: 0.699 D_real: 0.001 D_fake: 0.040 \n",
            "(epoch: 102, iters: 3300, time: 0.066, data: 0.009) G_GAN: 1.159 G_L1: 2.135 D_real: 0.780 D_fake: 0.777 \n",
            "(epoch: 102, iters: 3400, time: 0.066, data: 0.004) G_GAN: 1.232 G_L1: 1.900 D_real: 0.183 D_fake: 1.056 \n",
            "(epoch: 102, iters: 3500, time: 0.066, data: 0.006) G_GAN: 2.806 G_L1: 2.274 D_real: 0.178 D_fake: 0.122 \n",
            "(epoch: 102, iters: 3600, time: 0.205, data: 0.003) G_GAN: 1.304 G_L1: 1.025 D_real: 0.685 D_fake: 0.062 \n",
            "(epoch: 102, iters: 3700, time: 0.066, data: 0.003) G_GAN: 4.864 G_L1: 0.636 D_real: 0.010 D_fake: 0.065 \n",
            "(epoch: 102, iters: 3800, time: 0.066, data: 0.003) G_GAN: 1.766 G_L1: 1.777 D_real: 0.556 D_fake: 0.136 \n",
            "(epoch: 102, iters: 3900, time: 0.066, data: 0.003) G_GAN: 6.582 G_L1: 1.218 D_real: 0.001 D_fake: 0.003 \n",
            "(epoch: 102, iters: 4000, time: 0.575, data: 0.004) G_GAN: 3.326 G_L1: 1.921 D_real: 0.297 D_fake: 0.022 \n",
            "End of epoch 102 / 200 \t Time Taken: 176 sec\n",
            "learning rate 0.0001941 -> 0.0001921\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "(epoch: 103, iters: 100, time: 0.065, data: 0.148) G_GAN: 3.341 G_L1: 1.910 D_real: 0.062 D_fake: 1.407 \n",
            "(epoch: 103, iters: 200, time: 0.067, data: 0.005) G_GAN: 6.408 G_L1: 1.305 D_real: 0.000 D_fake: 0.005 \n",
            "(epoch: 103, iters: 300, time: 0.066, data: 0.002) G_GAN: 1.819 G_L1: 2.181 D_real: 0.099 D_fake: 0.502 \n",
            "(epoch: 103, iters: 400, time: 0.633, data: 0.003) G_GAN: 7.156 G_L1: 0.964 D_real: 0.145 D_fake: 0.002 \n",
            "(epoch: 103, iters: 500, time: 0.061, data: 0.003) G_GAN: 1.239 G_L1: 4.323 D_real: 1.005 D_fake: 0.383 \n",
            "(epoch: 103, iters: 600, time: 0.070, data: 0.002) G_GAN: 1.120 G_L1: 1.841 D_real: 0.475 D_fake: 0.649 \n",
            "(epoch: 103, iters: 700, time: 0.060, data: 0.003) G_GAN: 6.118 G_L1: 1.448 D_real: 0.130 D_fake: 0.005 \n",
            "(epoch: 103, iters: 800, time: 0.191, data: 0.004) G_GAN: 5.306 G_L1: 3.332 D_real: 0.841 D_fake: 0.008 \n",
            "(epoch: 103, iters: 900, time: 0.065, data: 0.003) G_GAN: 2.448 G_L1: 2.029 D_real: 0.183 D_fake: 0.100 \n",
            "(epoch: 103, iters: 1000, time: 0.066, data: 0.003) G_GAN: 2.529 G_L1: 2.478 D_real: 0.833 D_fake: 0.093 \n",
            "(epoch: 103, iters: 1100, time: 0.066, data: 0.002) G_GAN: 3.134 G_L1: 2.554 D_real: 0.046 D_fake: 0.170 \n",
            "(epoch: 103, iters: 1200, time: 0.181, data: 0.005) G_GAN: 2.583 G_L1: 2.545 D_real: 0.063 D_fake: 0.303 \n",
            "(epoch: 103, iters: 1300, time: 0.066, data: 0.002) G_GAN: 6.908 G_L1: 1.455 D_real: 0.096 D_fake: 0.001 \n",
            "(epoch: 103, iters: 1400, time: 0.066, data: 0.006) G_GAN: 8.416 G_L1: 0.585 D_real: 0.016 D_fake: 0.000 \n",
            "(epoch: 103, iters: 1500, time: 0.065, data: 0.003) G_GAN: 1.465 G_L1: 2.706 D_real: 0.021 D_fake: 1.251 \n",
            "(epoch: 103, iters: 1600, time: 0.184, data: 0.004) G_GAN: 4.496 G_L1: 2.146 D_real: 0.007 D_fake: 0.020 \n",
            "(epoch: 103, iters: 1700, time: 0.066, data: 0.003) G_GAN: 2.506 G_L1: 1.801 D_real: 0.571 D_fake: 0.123 \n",
            "(epoch: 103, iters: 1800, time: 0.066, data: 0.006) G_GAN: 3.456 G_L1: 1.560 D_real: 0.047 D_fake: 0.490 \n",
            "(epoch: 103, iters: 1900, time: 0.065, data: 0.003) G_GAN: 10.222 G_L1: 1.111 D_real: 0.003 D_fake: 0.000 \n",
            "(epoch: 103, iters: 2000, time: 0.715, data: 0.003) G_GAN: 2.478 G_L1: 2.805 D_real: 0.098 D_fake: 0.141 \n",
            "saving the latest model (epoch 103, total_iters 410000)\n",
            "(epoch: 103, iters: 2100, time: 0.066, data: 0.003) G_GAN: 1.433 G_L1: 1.642 D_real: 0.839 D_fake: 0.218 \n",
            "(epoch: 103, iters: 2200, time: 0.067, data: 0.004) G_GAN: 1.550 G_L1: 1.876 D_real: 0.085 D_fake: 0.784 \n",
            "(epoch: 103, iters: 2300, time: 0.066, data: 0.003) G_GAN: 1.164 G_L1: 2.303 D_real: 1.386 D_fake: 0.305 \n",
            "(epoch: 103, iters: 2400, time: 0.153, data: 0.002) G_GAN: 8.001 G_L1: 0.569 D_real: 0.001 D_fake: 0.001 \n",
            "(epoch: 103, iters: 2500, time: 0.066, data: 0.010) G_GAN: 5.683 G_L1: 1.565 D_real: 0.678 D_fake: 0.036 \n",
            "(epoch: 103, iters: 2600, time: 0.066, data: 0.004) G_GAN: 1.637 G_L1: 2.955 D_real: 0.777 D_fake: 0.472 \n",
            "(epoch: 103, iters: 2700, time: 0.066, data: 0.004) G_GAN: 1.810 G_L1: 1.391 D_real: 0.652 D_fake: 0.540 \n",
            "(epoch: 103, iters: 2800, time: 0.178, data: 0.004) G_GAN: 7.742 G_L1: 1.247 D_real: 0.026 D_fake: 0.001 \n",
            "(epoch: 103, iters: 2900, time: 0.065, data: 0.002) G_GAN: 0.821 G_L1: 2.092 D_real: 0.403 D_fake: 0.969 \n",
            "(epoch: 103, iters: 3000, time: 0.066, data: 0.004) G_GAN: 2.391 G_L1: 4.086 D_real: 0.037 D_fake: 0.365 \n",
            "(epoch: 103, iters: 3100, time: 0.063, data: 0.007) G_GAN: 1.586 G_L1: 3.306 D_real: 0.412 D_fake: 0.332 \n",
            "(epoch: 103, iters: 3200, time: 0.170, data: 0.003) G_GAN: 8.904 G_L1: 1.303 D_real: 0.000 D_fake: 0.000 \n",
            "(epoch: 103, iters: 3300, time: 0.061, data: 0.002) G_GAN: 2.278 G_L1: 1.499 D_real: 0.707 D_fake: 0.305 \n",
            "(epoch: 103, iters: 3400, time: 0.066, data: 0.005) G_GAN: 1.704 G_L1: 2.129 D_real: 0.295 D_fake: 0.224 \n",
            "(epoch: 103, iters: 3500, time: 0.065, data: 0.003) G_GAN: 5.931 G_L1: 0.653 D_real: 0.000 D_fake: 0.006 \n",
            "(epoch: 103, iters: 3600, time: 0.221, data: 0.004) G_GAN: 1.689 G_L1: 1.912 D_real: 0.665 D_fake: 0.128 \n",
            "(epoch: 103, iters: 3700, time: 0.067, data: 0.002) G_GAN: 8.426 G_L1: 0.556 D_real: 0.001 D_fake: 0.001 \n",
            "(epoch: 103, iters: 3800, time: 0.066, data: 0.003) G_GAN: 3.796 G_L1: 4.361 D_real: 0.088 D_fake: 0.252 \n",
            "(epoch: 103, iters: 3900, time: 0.065, data: 0.003) G_GAN: 4.626 G_L1: 1.163 D_real: 0.047 D_fake: 1.012 \n",
            "(epoch: 103, iters: 4000, time: 0.510, data: 0.003) G_GAN: 2.763 G_L1: 2.426 D_real: 0.092 D_fake: 0.399 \n",
            "End of epoch 103 / 200 \t Time Taken: 176 sec\n",
            "learning rate 0.0001921 -> 0.0001901\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "(epoch: 104, iters: 100, time: 0.066, data: 0.206) G_GAN: 4.115 G_L1: 2.180 D_real: 0.047 D_fake: 0.028 \n",
            "(epoch: 104, iters: 200, time: 0.066, data: 0.004) G_GAN: 1.175 G_L1: 1.914 D_real: 0.523 D_fake: 0.358 \n",
            "(epoch: 104, iters: 300, time: 0.066, data: 0.003) G_GAN: 2.326 G_L1: 1.713 D_real: 0.176 D_fake: 0.224 \n",
            "(epoch: 104, iters: 400, time: 0.623, data: 0.003) G_GAN: 4.513 G_L1: 1.838 D_real: 0.398 D_fake: 0.034 \n",
            "(epoch: 104, iters: 500, time: 0.065, data: 0.002) G_GAN: 2.525 G_L1: 2.264 D_real: 0.537 D_fake: 0.550 \n",
            "(epoch: 104, iters: 600, time: 0.065, data: 0.005) G_GAN: 3.343 G_L1: 2.083 D_real: 0.101 D_fake: 0.647 \n",
            "(epoch: 104, iters: 700, time: 0.067, data: 0.005) G_GAN: 2.352 G_L1: 1.542 D_real: 0.105 D_fake: 0.533 \n",
            "(epoch: 104, iters: 800, time: 0.169, data: 0.004) G_GAN: 6.186 G_L1: 1.465 D_real: 1.124 D_fake: 0.004 \n",
            "(epoch: 104, iters: 900, time: 0.064, data: 0.007) G_GAN: 0.743 G_L1: 1.049 D_real: 0.633 D_fake: 1.120 \n",
            "(epoch: 104, iters: 1000, time: 0.064, data: 0.008) G_GAN: 2.305 G_L1: 2.439 D_real: 0.169 D_fake: 0.168 \n",
            "(epoch: 104, iters: 1100, time: 0.066, data: 0.007) G_GAN: 1.576 G_L1: 2.531 D_real: 1.334 D_fake: 0.152 \n",
            "(epoch: 104, iters: 1200, time: 0.159, data: 0.003) G_GAN: 6.279 G_L1: 0.959 D_real: 0.001 D_fake: 0.005 \n",
            "(epoch: 104, iters: 1300, time: 0.064, data: 0.002) G_GAN: 3.458 G_L1: 1.761 D_real: 0.109 D_fake: 0.399 \n",
            "(epoch: 104, iters: 1400, time: 0.066, data: 0.003) G_GAN: 1.995 G_L1: 1.390 D_real: 1.349 D_fake: 0.070 \n",
            "(epoch: 104, iters: 1500, time: 0.065, data: 0.004) G_GAN: 8.400 G_L1: 2.720 D_real: 0.001 D_fake: 0.001 \n",
            "(epoch: 104, iters: 1600, time: 0.189, data: 0.004) G_GAN: 3.625 G_L1: 2.188 D_real: 0.165 D_fake: 0.113 \n",
            "(epoch: 104, iters: 1700, time: 0.064, data: 0.002) G_GAN: 4.146 G_L1: 2.698 D_real: 0.006 D_fake: 0.026 \n",
            "(epoch: 104, iters: 1800, time: 0.066, data: 0.003) G_GAN: 1.476 G_L1: 2.811 D_real: 1.118 D_fake: 0.042 \n",
            "(epoch: 104, iters: 1900, time: 0.066, data: 0.002) G_GAN: 1.456 G_L1: 1.721 D_real: 0.272 D_fake: 0.441 \n",
            "(epoch: 104, iters: 2000, time: 0.515, data: 0.004) G_GAN: 10.294 G_L1: 1.304 D_real: 0.001 D_fake: 0.000 \n",
            "(epoch: 104, iters: 2100, time: 0.066, data: 0.003) G_GAN: 8.073 G_L1: 1.049 D_real: 0.000 D_fake: 0.001 \n",
            "(epoch: 104, iters: 2200, time: 0.066, data: 0.007) G_GAN: 5.068 G_L1: 1.188 D_real: 0.002 D_fake: 0.015 \n",
            "(epoch: 104, iters: 2300, time: 0.066, data: 0.004) G_GAN: 4.944 G_L1: 2.369 D_real: 0.057 D_fake: 0.026 \n",
            "(epoch: 104, iters: 2400, time: 0.169, data: 0.003) G_GAN: 2.243 G_L1: 1.386 D_real: 0.317 D_fake: 0.091 \n",
            "(epoch: 104, iters: 2500, time: 0.066, data: 0.002) G_GAN: 9.934 G_L1: 2.225 D_real: 0.484 D_fake: 0.000 \n",
            "(epoch: 104, iters: 2600, time: 0.066, data: 0.004) G_GAN: 3.845 G_L1: 1.266 D_real: 0.048 D_fake: 0.036 \n",
            "(epoch: 104, iters: 2700, time: 0.067, data: 0.004) G_GAN: 3.330 G_L1: 1.983 D_real: 0.291 D_fake: 0.192 \n",
            "(epoch: 104, iters: 2800, time: 0.169, data: 0.008) G_GAN: 3.475 G_L1: 2.051 D_real: 0.612 D_fake: 0.098 \n",
            "(epoch: 104, iters: 2900, time: 0.067, data: 0.002) G_GAN: 8.524 G_L1: 1.492 D_real: 0.023 D_fake: 0.000 \n",
            "(epoch: 104, iters: 3000, time: 0.066, data: 0.003) G_GAN: 2.129 G_L1: 2.839 D_real: 0.216 D_fake: 0.345 \n",
            "saving the latest model (epoch 104, total_iters 415000)\n",
            "(epoch: 104, iters: 3100, time: 0.066, data: 0.006) G_GAN: 1.666 G_L1: 2.069 D_real: 0.506 D_fake: 0.780 \n",
            "(epoch: 104, iters: 3200, time: 0.285, data: 0.002) G_GAN: 7.391 G_L1: 1.079 D_real: 0.000 D_fake: 0.002 \n",
            "(epoch: 104, iters: 3300, time: 0.063, data: 0.004) G_GAN: 2.250 G_L1: 2.446 D_real: 0.118 D_fake: 0.955 \n",
            "(epoch: 104, iters: 3400, time: 0.063, data: 0.004) G_GAN: 1.790 G_L1: 1.879 D_real: 0.217 D_fake: 0.457 \n",
            "(epoch: 104, iters: 3500, time: 0.066, data: 0.002) G_GAN: 1.771 G_L1: 3.527 D_real: 0.328 D_fake: 0.824 \n",
            "(epoch: 104, iters: 3600, time: 0.219, data: 0.002) G_GAN: 1.835 G_L1: 2.883 D_real: 0.766 D_fake: 0.059 \n",
            "(epoch: 104, iters: 3700, time: 0.066, data: 0.003) G_GAN: 2.686 G_L1: 1.170 D_real: 0.161 D_fake: 0.236 \n",
            "(epoch: 104, iters: 3800, time: 0.067, data: 0.004) G_GAN: 2.575 G_L1: 2.210 D_real: 0.067 D_fake: 0.182 \n",
            "(epoch: 104, iters: 3900, time: 0.067, data: 0.002) G_GAN: 7.177 G_L1: 0.982 D_real: 0.025 D_fake: 0.002 \n",
            "(epoch: 104, iters: 4000, time: 0.508, data: 0.004) G_GAN: 2.292 G_L1: 1.670 D_real: 0.142 D_fake: 0.778 \n",
            "End of epoch 104 / 200 \t Time Taken: 176 sec\n",
            "learning rate 0.0001901 -> 0.0001881\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "(epoch: 105, iters: 100, time: 0.066, data: 0.197) G_GAN: 3.642 G_L1: 3.162 D_real: 0.042 D_fake: 0.041 \n",
            "(epoch: 105, iters: 200, time: 0.064, data: 0.003) G_GAN: 2.599 G_L1: 1.755 D_real: 0.953 D_fake: 0.680 \n",
            "(epoch: 105, iters: 300, time: 0.065, data: 0.003) G_GAN: 9.634 G_L1: 0.625 D_real: 0.003 D_fake: 0.000 \n",
            "(epoch: 105, iters: 400, time: 0.805, data: 0.003) G_GAN: 7.784 G_L1: 1.477 D_real: 0.040 D_fake: 0.001 \n",
            "(epoch: 105, iters: 500, time: 0.063, data: 0.004) G_GAN: 4.070 G_L1: 3.193 D_real: 0.028 D_fake: 0.025 \n",
            "(epoch: 105, iters: 600, time: 0.066, data: 0.005) G_GAN: 1.851 G_L1: 1.817 D_real: 0.082 D_fake: 0.800 \n",
            "(epoch: 105, iters: 700, time: 0.064, data: 0.004) G_GAN: 1.823 G_L1: 3.482 D_real: 0.096 D_fake: 0.706 \n",
            "(epoch: 105, iters: 800, time: 0.156, data: 0.005) G_GAN: 6.105 G_L1: 0.636 D_real: 0.002 D_fake: 0.005 \n",
            "(epoch: 105, iters: 900, time: 0.067, data: 0.007) G_GAN: 10.127 G_L1: 0.770 D_real: 0.005 D_fake: 0.000 \n",
            "(epoch: 105, iters: 1000, time: 0.067, data: 0.005) G_GAN: 3.261 G_L1: 0.988 D_real: 0.566 D_fake: 0.043 \n",
            "(epoch: 105, iters: 1100, time: 0.067, data: 0.002) G_GAN: 3.101 G_L1: 2.567 D_real: 0.127 D_fake: 0.056 \n",
            "(epoch: 105, iters: 1200, time: 0.172, data: 0.004) G_GAN: 2.527 G_L1: 1.944 D_real: 0.129 D_fake: 0.421 \n",
            "(epoch: 105, iters: 1300, time: 0.067, data: 0.002) G_GAN: 1.755 G_L1: 1.846 D_real: 0.331 D_fake: 0.203 \n",
            "(epoch: 105, iters: 1400, time: 0.066, data: 0.002) G_GAN: 2.355 G_L1: 2.630 D_real: 0.378 D_fake: 0.050 \n",
            "(epoch: 105, iters: 1500, time: 0.065, data: 0.002) G_GAN: 2.709 G_L1: 2.278 D_real: 0.077 D_fake: 0.111 \n",
            "(epoch: 105, iters: 1600, time: 0.195, data: 0.003) G_GAN: 6.319 G_L1: 1.000 D_real: 0.224 D_fake: 0.002 \n",
            "(epoch: 105, iters: 1700, time: 0.065, data: 0.008) G_GAN: 4.783 G_L1: 2.195 D_real: 0.441 D_fake: 0.007 \n",
            "(epoch: 105, iters: 1800, time: 0.066, data: 0.002) G_GAN: 10.609 G_L1: 1.185 D_real: 0.001 D_fake: 0.000 \n",
            "(epoch: 105, iters: 1900, time: 0.066, data: 0.003) G_GAN: 10.454 G_L1: 1.107 D_real: 0.000 D_fake: 0.000 \n",
            "(epoch: 105, iters: 2000, time: 0.558, data: 0.005) G_GAN: 0.948 G_L1: 1.950 D_real: 1.434 D_fake: 0.253 \n",
            "(epoch: 105, iters: 2100, time: 0.066, data: 0.004) G_GAN: 1.144 G_L1: 1.511 D_real: 0.540 D_fake: 0.796 \n",
            "(epoch: 105, iters: 2200, time: 0.067, data: 0.004) G_GAN: 6.290 G_L1: 0.825 D_real: 0.000 D_fake: 0.006 \n",
            "(epoch: 105, iters: 2300, time: 0.064, data: 0.002) G_GAN: 6.617 G_L1: 1.905 D_real: 0.092 D_fake: 0.002 \n",
            "(epoch: 105, iters: 2400, time: 0.224, data: 0.004) G_GAN: 1.728 G_L1: 2.001 D_real: 0.274 D_fake: 0.255 \n",
            "(epoch: 105, iters: 2500, time: 0.066, data: 0.008) G_GAN: 1.649 G_L1: 2.647 D_real: 0.589 D_fake: 0.338 \n",
            "(epoch: 105, iters: 2600, time: 0.067, data: 0.004) G_GAN: 1.862 G_L1: 2.043 D_real: 0.068 D_fake: 0.788 \n",
            "(epoch: 105, iters: 2700, time: 0.067, data: 0.003) G_GAN: 1.372 G_L1: 1.794 D_real: 0.507 D_fake: 0.483 \n",
            "(epoch: 105, iters: 2800, time: 0.171, data: 0.004) G_GAN: 1.487 G_L1: 1.057 D_real: 0.279 D_fake: 0.648 \n",
            "(epoch: 105, iters: 2900, time: 0.064, data: 0.006) G_GAN: 4.360 G_L1: 0.888 D_real: 0.004 D_fake: 0.063 \n",
            "(epoch: 105, iters: 3000, time: 0.066, data: 0.008) G_GAN: 4.315 G_L1: 0.739 D_real: 0.001 D_fake: 0.275 \n",
            "(epoch: 105, iters: 3100, time: 0.067, data: 0.004) G_GAN: 5.688 G_L1: 2.023 D_real: 0.000 D_fake: 0.007 \n",
            "(epoch: 105, iters: 3200, time: 0.193, data: 0.003) G_GAN: 6.286 G_L1: 1.008 D_real: 0.302 D_fake: 0.002 \n",
            "(epoch: 105, iters: 3300, time: 0.066, data: 0.002) G_GAN: 6.535 G_L1: 1.537 D_real: 0.000 D_fake: 0.003 \n",
            "(epoch: 105, iters: 3400, time: 0.066, data: 0.006) G_GAN: 2.638 G_L1: 1.068 D_real: 0.971 D_fake: 0.405 \n",
            "(epoch: 105, iters: 3500, time: 0.067, data: 0.004) G_GAN: 2.967 G_L1: 1.694 D_real: 0.105 D_fake: 0.158 \n",
            "(epoch: 105, iters: 3600, time: 0.227, data: 0.005) G_GAN: 2.021 G_L1: 2.606 D_real: 0.024 D_fake: 0.664 \n",
            "(epoch: 105, iters: 3700, time: 0.066, data: 0.003) G_GAN: 2.872 G_L1: 2.139 D_real: 0.040 D_fake: 0.125 \n",
            "(epoch: 105, iters: 3800, time: 0.066, data: 0.003) G_GAN: 1.256 G_L1: 3.079 D_real: 0.765 D_fake: 0.105 \n",
            "(epoch: 105, iters: 3900, time: 0.066, data: 0.003) G_GAN: 1.130 G_L1: 1.256 D_real: 0.423 D_fake: 0.717 \n",
            "(epoch: 105, iters: 4000, time: 0.633, data: 0.004) G_GAN: 10.155 G_L1: 0.910 D_real: 0.029 D_fake: 0.000 \n",
            "saving the latest model (epoch 105, total_iters 420000)\n",
            "saving the model at the end of epoch 105, iters 420000\n",
            "End of epoch 105 / 200 \t Time Taken: 177 sec\n",
            "learning rate 0.0001881 -> 0.0001861\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "(epoch: 106, iters: 100, time: 0.067, data: 0.160) G_GAN: 2.545 G_L1: 1.571 D_real: 0.573 D_fake: 0.045 \n",
            "(epoch: 106, iters: 200, time: 0.067, data: 0.003) G_GAN: 3.916 G_L1: 1.606 D_real: 0.019 D_fake: 0.055 \n",
            "(epoch: 106, iters: 300, time: 0.061, data: 0.003) G_GAN: 2.867 G_L1: 2.003 D_real: 0.023 D_fake: 0.182 \n",
            "(epoch: 106, iters: 400, time: 0.690, data: 0.004) G_GAN: 7.818 G_L1: 1.161 D_real: 0.000 D_fake: 0.001 \n",
            "(epoch: 106, iters: 500, time: 0.059, data: 0.003) G_GAN: 1.265 G_L1: 2.139 D_real: 0.403 D_fake: 0.114 \n",
            "(epoch: 106, iters: 600, time: 0.065, data: 0.004) G_GAN: 6.147 G_L1: 2.240 D_real: 0.041 D_fake: 0.005 \n",
            "(epoch: 106, iters: 700, time: 0.066, data: 0.002) G_GAN: 6.428 G_L1: 1.353 D_real: 0.000 D_fake: 0.003 \n",
            "(epoch: 106, iters: 800, time: 0.164, data: 0.002) G_GAN: 2.825 G_L1: 1.912 D_real: 0.973 D_fake: 0.455 \n",
            "(epoch: 106, iters: 900, time: 0.061, data: 0.003) G_GAN: 1.335 G_L1: 2.995 D_real: 0.163 D_fake: 0.904 \n",
            "(epoch: 106, iters: 1000, time: 0.063, data: 0.004) G_GAN: 8.693 G_L1: 0.944 D_real: 0.060 D_fake: 0.000 \n",
            "(epoch: 106, iters: 1100, time: 0.067, data: 0.004) G_GAN: 8.130 G_L1: 1.363 D_real: 0.017 D_fake: 0.000 \n",
            "(epoch: 106, iters: 1200, time: 0.172, data: 0.002) G_GAN: 4.540 G_L1: 1.020 D_real: 0.000 D_fake: 0.033 \n",
            "(epoch: 106, iters: 1300, time: 0.066, data: 0.002) G_GAN: 2.808 G_L1: 3.189 D_real: 0.141 D_fake: 0.156 \n",
            "(epoch: 106, iters: 1400, time: 0.066, data: 0.006) G_GAN: 8.316 G_L1: 0.748 D_real: 0.001 D_fake: 0.001 \n",
            "(epoch: 106, iters: 1500, time: 0.066, data: 0.003) G_GAN: 6.700 G_L1: 1.509 D_real: 0.728 D_fake: 0.003 \n",
            "(epoch: 106, iters: 1600, time: 0.222, data: 0.005) G_GAN: 2.433 G_L1: 2.871 D_real: 0.245 D_fake: 0.079 \n",
            "(epoch: 106, iters: 1700, time: 0.067, data: 0.003) G_GAN: 4.735 G_L1: 1.263 D_real: 0.103 D_fake: 0.013 \n",
            "(epoch: 106, iters: 1800, time: 0.067, data: 0.003) G_GAN: 2.405 G_L1: 1.026 D_real: 0.175 D_fake: 0.259 \n",
            "(epoch: 106, iters: 1900, time: 0.066, data: 0.003) G_GAN: 1.961 G_L1: 1.781 D_real: 0.632 D_fake: 0.229 \n",
            "(epoch: 106, iters: 2000, time: 0.526, data: 0.003) G_GAN: 9.881 G_L1: 1.566 D_real: 0.161 D_fake: 0.000 \n",
            "(epoch: 106, iters: 2100, time: 0.067, data: 0.004) G_GAN: 10.050 G_L1: 1.825 D_real: 0.108 D_fake: 0.000 \n",
            "(epoch: 106, iters: 2200, time: 0.066, data: 0.008) G_GAN: 5.692 G_L1: 0.788 D_real: 0.001 D_fake: 0.008 \n",
            "(epoch: 106, iters: 2300, time: 0.066, data: 0.003) G_GAN: 4.457 G_L1: 2.425 D_real: 0.081 D_fake: 0.020 \n",
            "(epoch: 106, iters: 2400, time: 0.204, data: 0.002) G_GAN: 3.216 G_L1: 1.863 D_real: 0.186 D_fake: 0.039 \n",
            "(epoch: 106, iters: 2500, time: 0.066, data: 0.002) G_GAN: 8.358 G_L1: 0.599 D_real: 0.001 D_fake: 0.001 \n",
            "(epoch: 106, iters: 2600, time: 0.066, data: 0.003) G_GAN: 3.861 G_L1: 0.934 D_real: 0.000 D_fake: 0.057 \n",
            "(epoch: 106, iters: 2700, time: 0.067, data: 0.002) G_GAN: 7.480 G_L1: 1.816 D_real: 0.103 D_fake: 0.001 \n",
            "(epoch: 106, iters: 2800, time: 0.172, data: 0.005) G_GAN: 7.809 G_L1: 1.408 D_real: 0.000 D_fake: 0.001 \n",
            "(epoch: 106, iters: 2900, time: 0.066, data: 0.003) G_GAN: 10.234 G_L1: 2.082 D_real: 0.732 D_fake: 0.000 \n",
            "(epoch: 106, iters: 3000, time: 0.061, data: 0.002) G_GAN: 3.327 G_L1: 1.550 D_real: 0.123 D_fake: 0.071 \n",
            "(epoch: 106, iters: 3100, time: 0.066, data: 0.005) G_GAN: 6.604 G_L1: 0.983 D_real: 0.000 D_fake: 0.004 \n",
            "(epoch: 106, iters: 3200, time: 0.225, data: 0.005) G_GAN: 2.634 G_L1: 2.452 D_real: 0.030 D_fake: 0.919 \n",
            "(epoch: 106, iters: 3300, time: 0.066, data: 0.006) G_GAN: 3.694 G_L1: 1.159 D_real: 0.160 D_fake: 0.115 \n",
            "(epoch: 106, iters: 3400, time: 0.066, data: 0.003) G_GAN: 2.274 G_L1: 1.906 D_real: 0.063 D_fake: 0.300 \n",
            "(epoch: 106, iters: 3500, time: 0.065, data: 0.004) G_GAN: 6.974 G_L1: 1.101 D_real: 0.010 D_fake: 0.002 \n",
            "(epoch: 106, iters: 3600, time: 0.170, data: 0.003) G_GAN: 1.920 G_L1: 1.341 D_real: 0.403 D_fake: 0.575 \n",
            "(epoch: 106, iters: 3700, time: 0.067, data: 0.002) G_GAN: 5.253 G_L1: 1.029 D_real: 0.002 D_fake: 0.010 \n",
            "(epoch: 106, iters: 3800, time: 0.066, data: 0.008) G_GAN: 1.141 G_L1: 2.006 D_real: 0.085 D_fake: 0.605 \n",
            "(epoch: 106, iters: 3900, time: 0.065, data: 0.008) G_GAN: 5.253 G_L1: 1.542 D_real: 0.105 D_fake: 0.007 \n",
            "(epoch: 106, iters: 4000, time: 0.518, data: 0.003) G_GAN: 1.586 G_L1: 1.453 D_real: 0.520 D_fake: 0.855 \n",
            "End of epoch 106 / 200 \t Time Taken: 175 sec\n",
            "learning rate 0.0001861 -> 0.0001842\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "(epoch: 107, iters: 100, time: 0.066, data: 0.201) G_GAN: 8.685 G_L1: 0.770 D_real: 0.003 D_fake: 0.001 \n",
            "(epoch: 107, iters: 200, time: 0.066, data: 0.003) G_GAN: 2.318 G_L1: 2.132 D_real: 0.041 D_fake: 0.610 \n",
            "(epoch: 107, iters: 300, time: 0.066, data: 0.004) G_GAN: 2.079 G_L1: 2.264 D_real: 0.220 D_fake: 0.367 \n",
            "(epoch: 107, iters: 400, time: 0.805, data: 0.004) G_GAN: 4.300 G_L1: 3.927 D_real: 0.020 D_fake: 0.021 \n",
            "(epoch: 107, iters: 500, time: 0.065, data: 0.005) G_GAN: 7.109 G_L1: 0.759 D_real: 0.001 D_fake: 0.002 \n",
            "(epoch: 107, iters: 600, time: 0.066, data: 0.004) G_GAN: 1.520 G_L1: 1.705 D_real: 0.544 D_fake: 0.273 \n",
            "(epoch: 107, iters: 700, time: 0.067, data: 0.004) G_GAN: 7.536 G_L1: 2.541 D_real: 0.016 D_fake: 0.001 \n",
            "(epoch: 107, iters: 800, time: 0.168, data: 0.002) G_GAN: 9.410 G_L1: 3.313 D_real: 0.101 D_fake: 0.000 \n",
            "(epoch: 107, iters: 900, time: 0.067, data: 0.003) G_GAN: 2.245 G_L1: 1.893 D_real: 0.085 D_fake: 0.438 \n",
            "(epoch: 107, iters: 1000, time: 0.065, data: 0.004) G_GAN: 2.321 G_L1: 1.084 D_real: 0.331 D_fake: 0.555 \n",
            "saving the latest model (epoch 107, total_iters 425000)\n",
            "(epoch: 107, iters: 1100, time: 0.066, data: 0.002) G_GAN: 1.731 G_L1: 2.260 D_real: 0.122 D_fake: 1.341 \n",
            "(epoch: 107, iters: 1200, time: 0.175, data: 0.003) G_GAN: 8.196 G_L1: 2.910 D_real: 0.111 D_fake: 0.000 \n",
            "(epoch: 107, iters: 1300, time: 0.063, data: 0.005) G_GAN: 10.479 G_L1: 0.869 D_real: 0.000 D_fake: 0.000 \n",
            "(epoch: 107, iters: 1400, time: 0.063, data: 0.004) G_GAN: 4.936 G_L1: 1.560 D_real: 0.237 D_fake: 0.004 \n",
            "(epoch: 107, iters: 1500, time: 0.066, data: 0.003) G_GAN: 1.973 G_L1: 2.235 D_real: 0.625 D_fake: 0.219 \n",
            "(epoch: 107, iters: 1600, time: 0.179, data: 0.004) G_GAN: 2.583 G_L1: 2.003 D_real: 0.094 D_fake: 0.486 \n",
            "(epoch: 107, iters: 1700, time: 0.067, data: 0.003) G_GAN: 1.656 G_L1: 2.620 D_real: 0.161 D_fake: 0.950 \n",
            "(epoch: 107, iters: 1800, time: 0.066, data: 0.007) G_GAN: 7.870 G_L1: 1.469 D_real: 0.296 D_fake: 0.001 \n",
            "(epoch: 107, iters: 1900, time: 0.065, data: 0.003) G_GAN: 6.176 G_L1: 0.907 D_real: 0.036 D_fake: 0.003 \n",
            "(epoch: 107, iters: 2000, time: 0.548, data: 0.004) G_GAN: 9.275 G_L1: 1.579 D_real: 0.055 D_fake: 0.000 \n",
            "(epoch: 107, iters: 2100, time: 0.065, data: 0.003) G_GAN: 1.714 G_L1: 2.047 D_real: 0.375 D_fake: 0.272 \n",
            "(epoch: 107, iters: 2200, time: 0.066, data: 0.003) G_GAN: 9.492 G_L1: 0.730 D_real: 0.000 D_fake: 0.000 \n",
            "(epoch: 107, iters: 2300, time: 0.067, data: 0.002) G_GAN: 7.452 G_L1: 0.889 D_real: 0.000 D_fake: 0.002 \n",
            "(epoch: 107, iters: 2400, time: 0.175, data: 0.003) G_GAN: 3.661 G_L1: 1.612 D_real: 0.047 D_fake: 0.138 \n",
            "(epoch: 107, iters: 2500, time: 0.064, data: 0.006) G_GAN: 1.495 G_L1: 1.606 D_real: 0.311 D_fake: 0.341 \n",
            "(epoch: 107, iters: 2600, time: 0.067, data: 0.003) G_GAN: 2.856 G_L1: 1.818 D_real: 0.019 D_fake: 1.076 \n",
            "(epoch: 107, iters: 2700, time: 0.067, data: 0.004) G_GAN: 5.059 G_L1: 1.678 D_real: 0.000 D_fake: 0.010 \n",
            "(epoch: 107, iters: 2800, time: 0.159, data: 0.003) G_GAN: 9.548 G_L1: 1.164 D_real: 0.004 D_fake: 0.000 \n",
            "(epoch: 107, iters: 2900, time: 0.063, data: 0.007) G_GAN: 5.432 G_L1: 0.743 D_real: 0.001 D_fake: 0.013 \n",
            "(epoch: 107, iters: 3000, time: 0.065, data: 0.005) G_GAN: 4.032 G_L1: 2.623 D_real: 0.114 D_fake: 0.024 \n",
            "(epoch: 107, iters: 3100, time: 0.066, data: 0.003) G_GAN: 1.678 G_L1: 2.005 D_real: 1.151 D_fake: 0.106 \n",
            "(epoch: 107, iters: 3200, time: 0.163, data: 0.003) G_GAN: 1.332 G_L1: 1.574 D_real: 1.044 D_fake: 0.232 \n",
            "(epoch: 107, iters: 3300, time: 0.065, data: 0.003) G_GAN: 9.363 G_L1: 0.882 D_real: 0.001 D_fake: 0.000 \n",
            "(epoch: 107, iters: 3400, time: 0.066, data: 0.003) G_GAN: 5.327 G_L1: 1.789 D_real: 0.000 D_fake: 0.020 \n",
            "(epoch: 107, iters: 3500, time: 0.067, data: 0.004) G_GAN: 7.674 G_L1: 1.185 D_real: 0.003 D_fake: 0.001 \n",
            "(epoch: 107, iters: 3600, time: 0.170, data: 0.007) G_GAN: 2.331 G_L1: 1.177 D_real: 0.057 D_fake: 1.305 \n",
            "(epoch: 107, iters: 3700, time: 0.064, data: 0.003) G_GAN: 6.728 G_L1: 0.774 D_real: 0.001 D_fake: 0.003 \n",
            "(epoch: 107, iters: 3800, time: 0.064, data: 0.006) G_GAN: 1.302 G_L1: 1.390 D_real: 0.646 D_fake: 0.587 \n",
            "(epoch: 107, iters: 3900, time: 0.066, data: 0.005) G_GAN: 7.683 G_L1: 0.765 D_real: 0.016 D_fake: 0.001 \n",
            "(epoch: 107, iters: 4000, time: 0.595, data: 0.004) G_GAN: 2.749 G_L1: 3.178 D_real: 0.187 D_fake: 0.055 \n",
            "End of epoch 107 / 200 \t Time Taken: 176 sec\n",
            "learning rate 0.0001842 -> 0.0001822\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "(epoch: 108, iters: 100, time: 0.067, data: 0.230) G_GAN: 5.652 G_L1: 1.209 D_real: 0.309 D_fake: 0.005 \n",
            "(epoch: 108, iters: 200, time: 0.066, data: 0.003) G_GAN: 9.212 G_L1: 0.711 D_real: 0.005 D_fake: 0.000 \n",
            "(epoch: 108, iters: 300, time: 0.064, data: 0.003) G_GAN: 9.309 G_L1: 0.767 D_real: 0.079 D_fake: 0.000 \n",
            "(epoch: 108, iters: 400, time: 0.762, data: 0.004) G_GAN: 5.284 G_L1: 1.068 D_real: 0.011 D_fake: 0.011 \n",
            "(epoch: 108, iters: 500, time: 0.064, data: 0.006) G_GAN: 3.765 G_L1: 1.671 D_real: 0.967 D_fake: 0.011 \n",
            "(epoch: 108, iters: 600, time: 0.067, data: 0.006) G_GAN: 4.073 G_L1: 1.460 D_real: 0.073 D_fake: 0.855 \n",
            "(epoch: 108, iters: 700, time: 0.056, data: 0.003) G_GAN: 3.105 G_L1: 1.667 D_real: 0.257 D_fake: 0.062 \n",
            "(epoch: 108, iters: 800, time: 0.175, data: 0.002) G_GAN: 5.540 G_L1: 2.134 D_real: 0.023 D_fake: 0.005 \n",
            "(epoch: 108, iters: 900, time: 0.063, data: 0.006) G_GAN: 10.309 G_L1: 0.990 D_real: 0.001 D_fake: 0.000 \n",
            "(epoch: 108, iters: 1000, time: 0.066, data: 0.004) G_GAN: 2.959 G_L1: 2.765 D_real: 0.388 D_fake: 0.114 \n",
            "(epoch: 108, iters: 1100, time: 0.067, data: 0.003) G_GAN: 7.061 G_L1: 1.452 D_real: 0.027 D_fake: 0.002 \n",
            "(epoch: 108, iters: 1200, time: 0.160, data: 0.003) G_GAN: 9.013 G_L1: 1.113 D_real: 0.014 D_fake: 0.001 \n",
            "(epoch: 108, iters: 1300, time: 0.066, data: 0.018) G_GAN: 2.029 G_L1: 2.089 D_real: 0.229 D_fake: 0.243 \n",
            "(epoch: 108, iters: 1400, time: 0.066, data: 0.004) G_GAN: 7.652 G_L1: 0.908 D_real: 0.000 D_fake: 0.001 \n",
            "(epoch: 108, iters: 1500, time: 0.066, data: 0.003) G_GAN: 3.133 G_L1: 1.921 D_real: 0.030 D_fake: 0.814 \n",
            "(epoch: 108, iters: 1600, time: 0.214, data: 0.004) G_GAN: 1.147 G_L1: 1.889 D_real: 0.651 D_fake: 0.465 \n",
            "(epoch: 108, iters: 1700, time: 0.063, data: 0.002) G_GAN: 2.944 G_L1: 1.700 D_real: 0.030 D_fake: 1.445 \n",
            "(epoch: 108, iters: 1800, time: 0.058, data: 0.004) G_GAN: 0.956 G_L1: 1.225 D_real: 1.090 D_fake: 0.558 \n",
            "(epoch: 108, iters: 1900, time: 0.064, data: 0.004) G_GAN: 2.927 G_L1: 2.667 D_real: 0.774 D_fake: 0.034 \n",
            "(epoch: 108, iters: 2000, time: 0.628, data: 0.004) G_GAN: 1.021 G_L1: 1.462 D_real: 2.396 D_fake: 0.374 \n",
            "saving the latest model (epoch 108, total_iters 430000)\n",
            "(epoch: 108, iters: 2100, time: 0.065, data: 0.002) G_GAN: 7.823 G_L1: 0.588 D_real: 0.293 D_fake: 0.001 \n",
            "(epoch: 108, iters: 2200, time: 0.067, data: 0.004) G_GAN: 3.393 G_L1: 1.099 D_real: 0.009 D_fake: 0.157 \n",
            "(epoch: 108, iters: 2300, time: 0.064, data: 0.003) G_GAN: 2.525 G_L1: 2.651 D_real: 0.598 D_fake: 0.232 \n",
            "(epoch: 108, iters: 2400, time: 0.217, data: 0.003) G_GAN: 1.766 G_L1: 2.295 D_real: 0.157 D_fake: 0.376 \n",
            "(epoch: 108, iters: 2500, time: 0.065, data: 0.003) G_GAN: 4.402 G_L1: 0.622 D_real: 0.029 D_fake: 0.067 \n",
            "(epoch: 108, iters: 2600, time: 0.063, data: 0.005) G_GAN: 2.121 G_L1: 1.579 D_real: 1.203 D_fake: 0.264 \n",
            "(epoch: 108, iters: 2700, time: 0.066, data: 0.003) G_GAN: 3.238 G_L1: 1.106 D_real: 0.073 D_fake: 0.645 \n",
            "(epoch: 108, iters: 2800, time: 0.188, data: 0.003) G_GAN: 2.574 G_L1: 1.196 D_real: 0.751 D_fake: 0.144 \n",
            "(epoch: 108, iters: 2900, time: 0.067, data: 0.002) G_GAN: 1.341 G_L1: 1.133 D_real: 0.529 D_fake: 0.454 \n",
            "(epoch: 108, iters: 3000, time: 0.064, data: 0.003) G_GAN: 8.468 G_L1: 1.744 D_real: 0.628 D_fake: 0.000 \n",
            "(epoch: 108, iters: 3100, time: 0.066, data: 0.003) G_GAN: 5.594 G_L1: 1.502 D_real: 0.631 D_fake: 0.033 \n",
            "(epoch: 108, iters: 3200, time: 0.169, data: 0.003) G_GAN: 2.001 G_L1: 2.797 D_real: 0.156 D_fake: 0.365 \n",
            "(epoch: 108, iters: 3300, time: 0.066, data: 0.002) G_GAN: 1.840 G_L1: 1.821 D_real: 0.350 D_fake: 0.231 \n",
            "(epoch: 108, iters: 3400, time: 0.066, data: 0.005) G_GAN: 1.814 G_L1: 1.784 D_real: 0.364 D_fake: 0.225 \n",
            "(epoch: 108, iters: 3500, time: 0.066, data: 0.007) G_GAN: 2.591 G_L1: 0.919 D_real: 0.190 D_fake: 0.200 \n",
            "(epoch: 108, iters: 3600, time: 0.172, data: 0.004) G_GAN: 1.478 G_L1: 1.278 D_real: 0.599 D_fake: 0.177 \n",
            "(epoch: 108, iters: 3700, time: 0.066, data: 0.003) G_GAN: 4.893 G_L1: 3.426 D_real: 0.045 D_fake: 0.012 \n",
            "(epoch: 108, iters: 3800, time: 0.055, data: 0.004) G_GAN: 11.200 G_L1: 0.739 D_real: 0.001 D_fake: 0.000 \n",
            "(epoch: 108, iters: 3900, time: 0.066, data: 0.004) G_GAN: 1.966 G_L1: 2.634 D_real: 0.558 D_fake: 0.079 \n",
            "(epoch: 108, iters: 4000, time: 0.545, data: 0.004) G_GAN: 1.278 G_L1: 0.921 D_real: 0.555 D_fake: 0.590 \n",
            "End of epoch 108 / 200 \t Time Taken: 176 sec\n",
            "learning rate 0.0001822 -> 0.0001802\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "(epoch: 109, iters: 100, time: 0.065, data: 0.188) G_GAN: 2.020 G_L1: 1.836 D_real: 0.404 D_fake: 0.287 \n",
            "(epoch: 109, iters: 200, time: 0.066, data: 0.004) G_GAN: 2.965 G_L1: 1.174 D_real: 0.047 D_fake: 0.190 \n",
            "(epoch: 109, iters: 300, time: 0.066, data: 0.004) G_GAN: 2.884 G_L1: 1.790 D_real: 0.028 D_fake: 0.290 \n",
            "(epoch: 109, iters: 400, time: 0.747, data: 0.005) G_GAN: 2.156 G_L1: 2.811 D_real: 0.146 D_fake: 0.171 \n",
            "(epoch: 109, iters: 500, time: 0.066, data: 0.003) G_GAN: 8.194 G_L1: 0.849 D_real: 0.001 D_fake: 0.001 \n",
            "(epoch: 109, iters: 600, time: 0.067, data: 0.005) G_GAN: 2.276 G_L1: 1.173 D_real: 0.212 D_fake: 0.442 \n",
            "(epoch: 109, iters: 700, time: 0.067, data: 0.004) G_GAN: 2.830 G_L1: 3.547 D_real: 0.070 D_fake: 0.415 \n",
            "(epoch: 109, iters: 800, time: 0.174, data: 0.005) G_GAN: 6.448 G_L1: 0.740 D_real: 0.119 D_fake: 0.002 \n",
            "(epoch: 109, iters: 900, time: 0.064, data: 0.006) G_GAN: 8.226 G_L1: 1.569 D_real: 0.049 D_fake: 0.001 \n",
            "(epoch: 109, iters: 1000, time: 0.063, data: 0.004) G_GAN: 2.460 G_L1: 3.010 D_real: 0.017 D_fake: 0.526 \n",
            "(epoch: 109, iters: 1100, time: 0.067, data: 0.006) G_GAN: 1.713 G_L1: 1.734 D_real: 0.484 D_fake: 0.128 \n",
            "(epoch: 109, iters: 1200, time: 0.173, data: 0.005) G_GAN: 10.071 G_L1: 0.720 D_real: 0.000 D_fake: 0.000 \n",
            "(epoch: 109, iters: 1300, time: 0.067, data: 0.004) G_GAN: 1.016 G_L1: 1.220 D_real: 0.697 D_fake: 0.750 \n",
            "(epoch: 109, iters: 1400, time: 0.059, data: 0.003) G_GAN: 8.809 G_L1: 0.667 D_real: 0.001 D_fake: 0.001 \n",
            "(epoch: 109, iters: 1500, time: 0.065, data: 0.005) G_GAN: 2.908 G_L1: 2.024 D_real: 0.058 D_fake: 0.491 \n",
            "(epoch: 109, iters: 1600, time: 0.187, data: 0.004) G_GAN: 4.300 G_L1: 1.958 D_real: 0.221 D_fake: 0.051 \n",
            "(epoch: 109, iters: 1700, time: 0.062, data: 0.007) G_GAN: 2.058 G_L1: 1.892 D_real: 0.569 D_fake: 0.175 \n",
            "(epoch: 109, iters: 1800, time: 0.062, data: 0.003) G_GAN: 4.103 G_L1: 1.824 D_real: 0.081 D_fake: 0.033 \n",
            "(epoch: 109, iters: 1900, time: 0.067, data: 0.003) G_GAN: 7.103 G_L1: 1.374 D_real: 0.659 D_fake: 0.001 \n",
            "(epoch: 109, iters: 2000, time: 0.500, data: 0.004) G_GAN: 8.662 G_L1: 0.642 D_real: 0.000 D_fake: 0.001 \n",
            "(epoch: 109, iters: 2100, time: 0.067, data: 0.006) G_GAN: 3.184 G_L1: 1.101 D_real: 0.155 D_fake: 0.066 \n",
            "(epoch: 109, iters: 2200, time: 0.066, data: 0.002) G_GAN: 1.774 G_L1: 2.166 D_real: 0.375 D_fake: 0.459 \n",
            "(epoch: 109, iters: 2300, time: 0.066, data: 0.002) G_GAN: 2.778 G_L1: 1.663 D_real: 0.013 D_fake: 0.203 \n",
            "(epoch: 109, iters: 2400, time: 0.274, data: 0.004) G_GAN: 3.664 G_L1: 1.225 D_real: 0.291 D_fake: 0.129 \n",
            "(epoch: 109, iters: 2500, time: 0.067, data: 0.008) G_GAN: 1.155 G_L1: 1.778 D_real: 0.827 D_fake: 0.127 \n",
            "(epoch: 109, iters: 2600, time: 0.066, data: 0.002) G_GAN: 1.285 G_L1: 1.427 D_real: 0.586 D_fake: 0.248 \n",
            "(epoch: 109, iters: 2700, time: 0.066, data: 0.003) G_GAN: 5.120 G_L1: 1.748 D_real: 0.776 D_fake: 0.005 \n",
            "(epoch: 109, iters: 2800, time: 0.171, data: 0.004) G_GAN: 2.415 G_L1: 1.427 D_real: 0.030 D_fake: 0.356 \n",
            "(epoch: 109, iters: 2900, time: 0.066, data: 0.007) G_GAN: 1.843 G_L1: 2.380 D_real: 0.071 D_fake: 0.314 \n",
            "(epoch: 109, iters: 3000, time: 0.067, data: 0.005) G_GAN: 10.503 G_L1: 0.767 D_real: 0.013 D_fake: 0.000 \n",
            "saving the latest model (epoch 109, total_iters 435000)\n",
            "(epoch: 109, iters: 3100, time: 0.066, data: 0.006) G_GAN: 5.486 G_L1: 2.293 D_real: 0.050 D_fake: 0.020 \n",
            "(epoch: 109, iters: 3200, time: 0.215, data: 0.003) G_GAN: 1.581 G_L1: 1.793 D_real: 0.307 D_fake: 0.966 \n",
            "(epoch: 109, iters: 3300, time: 0.065, data: 0.003) G_GAN: 1.002 G_L1: 2.277 D_real: 0.572 D_fake: 0.197 \n",
            "(epoch: 109, iters: 3400, time: 0.065, data: 0.007) G_GAN: 7.711 G_L1: 0.858 D_real: 0.001 D_fake: 0.001 \n",
            "(epoch: 109, iters: 3500, time: 0.067, data: 0.003) G_GAN: 1.730 G_L1: 1.786 D_real: 0.352 D_fake: 0.638 \n",
            "(epoch: 109, iters: 3600, time: 0.220, data: 0.003) G_GAN: 3.730 G_L1: 1.887 D_real: 0.860 D_fake: 0.014 \n",
            "(epoch: 109, iters: 3700, time: 0.065, data: 0.003) G_GAN: 7.807 G_L1: 2.856 D_real: 0.024 D_fake: 0.001 \n",
            "(epoch: 109, iters: 3800, time: 0.065, data: 0.003) G_GAN: 1.465 G_L1: 1.927 D_real: 0.217 D_fake: 0.472 \n",
            "(epoch: 109, iters: 3900, time: 0.066, data: 0.004) G_GAN: 8.189 G_L1: 0.724 D_real: 0.002 D_fake: 0.001 \n",
            "(epoch: 109, iters: 4000, time: 0.607, data: 0.003) G_GAN: 2.135 G_L1: 1.937 D_real: 0.079 D_fake: 0.572 \n",
            "End of epoch 109 / 200 \t Time Taken: 176 sec\n",
            "learning rate 0.0001802 -> 0.0001782\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "(epoch: 110, iters: 100, time: 0.066, data: 0.206) G_GAN: 7.149 G_L1: 1.532 D_real: 1.104 D_fake: 0.002 \n",
            "(epoch: 110, iters: 200, time: 0.066, data: 0.004) G_GAN: 5.077 G_L1: 2.970 D_real: 0.011 D_fake: 0.009 \n",
            "(epoch: 110, iters: 300, time: 0.066, data: 0.004) G_GAN: 6.685 G_L1: 1.038 D_real: 0.000 D_fake: 0.004 \n",
            "(epoch: 110, iters: 400, time: 0.655, data: 0.004) G_GAN: 6.970 G_L1: 0.745 D_real: 0.001 D_fake: 0.002 \n",
            "(epoch: 110, iters: 500, time: 0.065, data: 0.002) G_GAN: 8.609 G_L1: 0.869 D_real: 0.000 D_fake: 0.000 \n",
            "(epoch: 110, iters: 600, time: 0.066, data: 0.005) G_GAN: 6.681 G_L1: 2.154 D_real: 0.122 D_fake: 0.003 \n",
            "(epoch: 110, iters: 700, time: 0.065, data: 0.003) G_GAN: 2.152 G_L1: 2.822 D_real: 0.093 D_fake: 0.265 \n",
            "(epoch: 110, iters: 800, time: 0.171, data: 0.007) G_GAN: 7.312 G_L1: 0.848 D_real: 0.001 D_fake: 0.001 \n",
            "(epoch: 110, iters: 900, time: 0.065, data: 0.010) G_GAN: 2.897 G_L1: 1.668 D_real: 0.167 D_fake: 0.124 \n",
            "(epoch: 110, iters: 1000, time: 0.065, data: 0.004) G_GAN: 2.324 G_L1: 2.596 D_real: 0.418 D_fake: 0.389 \n",
            "(epoch: 110, iters: 1100, time: 0.065, data: 0.005) G_GAN: 1.080 G_L1: 2.219 D_real: 0.407 D_fake: 0.380 \n",
            "(epoch: 110, iters: 1200, time: 0.181, data: 0.002) G_GAN: 4.095 G_L1: 1.742 D_real: 0.397 D_fake: 0.010 \n",
            "(epoch: 110, iters: 1300, time: 0.063, data: 0.003) G_GAN: 1.912 G_L1: 1.846 D_real: 0.266 D_fake: 0.203 \n",
            "(epoch: 110, iters: 1400, time: 0.066, data: 0.003) G_GAN: 3.758 G_L1: 1.041 D_real: 0.668 D_fake: 0.012 \n",
            "(epoch: 110, iters: 1500, time: 0.066, data: 0.004) G_GAN: 1.579 G_L1: 2.028 D_real: 1.912 D_fake: 0.057 \n",
            "(epoch: 110, iters: 1600, time: 0.173, data: 0.003) G_GAN: 1.906 G_L1: 2.104 D_real: 0.226 D_fake: 0.477 \n",
            "(epoch: 110, iters: 1700, time: 0.066, data: 0.002) G_GAN: 1.618 G_L1: 1.856 D_real: 0.491 D_fake: 0.726 \n",
            "(epoch: 110, iters: 1800, time: 0.065, data: 0.003) G_GAN: 6.192 G_L1: 1.580 D_real: 0.021 D_fake: 0.028 \n",
            "(epoch: 110, iters: 1900, time: 0.066, data: 0.003) G_GAN: 6.864 G_L1: 1.322 D_real: 0.008 D_fake: 0.002 \n",
            "(epoch: 110, iters: 2000, time: 0.536, data: 0.003) G_GAN: 10.579 G_L1: 0.930 D_real: 0.002 D_fake: 0.000 \n",
            "(epoch: 110, iters: 2100, time: 0.061, data: 0.003) G_GAN: 3.413 G_L1: 2.761 D_real: 0.209 D_fake: 0.108 \n",
            "(epoch: 110, iters: 2200, time: 0.065, data: 0.007) G_GAN: 5.718 G_L1: 0.698 D_real: 0.000 D_fake: 0.006 \n",
            "(epoch: 110, iters: 2300, time: 0.066, data: 0.006) G_GAN: 4.251 G_L1: 1.024 D_real: 0.001 D_fake: 0.036 \n",
            "(epoch: 110, iters: 2400, time: 0.198, data: 0.003) G_GAN: 2.992 G_L1: 2.951 D_real: 0.262 D_fake: 0.071 \n",
            "(epoch: 110, iters: 2500, time: 0.066, data: 0.007) G_GAN: 2.490 G_L1: 1.544 D_real: 0.137 D_fake: 1.247 \n",
            "(epoch: 110, iters: 2600, time: 0.064, data: 0.004) G_GAN: 2.388 G_L1: 2.524 D_real: 0.266 D_fake: 0.104 \n",
            "(epoch: 110, iters: 2700, time: 0.063, data: 0.003) G_GAN: 1.038 G_L1: 1.796 D_real: 0.917 D_fake: 0.370 \n",
            "(epoch: 110, iters: 2800, time: 0.169, data: 0.004) G_GAN: 5.795 G_L1: 0.721 D_real: 0.000 D_fake: 0.007 \n",
            "(epoch: 110, iters: 2900, time: 0.066, data: 0.002) G_GAN: 2.820 G_L1: 1.786 D_real: 0.013 D_fake: 0.910 \n",
            "(epoch: 110, iters: 3000, time: 0.067, data: 0.005) G_GAN: 3.198 G_L1: 1.772 D_real: 0.031 D_fake: 1.679 \n",
            "(epoch: 110, iters: 3100, time: 0.066, data: 0.005) G_GAN: 3.926 G_L1: 1.940 D_real: 0.708 D_fake: 0.088 \n",
            "(epoch: 110, iters: 3200, time: 0.162, data: 0.007) G_GAN: 2.422 G_L1: 3.103 D_real: 0.024 D_fake: 0.781 \n",
            "(epoch: 110, iters: 3300, time: 0.065, data: 0.009) G_GAN: 1.836 G_L1: 1.217 D_real: 0.953 D_fake: 0.165 \n",
            "(epoch: 110, iters: 3400, time: 0.067, data: 0.003) G_GAN: 2.818 G_L1: 1.068 D_real: 0.011 D_fake: 0.210 \n",
            "(epoch: 110, iters: 3500, time: 0.066, data: 0.006) G_GAN: 3.063 G_L1: 1.916 D_real: 1.018 D_fake: 0.007 \n",
            "(epoch: 110, iters: 3600, time: 0.183, data: 0.006) G_GAN: 1.881 G_L1: 1.921 D_real: 0.033 D_fake: 0.820 \n",
            "(epoch: 110, iters: 3700, time: 0.060, data: 0.003) G_GAN: 8.221 G_L1: 0.694 D_real: 0.000 D_fake: 0.001 \n",
            "(epoch: 110, iters: 3800, time: 0.066, data: 0.005) G_GAN: 7.072 G_L1: 1.166 D_real: 0.000 D_fake: 0.002 \n",
            "(epoch: 110, iters: 3900, time: 0.066, data: 0.002) G_GAN: 2.072 G_L1: 1.598 D_real: 0.102 D_fake: 0.763 \n",
            "(epoch: 110, iters: 4000, time: 0.695, data: 0.003) G_GAN: 1.383 G_L1: 1.814 D_real: 0.573 D_fake: 0.398 \n",
            "saving the latest model (epoch 110, total_iters 440000)\n",
            "saving the model at the end of epoch 110, iters 440000\n",
            "End of epoch 110 / 200 \t Time Taken: 177 sec\n",
            "learning rate 0.0001782 -> 0.0001762\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "(epoch: 111, iters: 100, time: 0.066, data: 0.173) G_GAN: 2.820 G_L1: 1.972 D_real: 0.057 D_fake: 0.827 \n",
            "(epoch: 111, iters: 200, time: 0.065, data: 0.003) G_GAN: 2.914 G_L1: 1.563 D_real: 0.165 D_fake: 0.131 \n",
            "(epoch: 111, iters: 300, time: 0.065, data: 0.004) G_GAN: 3.123 G_L1: 2.274 D_real: 0.386 D_fake: 0.024 \n",
            "(epoch: 111, iters: 400, time: 0.644, data: 0.005) G_GAN: 3.280 G_L1: 4.209 D_real: 0.978 D_fake: 0.374 \n",
            "(epoch: 111, iters: 500, time: 0.067, data: 0.003) G_GAN: 1.383 G_L1: 1.818 D_real: 0.342 D_fake: 0.340 \n",
            "(epoch: 111, iters: 600, time: 0.066, data: 0.004) G_GAN: 3.144 G_L1: 3.249 D_real: 0.057 D_fake: 0.068 \n",
            "(epoch: 111, iters: 700, time: 0.066, data: 0.005) G_GAN: 8.610 G_L1: 2.437 D_real: 0.155 D_fake: 0.000 \n",
            "(epoch: 111, iters: 800, time: 0.220, data: 0.003) G_GAN: 1.825 G_L1: 1.818 D_real: 0.190 D_fake: 1.020 \n",
            "(epoch: 111, iters: 900, time: 0.066, data: 0.006) G_GAN: 4.873 G_L1: 0.922 D_real: 0.001 D_fake: 0.428 \n",
            "(epoch: 111, iters: 1000, time: 0.066, data: 0.003) G_GAN: 1.371 G_L1: 2.606 D_real: 0.735 D_fake: 0.753 \n",
            "(epoch: 111, iters: 1100, time: 0.066, data: 0.003) G_GAN: 3.499 G_L1: 2.238 D_real: 0.357 D_fake: 0.029 \n",
            "(epoch: 111, iters: 1200, time: 0.171, data: 0.004) G_GAN: 8.105 G_L1: 0.894 D_real: 0.000 D_fake: 0.001 \n",
            "(epoch: 111, iters: 1300, time: 0.066, data: 0.007) G_GAN: 4.325 G_L1: 1.574 D_real: 0.322 D_fake: 0.021 \n",
            "(epoch: 111, iters: 1400, time: 0.067, data: 0.003) G_GAN: 2.005 G_L1: 4.703 D_real: 1.224 D_fake: 0.151 \n",
            "(epoch: 111, iters: 1500, time: 0.067, data: 0.003) G_GAN: 2.606 G_L1: 1.750 D_real: 0.101 D_fake: 0.189 \n",
            "(epoch: 111, iters: 1600, time: 0.216, data: 0.004) G_GAN: 3.666 G_L1: 2.521 D_real: 0.358 D_fake: 0.018 \n",
            "(epoch: 111, iters: 1700, time: 0.065, data: 0.008) G_GAN: 3.866 G_L1: 1.207 D_real: 0.133 D_fake: 0.844 \n",
            "(epoch: 111, iters: 1800, time: 0.062, data: 0.004) G_GAN: 8.086 G_L1: 0.681 D_real: 0.005 D_fake: 0.001 \n",
            "(epoch: 111, iters: 1900, time: 0.066, data: 0.003) G_GAN: 2.672 G_L1: 4.863 D_real: 0.147 D_fake: 0.233 \n",
            "(epoch: 111, iters: 2000, time: 0.655, data: 0.003) G_GAN: 1.547 G_L1: 2.066 D_real: 1.356 D_fake: 0.253 \n",
            "(epoch: 111, iters: 2100, time: 0.066, data: 0.006) G_GAN: 2.547 G_L1: 1.359 D_real: 0.156 D_fake: 0.852 \n",
            "(epoch: 111, iters: 2200, time: 0.066, data: 0.003) G_GAN: 2.021 G_L1: 2.131 D_real: 0.718 D_fake: 0.097 \n",
            "(epoch: 111, iters: 2300, time: 0.066, data: 0.004) G_GAN: 2.505 G_L1: 2.832 D_real: 0.185 D_fake: 0.169 \n",
            "(epoch: 111, iters: 2400, time: 0.217, data: 0.002) G_GAN: 0.639 G_L1: 1.852 D_real: 1.865 D_fake: 0.237 \n",
            "(epoch: 111, iters: 2500, time: 0.066, data: 0.003) G_GAN: 3.671 G_L1: 2.571 D_real: 0.079 D_fake: 0.039 \n",
            "(epoch: 111, iters: 2600, time: 0.066, data: 0.006) G_GAN: 2.783 G_L1: 2.975 D_real: 0.072 D_fake: 0.115 \n",
            "(epoch: 111, iters: 2700, time: 0.066, data: 0.003) G_GAN: 2.487 G_L1: 1.372 D_real: 0.055 D_fake: 0.477 \n",
            "(epoch: 111, iters: 2800, time: 0.216, data: 0.004) G_GAN: 3.765 G_L1: 3.087 D_real: 0.082 D_fake: 0.027 \n",
            "(epoch: 111, iters: 2900, time: 0.066, data: 0.002) G_GAN: 1.557 G_L1: 4.030 D_real: 1.621 D_fake: 0.028 \n",
            "(epoch: 111, iters: 3000, time: 0.065, data: 0.005) G_GAN: 1.360 G_L1: 1.598 D_real: 0.147 D_fake: 1.062 \n",
            "(epoch: 111, iters: 3100, time: 0.067, data: 0.003) G_GAN: 3.820 G_L1: 0.960 D_real: 0.436 D_fake: 0.036 \n",
            "(epoch: 111, iters: 3200, time: 0.166, data: 0.005) G_GAN: 5.642 G_L1: 2.645 D_real: 0.250 D_fake: 0.010 \n",
            "(epoch: 111, iters: 3300, time: 0.066, data: 0.002) G_GAN: 7.416 G_L1: 0.890 D_real: 0.000 D_fake: 0.002 \n",
            "(epoch: 111, iters: 3400, time: 0.067, data: 0.004) G_GAN: 6.697 G_L1: 0.989 D_real: 0.000 D_fake: 0.002 \n",
            "(epoch: 111, iters: 3500, time: 0.066, data: 0.003) G_GAN: 6.847 G_L1: 1.640 D_real: 1.028 D_fake: 0.001 \n",
            "(epoch: 111, iters: 3600, time: 0.217, data: 0.002) G_GAN: 2.977 G_L1: 1.950 D_real: 0.045 D_fake: 0.837 \n",
            "(epoch: 111, iters: 3700, time: 0.066, data: 0.002) G_GAN: 7.397 G_L1: 1.160 D_real: 0.001 D_fake: 0.002 \n",
            "(epoch: 111, iters: 3800, time: 0.066, data: 0.002) G_GAN: 1.202 G_L1: 1.562 D_real: 0.873 D_fake: 0.331 \n",
            "(epoch: 111, iters: 3900, time: 0.066, data: 0.007) G_GAN: 3.923 G_L1: 1.977 D_real: 0.184 D_fake: 0.841 \n",
            "(epoch: 111, iters: 4000, time: 0.517, data: 0.004) G_GAN: 3.032 G_L1: 2.509 D_real: 0.092 D_fake: 0.125 \n",
            "End of epoch 111 / 200 \t Time Taken: 175 sec\n",
            "learning rate 0.0001762 -> 0.0001743\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "(epoch: 112, iters: 100, time: 0.066, data: 0.171) G_GAN: 1.580 G_L1: 1.935 D_real: 0.320 D_fake: 0.467 \n",
            "(epoch: 112, iters: 200, time: 0.065, data: 0.004) G_GAN: 2.449 G_L1: 3.444 D_real: 0.031 D_fake: 0.218 \n",
            "(epoch: 112, iters: 300, time: 0.061, data: 0.005) G_GAN: 3.627 G_L1: 5.623 D_real: 0.169 D_fake: 0.037 \n",
            "(epoch: 112, iters: 400, time: 0.839, data: 0.003) G_GAN: 3.788 G_L1: 2.083 D_real: 0.076 D_fake: 0.046 \n",
            "(epoch: 112, iters: 500, time: 0.066, data: 0.004) G_GAN: 4.022 G_L1: 2.791 D_real: 0.149 D_fake: 0.015 \n",
            "(epoch: 112, iters: 600, time: 0.067, data: 0.007) G_GAN: 3.075 G_L1: 2.933 D_real: 0.609 D_fake: 0.008 \n",
            "(epoch: 112, iters: 700, time: 0.065, data: 0.007) G_GAN: 7.401 G_L1: 1.774 D_real: 0.005 D_fake: 1.994 \n",
            "(epoch: 112, iters: 800, time: 0.166, data: 0.005) G_GAN: 4.236 G_L1: 1.838 D_real: 0.149 D_fake: 0.024 \n",
            "(epoch: 112, iters: 900, time: 0.066, data: 0.006) G_GAN: 2.511 G_L1: 2.299 D_real: 0.104 D_fake: 0.216 \n",
            "(epoch: 112, iters: 1000, time: 0.066, data: 0.004) G_GAN: 3.429 G_L1: 0.966 D_real: 0.052 D_fake: 0.071 \n",
            "saving the latest model (epoch 112, total_iters 445000)\n",
            "(epoch: 112, iters: 1100, time: 0.068, data: 0.004) G_GAN: 2.747 G_L1: 1.973 D_real: 0.880 D_fake: 0.028 \n",
            "(epoch: 112, iters: 1200, time: 0.215, data: 0.004) G_GAN: 2.363 G_L1: 1.788 D_real: 0.118 D_fake: 0.173 \n",
            "(epoch: 112, iters: 1300, time: 0.066, data: 0.006) G_GAN: 2.723 G_L1: 2.466 D_real: 0.298 D_fake: 0.035 \n",
            "(epoch: 112, iters: 1400, time: 0.065, data: 0.003) G_GAN: 4.146 G_L1: 2.692 D_real: 0.403 D_fake: 0.031 \n",
            "(epoch: 112, iters: 1500, time: 0.065, data: 0.003) G_GAN: 2.081 G_L1: 2.142 D_real: 0.519 D_fake: 0.296 \n",
            "(epoch: 112, iters: 1600, time: 0.197, data: 0.002) G_GAN: 1.849 G_L1: 0.945 D_real: 0.437 D_fake: 0.096 \n",
            "(epoch: 112, iters: 1700, time: 0.067, data: 0.005) G_GAN: 2.892 G_L1: 1.964 D_real: 0.092 D_fake: 0.419 \n",
            "(epoch: 112, iters: 1800, time: 0.066, data: 0.004) G_GAN: 4.784 G_L1: 1.306 D_real: 0.018 D_fake: 0.013 \n",
            "(epoch: 112, iters: 1900, time: 0.065, data: 0.004) G_GAN: 2.218 G_L1: 1.853 D_real: 0.067 D_fake: 0.298 \n",
            "(epoch: 112, iters: 2000, time: 0.545, data: 0.004) G_GAN: 2.900 G_L1: 1.607 D_real: 0.046 D_fake: 0.455 \n",
            "(epoch: 112, iters: 2100, time: 0.066, data: 0.004) G_GAN: 2.415 G_L1: 2.238 D_real: 0.242 D_fake: 0.569 \n",
            "(epoch: 112, iters: 2200, time: 0.066, data: 0.003) G_GAN: 1.248 G_L1: 2.749 D_real: 0.517 D_fake: 0.903 \n",
            "(epoch: 112, iters: 2300, time: 0.067, data: 0.005) G_GAN: 2.923 G_L1: 2.471 D_real: 0.832 D_fake: 0.143 \n",
            "(epoch: 112, iters: 2400, time: 0.178, data: 0.003) G_GAN: 1.491 G_L1: 1.487 D_real: 0.199 D_fake: 0.881 \n",
            "(epoch: 112, iters: 2500, time: 0.066, data: 0.008) G_GAN: 2.793 G_L1: 2.174 D_real: 0.074 D_fake: 0.121 \n",
            "(epoch: 112, iters: 2600, time: 0.066, data: 0.003) G_GAN: 0.833 G_L1: 1.079 D_real: 0.674 D_fake: 0.839 \n",
            "(epoch: 112, iters: 2700, time: 0.066, data: 0.004) G_GAN: 3.164 G_L1: 1.452 D_real: 0.326 D_fake: 1.258 \n",
            "(epoch: 112, iters: 2800, time: 0.171, data: 0.004) G_GAN: 1.068 G_L1: 1.146 D_real: 1.076 D_fake: 0.489 \n",
            "(epoch: 112, iters: 2900, time: 0.066, data: 0.003) G_GAN: 2.221 G_L1: 4.702 D_real: 0.264 D_fake: 0.295 \n",
            "(epoch: 112, iters: 3000, time: 0.066, data: 0.003) G_GAN: 4.124 G_L1: 1.823 D_real: 0.050 D_fake: 0.037 \n",
            "(epoch: 112, iters: 3100, time: 0.066, data: 0.003) G_GAN: 3.436 G_L1: 1.762 D_real: 0.106 D_fake: 0.043 \n",
            "(epoch: 112, iters: 3200, time: 0.170, data: 0.004) G_GAN: 2.572 G_L1: 1.230 D_real: 0.066 D_fake: 1.326 \n",
            "(epoch: 112, iters: 3300, time: 0.064, data: 0.006) G_GAN: 4.814 G_L1: 1.080 D_real: 0.781 D_fake: 0.013 \n",
            "(epoch: 112, iters: 3400, time: 0.066, data: 0.003) G_GAN: 2.428 G_L1: 2.156 D_real: 0.362 D_fake: 0.246 \n",
            "(epoch: 112, iters: 3500, time: 0.065, data: 0.004) G_GAN: 1.921 G_L1: 1.168 D_real: 0.178 D_fake: 0.728 \n",
            "(epoch: 112, iters: 3600, time: 0.218, data: 0.004) G_GAN: 3.474 G_L1: 2.184 D_real: 0.022 D_fake: 0.060 \n",
            "(epoch: 112, iters: 3700, time: 0.066, data: 0.002) G_GAN: 1.289 G_L1: 1.721 D_real: 0.275 D_fake: 0.897 \n",
            "(epoch: 112, iters: 3800, time: 0.066, data: 0.009) G_GAN: 1.615 G_L1: 1.887 D_real: 0.644 D_fake: 0.125 \n",
            "(epoch: 112, iters: 3900, time: 0.067, data: 0.003) G_GAN: 3.260 G_L1: 2.414 D_real: 0.104 D_fake: 0.105 \n",
            "(epoch: 112, iters: 4000, time: 0.532, data: 0.003) G_GAN: 2.153 G_L1: 1.165 D_real: 0.359 D_fake: 0.250 \n",
            "End of epoch 112 / 200 \t Time Taken: 176 sec\n",
            "learning rate 0.0001743 -> 0.0001723\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "(epoch: 113, iters: 100, time: 0.066, data: 0.222) G_GAN: 2.654 G_L1: 2.396 D_real: 0.199 D_fake: 0.293 \n",
            "(epoch: 113, iters: 200, time: 0.065, data: 0.004) G_GAN: 2.339 G_L1: 1.884 D_real: 0.150 D_fake: 0.410 \n",
            "(epoch: 113, iters: 300, time: 0.065, data: 0.003) G_GAN: 2.397 G_L1: 1.733 D_real: 0.226 D_fake: 0.146 \n",
            "(epoch: 113, iters: 400, time: 0.841, data: 0.003) G_GAN: 3.234 G_L1: 1.321 D_real: 0.285 D_fake: 0.081 \n",
            "(epoch: 113, iters: 500, time: 0.065, data: 0.003) G_GAN: 7.948 G_L1: 1.383 D_real: 0.000 D_fake: 0.001 \n",
            "(epoch: 113, iters: 600, time: 0.066, data: 0.004) G_GAN: 2.411 G_L1: 3.411 D_real: 0.087 D_fake: 1.366 \n",
            "(epoch: 113, iters: 700, time: 0.067, data: 0.003) G_GAN: 5.359 G_L1: 1.951 D_real: 0.001 D_fake: 0.010 \n",
            "(epoch: 113, iters: 800, time: 0.218, data: 0.004) G_GAN: 2.876 G_L1: 2.649 D_real: 0.046 D_fake: 0.116 \n",
            "(epoch: 113, iters: 900, time: 0.065, data: 0.003) G_GAN: 1.760 G_L1: 2.357 D_real: 0.421 D_fake: 1.156 \n",
            "(epoch: 113, iters: 1000, time: 0.067, data: 0.004) G_GAN: 2.322 G_L1: 1.776 D_real: 0.015 D_fake: 1.570 \n",
            "(epoch: 113, iters: 1100, time: 0.065, data: 0.004) G_GAN: 9.038 G_L1: 0.633 D_real: 0.048 D_fake: 0.000 \n",
            "(epoch: 113, iters: 1200, time: 0.224, data: 0.003) G_GAN: 2.453 G_L1: 2.201 D_real: 0.152 D_fake: 0.151 \n",
            "(epoch: 113, iters: 1300, time: 0.067, data: 0.006) G_GAN: 2.753 G_L1: 2.434 D_real: 0.032 D_fake: 0.237 \n",
            "(epoch: 113, iters: 1400, time: 0.064, data: 0.005) G_GAN: 2.485 G_L1: 2.011 D_real: 0.595 D_fake: 0.031 \n",
            "(epoch: 113, iters: 1500, time: 0.066, data: 0.004) G_GAN: 0.870 G_L1: 4.664 D_real: 0.658 D_fake: 0.973 \n",
            "(epoch: 113, iters: 1600, time: 0.191, data: 0.004) G_GAN: 2.104 G_L1: 2.620 D_real: 0.793 D_fake: 0.156 \n",
            "(epoch: 113, iters: 1700, time: 0.065, data: 0.003) G_GAN: 1.587 G_L1: 2.259 D_real: 0.188 D_fake: 0.423 \n",
            "(epoch: 113, iters: 1800, time: 0.066, data: 0.006) G_GAN: 2.222 G_L1: 1.566 D_real: 0.542 D_fake: 0.470 \n",
            "(epoch: 113, iters: 1900, time: 0.067, data: 0.003) G_GAN: 3.695 G_L1: 1.292 D_real: 0.299 D_fake: 0.051 \n",
            "(epoch: 113, iters: 2000, time: 0.546, data: 0.003) G_GAN: 6.527 G_L1: 1.063 D_real: 0.000 D_fake: 0.003 \n",
            "saving the latest model (epoch 113, total_iters 450000)\n",
            "(epoch: 113, iters: 2100, time: 0.065, data: 0.002) G_GAN: 3.206 G_L1: 2.179 D_real: 0.038 D_fake: 0.075 \n",
            "(epoch: 113, iters: 2200, time: 0.066, data: 0.004) G_GAN: 3.615 G_L1: 2.534 D_real: 0.126 D_fake: 0.023 \n",
            "(epoch: 113, iters: 2300, time: 0.066, data: 0.004) G_GAN: 1.334 G_L1: 1.796 D_real: 0.617 D_fake: 0.373 \n",
            "(epoch: 113, iters: 2400, time: 0.228, data: 0.005) G_GAN: 1.668 G_L1: 1.871 D_real: 0.881 D_fake: 0.052 \n",
            "(epoch: 113, iters: 2500, time: 0.066, data: 0.002) G_GAN: 9.312 G_L1: 0.710 D_real: 0.001 D_fake: 0.000 \n",
            "(epoch: 113, iters: 2600, time: 0.059, data: 0.002) G_GAN: 3.064 G_L1: 2.090 D_real: 0.036 D_fake: 0.075 \n",
            "(epoch: 113, iters: 2700, time: 0.066, data: 0.002) G_GAN: 2.458 G_L1: 3.018 D_real: 0.041 D_fake: 0.170 \n",
            "(epoch: 113, iters: 2800, time: 0.178, data: 0.002) G_GAN: 5.265 G_L1: 1.663 D_real: 0.481 D_fake: 0.008 \n",
            "(epoch: 113, iters: 2900, time: 0.066, data: 0.002) G_GAN: 1.634 G_L1: 2.051 D_real: 0.138 D_fake: 0.805 \n",
            "(epoch: 113, iters: 3000, time: 0.059, data: 0.005) G_GAN: 6.656 G_L1: 3.826 D_real: 0.340 D_fake: 0.002 \n",
            "(epoch: 113, iters: 3100, time: 0.066, data: 0.003) G_GAN: 2.642 G_L1: 1.033 D_real: 0.054 D_fake: 0.168 \n",
            "(epoch: 113, iters: 3200, time: 0.181, data: 0.004) G_GAN: 2.106 G_L1: 2.592 D_real: 0.567 D_fake: 0.835 \n",
            "(epoch: 113, iters: 3300, time: 0.064, data: 0.003) G_GAN: 7.475 G_L1: 1.129 D_real: 0.000 D_fake: 0.002 \n",
            "(epoch: 113, iters: 3400, time: 0.064, data: 0.003) G_GAN: 4.971 G_L1: 2.542 D_real: 0.790 D_fake: 0.008 \n",
            "(epoch: 113, iters: 3500, time: 0.067, data: 0.002) G_GAN: 1.995 G_L1: 2.522 D_real: 0.024 D_fake: 1.349 \n",
            "(epoch: 113, iters: 3600, time: 0.179, data: 0.002) G_GAN: 10.299 G_L1: 0.979 D_real: 0.000 D_fake: 0.000 \n",
            "(epoch: 113, iters: 3700, time: 0.066, data: 0.004) G_GAN: 3.378 G_L1: 2.984 D_real: 0.682 D_fake: 0.034 \n",
            "(epoch: 113, iters: 3800, time: 0.067, data: 0.003) G_GAN: 7.417 G_L1: 1.100 D_real: 0.002 D_fake: 0.002 \n",
            "(epoch: 113, iters: 3900, time: 0.064, data: 0.004) G_GAN: 2.312 G_L1: 2.009 D_real: 0.204 D_fake: 0.297 \n",
            "(epoch: 113, iters: 4000, time: 0.570, data: 0.004) G_GAN: 10.178 G_L1: 1.044 D_real: 0.001 D_fake: 0.000 \n",
            "End of epoch 113 / 200 \t Time Taken: 176 sec\n",
            "learning rate 0.0001723 -> 0.0001703\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "(epoch: 114, iters: 100, time: 0.067, data: 0.213) G_GAN: 7.465 G_L1: 0.667 D_real: 0.004 D_fake: 0.001 \n",
            "(epoch: 114, iters: 200, time: 0.066, data: 0.003) G_GAN: 2.838 G_L1: 4.598 D_real: 0.102 D_fake: 0.139 \n",
            "(epoch: 114, iters: 300, time: 0.060, data: 0.004) G_GAN: 3.185 G_L1: 1.132 D_real: 0.205 D_fake: 0.463 \n",
            "(epoch: 114, iters: 400, time: 0.887, data: 0.004) G_GAN: 9.512 G_L1: 1.355 D_real: 0.001 D_fake: 0.000 \n",
            "(epoch: 114, iters: 500, time: 0.065, data: 0.003) G_GAN: 2.835 G_L1: 2.514 D_real: 0.111 D_fake: 0.075 \n",
            "(epoch: 114, iters: 600, time: 0.066, data: 0.003) G_GAN: 3.834 G_L1: 1.517 D_real: 0.017 D_fake: 0.051 \n",
            "(epoch: 114, iters: 700, time: 0.065, data: 0.004) G_GAN: 9.050 G_L1: 1.068 D_real: 0.110 D_fake: 0.000 \n",
            "(epoch: 114, iters: 800, time: 0.166, data: 0.004) G_GAN: 5.991 G_L1: 0.754 D_real: 0.000 D_fake: 0.005 \n",
            "(epoch: 114, iters: 900, time: 0.065, data: 0.002) G_GAN: 7.802 G_L1: 0.827 D_real: 0.000 D_fake: 0.001 \n",
            "(epoch: 114, iters: 1000, time: 0.064, data: 0.004) G_GAN: 3.292 G_L1: 2.313 D_real: 0.423 D_fake: 0.028 \n",
            "(epoch: 114, iters: 1100, time: 0.067, data: 0.004) G_GAN: 4.038 G_L1: 2.220 D_real: 0.137 D_fake: 0.030 \n",
            "(epoch: 114, iters: 1200, time: 0.170, data: 0.003) G_GAN: 3.916 G_L1: 2.079 D_real: 0.087 D_fake: 0.029 \n",
            "(epoch: 114, iters: 1300, time: 0.066, data: 0.002) G_GAN: 1.867 G_L1: 3.105 D_real: 0.432 D_fake: 0.142 \n",
            "(epoch: 114, iters: 1400, time: 0.065, data: 0.004) G_GAN: 2.632 G_L1: 1.804 D_real: 0.114 D_fake: 0.178 \n",
            "(epoch: 114, iters: 1500, time: 0.065, data: 0.003) G_GAN: 6.887 G_L1: 0.881 D_real: 0.000 D_fake: 0.001 \n",
            "(epoch: 114, iters: 1600, time: 0.164, data: 0.005) G_GAN: 2.272 G_L1: 1.875 D_real: 0.291 D_fake: 1.201 \n",
            "(epoch: 114, iters: 1700, time: 0.067, data: 0.005) G_GAN: 4.290 G_L1: 3.115 D_real: 0.828 D_fake: 0.029 \n",
            "(epoch: 114, iters: 1800, time: 0.065, data: 0.003) G_GAN: 2.869 G_L1: 1.821 D_real: 1.386 D_fake: 0.018 \n",
            "(epoch: 114, iters: 1900, time: 0.067, data: 0.004) G_GAN: 2.224 G_L1: 2.508 D_real: 0.059 D_fake: 1.050 \n",
            "(epoch: 114, iters: 2000, time: 0.651, data: 0.003) G_GAN: 2.446 G_L1: 1.387 D_real: 0.013 D_fake: 0.291 \n",
            "(epoch: 114, iters: 2100, time: 0.066, data: 0.005) G_GAN: 7.972 G_L1: 2.791 D_real: 0.595 D_fake: 0.001 \n",
            "(epoch: 114, iters: 2200, time: 0.067, data: 0.004) G_GAN: 2.031 G_L1: 1.343 D_real: 0.180 D_fake: 0.644 \n",
            "(epoch: 114, iters: 2300, time: 0.066, data: 0.003) G_GAN: 1.172 G_L1: 1.315 D_real: 0.802 D_fake: 0.586 \n",
            "(epoch: 114, iters: 2400, time: 0.170, data: 0.006) G_GAN: 2.587 G_L1: 1.118 D_real: 0.473 D_fake: 0.593 \n",
            "(epoch: 114, iters: 2500, time: 0.066, data: 0.002) G_GAN: 3.610 G_L1: 0.997 D_real: 0.162 D_fake: 0.068 \n",
            "(epoch: 114, iters: 2600, time: 0.067, data: 0.003) G_GAN: 4.420 G_L1: 3.016 D_real: 0.052 D_fake: 0.020 \n",
            "(epoch: 114, iters: 2700, time: 0.067, data: 0.003) G_GAN: 1.204 G_L1: 1.574 D_real: 0.845 D_fake: 0.788 \n",
            "(epoch: 114, iters: 2800, time: 0.240, data: 0.003) G_GAN: 2.652 G_L1: 2.528 D_real: 0.090 D_fake: 0.198 \n",
            "(epoch: 114, iters: 2900, time: 0.066, data: 0.006) G_GAN: 3.520 G_L1: 1.165 D_real: 0.077 D_fake: 0.038 \n",
            "(epoch: 114, iters: 3000, time: 0.063, data: 0.007) G_GAN: 1.674 G_L1: 2.241 D_real: 0.035 D_fake: 0.803 \n",
            "saving the latest model (epoch 114, total_iters 455000)\n",
            "(epoch: 114, iters: 3100, time: 0.067, data: 0.002) G_GAN: 4.950 G_L1: 3.159 D_real: 0.009 D_fake: 0.014 \n",
            "(epoch: 114, iters: 3200, time: 0.221, data: 0.004) G_GAN: 5.395 G_L1: 3.980 D_real: 0.101 D_fake: 0.007 \n",
            "(epoch: 114, iters: 3300, time: 0.066, data: 0.003) G_GAN: 7.955 G_L1: 0.900 D_real: 0.000 D_fake: 0.001 \n",
            "(epoch: 114, iters: 3400, time: 0.066, data: 0.003) G_GAN: 4.464 G_L1: 2.287 D_real: 0.081 D_fake: 0.025 \n",
            "(epoch: 114, iters: 3500, time: 0.065, data: 0.004) G_GAN: 7.003 G_L1: 1.415 D_real: 0.000 D_fake: 0.002 \n",
            "(epoch: 114, iters: 3600, time: 0.170, data: 0.004) G_GAN: 6.662 G_L1: 1.663 D_real: 0.188 D_fake: 0.002 \n",
            "(epoch: 114, iters: 3700, time: 0.066, data: 0.007) G_GAN: 3.666 G_L1: 1.506 D_real: 0.330 D_fake: 0.050 \n",
            "(epoch: 114, iters: 3800, time: 0.066, data: 0.005) G_GAN: 3.981 G_L1: 6.290 D_real: 3.092 D_fake: 0.002 \n",
            "(epoch: 114, iters: 3900, time: 0.067, data: 0.003) G_GAN: 9.192 G_L1: 0.939 D_real: 0.000 D_fake: 0.001 \n",
            "(epoch: 114, iters: 4000, time: 0.534, data: 0.002) G_GAN: 2.065 G_L1: 2.196 D_real: 0.457 D_fake: 0.192 \n",
            "End of epoch 114 / 200 \t Time Taken: 176 sec\n",
            "learning rate 0.0001703 -> 0.0001683\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "(epoch: 115, iters: 100, time: 0.066, data: 0.219) G_GAN: 3.588 G_L1: 1.734 D_real: 0.000 D_fake: 0.156 \n",
            "(epoch: 115, iters: 200, time: 0.065, data: 0.002) G_GAN: 1.769 G_L1: 1.900 D_real: 0.146 D_fake: 0.758 \n",
            "(epoch: 115, iters: 300, time: 0.066, data: 0.003) G_GAN: 7.045 G_L1: 1.033 D_real: 0.006 D_fake: 0.002 \n",
            "(epoch: 115, iters: 400, time: 1.012, data: 0.003) G_GAN: 2.174 G_L1: 2.255 D_real: 0.126 D_fake: 0.284 \n",
            "(epoch: 115, iters: 500, time: 0.064, data: 0.003) G_GAN: 2.930 G_L1: 2.631 D_real: 0.238 D_fake: 0.031 \n",
            "(epoch: 115, iters: 600, time: 0.064, data: 0.004) G_GAN: 2.528 G_L1: 1.311 D_real: 0.176 D_fake: 0.233 \n",
            "(epoch: 115, iters: 700, time: 0.067, data: 0.003) G_GAN: 1.599 G_L1: 1.337 D_real: 0.233 D_fake: 0.964 \n",
            "(epoch: 115, iters: 800, time: 0.174, data: 0.003) G_GAN: 1.434 G_L1: 2.367 D_real: 0.673 D_fake: 0.352 \n",
            "(epoch: 115, iters: 900, time: 0.065, data: 0.008) G_GAN: 1.377 G_L1: 1.510 D_real: 0.555 D_fake: 0.302 \n",
            "(epoch: 115, iters: 1000, time: 0.066, data: 0.004) G_GAN: 6.023 G_L1: 1.945 D_real: 0.066 D_fake: 0.004 \n",
            "(epoch: 115, iters: 1100, time: 0.066, data: 0.004) G_GAN: 1.980 G_L1: 2.254 D_real: 0.249 D_fake: 0.198 \n",
            "(epoch: 115, iters: 1200, time: 0.160, data: 0.004) G_GAN: 9.177 G_L1: 0.946 D_real: 0.001 D_fake: 0.000 \n",
            "(epoch: 115, iters: 1300, time: 0.066, data: 0.007) G_GAN: 2.040 G_L1: 2.016 D_real: 0.186 D_fake: 0.433 \n",
            "(epoch: 115, iters: 1400, time: 0.066, data: 0.004) G_GAN: 1.920 G_L1: 1.735 D_real: 0.498 D_fake: 0.172 \n",
            "(epoch: 115, iters: 1500, time: 0.065, data: 0.003) G_GAN: 3.261 G_L1: 1.695 D_real: 0.048 D_fake: 0.407 \n",
            "(epoch: 115, iters: 1600, time: 0.178, data: 0.003) G_GAN: 2.687 G_L1: 2.877 D_real: 1.347 D_fake: 0.396 \n",
            "(epoch: 115, iters: 1700, time: 0.065, data: 0.007) G_GAN: 4.757 G_L1: 2.432 D_real: 0.080 D_fake: 0.017 \n",
            "(epoch: 115, iters: 1800, time: 0.066, data: 0.003) G_GAN: 4.891 G_L1: 1.936 D_real: 0.037 D_fake: 0.009 \n",
            "(epoch: 115, iters: 1900, time: 0.062, data: 0.002) G_GAN: 1.143 G_L1: 1.456 D_real: 1.013 D_fake: 0.405 \n",
            "(epoch: 115, iters: 2000, time: 0.528, data: 0.004) G_GAN: 9.004 G_L1: 0.764 D_real: 0.000 D_fake: 0.001 \n",
            "(epoch: 115, iters: 2100, time: 0.066, data: 0.003) G_GAN: 2.738 G_L1: 2.490 D_real: 0.112 D_fake: 0.220 \n",
            "(epoch: 115, iters: 2200, time: 0.065, data: 0.003) G_GAN: 7.850 G_L1: 0.650 D_real: 0.002 D_fake: 0.001 \n",
            "(epoch: 115, iters: 2300, time: 0.067, data: 0.004) G_GAN: 2.032 G_L1: 1.855 D_real: 1.758 D_fake: 0.420 \n",
            "(epoch: 115, iters: 2400, time: 0.217, data: 0.003) G_GAN: 1.931 G_L1: 2.064 D_real: 0.162 D_fake: 0.291 \n",
            "(epoch: 115, iters: 2500, time: 0.066, data: 0.005) G_GAN: 4.505 G_L1: 1.691 D_real: 0.223 D_fake: 0.039 \n",
            "(epoch: 115, iters: 2600, time: 0.065, data: 0.004) G_GAN: 1.312 G_L1: 1.727 D_real: 0.097 D_fake: 1.314 \n",
            "(epoch: 115, iters: 2700, time: 0.065, data: 0.004) G_GAN: 5.632 G_L1: 1.425 D_real: 0.000 D_fake: 0.009 \n",
            "(epoch: 115, iters: 2800, time: 0.236, data: 0.003) G_GAN: 6.123 G_L1: 3.364 D_real: 0.015 D_fake: 0.004 \n",
            "(epoch: 115, iters: 2900, time: 0.066, data: 0.009) G_GAN: 1.327 G_L1: 1.003 D_real: 0.364 D_fake: 0.429 \n",
            "(epoch: 115, iters: 3000, time: 0.066, data: 0.008) G_GAN: 5.041 G_L1: 1.077 D_real: 0.000 D_fake: 0.017 \n",
            "(epoch: 115, iters: 3100, time: 0.062, data: 0.005) G_GAN: 2.830 G_L1: 2.713 D_real: 0.125 D_fake: 0.108 \n",
            "(epoch: 115, iters: 3200, time: 0.299, data: 0.003) G_GAN: 8.372 G_L1: 1.049 D_real: 0.000 D_fake: 0.001 \n",
            "(epoch: 115, iters: 3300, time: 0.066, data: 0.002) G_GAN: 3.513 G_L1: 1.363 D_real: 0.202 D_fake: 0.094 \n",
            "(epoch: 115, iters: 3400, time: 0.064, data: 0.003) G_GAN: 8.071 G_L1: 2.136 D_real: 0.216 D_fake: 0.001 \n",
            "(epoch: 115, iters: 3500, time: 0.067, data: 0.004) G_GAN: 3.241 G_L1: 1.753 D_real: 1.286 D_fake: 0.037 \n",
            "(epoch: 115, iters: 3600, time: 0.171, data: 0.002) G_GAN: 1.361 G_L1: 1.245 D_real: 1.108 D_fake: 0.319 \n",
            "(epoch: 115, iters: 3700, time: 0.065, data: 0.003) G_GAN: 3.032 G_L1: 2.179 D_real: 0.010 D_fake: 1.928 \n",
            "(epoch: 115, iters: 3800, time: 0.066, data: 0.007) G_GAN: 10.107 G_L1: 1.082 D_real: 0.000 D_fake: 0.000 \n",
            "(epoch: 115, iters: 3900, time: 0.063, data: 0.002) G_GAN: 1.270 G_L1: 1.827 D_real: 0.512 D_fake: 0.695 \n",
            "(epoch: 115, iters: 4000, time: 0.533, data: 0.004) G_GAN: 2.578 G_L1: 1.312 D_real: 0.103 D_fake: 0.415 \n",
            "saving the latest model (epoch 115, total_iters 460000)\n",
            "saving the model at the end of epoch 115, iters 460000\n",
            "End of epoch 115 / 200 \t Time Taken: 178 sec\n",
            "learning rate 0.0001683 -> 0.0001663\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "(epoch: 116, iters: 100, time: 0.065, data: 0.217) G_GAN: 5.653 G_L1: 0.849 D_real: 0.001 D_fake: 0.007 \n",
            "(epoch: 116, iters: 200, time: 0.065, data: 0.003) G_GAN: 2.811 G_L1: 3.214 D_real: 0.025 D_fake: 0.234 \n",
            "(epoch: 116, iters: 300, time: 0.067, data: 0.004) G_GAN: 0.841 G_L1: 2.195 D_real: 1.151 D_fake: 0.065 \n",
            "(epoch: 116, iters: 400, time: 0.727, data: 0.004) G_GAN: 2.886 G_L1: 2.463 D_real: 0.094 D_fake: 0.819 \n",
            "(epoch: 116, iters: 500, time: 0.065, data: 0.005) G_GAN: 2.546 G_L1: 2.371 D_real: 0.158 D_fake: 0.197 \n",
            "(epoch: 116, iters: 600, time: 0.066, data: 0.004) G_GAN: 6.097 G_L1: 1.871 D_real: 0.015 D_fake: 0.007 \n",
            "(epoch: 116, iters: 700, time: 0.066, data: 0.004) G_GAN: 8.894 G_L1: 1.137 D_real: 0.169 D_fake: 0.000 \n",
            "(epoch: 116, iters: 800, time: 0.222, data: 0.007) G_GAN: 4.846 G_L1: 3.265 D_real: 0.143 D_fake: 0.022 \n",
            "(epoch: 116, iters: 900, time: 0.065, data: 0.003) G_GAN: 5.418 G_L1: 1.551 D_real: 0.010 D_fake: 2.472 \n",
            "(epoch: 116, iters: 1000, time: 0.066, data: 0.004) G_GAN: 2.802 G_L1: 1.853 D_real: 0.242 D_fake: 0.072 \n",
            "(epoch: 116, iters: 1100, time: 0.066, data: 0.003) G_GAN: 1.467 G_L1: 2.039 D_real: 0.355 D_fake: 0.321 \n",
            "(epoch: 116, iters: 1200, time: 0.178, data: 0.003) G_GAN: 1.427 G_L1: 2.451 D_real: 0.667 D_fake: 1.007 \n",
            "(epoch: 116, iters: 1300, time: 0.066, data: 0.002) G_GAN: 0.341 G_L1: 1.552 D_real: 1.866 D_fake: 0.045 \n",
            "(epoch: 116, iters: 1400, time: 0.065, data: 0.004) G_GAN: 3.232 G_L1: 1.245 D_real: 0.050 D_fake: 0.086 \n",
            "(epoch: 116, iters: 1500, time: 0.064, data: 0.004) G_GAN: 7.460 G_L1: 1.990 D_real: 0.046 D_fake: 0.001 \n",
            "(epoch: 116, iters: 1600, time: 0.217, data: 0.004) G_GAN: 2.344 G_L1: 1.886 D_real: 0.252 D_fake: 0.116 \n",
            "(epoch: 116, iters: 1700, time: 0.066, data: 0.003) G_GAN: 10.716 G_L1: 1.166 D_real: 0.007 D_fake: 0.000 \n",
            "(epoch: 116, iters: 1800, time: 0.067, data: 0.003) G_GAN: 4.777 G_L1: 0.959 D_real: 0.000 D_fake: 0.019 \n",
            "(epoch: 116, iters: 1900, time: 0.066, data: 0.004) G_GAN: 2.075 G_L1: 1.137 D_real: 0.036 D_fake: 1.131 \n",
            "(epoch: 116, iters: 2000, time: 0.555, data: 0.004) G_GAN: 2.767 G_L1: 3.414 D_real: 0.291 D_fake: 0.114 \n",
            "(epoch: 116, iters: 2100, time: 0.067, data: 0.003) G_GAN: 2.093 G_L1: 2.241 D_real: 0.508 D_fake: 0.062 \n",
            "(epoch: 116, iters: 2200, time: 0.065, data: 0.003) G_GAN: 5.862 G_L1: 3.195 D_real: 0.015 D_fake: 0.004 \n",
            "(epoch: 116, iters: 2300, time: 0.065, data: 0.006) G_GAN: 2.635 G_L1: 2.527 D_real: 0.083 D_fake: 0.150 \n",
            "(epoch: 116, iters: 2400, time: 0.187, data: 0.004) G_GAN: 2.745 G_L1: 1.387 D_real: 0.625 D_fake: 0.016 \n",
            "(epoch: 116, iters: 2500, time: 0.067, data: 0.003) G_GAN: 2.971 G_L1: 2.663 D_real: 0.026 D_fake: 0.218 \n",
            "(epoch: 116, iters: 2600, time: 0.065, data: 0.003) G_GAN: 3.357 G_L1: 1.664 D_real: 0.007 D_fake: 3.219 \n",
            "(epoch: 116, iters: 2700, time: 0.065, data: 0.004) G_GAN: 2.605 G_L1: 1.814 D_real: 0.350 D_fake: 0.298 \n",
            "(epoch: 116, iters: 2800, time: 0.215, data: 0.004) G_GAN: 3.885 G_L1: 2.532 D_real: 6.135 D_fake: 0.004 \n",
            "(epoch: 116, iters: 2900, time: 0.066, data: 0.006) G_GAN: 2.023 G_L1: 2.268 D_real: 0.235 D_fake: 0.760 \n",
            "(epoch: 116, iters: 3000, time: 0.059, data: 0.003) G_GAN: 2.302 G_L1: 3.477 D_real: 0.324 D_fake: 0.292 \n",
            "(epoch: 116, iters: 3100, time: 0.064, data: 0.005) G_GAN: 7.449 G_L1: 0.971 D_real: 0.000 D_fake: 0.002 \n",
            "(epoch: 116, iters: 3200, time: 0.173, data: 0.004) G_GAN: 4.736 G_L1: 1.693 D_real: 0.257 D_fake: 0.013 \n",
            "(epoch: 116, iters: 3300, time: 0.066, data: 0.005) G_GAN: 1.487 G_L1: 1.829 D_real: 0.204 D_fake: 0.583 \n",
            "(epoch: 116, iters: 3400, time: 0.066, data: 0.004) G_GAN: 3.089 G_L1: 2.112 D_real: 0.041 D_fake: 0.093 \n",
            "(epoch: 116, iters: 3500, time: 0.063, data: 0.003) G_GAN: 7.340 G_L1: 1.033 D_real: 0.120 D_fake: 0.001 \n",
            "(epoch: 116, iters: 3600, time: 0.171, data: 0.004) G_GAN: 7.041 G_L1: 0.673 D_real: 0.000 D_fake: 0.002 \n",
            "(epoch: 116, iters: 3700, time: 0.066, data: 0.002) G_GAN: 2.888 G_L1: 1.729 D_real: 0.033 D_fake: 0.159 \n",
            "(epoch: 116, iters: 3800, time: 0.066, data: 0.003) G_GAN: 2.985 G_L1: 2.172 D_real: 0.602 D_fake: 0.026 \n",
            "(epoch: 116, iters: 3900, time: 0.066, data: 0.003) G_GAN: 12.659 G_L1: 0.981 D_real: 0.001 D_fake: 0.000 \n",
            "(epoch: 116, iters: 4000, time: 0.735, data: 0.003) G_GAN: 1.516 G_L1: 1.703 D_real: 0.536 D_fake: 0.284 \n",
            "End of epoch 116 / 200 \t Time Taken: 175 sec\n",
            "learning rate 0.0001663 -> 0.0001644\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "(epoch: 117, iters: 100, time: 0.066, data: 0.186) G_GAN: 3.719 G_L1: 1.961 D_real: 0.313 D_fake: 0.012 \n",
            "(epoch: 117, iters: 200, time: 0.066, data: 0.004) G_GAN: 0.876 G_L1: 0.634 D_real: 0.000 D_fake: 0.987 \n",
            "(epoch: 117, iters: 300, time: 0.066, data: 0.004) G_GAN: 2.417 G_L1: 1.535 D_real: 0.210 D_fake: 0.862 \n",
            "(epoch: 117, iters: 400, time: 0.673, data: 0.004) G_GAN: 6.255 G_L1: 1.954 D_real: 0.200 D_fake: 0.004 \n",
            "(epoch: 117, iters: 500, time: 0.066, data: 0.005) G_GAN: 3.200 G_L1: 1.928 D_real: 0.038 D_fake: 0.092 \n",
            "(epoch: 117, iters: 600, time: 0.064, data: 0.003) G_GAN: 6.684 G_L1: 1.821 D_real: 0.003 D_fake: 0.004 \n",
            "(epoch: 117, iters: 700, time: 0.066, data: 0.003) G_GAN: 1.816 G_L1: 1.811 D_real: 0.381 D_fake: 0.186 \n",
            "(epoch: 117, iters: 800, time: 0.195, data: 0.003) G_GAN: 3.248 G_L1: 1.693 D_real: 0.675 D_fake: 0.027 \n",
            "(epoch: 117, iters: 900, time: 0.064, data: 0.011) G_GAN: 9.595 G_L1: 1.566 D_real: 0.002 D_fake: 0.000 \n",
            "(epoch: 117, iters: 1000, time: 0.065, data: 0.004) G_GAN: 0.604 G_L1: 1.118 D_real: 0.258 D_fake: 1.375 \n",
            "saving the latest model (epoch 117, total_iters 465000)\n",
            "(epoch: 117, iters: 1100, time: 0.066, data: 0.002) G_GAN: 2.567 G_L1: 1.578 D_real: 0.530 D_fake: 0.106 \n",
            "(epoch: 117, iters: 1200, time: 0.168, data: 0.002) G_GAN: 2.547 G_L1: 1.520 D_real: 0.074 D_fake: 0.929 \n",
            "(epoch: 117, iters: 1300, time: 0.066, data: 0.011) G_GAN: 2.955 G_L1: 1.588 D_real: 0.041 D_fake: 0.196 \n",
            "(epoch: 117, iters: 1400, time: 0.066, data: 0.004) G_GAN: 1.478 G_L1: 1.788 D_real: 0.758 D_fake: 0.122 \n",
            "(epoch: 117, iters: 1500, time: 0.066, data: 0.003) G_GAN: 3.488 G_L1: 2.394 D_real: 0.077 D_fake: 0.052 \n",
            "(epoch: 117, iters: 1600, time: 0.216, data: 0.003) G_GAN: 1.439 G_L1: 1.698 D_real: 0.184 D_fake: 0.879 \n",
            "(epoch: 117, iters: 1700, time: 0.067, data: 0.002) G_GAN: 1.290 G_L1: 0.918 D_real: 0.531 D_fake: 0.334 \n",
            "(epoch: 117, iters: 1800, time: 0.067, data: 0.004) G_GAN: 1.186 G_L1: 2.290 D_real: 0.744 D_fake: 0.296 \n",
            "(epoch: 117, iters: 1900, time: 0.066, data: 0.003) G_GAN: 2.526 G_L1: 1.924 D_real: 0.093 D_fake: 0.356 \n",
            "(epoch: 117, iters: 2000, time: 0.572, data: 0.004) G_GAN: 2.448 G_L1: 1.616 D_real: 0.300 D_fake: 0.147 \n",
            "(epoch: 117, iters: 2100, time: 0.067, data: 0.003) G_GAN: 6.440 G_L1: 0.897 D_real: 0.000 D_fake: 0.003 \n",
            "(epoch: 117, iters: 2200, time: 0.066, data: 0.010) G_GAN: 2.356 G_L1: 2.527 D_real: 0.162 D_fake: 0.373 \n",
            "(epoch: 117, iters: 2300, time: 0.062, data: 0.004) G_GAN: 6.126 G_L1: 0.657 D_real: 0.000 D_fake: 0.006 \n",
            "(epoch: 117, iters: 2400, time: 0.247, data: 0.005) G_GAN: 4.142 G_L1: 3.575 D_real: 0.009 D_fake: 0.905 \n",
            "(epoch: 117, iters: 2500, time: 0.066, data: 0.002) G_GAN: 6.622 G_L1: 1.336 D_real: 0.169 D_fake: 0.002 \n",
            "(epoch: 117, iters: 2600, time: 0.064, data: 0.004) G_GAN: 3.096 G_L1: 2.141 D_real: 0.080 D_fake: 0.074 \n",
            "(epoch: 117, iters: 2700, time: 0.066, data: 0.004) G_GAN: 2.956 G_L1: 2.361 D_real: 0.031 D_fake: 0.126 \n",
            "(epoch: 117, iters: 2800, time: 0.217, data: 0.003) G_GAN: 1.872 G_L1: 1.732 D_real: 0.549 D_fake: 0.383 \n",
            "(epoch: 117, iters: 2900, time: 0.065, data: 0.010) G_GAN: 1.802 G_L1: 2.802 D_real: 0.503 D_fake: 0.269 \n",
            "(epoch: 117, iters: 3000, time: 0.067, data: 0.003) G_GAN: 1.495 G_L1: 1.155 D_real: 0.436 D_fake: 0.306 \n",
            "(epoch: 117, iters: 3100, time: 0.064, data: 0.003) G_GAN: 10.198 G_L1: 1.605 D_real: 0.004 D_fake: 0.000 \n",
            "(epoch: 117, iters: 3200, time: 0.162, data: 0.004) G_GAN: 5.010 G_L1: 0.777 D_real: 0.001 D_fake: 0.017 \n",
            "(epoch: 117, iters: 3300, time: 0.066, data: 0.002) G_GAN: 3.134 G_L1: 2.299 D_real: 0.031 D_fake: 1.490 \n",
            "(epoch: 117, iters: 3400, time: 0.066, data: 0.004) G_GAN: 5.078 G_L1: 1.070 D_real: 0.000 D_fake: 0.026 \n",
            "(epoch: 117, iters: 3500, time: 0.066, data: 0.003) G_GAN: 8.355 G_L1: 2.091 D_real: 0.000 D_fake: 0.001 \n",
            "(epoch: 117, iters: 3600, time: 0.182, data: 0.004) G_GAN: 3.972 G_L1: 1.941 D_real: 0.002 D_fake: 0.046 \n",
            "(epoch: 117, iters: 3700, time: 0.066, data: 0.003) G_GAN: 2.037 G_L1: 0.979 D_real: 0.157 D_fake: 0.773 \n",
            "(epoch: 117, iters: 3800, time: 0.065, data: 0.004) G_GAN: 1.636 G_L1: 1.866 D_real: 0.050 D_fake: 2.077 \n",
            "(epoch: 117, iters: 3900, time: 0.066, data: 0.003) G_GAN: 2.273 G_L1: 2.196 D_real: 0.148 D_fake: 0.346 \n",
            "(epoch: 117, iters: 4000, time: 0.560, data: 0.003) G_GAN: 2.256 G_L1: 1.563 D_real: 0.150 D_fake: 1.342 \n",
            "End of epoch 117 / 200 \t Time Taken: 177 sec\n",
            "learning rate 0.0001644 -> 0.0001624\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "(epoch: 118, iters: 100, time: 0.066, data: 0.175) G_GAN: 3.354 G_L1: 2.533 D_real: 0.047 D_fake: 0.058 \n",
            "(epoch: 118, iters: 200, time: 0.065, data: 0.005) G_GAN: 3.273 G_L1: 1.928 D_real: 0.601 D_fake: 0.055 \n",
            "(epoch: 118, iters: 300, time: 0.061, data: 0.003) G_GAN: 9.518 G_L1: 0.863 D_real: 0.000 D_fake: 0.000 \n",
            "(epoch: 118, iters: 400, time: 0.778, data: 0.004) G_GAN: 2.645 G_L1: 2.843 D_real: 0.176 D_fake: 0.596 \n",
            "(epoch: 118, iters: 500, time: 0.066, data: 0.004) G_GAN: 2.880 G_L1: 1.883 D_real: 0.132 D_fake: 0.383 \n",
            "(epoch: 118, iters: 600, time: 0.067, data: 0.003) G_GAN: 3.277 G_L1: 1.367 D_real: 0.144 D_fake: 1.064 \n",
            "(epoch: 118, iters: 700, time: 0.066, data: 0.004) G_GAN: 7.323 G_L1: 1.263 D_real: 0.000 D_fake: 0.001 \n",
            "(epoch: 118, iters: 800, time: 0.172, data: 0.003) G_GAN: 7.951 G_L1: 0.868 D_real: 0.001 D_fake: 0.001 \n",
            "(epoch: 118, iters: 900, time: 0.063, data: 0.002) G_GAN: 1.350 G_L1: 1.837 D_real: 0.731 D_fake: 0.198 \n",
            "(epoch: 118, iters: 1000, time: 0.066, data: 0.004) G_GAN: 3.253 G_L1: 3.806 D_real: 0.058 D_fake: 0.080 \n",
            "(epoch: 118, iters: 1100, time: 0.066, data: 0.004) G_GAN: 6.895 G_L1: 2.009 D_real: 0.044 D_fake: 0.002 \n",
            "(epoch: 118, iters: 1200, time: 0.222, data: 0.011) G_GAN: 2.814 G_L1: 2.453 D_real: 0.074 D_fake: 0.088 \n",
            "(epoch: 118, iters: 1300, time: 0.066, data: 0.012) G_GAN: 4.177 G_L1: 1.927 D_real: 0.234 D_fake: 0.019 \n",
            "(epoch: 118, iters: 1400, time: 0.066, data: 0.003) G_GAN: 2.837 G_L1: 3.093 D_real: 0.063 D_fake: 0.227 \n",
            "(epoch: 118, iters: 1500, time: 0.067, data: 0.005) G_GAN: 8.799 G_L1: 1.129 D_real: 0.040 D_fake: 0.000 \n",
            "(epoch: 118, iters: 1600, time: 0.175, data: 0.005) G_GAN: 5.550 G_L1: 2.214 D_real: 0.376 D_fake: 0.007 \n",
            "(epoch: 118, iters: 1700, time: 0.064, data: 0.003) G_GAN: 1.933 G_L1: 1.704 D_real: 0.204 D_fake: 0.250 \n",
            "(epoch: 118, iters: 1800, time: 0.063, data: 0.004) G_GAN: 2.601 G_L1: 2.775 D_real: 0.312 D_fake: 0.107 \n",
            "(epoch: 118, iters: 1900, time: 0.065, data: 0.004) G_GAN: 3.445 G_L1: 1.460 D_real: 0.044 D_fake: 0.858 \n",
            "(epoch: 118, iters: 2000, time: 0.548, data: 0.003) G_GAN: 8.096 G_L1: 1.742 D_real: 0.175 D_fake: 0.000 \n",
            "saving the latest model (epoch 118, total_iters 470000)\n",
            "(epoch: 118, iters: 2100, time: 0.061, data: 0.005) G_GAN: 3.036 G_L1: 10.653 D_real: 1.455 D_fake: 0.062 \n",
            "(epoch: 118, iters: 2200, time: 0.065, data: 0.004) G_GAN: 1.742 G_L1: 1.436 D_real: 0.225 D_fake: 0.655 \n",
            "(epoch: 118, iters: 2300, time: 0.062, data: 0.004) G_GAN: 10.029 G_L1: 0.662 D_real: 0.006 D_fake: 0.000 \n",
            "(epoch: 118, iters: 2400, time: 0.172, data: 0.003) G_GAN: 2.135 G_L1: 2.417 D_real: 0.320 D_fake: 0.680 \n",
            "(epoch: 118, iters: 2500, time: 0.066, data: 0.003) G_GAN: 3.723 G_L1: 1.771 D_real: 0.202 D_fake: 0.482 \n",
            "(epoch: 118, iters: 2600, time: 0.066, data: 0.004) G_GAN: 2.598 G_L1: 1.701 D_real: 0.366 D_fake: 0.073 \n",
            "(epoch: 118, iters: 2700, time: 0.066, data: 0.004) G_GAN: 5.029 G_L1: 2.779 D_real: 0.116 D_fake: 0.016 \n",
            "(epoch: 118, iters: 2800, time: 0.221, data: 0.003) G_GAN: 2.043 G_L1: 1.813 D_real: 0.292 D_fake: 0.178 \n",
            "(epoch: 118, iters: 2900, time: 0.067, data: 0.008) G_GAN: 4.561 G_L1: 1.853 D_real: 0.031 D_fake: 0.022 \n",
            "(epoch: 118, iters: 3000, time: 0.067, data: 0.003) G_GAN: 3.833 G_L1: 1.289 D_real: 0.101 D_fake: 0.407 \n",
            "(epoch: 118, iters: 3100, time: 0.066, data: 0.004) G_GAN: 12.551 G_L1: 0.826 D_real: 0.005 D_fake: 0.000 \n",
            "(epoch: 118, iters: 3200, time: 0.176, data: 0.004) G_GAN: 6.406 G_L1: 2.212 D_real: 0.037 D_fake: 0.003 \n",
            "(epoch: 118, iters: 3300, time: 0.066, data: 0.009) G_GAN: 5.466 G_L1: 0.835 D_real: 0.000 D_fake: 0.012 \n",
            "(epoch: 118, iters: 3400, time: 0.065, data: 0.002) G_GAN: 8.191 G_L1: 0.900 D_real: 0.000 D_fake: 0.001 \n",
            "(epoch: 118, iters: 3500, time: 0.066, data: 0.004) G_GAN: 3.273 G_L1: 4.081 D_real: 0.015 D_fake: 0.308 \n",
            "(epoch: 118, iters: 3600, time: 0.229, data: 0.004) G_GAN: 2.689 G_L1: 2.436 D_real: 0.034 D_fake: 0.297 \n",
            "(epoch: 118, iters: 3700, time: 0.063, data: 0.002) G_GAN: 4.549 G_L1: 1.252 D_real: 0.007 D_fake: 0.009 \n",
            "(epoch: 118, iters: 3800, time: 0.066, data: 0.010) G_GAN: 1.621 G_L1: 5.005 D_real: 0.653 D_fake: 0.215 \n",
            "(epoch: 118, iters: 3900, time: 0.066, data: 0.003) G_GAN: 4.688 G_L1: 1.296 D_real: 0.019 D_fake: 0.560 \n",
            "(epoch: 118, iters: 4000, time: 0.536, data: 0.005) G_GAN: 11.173 G_L1: 0.752 D_real: 0.002 D_fake: 0.000 \n",
            "End of epoch 118 / 200 \t Time Taken: 177 sec\n",
            "learning rate 0.0001624 -> 0.0001604\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "(epoch: 119, iters: 100, time: 0.065, data: 0.211) G_GAN: 1.126 G_L1: 1.218 D_real: 0.617 D_fake: 0.227 \n",
            "(epoch: 119, iters: 200, time: 0.066, data: 0.007) G_GAN: 4.868 G_L1: 1.157 D_real: 0.111 D_fake: 0.016 \n",
            "(epoch: 119, iters: 300, time: 0.066, data: 0.003) G_GAN: 2.416 G_L1: 2.084 D_real: 0.091 D_fake: 0.357 \n",
            "(epoch: 119, iters: 400, time: 0.768, data: 0.003) G_GAN: 4.698 G_L1: 1.270 D_real: 0.072 D_fake: 0.818 \n",
            "(epoch: 119, iters: 500, time: 0.066, data: 0.009) G_GAN: 8.598 G_L1: 0.804 D_real: 0.000 D_fake: 0.000 \n",
            "(epoch: 119, iters: 600, time: 0.064, data: 0.006) G_GAN: 2.769 G_L1: 2.962 D_real: 0.406 D_fake: 0.162 \n",
            "(epoch: 119, iters: 700, time: 0.066, data: 0.004) G_GAN: 2.411 G_L1: 1.869 D_real: 0.078 D_fake: 0.282 \n",
            "(epoch: 119, iters: 800, time: 0.169, data: 0.004) G_GAN: 1.995 G_L1: 1.821 D_real: 0.173 D_fake: 0.485 \n",
            "(epoch: 119, iters: 900, time: 0.066, data: 0.006) G_GAN: 5.268 G_L1: 1.506 D_real: 0.000 D_fake: 0.012 \n",
            "(epoch: 119, iters: 1000, time: 0.065, data: 0.004) G_GAN: 2.810 G_L1: 1.287 D_real: 0.651 D_fake: 0.059 \n",
            "(epoch: 119, iters: 1100, time: 0.055, data: 0.006) G_GAN: 10.206 G_L1: 2.541 D_real: 0.000 D_fake: 0.000 \n",
            "(epoch: 119, iters: 1200, time: 0.218, data: 0.004) G_GAN: 2.870 G_L1: 1.912 D_real: 0.031 D_fake: 0.884 \n",
            "(epoch: 119, iters: 1300, time: 0.066, data: 0.010) G_GAN: 3.557 G_L1: 2.191 D_real: 0.010 D_fake: 0.701 \n",
            "(epoch: 119, iters: 1400, time: 0.066, data: 0.005) G_GAN: 3.632 G_L1: 1.950 D_real: 0.074 D_fake: 0.460 \n",
            "(epoch: 119, iters: 1500, time: 0.066, data: 0.003) G_GAN: 2.415 G_L1: 2.017 D_real: 0.091 D_fake: 0.448 \n",
            "(epoch: 119, iters: 1600, time: 0.185, data: 0.006) G_GAN: 8.055 G_L1: 3.985 D_real: 0.166 D_fake: 0.001 \n",
            "(epoch: 119, iters: 1700, time: 0.066, data: 0.003) G_GAN: 4.428 G_L1: 0.937 D_real: 0.002 D_fake: 0.176 \n",
            "(epoch: 119, iters: 1800, time: 0.062, data: 0.003) G_GAN: 4.800 G_L1: 1.145 D_real: 0.007 D_fake: 0.014 \n",
            "(epoch: 119, iters: 1900, time: 0.063, data: 0.006) G_GAN: 3.126 G_L1: 3.528 D_real: 0.207 D_fake: 0.047 \n",
            "(epoch: 119, iters: 2000, time: 0.621, data: 0.004) G_GAN: 3.828 G_L1: 1.969 D_real: 0.035 D_fake: 0.053 \n",
            "(epoch: 119, iters: 2100, time: 0.066, data: 0.003) G_GAN: 2.870 G_L1: 2.178 D_real: 0.164 D_fake: 1.305 \n",
            "(epoch: 119, iters: 2200, time: 0.065, data: 0.003) G_GAN: 8.291 G_L1: 2.418 D_real: 0.001 D_fake: 0.001 \n",
            "(epoch: 119, iters: 2300, time: 0.066, data: 0.002) G_GAN: 2.776 G_L1: 1.794 D_real: 0.363 D_fake: 0.036 \n",
            "(epoch: 119, iters: 2400, time: 0.229, data: 0.004) G_GAN: 3.159 G_L1: 1.786 D_real: 0.005 D_fake: 0.468 \n",
            "(epoch: 119, iters: 2500, time: 0.066, data: 0.003) G_GAN: 6.376 G_L1: 1.084 D_real: 0.202 D_fake: 0.002 \n",
            "(epoch: 119, iters: 2600, time: 0.066, data: 0.003) G_GAN: 1.118 G_L1: 2.644 D_real: 0.919 D_fake: 0.857 \n",
            "(epoch: 119, iters: 2700, time: 0.066, data: 0.003) G_GAN: 2.397 G_L1: 2.048 D_real: 0.110 D_fake: 0.539 \n",
            "(epoch: 119, iters: 2800, time: 0.163, data: 0.003) G_GAN: 7.147 G_L1: 0.654 D_real: 0.012 D_fake: 0.004 \n",
            "(epoch: 119, iters: 2900, time: 0.063, data: 0.005) G_GAN: 7.247 G_L1: 2.154 D_real: 0.011 D_fake: 0.002 \n",
            "(epoch: 119, iters: 3000, time: 0.064, data: 0.004) G_GAN: 3.392 G_L1: 1.173 D_real: 0.185 D_fake: 0.048 \n",
            "saving the latest model (epoch 119, total_iters 475000)\n",
            "(epoch: 119, iters: 3100, time: 0.066, data: 0.004) G_GAN: 1.662 G_L1: 1.128 D_real: 0.525 D_fake: 0.142 \n",
            "(epoch: 119, iters: 3200, time: 0.181, data: 0.006) G_GAN: 3.384 G_L1: 2.419 D_real: 0.150 D_fake: 1.093 \n",
            "(epoch: 119, iters: 3300, time: 0.066, data: 0.003) G_GAN: 2.378 G_L1: 1.872 D_real: 0.200 D_fake: 0.361 \n",
            "(epoch: 119, iters: 3400, time: 0.066, data: 0.003) G_GAN: 1.936 G_L1: 1.349 D_real: 0.222 D_fake: 0.829 \n",
            "(epoch: 119, iters: 3500, time: 0.064, data: 0.003) G_GAN: 1.156 G_L1: 1.781 D_real: 0.567 D_fake: 0.084 \n",
            "(epoch: 119, iters: 3600, time: 0.171, data: 0.003) G_GAN: 2.609 G_L1: 2.064 D_real: 0.253 D_fake: 0.511 \n",
            "(epoch: 119, iters: 3700, time: 0.065, data: 0.003) G_GAN: 5.133 G_L1: 2.016 D_real: 0.303 D_fake: 0.007 \n",
            "(epoch: 119, iters: 3800, time: 0.066, data: 0.004) G_GAN: 3.815 G_L1: 1.894 D_real: 0.063 D_fake: 0.052 \n",
            "(epoch: 119, iters: 3900, time: 0.065, data: 0.007) G_GAN: 11.247 G_L1: 1.040 D_real: 0.000 D_fake: 0.000 \n",
            "(epoch: 119, iters: 4000, time: 0.589, data: 0.002) G_GAN: 1.067 G_L1: 1.311 D_real: 1.079 D_fake: 0.332 \n",
            "End of epoch 119 / 200 \t Time Taken: 177 sec\n",
            "learning rate 0.0001604 -> 0.0001584\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "(epoch: 120, iters: 100, time: 0.066, data: 0.195) G_GAN: 6.532 G_L1: 1.668 D_real: 0.000 D_fake: 0.003 \n",
            "(epoch: 120, iters: 200, time: 0.066, data: 0.004) G_GAN: 2.526 G_L1: 1.883 D_real: 0.118 D_fake: 0.206 \n",
            "(epoch: 120, iters: 300, time: 0.066, data: 0.003) G_GAN: 2.833 G_L1: 1.346 D_real: 0.124 D_fake: 0.165 \n",
            "(epoch: 120, iters: 400, time: 0.703, data: 0.004) G_GAN: 9.554 G_L1: 0.694 D_real: 0.002 D_fake: 0.000 \n",
            "(epoch: 120, iters: 500, time: 0.058, data: 0.003) G_GAN: 3.308 G_L1: 1.819 D_real: 0.219 D_fake: 0.085 \n",
            "(epoch: 120, iters: 600, time: 0.065, data: 0.009) G_GAN: 1.755 G_L1: 2.048 D_real: 0.330 D_fake: 0.167 \n",
            "(epoch: 120, iters: 700, time: 0.065, data: 0.009) G_GAN: 3.798 G_L1: 2.273 D_real: 0.002 D_fake: 0.350 \n",
            "(epoch: 120, iters: 800, time: 0.219, data: 0.006) G_GAN: 5.064 G_L1: 2.212 D_real: 0.026 D_fake: 0.014 \n",
            "(epoch: 120, iters: 900, time: 0.066, data: 0.003) G_GAN: 2.838 G_L1: 1.946 D_real: 0.042 D_fake: 0.404 \n",
            "(epoch: 120, iters: 1000, time: 0.067, data: 0.003) G_GAN: 5.767 G_L1: 1.946 D_real: 0.019 D_fake: 0.020 \n",
            "(epoch: 120, iters: 1100, time: 0.066, data: 0.004) G_GAN: 3.216 G_L1: 2.052 D_real: 0.004 D_fake: 0.272 \n",
            "(epoch: 120, iters: 1200, time: 0.182, data: 0.003) G_GAN: 4.255 G_L1: 0.882 D_real: 0.000 D_fake: 0.032 \n",
            "(epoch: 120, iters: 1300, time: 0.065, data: 0.008) G_GAN: 9.040 G_L1: 0.858 D_real: 0.000 D_fake: 0.000 \n",
            "(epoch: 120, iters: 1400, time: 0.065, data: 0.004) G_GAN: 7.895 G_L1: 0.752 D_real: 0.003 D_fake: 0.001 \n",
            "(epoch: 120, iters: 1500, time: 0.066, data: 0.004) G_GAN: 3.880 G_L1: 2.503 D_real: 0.070 D_fake: 0.039 \n",
            "(epoch: 120, iters: 1600, time: 0.308, data: 0.004) G_GAN: 12.092 G_L1: 1.178 D_real: 0.001 D_fake: 0.000 \n",
            "(epoch: 120, iters: 1700, time: 0.066, data: 0.003) G_GAN: 7.018 G_L1: 1.563 D_real: 0.046 D_fake: 0.002 \n",
            "(epoch: 120, iters: 1800, time: 0.066, data: 0.002) G_GAN: 0.804 G_L1: 2.014 D_real: 1.969 D_fake: 0.196 \n",
            "(epoch: 120, iters: 1900, time: 0.066, data: 0.002) G_GAN: 1.815 G_L1: 2.754 D_real: 0.325 D_fake: 0.480 \n",
            "(epoch: 120, iters: 2000, time: 0.541, data: 0.004) G_GAN: 7.980 G_L1: 1.144 D_real: 0.000 D_fake: 0.002 \n",
            "(epoch: 120, iters: 2100, time: 0.066, data: 0.004) G_GAN: 3.845 G_L1: 1.163 D_real: 0.028 D_fake: 0.278 \n",
            "(epoch: 120, iters: 2200, time: 0.067, data: 0.003) G_GAN: 1.254 G_L1: 1.572 D_real: 1.558 D_fake: 0.027 \n",
            "(epoch: 120, iters: 2300, time: 0.067, data: 0.003) G_GAN: 1.366 G_L1: 1.963 D_real: 1.437 D_fake: 0.685 \n",
            "(epoch: 120, iters: 2400, time: 0.176, data: 0.004) G_GAN: 6.594 G_L1: 1.997 D_real: 0.514 D_fake: 0.004 \n",
            "(epoch: 120, iters: 2500, time: 0.062, data: 0.003) G_GAN: 1.788 G_L1: 1.819 D_real: 0.544 D_fake: 0.156 \n",
            "(epoch: 120, iters: 2600, time: 0.067, data: 0.003) G_GAN: 2.318 G_L1: 3.701 D_real: 0.410 D_fake: 0.916 \n",
            "(epoch: 120, iters: 2700, time: 0.065, data: 0.003) G_GAN: 10.798 G_L1: 0.680 D_real: 0.000 D_fake: 0.000 \n",
            "(epoch: 120, iters: 2800, time: 0.213, data: 0.007) G_GAN: 2.951 G_L1: 2.135 D_real: 0.501 D_fake: 0.030 \n",
            "(epoch: 120, iters: 2900, time: 0.066, data: 0.010) G_GAN: 3.057 G_L1: 2.033 D_real: 0.136 D_fake: 0.434 \n",
            "(epoch: 120, iters: 3000, time: 0.066, data: 0.007) G_GAN: 9.136 G_L1: 0.973 D_real: 0.001 D_fake: 0.000 \n",
            "(epoch: 120, iters: 3100, time: 0.067, data: 0.004) G_GAN: 3.942 G_L1: 1.758 D_real: 0.020 D_fake: 0.313 \n",
            "(epoch: 120, iters: 3200, time: 0.181, data: 0.004) G_GAN: 3.343 G_L1: 3.837 D_real: 0.161 D_fake: 0.059 \n",
            "(epoch: 120, iters: 3300, time: 0.065, data: 0.003) G_GAN: 2.708 G_L1: 1.083 D_real: 0.252 D_fake: 0.327 \n",
            "(epoch: 120, iters: 3400, time: 0.063, data: 0.004) G_GAN: 3.764 G_L1: 2.400 D_real: 0.253 D_fake: 0.043 \n",
            "(epoch: 120, iters: 3500, time: 0.065, data: 0.004) G_GAN: 5.657 G_L1: 1.753 D_real: 0.032 D_fake: 0.005 \n",
            "(epoch: 120, iters: 3600, time: 0.191, data: 0.003) G_GAN: 6.208 G_L1: 2.082 D_real: 0.008 D_fake: 0.006 \n",
            "(epoch: 120, iters: 3700, time: 0.064, data: 0.003) G_GAN: 5.487 G_L1: 1.088 D_real: 0.000 D_fake: 0.009 \n",
            "(epoch: 120, iters: 3800, time: 0.066, data: 0.004) G_GAN: 8.880 G_L1: 1.207 D_real: 0.000 D_fake: 0.000 \n",
            "(epoch: 120, iters: 3900, time: 0.066, data: 0.005) G_GAN: 1.315 G_L1: 1.290 D_real: 0.548 D_fake: 0.596 \n",
            "(epoch: 120, iters: 4000, time: 0.538, data: 0.004) G_GAN: 0.640 G_L1: 1.261 D_real: 0.470 D_fake: 1.264 \n",
            "saving the latest model (epoch 120, total_iters 480000)\n",
            "saving the model at the end of epoch 120, iters 480000\n",
            "End of epoch 120 / 200 \t Time Taken: 178 sec\n",
            "learning rate 0.0001584 -> 0.0001564\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "(epoch: 121, iters: 100, time: 0.064, data: 0.190) G_GAN: 11.887 G_L1: 1.040 D_real: 0.002 D_fake: 0.000 \n",
            "(epoch: 121, iters: 200, time: 0.066, data: 0.008) G_GAN: 6.717 G_L1: 2.934 D_real: 0.014 D_fake: 0.003 \n",
            "(epoch: 121, iters: 300, time: 0.066, data: 0.004) G_GAN: 3.927 G_L1: 1.425 D_real: 0.060 D_fake: 0.047 \n",
            "(epoch: 121, iters: 400, time: 0.690, data: 0.004) G_GAN: 6.427 G_L1: 1.165 D_real: 0.000 D_fake: 0.006 \n",
            "(epoch: 121, iters: 500, time: 0.066, data: 0.004) G_GAN: 13.959 G_L1: 0.735 D_real: 0.001 D_fake: 0.000 \n",
            "(epoch: 121, iters: 600, time: 0.066, data: 0.004) G_GAN: 3.193 G_L1: 1.504 D_real: 0.072 D_fake: 0.158 \n",
            "(epoch: 121, iters: 700, time: 0.066, data: 0.003) G_GAN: 4.412 G_L1: 2.535 D_real: 0.034 D_fake: 0.030 \n",
            "(epoch: 121, iters: 800, time: 0.225, data: 0.003) G_GAN: 2.354 G_L1: 1.897 D_real: 0.108 D_fake: 0.495 \n",
            "(epoch: 121, iters: 900, time: 0.065, data: 0.003) G_GAN: 10.592 G_L1: 0.704 D_real: 0.005 D_fake: 0.000 \n",
            "(epoch: 121, iters: 1000, time: 0.065, data: 0.003) G_GAN: 0.612 G_L1: 1.863 D_real: 1.826 D_fake: 0.197 \n",
            "(epoch: 121, iters: 1100, time: 0.067, data: 0.004) G_GAN: 2.667 G_L1: 1.238 D_real: 1.623 D_fake: 0.019 \n",
            "(epoch: 121, iters: 1200, time: 0.166, data: 0.004) G_GAN: 9.331 G_L1: 1.235 D_real: 0.053 D_fake: 0.000 \n",
            "(epoch: 121, iters: 1300, time: 0.066, data: 0.005) G_GAN: 3.829 G_L1: 1.486 D_real: 0.044 D_fake: 0.058 \n",
            "(epoch: 121, iters: 1400, time: 0.065, data: 0.004) G_GAN: 1.723 G_L1: 2.269 D_real: 0.464 D_fake: 0.834 \n",
            "(epoch: 121, iters: 1500, time: 0.066, data: 0.004) G_GAN: 2.320 G_L1: 1.845 D_real: 0.184 D_fake: 0.379 \n",
            "(epoch: 121, iters: 1600, time: 0.210, data: 0.004) G_GAN: 3.124 G_L1: 3.368 D_real: 0.017 D_fake: 0.188 \n",
            "(epoch: 121, iters: 1700, time: 0.066, data: 0.007) G_GAN: 2.472 G_L1: 1.540 D_real: 0.229 D_fake: 0.231 \n",
            "(epoch: 121, iters: 1800, time: 0.065, data: 0.004) G_GAN: 3.939 G_L1: 4.326 D_real: 0.366 D_fake: 0.015 \n",
            "(epoch: 121, iters: 1900, time: 0.066, data: 0.006) G_GAN: 8.784 G_L1: 3.809 D_real: 0.377 D_fake: 0.001 \n",
            "(epoch: 121, iters: 2000, time: 0.663, data: 0.003) G_GAN: 2.857 G_L1: 2.823 D_real: 0.029 D_fake: 0.331 \n",
            "(epoch: 121, iters: 2100, time: 0.063, data: 0.004) G_GAN: 1.117 G_L1: 1.518 D_real: 0.836 D_fake: 0.250 \n",
            "(epoch: 121, iters: 2200, time: 0.065, data: 0.004) G_GAN: 7.950 G_L1: 1.008 D_real: 0.001 D_fake: 0.001 \n",
            "(epoch: 121, iters: 2300, time: 0.063, data: 0.002) G_GAN: 3.152 G_L1: 2.074 D_real: 0.035 D_fake: 0.473 \n",
            "(epoch: 121, iters: 2400, time: 0.168, data: 0.003) G_GAN: 5.187 G_L1: 1.927 D_real: 0.157 D_fake: 0.013 \n",
            "(epoch: 121, iters: 2500, time: 0.066, data: 0.002) G_GAN: 8.115 G_L1: 1.069 D_real: 0.000 D_fake: 0.001 \n",
            "(epoch: 121, iters: 2600, time: 0.067, data: 0.003) G_GAN: 2.842 G_L1: 2.072 D_real: 0.158 D_fake: 0.481 \n",
            "(epoch: 121, iters: 2700, time: 0.065, data: 0.003) G_GAN: 2.396 G_L1: 1.208 D_real: 0.346 D_fake: 0.189 \n",
            "(epoch: 121, iters: 2800, time: 0.173, data: 0.003) G_GAN: 1.984 G_L1: 1.225 D_real: 0.226 D_fake: 0.535 \n",
            "(epoch: 121, iters: 2900, time: 0.065, data: 0.002) G_GAN: 3.168 G_L1: 1.996 D_real: 0.007 D_fake: 0.341 \n",
            "(epoch: 121, iters: 3000, time: 0.062, data: 0.007) G_GAN: 4.403 G_L1: 4.302 D_real: 0.012 D_fake: 0.032 \n",
            "(epoch: 121, iters: 3100, time: 0.064, data: 0.003) G_GAN: 4.581 G_L1: 1.479 D_real: 1.406 D_fake: 0.012 \n",
            "(epoch: 121, iters: 3200, time: 0.189, data: 0.004) G_GAN: 7.985 G_L1: 1.001 D_real: 0.048 D_fake: 0.001 \n",
            "(epoch: 121, iters: 3300, time: 0.067, data: 0.002) G_GAN: 3.010 G_L1: 2.029 D_real: 0.042 D_fake: 0.172 \n",
            "(epoch: 121, iters: 3400, time: 0.062, data: 0.004) G_GAN: 4.043 G_L1: 1.810 D_real: 0.130 D_fake: 0.040 \n",
            "(epoch: 121, iters: 3500, time: 0.066, data: 0.003) G_GAN: 3.110 G_L1: 1.443 D_real: 0.170 D_fake: 0.078 \n",
            "(epoch: 121, iters: 3600, time: 0.159, data: 0.004) G_GAN: 11.458 G_L1: 0.809 D_real: 0.000 D_fake: 0.000 \n",
            "(epoch: 121, iters: 3700, time: 0.066, data: 0.003) G_GAN: 2.568 G_L1: 2.306 D_real: 0.203 D_fake: 0.090 \n",
            "(epoch: 121, iters: 3800, time: 0.066, data: 0.004) G_GAN: 8.631 G_L1: 1.465 D_real: 0.015 D_fake: 0.001 \n",
            "(epoch: 121, iters: 3900, time: 0.066, data: 0.003) G_GAN: 10.603 G_L1: 0.717 D_real: 0.001 D_fake: 0.000 \n",
            "(epoch: 121, iters: 4000, time: 0.561, data: 0.004) G_GAN: 3.087 G_L1: 2.006 D_real: 0.254 D_fake: 0.367 \n",
            "End of epoch 121 / 200 \t Time Taken: 175 sec\n",
            "learning rate 0.0001564 -> 0.0001545\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "(epoch: 122, iters: 100, time: 0.066, data: 0.195) G_GAN: 4.952 G_L1: 1.100 D_real: 0.002 D_fake: 0.027 \n",
            "(epoch: 122, iters: 200, time: 0.065, data: 0.005) G_GAN: 3.827 G_L1: 1.851 D_real: 0.013 D_fake: 0.393 \n",
            "(epoch: 122, iters: 300, time: 0.066, data: 0.004) G_GAN: 0.982 G_L1: 1.368 D_real: 1.350 D_fake: 0.341 \n",
            "(epoch: 122, iters: 400, time: 0.647, data: 0.004) G_GAN: 3.242 G_L1: 1.865 D_real: 0.056 D_fake: 1.471 \n",
            "(epoch: 122, iters: 500, time: 0.066, data: 0.004) G_GAN: 7.970 G_L1: 1.187 D_real: 0.000 D_fake: 0.001 \n",
            "(epoch: 122, iters: 600, time: 0.066, data: 0.003) G_GAN: 6.284 G_L1: 0.886 D_real: 0.000 D_fake: 0.004 \n",
            "(epoch: 122, iters: 700, time: 0.066, data: 0.008) G_GAN: 12.431 G_L1: 1.288 D_real: 0.000 D_fake: 0.000 \n",
            "(epoch: 122, iters: 800, time: 0.179, data: 0.004) G_GAN: 7.715 G_L1: 0.969 D_real: 0.001 D_fake: 0.001 \n",
            "(epoch: 122, iters: 900, time: 0.066, data: 0.007) G_GAN: 2.478 G_L1: 1.538 D_real: 0.929 D_fake: 0.413 \n",
            "(epoch: 122, iters: 1000, time: 0.065, data: 0.003) G_GAN: 5.375 G_L1: 2.604 D_real: 2.290 D_fake: 0.002 \n",
            "saving the latest model (epoch 122, total_iters 485000)\n",
            "(epoch: 122, iters: 1100, time: 0.064, data: 0.002) G_GAN: 4.705 G_L1: 2.823 D_real: 0.022 D_fake: 0.024 \n",
            "(epoch: 122, iters: 1200, time: 0.178, data: 0.004) G_GAN: 2.544 G_L1: 1.306 D_real: 0.153 D_fake: 0.865 \n",
            "(epoch: 122, iters: 1300, time: 0.066, data: 0.003) G_GAN: 8.252 G_L1: 2.405 D_real: 0.000 D_fake: 0.001 \n",
            "(epoch: 122, iters: 1400, time: 0.064, data: 0.004) G_GAN: 3.140 G_L1: 1.144 D_real: 0.389 D_fake: 0.065 \n",
            "(epoch: 122, iters: 1500, time: 0.066, data: 0.004) G_GAN: 9.349 G_L1: 1.422 D_real: 0.000 D_fake: 0.000 \n",
            "(epoch: 122, iters: 1600, time: 0.172, data: 0.002) G_GAN: 2.425 G_L1: 1.989 D_real: 0.084 D_fake: 0.429 \n",
            "(epoch: 122, iters: 1700, time: 0.063, data: 0.003) G_GAN: 2.076 G_L1: 1.884 D_real: 0.352 D_fake: 0.184 \n",
            "(epoch: 122, iters: 1800, time: 0.066, data: 0.004) G_GAN: 8.972 G_L1: 1.837 D_real: 0.002 D_fake: 0.000 \n",
            "(epoch: 122, iters: 1900, time: 0.067, data: 0.002) G_GAN: 1.960 G_L1: 1.937 D_real: 0.154 D_fake: 0.344 \n",
            "(epoch: 122, iters: 2000, time: 0.515, data: 0.003) G_GAN: 9.384 G_L1: 1.017 D_real: 0.000 D_fake: 0.000 \n",
            "(epoch: 122, iters: 2100, time: 0.066, data: 0.003) G_GAN: 11.625 G_L1: 1.165 D_real: 0.006 D_fake: 0.000 \n",
            "(epoch: 122, iters: 2200, time: 0.067, data: 0.004) G_GAN: 3.685 G_L1: 1.817 D_real: 0.025 D_fake: 0.066 \n",
            "(epoch: 122, iters: 2300, time: 0.066, data: 0.003) G_GAN: 4.931 G_L1: 1.519 D_real: 0.000 D_fake: 0.025 \n",
            "(epoch: 122, iters: 2400, time: 0.206, data: 0.009) G_GAN: 3.537 G_L1: 1.345 D_real: 0.088 D_fake: 0.165 \n",
            "(epoch: 122, iters: 2500, time: 0.066, data: 0.005) G_GAN: 10.973 G_L1: 0.849 D_real: 0.000 D_fake: 0.000 \n",
            "(epoch: 122, iters: 2600, time: 0.066, data: 0.004) G_GAN: 3.151 G_L1: 1.252 D_real: 0.218 D_fake: 0.404 \n",
            "(epoch: 122, iters: 2700, time: 0.067, data: 0.004) G_GAN: 5.566 G_L1: 2.387 D_real: 0.109 D_fake: 0.005 \n",
            "(epoch: 122, iters: 2800, time: 0.333, data: 0.003) G_GAN: 3.212 G_L1: 2.296 D_real: 0.013 D_fake: 0.340 \n",
            "(epoch: 122, iters: 2900, time: 0.065, data: 0.006) G_GAN: 6.887 G_L1: 1.952 D_real: 0.185 D_fake: 0.003 \n",
            "(epoch: 122, iters: 3000, time: 0.064, data: 0.004) G_GAN: 1.374 G_L1: 2.181 D_real: 0.166 D_fake: 0.902 \n",
            "(epoch: 122, iters: 3100, time: 0.063, data: 0.006) G_GAN: 1.944 G_L1: 2.380 D_real: 0.574 D_fake: 0.223 \n",
            "(epoch: 122, iters: 3200, time: 0.174, data: 0.004) G_GAN: 1.745 G_L1: 1.566 D_real: 0.054 D_fake: 0.864 \n",
            "(epoch: 122, iters: 3300, time: 0.064, data: 0.003) G_GAN: 3.031 G_L1: 3.289 D_real: 0.317 D_fake: 0.006 \n",
            "(epoch: 122, iters: 3400, time: 0.065, data: 0.003) G_GAN: 1.912 G_L1: 2.011 D_real: 0.330 D_fake: 0.257 \n",
            "(epoch: 122, iters: 3500, time: 0.065, data: 0.004) G_GAN: 0.891 G_L1: 1.539 D_real: 0.682 D_fake: 0.829 \n",
            "(epoch: 122, iters: 3600, time: 0.223, data: 0.003) G_GAN: 3.237 G_L1: 1.766 D_real: 0.066 D_fake: 0.151 \n",
            "(epoch: 122, iters: 3700, time: 0.066, data: 0.002) G_GAN: 4.733 G_L1: 1.789 D_real: 0.003 D_fake: 0.023 \n",
            "(epoch: 122, iters: 3800, time: 0.066, data: 0.004) G_GAN: 2.255 G_L1: 1.755 D_real: 0.057 D_fake: 0.430 \n",
            "(epoch: 122, iters: 3900, time: 0.065, data: 0.003) G_GAN: 4.995 G_L1: 2.679 D_real: 0.019 D_fake: 0.013 \n",
            "(epoch: 122, iters: 4000, time: 0.619, data: 0.004) G_GAN: 5.937 G_L1: 2.334 D_real: 0.065 D_fake: 0.051 \n",
            "End of epoch 122 / 200 \t Time Taken: 177 sec\n",
            "learning rate 0.0001545 -> 0.0001525\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "(epoch: 123, iters: 100, time: 0.066, data: 0.231) G_GAN: 13.145 G_L1: 0.697 D_real: 0.001 D_fake: 0.000 \n",
            "(epoch: 123, iters: 200, time: 0.056, data: 0.004) G_GAN: 12.281 G_L1: 2.422 D_real: 0.000 D_fake: 0.000 \n",
            "(epoch: 123, iters: 300, time: 0.066, data: 0.004) G_GAN: 3.012 G_L1: 1.184 D_real: 0.177 D_fake: 0.997 \n",
            "(epoch: 123, iters: 400, time: 0.683, data: 0.005) G_GAN: 13.367 G_L1: 1.354 D_real: 0.000 D_fake: 0.000 \n",
            "(epoch: 123, iters: 500, time: 0.067, data: 0.003) G_GAN: 4.565 G_L1: 1.337 D_real: 0.067 D_fake: 1.099 \n",
            "(epoch: 123, iters: 600, time: 0.066, data: 0.005) G_GAN: 9.070 G_L1: 2.048 D_real: 0.067 D_fake: 0.000 \n",
            "(epoch: 123, iters: 700, time: 0.064, data: 0.002) G_GAN: 10.239 G_L1: 0.926 D_real: 0.014 D_fake: 0.000 \n",
            "(epoch: 123, iters: 800, time: 0.190, data: 0.009) G_GAN: 3.368 G_L1: 1.532 D_real: 0.213 D_fake: 0.072 \n",
            "(epoch: 123, iters: 900, time: 0.067, data: 0.007) G_GAN: 2.768 G_L1: 1.449 D_real: 0.125 D_fake: 0.937 \n",
            "(epoch: 123, iters: 1000, time: 0.062, data: 0.003) G_GAN: 3.952 G_L1: 2.426 D_real: 0.048 D_fake: 0.037 \n",
            "(epoch: 123, iters: 1100, time: 0.067, data: 0.004) G_GAN: 8.118 G_L1: 1.179 D_real: 0.029 D_fake: 0.001 \n",
            "(epoch: 123, iters: 1200, time: 0.171, data: 0.002) G_GAN: 2.563 G_L1: 1.456 D_real: 0.238 D_fake: 0.477 \n",
            "(epoch: 123, iters: 1300, time: 0.066, data: 0.007) G_GAN: 2.940 G_L1: 2.281 D_real: 0.146 D_fake: 0.145 \n",
            "(epoch: 123, iters: 1400, time: 0.066, data: 0.003) G_GAN: 1.014 G_L1: 1.388 D_real: 0.786 D_fake: 0.674 \n",
            "(epoch: 123, iters: 1500, time: 0.067, data: 0.003) G_GAN: 11.625 G_L1: 0.876 D_real: 0.000 D_fake: 0.000 \n",
            "(epoch: 123, iters: 1600, time: 0.216, data: 0.003) G_GAN: 3.235 G_L1: 1.971 D_real: 0.105 D_fake: 0.061 \n",
            "(epoch: 123, iters: 1700, time: 0.066, data: 0.004) G_GAN: 9.122 G_L1: 1.050 D_real: 0.000 D_fake: 0.000 \n",
            "(epoch: 123, iters: 1800, time: 0.066, data: 0.006) G_GAN: 10.670 G_L1: 0.951 D_real: 0.001 D_fake: 0.000 \n",
            "(epoch: 123, iters: 1900, time: 0.067, data: 0.007) G_GAN: 1.626 G_L1: 1.243 D_real: 1.888 D_fake: 0.169 \n",
            "(epoch: 123, iters: 2000, time: 0.557, data: 0.004) G_GAN: 10.773 G_L1: 1.584 D_real: 0.004 D_fake: 0.000 \n",
            "saving the latest model (epoch 123, total_iters 490000)\n",
            "(epoch: 123, iters: 2100, time: 0.065, data: 0.005) G_GAN: 2.105 G_L1: 1.992 D_real: 0.070 D_fake: 1.400 \n",
            "(epoch: 123, iters: 2200, time: 0.061, data: 0.003) G_GAN: 6.212 G_L1: 0.942 D_real: 0.371 D_fake: 0.001 \n",
            "(epoch: 123, iters: 2300, time: 0.066, data: 0.004) G_GAN: 1.780 G_L1: 1.300 D_real: 0.516 D_fake: 0.163 \n",
            "(epoch: 123, iters: 2400, time: 0.193, data: 0.003) G_GAN: 4.541 G_L1: 1.846 D_real: 0.021 D_fake: 0.021 \n",
            "(epoch: 123, iters: 2500, time: 0.066, data: 0.006) G_GAN: 6.995 G_L1: 2.401 D_real: 0.132 D_fake: 0.001 \n",
            "(epoch: 123, iters: 2600, time: 0.066, data: 0.003) G_GAN: 2.591 G_L1: 1.943 D_real: 0.092 D_fake: 0.188 \n",
            "(epoch: 123, iters: 2700, time: 0.064, data: 0.003) G_GAN: 0.871 G_L1: 3.210 D_real: 0.109 D_fake: 2.633 \n",
            "(epoch: 123, iters: 2800, time: 0.187, data: 0.004) G_GAN: 3.102 G_L1: 1.594 D_real: 0.019 D_fake: 0.274 \n",
            "(epoch: 123, iters: 2900, time: 0.066, data: 0.002) G_GAN: 2.728 G_L1: 2.284 D_real: 0.133 D_fake: 0.125 \n",
            "(epoch: 123, iters: 3000, time: 0.066, data: 0.002) G_GAN: 6.083 G_L1: 1.421 D_real: 0.026 D_fake: 0.007 \n",
            "(epoch: 123, iters: 3100, time: 0.066, data: 0.002) G_GAN: 3.260 G_L1: 1.499 D_real: 0.238 D_fake: 0.053 \n",
            "(epoch: 123, iters: 3200, time: 0.171, data: 0.004) G_GAN: 2.595 G_L1: 2.286 D_real: 0.206 D_fake: 0.416 \n",
            "(epoch: 123, iters: 3300, time: 0.065, data: 0.007) G_GAN: 1.825 G_L1: 1.030 D_real: 0.145 D_fake: 0.848 \n",
            "(epoch: 123, iters: 3400, time: 0.065, data: 0.003) G_GAN: 3.351 G_L1: 1.746 D_real: 0.035 D_fake: 0.270 \n",
            "(epoch: 123, iters: 3500, time: 0.067, data: 0.008) G_GAN: 3.245 G_L1: 2.229 D_real: 0.722 D_fake: 0.076 \n",
            "(epoch: 123, iters: 3600, time: 0.220, data: 0.004) G_GAN: 2.714 G_L1: 2.371 D_real: 0.075 D_fake: 0.218 \n",
            "(epoch: 123, iters: 3700, time: 0.066, data: 0.004) G_GAN: 2.406 G_L1: 1.493 D_real: 0.108 D_fake: 0.281 \n",
            "(epoch: 123, iters: 3800, time: 0.066, data: 0.005) G_GAN: 6.901 G_L1: 1.013 D_real: 0.526 D_fake: 0.032 \n",
            "(epoch: 123, iters: 3900, time: 0.067, data: 0.003) G_GAN: 9.255 G_L1: 0.785 D_real: 0.003 D_fake: 0.000 \n",
            "(epoch: 123, iters: 4000, time: 0.719, data: 0.003) G_GAN: 4.422 G_L1: 1.256 D_real: 0.022 D_fake: 0.413 \n",
            "End of epoch 123 / 200 \t Time Taken: 176 sec\n",
            "learning rate 0.0001525 -> 0.0001505\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "(epoch: 124, iters: 100, time: 0.066, data: 0.226) G_GAN: 3.198 G_L1: 1.441 D_real: 0.026 D_fake: 0.146 \n",
            "(epoch: 124, iters: 200, time: 0.066, data: 0.003) G_GAN: 8.517 G_L1: 2.263 D_real: 0.092 D_fake: 0.000 \n",
            "(epoch: 124, iters: 300, time: 0.067, data: 0.003) G_GAN: 2.744 G_L1: 1.191 D_real: 0.240 D_fake: 0.088 \n",
            "(epoch: 124, iters: 400, time: 0.799, data: 0.004) G_GAN: 2.933 G_L1: 1.738 D_real: 0.295 D_fake: 0.050 \n",
            "(epoch: 124, iters: 500, time: 0.066, data: 0.003) G_GAN: 3.248 G_L1: 1.746 D_real: 0.512 D_fake: 0.016 \n",
            "(epoch: 124, iters: 600, time: 0.063, data: 0.003) G_GAN: 8.571 G_L1: 0.764 D_real: 0.000 D_fake: 0.001 \n",
            "(epoch: 124, iters: 700, time: 0.067, data: 0.002) G_GAN: 2.370 G_L1: 1.738 D_real: 0.836 D_fake: 0.340 \n",
            "(epoch: 124, iters: 800, time: 0.172, data: 0.003) G_GAN: 1.768 G_L1: 1.521 D_real: 0.375 D_fake: 0.102 \n",
            "(epoch: 124, iters: 900, time: 0.066, data: 0.007) G_GAN: 3.399 G_L1: 1.365 D_real: 0.015 D_fake: 0.182 \n",
            "(epoch: 124, iters: 1000, time: 0.067, data: 0.003) G_GAN: 4.487 G_L1: 1.188 D_real: 0.018 D_fake: 0.167 \n",
            "(epoch: 124, iters: 1100, time: 0.067, data: 0.003) G_GAN: 2.935 G_L1: 1.446 D_real: 0.098 D_fake: 0.799 \n",
            "(epoch: 124, iters: 1200, time: 0.163, data: 0.004) G_GAN: 9.530 G_L1: 0.759 D_real: 0.005 D_fake: 0.000 \n",
            "(epoch: 124, iters: 1300, time: 0.066, data: 0.003) G_GAN: 2.967 G_L1: 1.011 D_real: 0.045 D_fake: 0.236 \n",
            "(epoch: 124, iters: 1400, time: 0.064, data: 0.004) G_GAN: 4.114 G_L1: 2.014 D_real: 0.201 D_fake: 0.022 \n",
            "(epoch: 124, iters: 1500, time: 0.067, data: 0.006) G_GAN: 2.460 G_L1: 2.196 D_real: 0.153 D_fake: 0.540 \n",
            "(epoch: 124, iters: 1600, time: 0.184, data: 0.004) G_GAN: 5.138 G_L1: 0.985 D_real: 0.002 D_fake: 3.479 \n",
            "(epoch: 124, iters: 1700, time: 0.063, data: 0.003) G_GAN: 3.154 G_L1: 2.048 D_real: 0.039 D_fake: 0.128 \n",
            "(epoch: 124, iters: 1800, time: 0.066, data: 0.003) G_GAN: 8.307 G_L1: 2.414 D_real: 0.001 D_fake: 0.001 \n",
            "(epoch: 124, iters: 1900, time: 0.067, data: 0.003) G_GAN: 3.379 G_L1: 2.965 D_real: 0.007 D_fake: 0.095 \n",
            "(epoch: 124, iters: 2000, time: 0.562, data: 0.003) G_GAN: 2.276 G_L1: 2.170 D_real: 0.112 D_fake: 1.237 \n",
            "(epoch: 124, iters: 2100, time: 0.066, data: 0.005) G_GAN: 2.328 G_L1: 1.812 D_real: 0.892 D_fake: 0.055 \n",
            "(epoch: 124, iters: 2200, time: 0.065, data: 0.003) G_GAN: 2.868 G_L1: 1.505 D_real: 0.007 D_fake: 0.162 \n",
            "(epoch: 124, iters: 2300, time: 0.067, data: 0.005) G_GAN: 2.836 G_L1: 1.985 D_real: 0.015 D_fake: 0.280 \n",
            "(epoch: 124, iters: 2400, time: 0.181, data: 0.005) G_GAN: 6.844 G_L1: 2.722 D_real: 0.000 D_fake: 0.003 \n",
            "(epoch: 124, iters: 2500, time: 0.065, data: 0.004) G_GAN: 1.856 G_L1: 1.711 D_real: 0.050 D_fake: 0.748 \n",
            "(epoch: 124, iters: 2600, time: 0.065, data: 0.004) G_GAN: 1.588 G_L1: 1.881 D_real: 0.437 D_fake: 0.294 \n",
            "(epoch: 124, iters: 2700, time: 0.066, data: 0.007) G_GAN: 1.687 G_L1: 1.890 D_real: 0.992 D_fake: 0.066 \n",
            "(epoch: 124, iters: 2800, time: 0.179, data: 0.003) G_GAN: 7.338 G_L1: 1.411 D_real: 0.000 D_fake: 0.002 \n",
            "(epoch: 124, iters: 2900, time: 0.066, data: 0.003) G_GAN: 3.265 G_L1: 2.387 D_real: 0.020 D_fake: 0.130 \n",
            "(epoch: 124, iters: 3000, time: 0.066, data: 0.006) G_GAN: 10.604 G_L1: 2.937 D_real: 0.000 D_fake: 0.000 \n",
            "saving the latest model (epoch 124, total_iters 495000)\n",
            "(epoch: 124, iters: 3100, time: 0.067, data: 0.002) G_GAN: 6.062 G_L1: 1.011 D_real: 0.001 D_fake: 0.005 \n",
            "(epoch: 124, iters: 3200, time: 0.169, data: 0.002) G_GAN: 1.186 G_L1: 0.861 D_real: 0.582 D_fake: 0.291 \n",
            "(epoch: 124, iters: 3300, time: 0.067, data: 0.003) G_GAN: 9.154 G_L1: 1.181 D_real: 0.000 D_fake: 0.000 \n",
            "(epoch: 124, iters: 3400, time: 0.065, data: 0.003) G_GAN: 11.727 G_L1: 1.533 D_real: 0.000 D_fake: 0.000 \n",
            "(epoch: 124, iters: 3500, time: 0.066, data: 0.003) G_GAN: 2.425 G_L1: 1.846 D_real: 0.272 D_fake: 0.310 \n",
            "(epoch: 124, iters: 3600, time: 0.213, data: 0.004) G_GAN: 1.579 G_L1: 1.794 D_real: 0.475 D_fake: 0.280 \n",
            "(epoch: 124, iters: 3700, time: 0.063, data: 0.002) G_GAN: 7.752 G_L1: 4.615 D_real: 0.040 D_fake: 0.001 \n",
            "(epoch: 124, iters: 3800, time: 0.067, data: 0.006) G_GAN: 9.733 G_L1: 1.301 D_real: 0.002 D_fake: 0.000 \n",
            "(epoch: 124, iters: 3900, time: 0.066, data: 0.004) G_GAN: 2.543 G_L1: 1.702 D_real: 0.077 D_fake: 0.616 \n",
            "(epoch: 124, iters: 4000, time: 0.688, data: 0.003) G_GAN: 6.988 G_L1: 1.521 D_real: 0.692 D_fake: 0.002 \n",
            "End of epoch 124 / 200 \t Time Taken: 176 sec\n",
            "learning rate 0.0001505 -> 0.0001485\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "(epoch: 125, iters: 100, time: 0.067, data: 0.213) G_GAN: 2.928 G_L1: 1.101 D_real: 0.111 D_fake: 0.215 \n",
            "(epoch: 125, iters: 200, time: 0.064, data: 0.004) G_GAN: 2.038 G_L1: 1.352 D_real: 0.104 D_fake: 0.771 \n",
            "(epoch: 125, iters: 300, time: 0.064, data: 0.003) G_GAN: 2.338 G_L1: 2.077 D_real: 0.107 D_fake: 0.334 \n",
            "(epoch: 125, iters: 400, time: 2.064, data: 0.003) G_GAN: 1.796 G_L1: 1.333 D_real: 0.942 D_fake: 0.090 \n",
            "(epoch: 125, iters: 500, time: 0.066, data: 0.005) G_GAN: 9.435 G_L1: 3.288 D_real: 0.067 D_fake: 0.000 \n",
            "(epoch: 125, iters: 600, time: 0.065, data: 0.004) G_GAN: 2.527 G_L1: 1.569 D_real: 0.096 D_fake: 0.216 \n",
            "(epoch: 125, iters: 700, time: 0.067, data: 0.003) G_GAN: 10.198 G_L1: 3.354 D_real: 0.039 D_fake: 0.000 \n",
            "(epoch: 125, iters: 800, time: 0.179, data: 0.003) G_GAN: 6.276 G_L1: 0.787 D_real: 0.000 D_fake: 0.005 \n",
            "(epoch: 125, iters: 900, time: 0.067, data: 0.003) G_GAN: 3.239 G_L1: 1.067 D_real: 0.164 D_fake: 0.436 \n",
            "(epoch: 125, iters: 1000, time: 0.067, data: 0.003) G_GAN: 12.223 G_L1: 1.047 D_real: 0.000 D_fake: 0.000 \n",
            "(epoch: 125, iters: 1100, time: 0.062, data: 0.003) G_GAN: 13.729 G_L1: 0.981 D_real: 0.000 D_fake: 0.000 \n",
            "(epoch: 125, iters: 1200, time: 0.176, data: 0.004) G_GAN: 3.253 G_L1: 2.242 D_real: 0.168 D_fake: 0.106 \n",
            "(epoch: 125, iters: 1300, time: 0.067, data: 0.009) G_GAN: 2.601 G_L1: 1.223 D_real: 0.450 D_fake: 1.217 \n",
            "(epoch: 125, iters: 1400, time: 0.066, data: 0.003) G_GAN: 6.254 G_L1: 2.128 D_real: 0.207 D_fake: 0.003 \n",
            "(epoch: 125, iters: 1500, time: 0.064, data: 0.003) G_GAN: 4.034 G_L1: 1.799 D_real: 0.103 D_fake: 0.028 \n",
            "(epoch: 125, iters: 1600, time: 0.183, data: 0.002) G_GAN: 6.552 G_L1: 1.683 D_real: 0.000 D_fake: 0.005 \n",
            "(epoch: 125, iters: 1700, time: 0.066, data: 0.002) G_GAN: 3.146 G_L1: 2.092 D_real: 0.004 D_fake: 0.115 \n",
            "(epoch: 125, iters: 1800, time: 0.067, data: 0.005) G_GAN: 4.020 G_L1: 1.687 D_real: 0.087 D_fake: 0.046 \n",
            "(epoch: 125, iters: 1900, time: 0.064, data: 0.007) G_GAN: 4.344 G_L1: 1.852 D_real: 0.166 D_fake: 0.026 \n",
            "(epoch: 125, iters: 2000, time: 0.688, data: 0.004) G_GAN: 1.750 G_L1: 1.781 D_real: 0.308 D_fake: 0.319 \n",
            "(epoch: 125, iters: 2100, time: 0.067, data: 0.006) G_GAN: 7.617 G_L1: 0.811 D_real: 0.000 D_fake: 0.002 \n",
            "(epoch: 125, iters: 2200, time: 0.067, data: 0.004) G_GAN: 7.956 G_L1: 1.549 D_real: 1.141 D_fake: 0.000 \n",
            "(epoch: 125, iters: 2300, time: 0.066, data: 0.004) G_GAN: 2.188 G_L1: 1.600 D_real: 0.353 D_fake: 0.391 \n",
            "(epoch: 125, iters: 2400, time: 0.191, data: 0.004) G_GAN: 3.281 G_L1: 1.713 D_real: 0.067 D_fake: 0.276 \n",
            "(epoch: 125, iters: 2500, time: 0.066, data: 0.005) G_GAN: 3.377 G_L1: 1.945 D_real: 0.092 D_fake: 0.055 \n",
            "(epoch: 125, iters: 2600, time: 0.067, data: 0.004) G_GAN: 5.292 G_L1: 1.233 D_real: 0.148 D_fake: 0.006 \n",
            "(epoch: 125, iters: 2700, time: 0.067, data: 0.003) G_GAN: 2.336 G_L1: 1.303 D_real: 0.253 D_fake: 0.653 \n",
            "(epoch: 125, iters: 2800, time: 0.179, data: 0.004) G_GAN: 2.888 G_L1: 1.537 D_real: 0.054 D_fake: 0.510 \n",
            "(epoch: 125, iters: 2900, time: 0.067, data: 0.003) G_GAN: 3.978 G_L1: 2.555 D_real: 0.081 D_fake: 0.110 \n",
            "(epoch: 125, iters: 3000, time: 0.067, data: 0.006) G_GAN: 4.087 G_L1: 1.660 D_real: 0.001 D_fake: 0.096 \n",
            "(epoch: 125, iters: 3100, time: 0.065, data: 0.004) G_GAN: 11.855 G_L1: 0.942 D_real: 0.013 D_fake: 0.000 \n",
            "(epoch: 125, iters: 3200, time: 0.186, data: 0.003) G_GAN: 5.459 G_L1: 1.107 D_real: 0.000 D_fake: 0.011 \n",
            "(epoch: 125, iters: 3300, time: 0.066, data: 0.005) G_GAN: 3.670 G_L1: 0.774 D_real: 0.000 D_fake: 0.092 \n",
            "(epoch: 125, iters: 3400, time: 0.067, data: 0.003) G_GAN: 4.589 G_L1: 1.896 D_real: 0.005 D_fake: 0.454 \n",
            "(epoch: 125, iters: 3500, time: 0.067, data: 0.004) G_GAN: 4.722 G_L1: 2.209 D_real: 0.053 D_fake: 0.023 \n",
            "(epoch: 125, iters: 3600, time: 0.168, data: 0.003) G_GAN: 9.554 G_L1: 1.032 D_real: 0.001 D_fake: 0.000 \n",
            "(epoch: 125, iters: 3700, time: 0.066, data: 0.002) G_GAN: 5.594 G_L1: 1.372 D_real: 0.001 D_fake: 0.008 \n",
            "(epoch: 125, iters: 3800, time: 0.065, data: 0.003) G_GAN: 9.593 G_L1: 1.388 D_real: 0.368 D_fake: 0.000 \n",
            "(epoch: 125, iters: 3900, time: 0.067, data: 0.003) G_GAN: 2.519 G_L1: 1.773 D_real: 0.077 D_fake: 0.320 \n",
            "(epoch: 125, iters: 4000, time: 0.591, data: 0.004) G_GAN: 2.943 G_L1: 1.753 D_real: 0.010 D_fake: 0.204 \n",
            "saving the latest model (epoch 125, total_iters 500000)\n",
            "saving the model at the end of epoch 125, iters 500000\n",
            "End of epoch 125 / 200 \t Time Taken: 179 sec\n",
            "learning rate 0.0001485 -> 0.0001465\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "(epoch: 126, iters: 100, time: 0.067, data: 0.156) G_GAN: 1.327 G_L1: 1.965 D_real: 0.284 D_fake: 0.609 \n",
            "(epoch: 126, iters: 200, time: 0.067, data: 0.004) G_GAN: 3.148 G_L1: 1.074 D_real: 0.194 D_fake: 0.050 \n",
            "(epoch: 126, iters: 300, time: 0.065, data: 0.004) G_GAN: 6.694 G_L1: 1.951 D_real: 0.016 D_fake: 0.002 \n",
            "(epoch: 126, iters: 400, time: 0.864, data: 0.004) G_GAN: 0.937 G_L1: 1.985 D_real: 0.332 D_fake: 1.076 \n",
            "(epoch: 126, iters: 500, time: 0.067, data: 0.006) G_GAN: 3.710 G_L1: 1.795 D_real: 0.017 D_fake: 0.254 \n",
            "(epoch: 126, iters: 600, time: 0.065, data: 0.003) G_GAN: 8.486 G_L1: 3.103 D_real: 0.001 D_fake: 0.001 \n",
            "(epoch: 126, iters: 700, time: 0.066, data: 0.002) G_GAN: 2.216 G_L1: 1.870 D_real: 1.353 D_fake: 0.190 \n",
            "(epoch: 126, iters: 800, time: 0.203, data: 0.004) G_GAN: 4.210 G_L1: 2.514 D_real: 0.004 D_fake: 0.532 \n",
            "(epoch: 126, iters: 900, time: 0.066, data: 0.003) G_GAN: 4.048 G_L1: 3.224 D_real: 0.003 D_fake: 0.032 \n",
            "(epoch: 126, iters: 1000, time: 0.067, data: 0.004) G_GAN: 1.061 G_L1: 1.410 D_real: 1.237 D_fake: 0.392 \n",
            "(epoch: 126, iters: 1100, time: 0.066, data: 0.002) G_GAN: 2.824 G_L1: 1.646 D_real: 0.165 D_fake: 0.496 \n",
            "(epoch: 126, iters: 1200, time: 0.176, data: 0.003) G_GAN: 9.944 G_L1: 1.085 D_real: 0.000 D_fake: 0.000 \n",
            "(epoch: 126, iters: 1300, time: 0.066, data: 0.002) G_GAN: 8.024 G_L1: 1.726 D_real: 0.000 D_fake: 0.001 \n",
            "(epoch: 126, iters: 1400, time: 0.066, data: 0.003) G_GAN: 3.036 G_L1: 1.312 D_real: 0.419 D_fake: 0.062 \n",
            "(epoch: 126, iters: 1500, time: 0.067, data: 0.004) G_GAN: 2.067 G_L1: 1.052 D_real: 0.194 D_fake: 0.723 \n",
            "(epoch: 126, iters: 1600, time: 0.215, data: 0.004) G_GAN: 4.298 G_L1: 1.820 D_real: 0.787 D_fake: 0.005 \n",
            "(epoch: 126, iters: 1700, time: 0.065, data: 0.003) G_GAN: 2.225 G_L1: 1.395 D_real: 0.272 D_fake: 0.217 \n",
            "(epoch: 126, iters: 1800, time: 0.067, data: 0.004) G_GAN: 3.512 G_L1: 1.831 D_real: 0.055 D_fake: 0.093 \n",
            "(epoch: 126, iters: 1900, time: 0.066, data: 0.002) G_GAN: 2.440 G_L1: 1.843 D_real: 0.225 D_fake: 0.527 \n",
            "(epoch: 126, iters: 2000, time: 0.567, data: 0.004) G_GAN: 8.109 G_L1: 0.910 D_real: 0.001 D_fake: 0.001 \n",
            "(epoch: 126, iters: 2100, time: 0.067, data: 0.003) G_GAN: 4.502 G_L1: 1.432 D_real: 0.473 D_fake: 0.014 \n",
            "(epoch: 126, iters: 2200, time: 0.067, data: 0.006) G_GAN: 8.194 G_L1: 3.235 D_real: 1.002 D_fake: 0.001 \n",
            "(epoch: 126, iters: 2300, time: 0.066, data: 0.004) G_GAN: 8.546 G_L1: 1.455 D_real: 0.000 D_fake: 0.001 \n",
            "(epoch: 126, iters: 2400, time: 0.169, data: 0.006) G_GAN: 3.000 G_L1: 1.893 D_real: 0.137 D_fake: 0.428 \n",
            "(epoch: 126, iters: 2500, time: 0.067, data: 0.004) G_GAN: 3.246 G_L1: 1.913 D_real: 0.027 D_fake: 0.072 \n",
            "(epoch: 126, iters: 2600, time: 0.063, data: 0.004) G_GAN: 2.143 G_L1: 2.867 D_real: 0.218 D_fake: 0.098 \n",
            "(epoch: 126, iters: 2700, time: 0.066, data: 0.003) G_GAN: 7.857 G_L1: 1.780 D_real: 0.538 D_fake: 0.001 \n",
            "(epoch: 126, iters: 2800, time: 0.186, data: 0.002) G_GAN: 3.285 G_L1: 2.413 D_real: 0.031 D_fake: 1.566 \n",
            "(epoch: 126, iters: 2900, time: 0.067, data: 0.003) G_GAN: 8.737 G_L1: 0.987 D_real: 0.001 D_fake: 0.000 \n",
            "(epoch: 126, iters: 3000, time: 0.066, data: 0.004) G_GAN: 1.712 G_L1: 1.230 D_real: 0.285 D_fake: 0.858 \n",
            "(epoch: 126, iters: 3100, time: 0.067, data: 0.004) G_GAN: 11.964 G_L1: 1.451 D_real: 0.118 D_fake: 0.000 \n",
            "(epoch: 126, iters: 3200, time: 0.228, data: 0.004) G_GAN: 3.239 G_L1: 1.943 D_real: 0.555 D_fake: 0.023 \n",
            "(epoch: 126, iters: 3300, time: 0.067, data: 0.007) G_GAN: 2.224 G_L1: 1.754 D_real: 0.018 D_fake: 0.560 \n",
            "(epoch: 126, iters: 3400, time: 0.066, data: 0.003) G_GAN: 2.844 G_L1: 1.853 D_real: 0.008 D_fake: 0.443 \n",
            "(epoch: 126, iters: 3500, time: 0.067, data: 0.003) G_GAN: 2.648 G_L1: 1.891 D_real: 0.694 D_fake: 0.037 \n",
            "(epoch: 126, iters: 3600, time: 0.178, data: 0.003) G_GAN: 8.743 G_L1: 0.776 D_real: 0.000 D_fake: 0.000 \n",
            "(epoch: 126, iters: 3700, time: 0.066, data: 0.003) G_GAN: 7.519 G_L1: 0.799 D_real: 0.002 D_fake: 0.001 \n",
            "(epoch: 126, iters: 3800, time: 0.063, data: 0.004) G_GAN: 7.652 G_L1: 1.237 D_real: 0.075 D_fake: 0.001 \n",
            "(epoch: 126, iters: 3900, time: 0.066, data: 0.008) G_GAN: 6.314 G_L1: 2.106 D_real: 0.171 D_fake: 0.002 \n",
            "(epoch: 126, iters: 4000, time: 0.591, data: 0.003) G_GAN: 12.062 G_L1: 1.571 D_real: 0.000 D_fake: 0.000 \n",
            "End of epoch 126 / 200 \t Time Taken: 175 sec\n",
            "learning rate 0.0001465 -> 0.0001446\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "(epoch: 127, iters: 100, time: 0.066, data: 0.201) G_GAN: 5.367 G_L1: 2.159 D_real: 0.004 D_fake: 0.018 \n",
            "(epoch: 127, iters: 200, time: 0.066, data: 0.003) G_GAN: 2.123 G_L1: 1.305 D_real: 0.173 D_fake: 0.485 \n",
            "(epoch: 127, iters: 300, time: 0.067, data: 0.003) G_GAN: 1.483 G_L1: 1.869 D_real: 0.409 D_fake: 0.298 \n",
            "(epoch: 127, iters: 400, time: 0.878, data: 0.002) G_GAN: 1.879 G_L1: 1.841 D_real: 0.284 D_fake: 0.818 \n",
            "(epoch: 127, iters: 500, time: 0.067, data: 0.006) G_GAN: 11.853 G_L1: 4.373 D_real: 0.005 D_fake: 0.000 \n",
            "(epoch: 127, iters: 600, time: 0.067, data: 0.003) G_GAN: 7.418 G_L1: 0.840 D_real: 0.002 D_fake: 0.001 \n",
            "(epoch: 127, iters: 700, time: 0.066, data: 0.004) G_GAN: 1.665 G_L1: 1.576 D_real: 0.382 D_fake: 0.521 \n",
            "(epoch: 127, iters: 800, time: 0.188, data: 0.006) G_GAN: 1.126 G_L1: 2.632 D_real: 1.056 D_fake: 0.096 \n",
            "(epoch: 127, iters: 900, time: 0.066, data: 0.007) G_GAN: 7.228 G_L1: 1.573 D_real: 0.000 D_fake: 0.001 \n",
            "(epoch: 127, iters: 1000, time: 0.064, data: 0.004) G_GAN: 2.983 G_L1: 1.274 D_real: 0.114 D_fake: 0.416 \n",
            "saving the latest model (epoch 127, total_iters 505000)\n",
            "(epoch: 127, iters: 1100, time: 0.066, data: 0.002) G_GAN: 1.693 G_L1: 1.778 D_real: 0.158 D_fake: 0.465 \n",
            "(epoch: 127, iters: 1200, time: 0.164, data: 0.003) G_GAN: 10.958 G_L1: 1.767 D_real: 0.001 D_fake: 0.000 \n",
            "(epoch: 127, iters: 1300, time: 0.066, data: 0.003) G_GAN: 2.974 G_L1: 1.116 D_real: 0.116 D_fake: 0.253 \n",
            "(epoch: 127, iters: 1400, time: 0.067, data: 0.002) G_GAN: 4.937 G_L1: 1.739 D_real: 0.034 D_fake: 0.015 \n",
            "(epoch: 127, iters: 1500, time: 0.066, data: 0.002) G_GAN: 3.323 G_L1: 1.826 D_real: 0.084 D_fake: 0.086 \n",
            "(epoch: 127, iters: 1600, time: 0.176, data: 0.004) G_GAN: 3.500 G_L1: 1.701 D_real: 0.078 D_fake: 0.046 \n",
            "(epoch: 127, iters: 1700, time: 0.066, data: 0.003) G_GAN: 2.380 G_L1: 1.921 D_real: 0.145 D_fake: 0.245 \n",
            "(epoch: 127, iters: 1800, time: 0.067, data: 0.003) G_GAN: 12.015 G_L1: 1.151 D_real: 0.001 D_fake: 0.000 \n",
            "(epoch: 127, iters: 1900, time: 0.066, data: 0.003) G_GAN: 2.847 G_L1: 1.638 D_real: 0.129 D_fake: 0.128 \n",
            "(epoch: 127, iters: 2000, time: 0.666, data: 0.003) G_GAN: 2.434 G_L1: 2.038 D_real: 0.471 D_fake: 0.042 \n",
            "(epoch: 127, iters: 2100, time: 0.067, data: 0.003) G_GAN: 2.248 G_L1: 1.727 D_real: 0.451 D_fake: 0.728 \n",
            "(epoch: 127, iters: 2200, time: 0.065, data: 0.005) G_GAN: 2.384 G_L1: 2.129 D_real: 0.611 D_fake: 0.130 \n",
            "(epoch: 127, iters: 2300, time: 0.066, data: 0.003) G_GAN: 3.461 G_L1: 3.291 D_real: 0.007 D_fake: 0.178 \n",
            "(epoch: 127, iters: 2400, time: 0.219, data: 0.004) G_GAN: 6.290 G_L1: 3.176 D_real: 0.006 D_fake: 0.004 \n",
            "(epoch: 127, iters: 2500, time: 0.066, data: 0.003) G_GAN: 3.374 G_L1: 2.542 D_real: 0.017 D_fake: 0.464 \n",
            "(epoch: 127, iters: 2600, time: 0.066, data: 0.002) G_GAN: 1.754 G_L1: 1.655 D_real: 0.475 D_fake: 0.184 \n",
            "(epoch: 127, iters: 2700, time: 0.066, data: 0.002) G_GAN: 3.945 G_L1: 2.030 D_real: 0.018 D_fake: 0.037 \n",
            "(epoch: 127, iters: 2800, time: 0.227, data: 0.002) G_GAN: 4.325 G_L1: 2.139 D_real: 0.013 D_fake: 0.028 \n",
            "(epoch: 127, iters: 2900, time: 0.065, data: 0.002) G_GAN: 2.065 G_L1: 2.146 D_real: 0.225 D_fake: 0.519 \n",
            "(epoch: 127, iters: 3000, time: 0.066, data: 0.004) G_GAN: 1.465 G_L1: 1.770 D_real: 0.416 D_fake: 0.629 \n",
            "(epoch: 127, iters: 3100, time: 0.067, data: 0.002) G_GAN: 2.893 G_L1: 2.202 D_real: 0.073 D_fake: 0.690 \n",
            "(epoch: 127, iters: 3200, time: 0.174, data: 0.004) G_GAN: 10.116 G_L1: 1.557 D_real: 0.000 D_fake: 0.000 \n",
            "(epoch: 127, iters: 3300, time: 0.064, data: 0.003) G_GAN: 2.404 G_L1: 1.891 D_real: 0.069 D_fake: 0.392 \n",
            "(epoch: 127, iters: 3400, time: 0.066, data: 0.004) G_GAN: 9.951 G_L1: 0.688 D_real: 0.000 D_fake: 0.000 \n",
            "(epoch: 127, iters: 3500, time: 0.066, data: 0.003) G_GAN: 1.522 G_L1: 1.069 D_real: 0.082 D_fake: 1.065 \n",
            "(epoch: 127, iters: 3600, time: 0.183, data: 0.003) G_GAN: 4.020 G_L1: 1.745 D_real: 0.702 D_fake: 0.073 \n",
            "(epoch: 127, iters: 3700, time: 0.066, data: 0.002) G_GAN: 3.465 G_L1: 2.054 D_real: 0.401 D_fake: 0.053 \n",
            "(epoch: 127, iters: 3800, time: 0.067, data: 0.003) G_GAN: 3.990 G_L1: 0.749 D_real: 0.002 D_fake: 0.275 \n",
            "(epoch: 127, iters: 3900, time: 0.067, data: 0.004) G_GAN: 8.176 G_L1: 1.138 D_real: 0.000 D_fake: 0.001 \n",
            "(epoch: 127, iters: 4000, time: 0.596, data: 0.005) G_GAN: 2.268 G_L1: 2.678 D_real: 0.451 D_fake: 0.219 \n",
            "End of epoch 127 / 200 \t Time Taken: 176 sec\n",
            "learning rate 0.0001446 -> 0.0001426\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "(epoch: 128, iters: 100, time: 0.066, data: 0.177) G_GAN: 2.457 G_L1: 1.580 D_real: 0.090 D_fake: 0.346 \n",
            "(epoch: 128, iters: 200, time: 0.066, data: 0.004) G_GAN: 8.555 G_L1: 0.927 D_real: 0.000 D_fake: 0.000 \n",
            "(epoch: 128, iters: 300, time: 0.066, data: 0.003) G_GAN: 2.729 G_L1: 2.404 D_real: 0.216 D_fake: 0.196 \n",
            "(epoch: 128, iters: 400, time: 0.766, data: 0.003) G_GAN: 2.255 G_L1: 1.897 D_real: 0.303 D_fake: 0.307 \n",
            "(epoch: 128, iters: 500, time: 0.067, data: 0.005) G_GAN: 3.226 G_L1: 2.128 D_real: 0.030 D_fake: 0.163 \n",
            "(epoch: 128, iters: 600, time: 0.067, data: 0.003) G_GAN: 4.490 G_L1: 1.106 D_real: 0.439 D_fake: 0.026 \n",
            "(epoch: 128, iters: 700, time: 0.064, data: 0.008) G_GAN: 2.616 G_L1: 1.310 D_real: 0.222 D_fake: 0.147 \n",
            "(epoch: 128, iters: 800, time: 0.267, data: 0.003) G_GAN: 5.939 G_L1: 1.190 D_real: 0.031 D_fake: 0.006 \n",
            "(epoch: 128, iters: 900, time: 0.067, data: 0.003) G_GAN: 1.918 G_L1: 1.821 D_real: 0.465 D_fake: 0.116 \n",
            "(epoch: 128, iters: 1000, time: 0.067, data: 0.003) G_GAN: 1.682 G_L1: 1.455 D_real: 0.837 D_fake: 0.158 \n",
            "(epoch: 128, iters: 1100, time: 0.065, data: 0.004) G_GAN: 7.343 G_L1: 3.363 D_real: 0.067 D_fake: 0.001 \n",
            "(epoch: 128, iters: 1200, time: 0.223, data: 0.003) G_GAN: 3.851 G_L1: 2.512 D_real: 0.003 D_fake: 0.225 \n",
            "(epoch: 128, iters: 1300, time: 0.066, data: 0.003) G_GAN: 6.534 G_L1: 1.379 D_real: 0.064 D_fake: 0.001 \n",
            "(epoch: 128, iters: 1400, time: 0.066, data: 0.003) G_GAN: 2.241 G_L1: 2.865 D_real: 0.025 D_fake: 1.476 \n",
            "(epoch: 128, iters: 1500, time: 0.067, data: 0.003) G_GAN: 5.474 G_L1: 1.520 D_real: 0.098 D_fake: 0.009 \n",
            "(epoch: 128, iters: 1600, time: 0.177, data: 0.006) G_GAN: 1.818 G_L1: 2.666 D_real: 0.781 D_fake: 0.140 \n",
            "(epoch: 128, iters: 1700, time: 0.067, data: 0.003) G_GAN: 8.093 G_L1: 1.663 D_real: 0.481 D_fake: 0.000 \n",
            "(epoch: 128, iters: 1800, time: 0.067, data: 0.003) G_GAN: 8.119 G_L1: 1.297 D_real: 0.000 D_fake: 0.001 \n",
            "(epoch: 128, iters: 1900, time: 0.067, data: 0.003) G_GAN: 11.374 G_L1: 0.887 D_real: 0.000 D_fake: 0.000 \n",
            "(epoch: 128, iters: 2000, time: 0.604, data: 0.004) G_GAN: 6.164 G_L1: 1.644 D_real: 0.135 D_fake: 0.004 \n",
            "saving the latest model (epoch 128, total_iters 510000)\n",
            "(epoch: 128, iters: 2100, time: 0.054, data: 0.002) G_GAN: 5.282 G_L1: 0.983 D_real: 0.014 D_fake: 0.008 \n",
            "(epoch: 128, iters: 2200, time: 0.063, data: 0.005) G_GAN: 6.029 G_L1: 0.995 D_real: 0.000 D_fake: 0.008 \n",
            "(epoch: 128, iters: 2300, time: 0.067, data: 0.005) G_GAN: 3.367 G_L1: 2.833 D_real: 0.054 D_fake: 0.239 \n",
            "(epoch: 128, iters: 2400, time: 0.219, data: 0.003) G_GAN: 2.787 G_L1: 2.536 D_real: 0.135 D_fake: 0.281 \n",
            "(epoch: 128, iters: 2500, time: 0.066, data: 0.002) G_GAN: 5.209 G_L1: 1.146 D_real: 0.000 D_fake: 0.050 \n",
            "(epoch: 128, iters: 2600, time: 0.065, data: 0.005) G_GAN: 2.904 G_L1: 1.812 D_real: 0.222 D_fake: 0.055 \n",
            "(epoch: 128, iters: 2700, time: 0.065, data: 0.003) G_GAN: 3.698 G_L1: 1.244 D_real: 0.267 D_fake: 0.032 \n",
            "(epoch: 128, iters: 2800, time: 0.219, data: 0.003) G_GAN: 3.092 G_L1: 1.832 D_real: 0.056 D_fake: 0.100 \n",
            "(epoch: 128, iters: 2900, time: 0.066, data: 0.008) G_GAN: 9.083 G_L1: 1.736 D_real: 0.000 D_fake: 0.001 \n",
            "(epoch: 128, iters: 3000, time: 0.066, data: 0.007) G_GAN: 1.458 G_L1: 1.471 D_real: 0.708 D_fake: 0.427 \n",
            "(epoch: 128, iters: 3100, time: 0.065, data: 0.003) G_GAN: 3.487 G_L1: 1.478 D_real: 0.018 D_fake: 0.082 \n",
            "(epoch: 128, iters: 3200, time: 0.212, data: 0.004) G_GAN: 1.834 G_L1: 1.839 D_real: 0.475 D_fake: 0.230 \n",
            "(epoch: 128, iters: 3300, time: 0.066, data: 0.003) G_GAN: 5.249 G_L1: 2.464 D_real: 0.036 D_fake: 0.009 \n",
            "(epoch: 128, iters: 3400, time: 0.066, data: 0.004) G_GAN: 6.739 G_L1: 0.785 D_real: 0.000 D_fake: 0.005 \n",
            "(epoch: 128, iters: 3500, time: 0.062, data: 0.006) G_GAN: 2.962 G_L1: 1.849 D_real: 0.017 D_fake: 0.178 \n",
            "(epoch: 128, iters: 3600, time: 0.222, data: 0.005) G_GAN: 3.134 G_L1: 2.615 D_real: 0.013 D_fake: 0.248 \n",
            "(epoch: 128, iters: 3700, time: 0.064, data: 0.003) G_GAN: 3.471 G_L1: 2.907 D_real: 0.033 D_fake: 0.329 \n",
            "(epoch: 128, iters: 3800, time: 0.065, data: 0.003) G_GAN: 2.097 G_L1: 1.751 D_real: 0.076 D_fake: 0.457 \n",
            "(epoch: 128, iters: 3900, time: 0.067, data: 0.006) G_GAN: 1.972 G_L1: 1.433 D_real: 0.477 D_fake: 0.496 \n",
            "(epoch: 128, iters: 4000, time: 0.509, data: 0.003) G_GAN: 2.043 G_L1: 1.394 D_real: 0.912 D_fake: 0.163 \n",
            "End of epoch 128 / 200 \t Time Taken: 176 sec\n",
            "learning rate 0.0001426 -> 0.0001406\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "(epoch: 129, iters: 100, time: 0.066, data: 0.271) G_GAN: 1.654 G_L1: 1.690 D_real: 0.155 D_fake: 0.526 \n",
            "(epoch: 129, iters: 200, time: 0.066, data: 0.003) G_GAN: 11.831 G_L1: 1.353 D_real: 0.000 D_fake: 0.000 \n",
            "(epoch: 129, iters: 300, time: 0.067, data: 0.004) G_GAN: 7.953 G_L1: 0.985 D_real: 0.007 D_fake: 0.001 \n",
            "(epoch: 129, iters: 400, time: 0.715, data: 0.004) G_GAN: 3.406 G_L1: 1.603 D_real: 0.038 D_fake: 0.572 \n",
            "(epoch: 129, iters: 500, time: 0.066, data: 0.003) G_GAN: 3.192 G_L1: 1.979 D_real: 0.024 D_fake: 1.532 \n",
            "(epoch: 129, iters: 600, time: 0.066, data: 0.003) G_GAN: 2.224 G_L1: 1.437 D_real: 0.246 D_fake: 0.448 \n",
            "(epoch: 129, iters: 700, time: 0.066, data: 0.003) G_GAN: 7.232 G_L1: 1.746 D_real: 0.001 D_fake: 0.002 \n",
            "(epoch: 129, iters: 800, time: 0.182, data: 0.002) G_GAN: 0.832 G_L1: 1.065 D_real: 0.703 D_fake: 0.698 \n",
            "(epoch: 129, iters: 900, time: 0.066, data: 0.007) G_GAN: 1.962 G_L1: 1.285 D_real: 0.093 D_fake: 0.979 \n",
            "(epoch: 129, iters: 1000, time: 0.065, data: 0.004) G_GAN: 3.523 G_L1: 1.789 D_real: 0.057 D_fake: 0.064 \n",
            "(epoch: 129, iters: 1100, time: 0.066, data: 0.003) G_GAN: 3.659 G_L1: 2.250 D_real: 0.197 D_fake: 0.070 \n",
            "(epoch: 129, iters: 1200, time: 0.170, data: 0.004) G_GAN: 2.407 G_L1: 1.725 D_real: 0.490 D_fake: 0.547 \n",
            "(epoch: 129, iters: 1300, time: 0.067, data: 0.002) G_GAN: 3.073 G_L1: 1.561 D_real: 0.010 D_fake: 0.268 \n",
            "(epoch: 129, iters: 1400, time: 0.066, data: 0.003) G_GAN: 3.212 G_L1: 1.756 D_real: 2.608 D_fake: 0.016 \n",
            "(epoch: 129, iters: 1500, time: 0.067, data: 0.004) G_GAN: 3.342 G_L1: 1.566 D_real: 0.242 D_fake: 0.064 \n",
            "(epoch: 129, iters: 1600, time: 0.224, data: 0.003) G_GAN: 5.306 G_L1: 2.180 D_real: 0.094 D_fake: 0.006 \n",
            "(epoch: 129, iters: 1700, time: 0.067, data: 0.008) G_GAN: 1.595 G_L1: 1.768 D_real: 0.359 D_fake: 0.762 \n",
            "(epoch: 129, iters: 1800, time: 0.066, data: 0.002) G_GAN: 9.540 G_L1: 0.977 D_real: 0.001 D_fake: 0.000 \n",
            "(epoch: 129, iters: 1900, time: 0.066, data: 0.003) G_GAN: 1.655 G_L1: 3.448 D_real: 0.613 D_fake: 0.469 \n"
          ]
        }
      ],
      "source": [
        "!python train.py --dataroot ./datasets/phase4 --name phase4_pix2pix --model pix2pix --direction BtoA --use_wandb"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9UkcaFZiyASl"
      },
      "source": [
        "# Testing\n",
        "\n",
        "-   `python test.py --dataroot ./datasets/facades --direction BtoA --model pix2pix --name facades_pix2pix`\n",
        "\n",
        "Change the `--dataroot`, `--name`, and `--direction` to be consistent with your trained model's configuration and how you want to transform images.\n",
        "\n",
        "> from https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix:\n",
        "> Note that we specified --direction BtoA as Facades dataset's A to B direction is photos to labels.\n",
        "\n",
        "> If you would like to apply a pre-trained model to a collection of input images (rather than image pairs), please use --model test option. See ./scripts/test_single.sh for how to apply a model to Facade label maps (stored in the directory facades/testB).\n",
        "\n",
        "> See a list of currently available models at ./scripts/download_pix2pix_model.sh"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mey7o6j-0368"
      },
      "outputs": [],
      "source": [
        "!ls checkpoints/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uCsKkEq0yGh0"
      },
      "outputs": [],
      "source": [
        "!python test.py --dataroot ./datasets/facades --direction BtoA --model pix2pix --name facades_label2photo_pretrained --use_wandb"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OzSKIPUByfiN"
      },
      "source": [
        "# Visualize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Mgg8raPyizq"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "img = plt.imread('./results/facades_label2photo_pretrained/test_latest/images/100_fake_B.png')\n",
        "plt.imshow(img)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0G3oVH9DyqLQ"
      },
      "outputs": [],
      "source": [
        "img = plt.imread('./results/facades_label2photo_pretrained/test_latest/images/100_real_A.png')\n",
        "plt.imshow(img)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ErK5OC1j1LH4"
      },
      "outputs": [],
      "source": [
        "img = plt.imread('./results/facades_label2photo_pretrained/test_latest/images/100_real_B.png')\n",
        "plt.imshow(img)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "“pix2pix”的副本",
      "provenance": [],
      "include_colab_link": true
    },
    "environment": {
      "name": "tf2-gpu.2-3.m74",
      "type": "gcloud",
      "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-3:m74"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}